"""
è°ƒè¯•VA-VAEå½’ä¸€åŒ–æµç¨‹ï¼ŒéªŒè¯å„ä¸ªé˜¶æ®µçš„æ•°æ®èŒƒå›´
"""
import torch
import numpy as np
from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
from simplified_vavae import SimplifiedVAVAE

def test_vae_normalization():
    """æµ‹è¯•VA-VAEçš„å½’ä¸€åŒ–å’Œåå½’ä¸€åŒ–æµç¨‹"""
    
    print("="*60)
    print("VA-VAE å½’ä¸€åŒ–æµç¨‹æµ‹è¯•")
    print("="*60)
    
    # 1. åˆå§‹åŒ–VAE
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    vae_path = "/kaggle/input/stage3/vavae-stage3-epoch26-val_rec_loss0.0000.ckpt"
    vae = SimplifiedVAVAE(vae_path)
    vae.eval()
    vae.freeze()
    vae = vae.to(device)  # ç¡®ä¿VAEåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
    
    print(f"\nğŸ“Œ VAEç¼©æ”¾å› å­: {vae.scale_factor}")
    
    # 2. åˆ›å»ºæµ‹è¯•å›¾åƒ
    print("\n" + "="*40)
    print("æµ‹è¯•1: ä¸åŒè¾“å…¥èŒƒå›´çš„ç¼–ç ")
    print("="*40)
    
    # æµ‹è¯•ä¸åŒèŒƒå›´çš„è¾“å…¥
    test_ranges = [
        ("[0, 1]", torch.rand(1, 3, 256, 256).to(device)),
        ("[-1, 1]", (torch.rand(1, 3, 256, 256) * 2 - 1).to(device)),
        ("[0, 255]", (torch.rand(1, 3, 256, 256) * 255).to(device))
    ]
    
    for range_name, test_img in test_ranges:
        print(f"\nè¾“å…¥èŒƒå›´ {range_name}:")
        print(f"  Min: {test_img.min():.3f}, Max: {test_img.max():.3f}")
        
        # ç¼–ç 
        with torch.no_grad():
            latent = vae.encode(test_img)
        
        print(f"  ç¼–ç ålatent:")
        print(f"    å½¢çŠ¶: {latent.shape}")
        print(f"    Min: {latent.min():.3f}, Max: {latent.max():.3f}")
        print(f"    Mean: {latent.mean():.3f}, Std: {latent.std():.3f}")
    
    # 3. æµ‹è¯•è§£ç æµç¨‹
    print("\n" + "="*40)
    print("æµ‹è¯•2: è§£ç æµç¨‹")
    print("="*40)
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = torch.rand(1, 3, 256, 256).to(device)  # [0,1]èŒƒå›´
    
    print(f"åŸå§‹å›¾åƒ [0,1]:")
    print(f"  Min: {test_image.min():.3f}, Max: {test_image.max():.3f}")
    
    # ç¼–ç 
    with torch.no_grad():
        latent = vae.encode(test_image)
    
    print(f"\nç¼–ç ålatent:")
    print(f"  å½¢çŠ¶: {latent.shape}")
    print(f"  Min: {latent.min():.3f}, Max: {latent.max():.3f}")
    print(f"  Mean: {latent.mean():.3f}, Std: {latent.std():.3f}")
    
    # è§£ç 
    with torch.no_grad():
        reconstructed = vae.decode(latent)
    
    print(f"\nè§£ç åå›¾åƒ:")
    print(f"  å½¢çŠ¶: {reconstructed.shape}")
    print(f"  Min: {reconstructed.min():.3f}, Max: {reconstructed.max():.3f}")
    print(f"  Mean: {reconstructed.mean():.3f}, Std: {reconstructed.std():.3f}")
    
    # 4. æµ‹è¯•æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„latentè§£ç 
    print("\n" + "="*40)
    print("æµ‹è¯•3: æ¨¡æ‹Ÿæ‰©æ•£æ¨¡å‹è¾“å‡º")
    print("="*40)
    
    # æ¨¡æ‹Ÿæ‰©æ•£æ¨¡å‹çš„è¾“å‡ºï¼ˆä¸åŒå°ºåº¦çš„å™ªå£°ï¼‰
    noise_scales = [0.1, 0.5, 1.0, 2.0]
    
    for scale in noise_scales:
        noise_latent = torch.randn(1, 32, 16, 16).to(device) * scale
        print(f"\nå™ªå£°å°ºåº¦ {scale}:")
        print(f"  Latent Min: {noise_latent.min():.3f}, Max: {noise_latent.max():.3f}")
        print(f"  Latent Std: {noise_latent.std():.3f}")
        
        # è§£ç 
        with torch.no_grad():
            decoded = vae.decode(noise_latent)
        
        print(f"  è§£ç å Min: {decoded.min():.3f}, Max: {decoded.max():.3f}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é¢å¤–å¤„ç†
        if decoded.min() < 0 or decoded.max() > 1:
            print(f"  âš ï¸ è§£ç ç»“æœè¶…å‡º[0,1]èŒƒå›´!")
    
    # 5. æµ‹è¯•VAEå†…éƒ¨å¤„ç†
    print("\n" + "="*40)
    print("æµ‹è¯•4: VAEå†…éƒ¨å½’ä¸€åŒ–æ£€æŸ¥")
    print("="*40)
    
    # ç›´æ¥è°ƒç”¨VAEçš„encodeå’Œdecodeï¼ˆä¸é€šè¿‡wrapperï¼‰
    test_img_normalized = test_image * 2 - 1  # è½¬æ¢åˆ°[-1,1]
    
    print(f"è¾“å…¥VAE.encodeçš„å›¾åƒ[-1,1]:")
    print(f"  Min: {test_img_normalized.min():.3f}, Max: {test_img_normalized.max():.3f}")
    
    # ç›´æ¥ç¼–ç 
    with torch.no_grad():
        posterior = vae.vae.encode(test_img_normalized)
        z = posterior.sample()
    
    print(f"\nåŸå§‹latentï¼ˆæœªç¼©æ”¾ï¼‰:")
    print(f"  Min: {z.min():.3f}, Max: {z.max():.3f}")
    print(f"  Mean: {z.mean():.3f}, Std: {z.std():.3f}")
    
    # ç¼©æ”¾å
    z_scaled = z * vae.scale_factor
    print(f"\nç¼©æ”¾ålatentï¼ˆÃ—{vae.scale_factor}ï¼‰:")
    print(f"  Min: {z_scaled.min():.3f}, Max: {z_scaled.max():.3f}")
    print(f"  Mean: {z_scaled.mean():.3f}, Std: {z_scaled.std():.3f}")
    
    # è¿˜åŸç¼©æ”¾å¹¶è§£ç 
    z_unscaled = z_scaled / vae.scale_factor
    with torch.no_grad():
        x_decoded = vae.vae.decode(z_unscaled)
    
    print(f"\nåŸå§‹è§£ç è¾“å‡º:")
    print(f"  Min: {x_decoded.min():.3f}, Max: {x_decoded.max():.3f}")
    
    # è½¬æ¢åˆ°[0,1]
    x_01 = (x_decoded + 1.0) / 2.0
    x_01 = torch.clamp(x_01, 0, 1)
    
    print(f"\nè½¬æ¢åˆ°[0,1]å:")
    print(f"  Min: {x_01.min():.3f}, Max: {x_01.max():.3f}")
    
    print("\n" + "="*60)
    print("æ€»ç»“:")
    print("="*60)
    print("1. VA-VAEæœŸæœ›è¾“å…¥: [-1,1]èŒƒå›´çš„å›¾åƒ")
    print("2. ç¼–ç è¾“å‡º: latent * scale_factor")
    print("3. è§£ç è¾“å…¥: latent / scale_factor")
    print("4. è§£ç è¾“å‡º: [-1,1]èŒƒå›´ï¼Œéœ€è¦è½¬æ¢åˆ°[0,1]")
    print(f"5. å½“å‰scale_factor: {vae.scale_factor}")
    
    return vae

if __name__ == "__main__":
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è¿è¡Œæµ‹è¯•
    vae = test_vae_normalization()
    
    # 6. å®é™…å›¾åƒæµ‹è¯•
    print("\n" + "="*60)
    print("æµ‹è¯•5: çœŸå®å¾®å¤šæ™®å‹’å›¾åƒ")
    print("="*60)
    
    # å°è¯•åŠ è½½ä¸€å¼ çœŸå®å›¾åƒ
    # ä½¿ç”¨æ­£ç¡®çš„æ•°æ®é›†è·¯å¾„
    possible_paths = [
        "/kaggle/input/dataset/ID_1/ID1_case1_1_Doppler1.jpg",
        "/kaggle/input/dataset/ID_1/ID1_case1_1_Doppler10.jpg",
        "/kaggle/input/dataset/ID_1/ID1_case1_1_Doppler100.jpg"
    ]
    
    image_path = None
    for path in possible_paths:
        if Path(path).exists():
            image_path = path
            break
    
    if image_path:
        img = Image.open(image_path).convert('RGB')
        img_array = np.array(img).astype(np.float32) / 255.0  # [0,1]
        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0).to(device)  # ç›´æ¥ç§»åŠ¨åˆ°GPU
        
        print(f"çœŸå®å›¾åƒ:")
        print(f"  åŸå§‹èŒƒå›´: [0, 255]")
        print(f"  å½’ä¸€åŒ–å: [{img_tensor.min():.3f}, {img_tensor.max():.3f}]")
        
        # ç¼–ç -è§£ç 
        with torch.no_grad():
            latent = vae.encode(img_tensor)
            reconstructed = vae.decode(latent)
        
        print(f"\nç¼–ç latent:")
        print(f"  Min: {latent.min():.3f}, Max: {latent.max():.3f}")
        print(f"  Std: {latent.std():.3f}")
        
        print(f"\né‡å»ºå›¾åƒ:")
        print(f"  Min: {reconstructed.min():.3f}, Max: {reconstructed.max():.3f}")
        
        # ä¿å­˜å¯¹æ¯”å›¾
        fig, axes = plt.subplots(1, 2, figsize=(10, 5))
        
        axes[0].imshow(img_tensor[0].permute(1, 2, 0).cpu())
        axes[0].set_title(f"åŸå§‹ [{img_tensor.min():.2f}, {img_tensor.max():.2f}]")
        axes[0].axis('off')
        
        axes[1].imshow(reconstructed[0].permute(1, 2, 0).cpu().clamp(0, 1))
        axes[1].set_title(f"é‡å»º [{reconstructed.min():.2f}, {reconstructed.max():.2f}]")
        axes[1].axis('off')
        
        plt.tight_layout()
        plt.savefig('/kaggle/working/vae_normalization_test.png', dpi=100, bbox_inches='tight')
        print("\nâœ… å¯¹æ¯”å›¾å·²ä¿å­˜åˆ° /kaggle/working/vae_normalization_test.png")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°çœŸå®å›¾åƒæ–‡ä»¶ï¼Œè·³è¿‡æ­¤æµ‹è¯•")
        print("   å°è¯•è¿‡çš„è·¯å¾„:")
        for path in possible_paths:
            print(f"   - {path}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•å®Œæˆï¼")
