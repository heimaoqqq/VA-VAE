# VA-VAE å¾®å¤šæ™®å‹’ä¿¡å·ç”Ÿæˆé¡¹ç›®

åŸºäºLightningDiTçš„å¾®å¤šæ™®å‹’ä¿¡å·å›¾åƒç”Ÿæˆé¡¹ç›®ï¼Œä½¿ç”¨VA-VAEè¿›è¡Œç‰¹å¾æå–å’ŒDiTè¿›è¡Œæ¡ä»¶åŒ–ç”Ÿæˆã€‚

## â­ æ¨èæ–¹æ³•ï¼šä¸¥æ ¼æŒ‰ç…§å®˜æ–¹æ–¹æ³•

**æˆ‘ä»¬å®Œå…¨æŒ‰ç…§LightningDiTå®˜æ–¹READMEå’Œæ•™ç¨‹å®ç°ï¼Œç¡®ä¿æœ€ä½³æ•ˆæœï¼š**

### ğŸ¯ å®˜æ–¹æ–¹æ³•å¯¹ç…§è¡¨

| æ­¥éª¤ | å®˜æ–¹è¦æ±‚ | æˆ‘ä»¬çš„å®ç° | çŠ¶æ€ |
|------|----------|------------|------|
| æ¨¡å‹ä¸‹è½½ | æ‰‹åŠ¨ä¸‹è½½3ä¸ªæ–‡ä»¶ | `setup_official_models.py` | âœ… è‡ªåŠ¨åŒ– |
| é…ç½®ä¿®æ”¹ | ä¿®æ”¹reproductionsé…ç½® | è‡ªåŠ¨ç”Ÿæˆæ ‡å‡†é…ç½® | âœ… æ ‡å‡†åŒ– |
| VA-VAEé…ç½® | ä¿®æ”¹tokenizeré…ç½®è·¯å¾„ | è‡ªåŠ¨æ›´æ–°è·¯å¾„ | âœ… è‡ªåŠ¨åŒ– |
| æ¨ç†å‘½ä»¤ | `bash run_fast_inference.sh` | å°è£…åœ¨Pythonè„šæœ¬ä¸­ | âœ… ç®€åŒ– |

### 1. ä¸‹è½½å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹
```bash
python setup_official_models.py
```
**ä¸‹è½½å†…å®¹**ï¼š
- âœ… VA-VAE: `vavae-imagenet256-f16d32-dinov2.pt` (å®˜æ–¹tokenizer)
- âœ… LightningDiT-XL: `lightningdit-xl-imagenet256-800ep.pt` (FID=1.35æ€§èƒ½)
- âœ… æ½œåœ¨ç»Ÿè®¡: `latents_stats.pt` (æ•°æ®å½’ä¸€åŒ–)

### 2. éªŒè¯è®¾ç½®æ­£ç¡®æ€§
```bash
python verify_official_setup.py
```
**æ£€æŸ¥é¡¹ç›®**ï¼š
- ğŸ“ æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
- âš™ï¸ é…ç½®å‚æ•°æ­£ç¡®æ€§
- ğŸ”§ VA-VAEè·¯å¾„è®¾ç½®
- ğŸ“‹ ä¸å®˜æ–¹é…ç½®å¯¹æ¯”

### 3. æµ‹è¯•æ¨¡å‹åŠ è½½
```bash
python test_official_models.py
```

### 4. è¿è¡Œå®˜æ–¹æ¨ç†
```bash
python run_official_inference.py
```
**æŠ€æœ¯ç»†èŠ‚**ï¼š
- ğŸ¯ ä½¿ç”¨å®˜æ–¹ `bash run_fast_inference.sh`
- ğŸ¨ Demoæ¨¡å¼: cfg_scale=9.0 (è‡ªåŠ¨è¦†ç›–é…ç½®)
- ğŸ“Š 250é‡‡æ ·æ­¥æ•°ï¼ŒEuleræ–¹æ³•
- ğŸ–¼ï¸ è¾“å‡º: `LightningDiT/demo_images/demo_samples.png`

---

## ğŸ¯ é¡¹ç›®ç‰¹ç‚¹

- **ä¸‰é˜¶æ®µæµæ°´çº¿**: ç‰¹å¾æå– â†’ DiTè®­ç»ƒ â†’ å›¾åƒç”Ÿæˆ
- **ç¯å¢ƒæ£€æŸ¥**: å†…ç½®ç¯å¢ƒå’Œä¾èµ–æ£€æŸ¥åŠŸèƒ½
- **é”™è¯¯ä¿®å¤**: è§£å†³äº†å¯¼å…¥ã€é¢œè‰²ã€ç»´åº¦ç­‰å…³é”®é—®é¢˜
- **å³ç”¨æ€§å¼º**: æ”¯æŒKaggleå’Œæœ¬åœ°ç¯å¢ƒ

## ğŸ“ é¡¹ç›®ç»“æ„

```
VA-VAE/
â”œâ”€â”€ æ ¸å¿ƒæµæ°´çº¿ (3ä¸ªé˜¶æ®µ)
â”‚   â”œâ”€â”€ stage1_extract_features.py    # é˜¶æ®µ1: VA-VAEç‰¹å¾æå– (å«ç¯å¢ƒæ£€æŸ¥)
â”‚   â”œâ”€â”€ stage2_train_dit.py          # é˜¶æ®µ2: DiTæ¨¡å‹è®­ç»ƒ (å«ç¯å¢ƒæ£€æŸ¥)
â”‚   â””â”€â”€ stage3_inference.py          # é˜¶æ®µ3: å›¾åƒç”Ÿæˆæ¨ç† (å«å¯¼å…¥æµ‹è¯•)
â”‚
â”œâ”€â”€ è¾…åŠ©å·¥å…·
â”‚   â”œâ”€â”€ data_split.py               # æ•°æ®é›†åˆ’åˆ†å·¥å…·
â”‚   â””â”€â”€ download_vavae_model.py     # VA-VAEæ¨¡å‹ä¸‹è½½
â”‚
â”œâ”€â”€ é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ vavae_config.yaml          # VA-VAEé…ç½®
â”‚   â”œâ”€â”€ accelerate_config.yaml     # Accelerateåˆ†å¸ƒå¼é…ç½®
â”‚   â””â”€â”€ requirements.txt           # ä¾èµ–åŒ…åˆ—è¡¨
â”‚
â”œâ”€â”€ åŸå§‹é¡¹ç›®
â”‚   â””â”€â”€ LightningDiT/              # å®Œæ•´çš„LightningDiTé¡¹ç›®
â”‚
â””â”€â”€ æ•°æ®ç›®å½•
    â””â”€â”€ data/                      # æ•°æ®å­˜å‚¨ç›®å½•
        â”œâ”€â”€ raw/                   # åŸå§‹æ•°æ®
        â”œâ”€â”€ processed/             # å¤„ç†åæ•°æ®
        â””â”€â”€ generated/             # ç”Ÿæˆæ•°æ®
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒæ£€æŸ¥
```bash
# 1. æµ‹è¯•å¯¼å…¥æ˜¯å¦æ­£å¸¸
python stage3_inference.py --test_imports

# 2. æ£€æŸ¥ç‰¹å¾æå–ç¯å¢ƒ
python stage1_extract_features.py --help

# 3. æ£€æŸ¥è®­ç»ƒç¯å¢ƒ
python stage2_train_dit.py --help
```

### ç¯å¢ƒè¦æ±‚
- Python 3.10+
- PyTorch 2.0+
- CUDA 11.8+ (GPUæ¨ç†)
- Accelerate (åˆ†å¸ƒå¼è®­ç»ƒ)
- Safetensors (æ¨¡å‹ä¿å­˜)

### å®‰è£…ä¾èµ–
```bash
git clone git@github.com:heimaoqqq/VA-VAE.git
cd VA-VAE
pip install -r requirements.txt
```

## ğŸ¯ å®Œæ•´æµæ°´çº¿ (æ¨èä½¿ç”¨)

### ä¸€é”®è¿è¡Œ
```bash
# è¿è¡Œå®Œæ•´æµæ°´çº¿ (ç‰¹å¾æå– + è®­ç»ƒ + ç”Ÿæˆ)
python complete_pipeline.py

# è‡ªå®šä¹‰è®­ç»ƒè½®æ•°å’Œè¾“å‡ºç›®å½•
python complete_pipeline.py --max_epochs 100 --output_dir ./my_samples

# åªç”Ÿæˆæ ·æœ¬ (è·³è¿‡è®­ç»ƒï¼Œä½¿ç”¨ç°æœ‰æ¨¡å‹)
python complete_pipeline.py --skip_extract --skip_train

# å¼ºåˆ¶é‡æ–°è®­ç»ƒæ¨¡å‹
python complete_pipeline.py --force_retrain --max_epochs 100
```

### æµæ°´çº¿å‚æ•°è¯´æ˜
- `--max_epochs`: è®­ç»ƒè½®æ•° (é»˜è®¤50)
- `--checkpoint_dir`: æ¨¡å‹ä¿å­˜ç›®å½• (é»˜è®¤./checkpoints)
- `--output_dir`: ç”Ÿæˆæ ·æœ¬è¾“å‡ºç›®å½• (é»˜è®¤./generated_samples)
- `--skip_extract`: è·³è¿‡ç‰¹å¾æå–
- `--skip_train`: è·³è¿‡æ¨¡å‹è®­ç»ƒ
- `--skip_generate`: è·³è¿‡æ ·æœ¬ç”Ÿæˆ
- `--force_retrain`: å¼ºåˆ¶é‡æ–°è®­ç»ƒæ¨¡å‹

## ğŸ“‹ åˆ†æ­¥æ‰§è¡Œ (é«˜çº§ç”¨æˆ·)

### é˜¶æ®µ1: ç‰¹å¾æå–
```bash
python stage1_extract_features.py
```

### é˜¶æ®µ2: æ¨¡å‹è®­ç»ƒ
```bash
python stage2_train_dit.py \
    --latent_dir ./data/processed \
    --output_dir ./checkpoints \
    --max_epochs 50 \
    --batch_size 16
```

### é˜¶æ®µ3: æ ·æœ¬ç”Ÿæˆ
```bash
python stage3_inference.py \
    --dit_checkpoint ./checkpoints/best_model \
    --vavae_config vavae_config.yaml \
    --output_dir ./generated_samples \
    --user_ids 1 2 3 4 5 \
    --num_samples_per_user 4
```

## âš ï¸ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜1: ç”Ÿæˆçš„å›¾åƒè´¨é‡å¾ˆå·® (åƒå™ªå£°)
**åŸå› **: æ¨¡å‹æ²¡æœ‰æ­£ç¡®åŠ è½½è®­ç»ƒå¥½çš„æƒé‡ï¼Œä½¿ç”¨çš„æ˜¯éšæœºåˆå§‹åŒ–çš„æ¨¡å‹

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®ä¿è®­ç»ƒå®Œæˆå¹¶ä¿å­˜äº†æ£€æŸ¥ç‚¹:
   ```bash
   # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
   ls -la checkpoints/best_model/
   ```

2. å¦‚æœæ²¡æœ‰æ£€æŸ¥ç‚¹ï¼Œé‡æ–°è®­ç»ƒ:
   ```bash
   python complete_pipeline.py --force_retrain --max_epochs 100
   ```

3. å¦‚æœæœ‰æ£€æŸ¥ç‚¹ä½†ä»ç„¶è´¨é‡å·®ï¼Œå¢åŠ è®­ç»ƒè½®æ•°:
   ```bash
   python complete_pipeline.py --force_retrain --max_epochs 200
   ```

### é—®é¢˜2: è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯
**å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ**:
- `CUDA out of memory`: å‡å°‘batch_size
- `æ¨¡å—å¯¼å…¥é”™è¯¯`: æ£€æŸ¥ä¾èµ–å®‰è£…
- `æ•°æ®åŠ è½½é”™è¯¯`: æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„

### é—®é¢˜3: ç‰¹å¾æå–å¤±è´¥
**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥VA-VAEæ¨¡å‹æ˜¯å¦æ­£ç¡®ä¸‹è½½:
   ```bash
   python verify_vavae_setup.py
   ```

2. é‡æ–°ä¸‹è½½VA-VAEæ¨¡å‹:
   ```bash
   python download_vavae_model.py
   ```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### è®­ç»ƒä¼˜åŒ–
- ä½¿ç”¨æ›´å¤§çš„batch_size (å¦‚æœGPUå†…å­˜å…è®¸)
- å¢åŠ è®­ç»ƒè½®æ•°åˆ°100-200è½®
- ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨

### ç”Ÿæˆä¼˜åŒ–
- è°ƒæ•´guidance_scale (2.0-8.0)
- å¢åŠ é‡‡æ ·æ­¥æ•° (250-1000)
- å°è¯•ä¸åŒçš„ç”¨æˆ·ID

## ğŸ”§ åŸå§‹Kaggleæ–¹æ³• (å·²å¼ƒç”¨)

### Step 1: æ•°æ®é›†åˆ’åˆ†
```bash
# é’ˆå¯¹Kaggleæ•°æ®é›†ç»“æ„ (ID_1, ID_2...ID_31)
python data_split.py \
    --input_dir /kaggle/input/dataset \
    --output_dir data_split \
    --train_ratio 0.8 \
    --val_ratio 0.2 \
    --image_extensions png,jpg,jpeg

# åˆ’åˆ†åçš„ç»“æ„ï¼š
# data_split/
# â”œâ”€â”€ train/
# â”‚   â”œâ”€â”€ user_01_sample_001.png
# â”‚   â””â”€â”€ ...
# â”œâ”€â”€ val/
# â”‚   â”œâ”€â”€ user_01_sample_010.png
# â”‚   â””â”€â”€ ...
# â””â”€â”€ split_info.txt
```

### Step 2: æ¨¡å‹è®­ç»ƒ

#### å•GPUè®­ç»ƒ
```bash
python minimal_training_modification.py \
    --data_dir data_split \
    --original_vavae path/to/vavae.pth \
    --batch_size 16 \
    --max_epochs 100 \
    --devices 1
```

#### å¤šGPUè®­ç»ƒ (æ¨è)
```bash
# åŒGPUè®­ç»ƒ
python minimal_training_modification.py \
    --data_dir data_split \
    --original_vavae path/to/vavae.pth \
    --batch_size 16 \
    --max_epochs 100 \
    --devices 2 \
    --strategy ddp

# å››GPUè®­ç»ƒ
python minimal_training_modification.py \
    --data_dir data_split \
    --original_vavae path/to/vavae.pth \
    --batch_size 16 \
    --max_epochs 100 \
    --devices 4 \
    --strategy ddp_find_unused_parameters_true \
    --precision 16  # æ··åˆç²¾åº¦è®­ç»ƒ
```

#### Kaggleç¯å¢ƒè®­ç»ƒ
```bash
python minimal_training_modification.py \
    --data_dir /kaggle/working/data_split \
    --original_vavae /kaggle/input/pretrained/vavae.pth \
    --batch_size 12 \
    --max_epochs 50 \
    --devices 1 \
    --precision 16 \
    --output_dir /kaggle/working/outputs
```

## ğŸ”§ è¯¦ç»†é…ç½®è¯´æ˜

### è®­ç»ƒå‚æ•°
- `--data_dir`: æ•°æ®ç›®å½•è·¯å¾„
- `--original_vavae`: åŸå§‹VA-VAEæ¨¡å‹è·¯å¾„
- `--batch_size`: æ¯ä¸ªGPUçš„æ‰¹æ¬¡å¤§å° (é»˜è®¤16)
- `--max_epochs`: æœ€å¤§è®­ç»ƒè½®æ•° (é»˜è®¤100)
- `--lr`: å­¦ä¹ ç‡ (é»˜è®¤1e-4)
- `--condition_dim`: ç”¨æˆ·æ¡ä»¶å‘é‡ç»´åº¦ (é»˜è®¤128)
- `--kl_weight`: KLæ•£åº¦æŸå¤±æƒé‡ (é»˜è®¤1e-6)

### PyTorch Lightningå‚æ•°
- `--devices`: GPUæ•°é‡ (1, 2, 4, 8ç­‰)
- `--strategy`: è®­ç»ƒç­–ç•¥ (auto, ddp, ddp_find_unused_parameters_true)
- `--accelerator`: åŠ é€Ÿå™¨ç±»å‹ (gpu, cpu)
- `--precision`: ç²¾åº¦ (16, 32, bf16)

### æ•°æ®åˆ’åˆ†å‚æ•°
- `--train_ratio`: è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤0.8)
- `--val_ratio`: éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤0.2)
- `--image_extensions`: å›¾åƒæ–‡ä»¶æ‰©å±•å (é»˜è®¤png,jpg,jpeg)

## ğŸ“Š æŠ€æœ¯æ¶æ„

### åŸé¡¹ç›®å¤šGPUæ”¯æŒ
æœ¬é¡¹ç›®ä½¿ç”¨ä¸åŸVA-VAEé¡¹ç›®ç›¸åŒçš„å¤šGPUå®ç°æ–¹å¼ï¼š
- **PyTorch Lightning**: è‡ªåŠ¨å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒ
- **DDPç­–ç•¥**: DistributedDataParallelè¿›è¡Œæ•°æ®å¹¶è¡Œ
- **è‡ªåŠ¨åŒæ­¥**: æŸå¤±å€¼å’Œæ¢¯åº¦è‡ªåŠ¨åœ¨GPUé—´åŒæ­¥

### ç”¨æˆ·æ¡ä»¶åŒ–æ‰©å±•
- **ç”¨æˆ·åµŒå…¥**: å°†ç”¨æˆ·IDæ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ç©ºé—´
- **æ¡ä»¶æ³¨å…¥**: é€šè¿‡ç‰¹å¾ç›¸åŠ çš„æ–¹å¼æ³¨å…¥ç”¨æˆ·ä¿¡æ¯
- **æœ€å°ä¿®æ”¹**: åœ¨åŸVA-VAEåŸºç¡€ä¸Šä»…æ·»åŠ å¿…è¦çš„æ¡ä»¶åŠŸèƒ½

### æ•°æ®å¤„ç†
- **è‡ªåŠ¨è¯†åˆ«**: æ”¯æŒKaggleçš„ID_1...ID_31ç›®å½•ç»“æ„
- **æ ¼å¼æ”¯æŒ**: PNG, JPG, JPEGç­‰å›¾åƒæ ¼å¼
- **å°ºå¯¸æ ‡å‡†åŒ–**: è‡ªåŠ¨è°ƒæ•´åˆ°256Ã—256åˆ†è¾¨ç‡
- **RGBè½¬æ¢**: è‡ªåŠ¨è½¬æ¢ä¸º3é€šé“RGBæ ¼å¼

## ğŸ“ˆ æ€§èƒ½é¢„æœŸ

### å•GPU vs å¤šGPU
| é…ç½® | æ‰¹æ¬¡å¤§å° | è®­ç»ƒé€Ÿåº¦ | å†…å­˜ä½¿ç”¨ | æ€»ååé‡ |
|------|----------|----------|----------|----------|
| 1Ã—RTX 3080 | 16 | 3ç§’/æ‰¹æ¬¡ | 12GB | 5.3 æ ·æœ¬/ç§’ |
| 2Ã—RTX 3080 | 16Ã—2 | 3ç§’/æ‰¹æ¬¡ | 6GBÃ—2 | 10.6 æ ·æœ¬/ç§’ |

### Kaggleç¯å¢ƒ
- **GPU**: é€šå¸¸æä¾›å•ä¸ªGPU (P100/T4)
- **æ‰¹æ¬¡å¤§å°**: æ¨è12-16
- **è®­ç»ƒæ—¶é—´**: çº¦2-4å°æ—¶ (50 epochs)
- **å†…å­˜ä½¿ç”¨**: 8-12GB

## ğŸ” ç›‘æ§å’Œæ—¥å¿—

### TensorBoardå¯è§†åŒ–
```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir outputs/lightning_logs

# åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹è®­ç»ƒè¿›åº¦
# http://localhost:6006
```

### æ£€æŸ¥ç‚¹ç®¡ç†
- **æœ€ä½³æ¨¡å‹**: `outputs/checkpoints/best-*.ckpt`
- **æœ€åæ¨¡å‹**: `outputs/checkpoints/last.ckpt`
- **è®­ç»ƒæ—¥å¿—**: `outputs/lightning_logs/`

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: CUDAå†…å­˜ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°æ‰¹æ¬¡å¤§å°æˆ–ä½¿ç”¨æ··åˆç²¾åº¦
python minimal_training_modification.py --batch_size 8 --precision 16
```

### Q2: æ•°æ®åŠ è½½é”™è¯¯
```bash
# æ£€æŸ¥æ•°æ®æ–‡ä»¶æ ¼å¼å’Œå‘½å
ls your_data_dir/*.png | head -5

# ç¡®ä¿ç›®å½•ç»“æ„ä¸º ID_1/, ID_2/, ..., ID_31/
```

### Q3: å¤šGPUè®­ç»ƒå¤±è´¥
```bash
# æ£€æŸ¥GPUæ•°é‡
nvidia-smi

# ä½¿ç”¨æ¨èçš„ç­–ç•¥
python minimal_training_modification.py --devices 2 --strategy ddp_find_unused_parameters_true
```

## ğŸ¯ ä¸åŸé¡¹ç›®çš„å¯¹æ¯”

| é¡¹ç›® | æ–‡ä»¶æ•°é‡ | ä»£ç è¡Œæ•° | å¤šGPUæ–¹æ¡ˆ | å¤æ‚åº¦ |
|------|----------|----------|-----------|--------|
| åŸå§‹LightningDiT | 50+ | 10000+ | HuggingFace Accelerator | é«˜ |
| åŸå§‹VA-VAE | 30+ | 8000+ | PyTorch Lightning | ä¸­ |
| **æˆ‘ä»¬çš„ç‰ˆæœ¬** | **4** | **<600** | **PyTorch Lightning** | **ä½** |

## ğŸ“ å¼€å‘å†ç¨‹

- [x] é¡¹ç›®åˆå§‹åŒ–å’Œç¯å¢ƒæ­å»º
- [x] å¾®å¤šæ™®å‹’æ•°æ®é¢„å¤„ç†æ¨¡å—
- [x] æ¡ä»¶VA-VAEæ¨¡å‹è®¾è®¡
- [x] è®­ç»ƒç­–ç•¥ä¼˜åŒ–
- [x] æ¨¡å‹è®­ç»ƒå’ŒéªŒè¯
- [x] ç”Ÿæˆæ¥å£å¼€å‘
- [x] PyTorch Lightningé›†æˆ
- [x] å¤šGPUæ”¯æŒå®Œå–„
- [x] Kaggleç¯å¢ƒé€‚é…

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºåŸå§‹LightningDiTé¡¹ç›®ï¼Œéµå¾ªç›¸åº”çš„å¼€æºè®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- æ„Ÿè°¢LightningDiTé¡¹ç›®æä¾›çš„VA-VAEåŸºç¡€æ¶æ„
- æ„Ÿè°¢PyTorch Lightningå›¢é˜Ÿæä¾›çš„ä¼˜ç§€æ¡†æ¶
- æ„Ÿè°¢å¼€æºç¤¾åŒºçš„è´¡çŒ®å’Œæ”¯æŒ

---

**é¡¹ç›®åœ°å€**: https://github.com/heimaoqqq/VA-VAE  
**é—®é¢˜åé¦ˆ**: è¯·åœ¨GitHub Issuesä¸­æå‡ºé—®é¢˜å’Œå»ºè®®
