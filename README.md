# å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•°æ®å¢å¹¿é¡¹ç›® - æœ€å°æ”¹åŠ¨ç‰ˆæœ¬

åŸºäºVA-VAE (Vision foundation model Aligned Variational AutoEncoder) çš„å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•°æ®å¢å¹¿é¡¹ç›®ã€‚æœ¬é¡¹ç›®åœ¨åŸå§‹LightningDiTé¡¹ç›®åŸºç¡€ä¸Šè¿›è¡Œ**æœ€å°åŒ–ä¿®æ”¹**ï¼Œå®ç°ç”¨æˆ·æ¡ä»¶åŒ–çš„æ—¶é¢‘å›¾ç”Ÿæˆï¼Œä¸“é—¨é€‚é…31ä¸ªç”¨æˆ·çš„æ­¥æ€å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•°æ®ã€‚

## ğŸ¯ é¡¹ç›®ç‰¹ç‚¹

- **æœ€å°æ”¹åŠ¨**: ä»…4ä¸ªæ ¸å¿ƒæ–‡ä»¶ï¼ŒåŸºäºåŸé¡¹ç›®æ¶æ„
- **å®Œå…¨å…¼å®¹**: ä½¿ç”¨PyTorch Lightningï¼Œä¸åŸé¡¹ç›®å¤šGPUæ–¹å¼ä¸€è‡´  
- **å³ç”¨æ€§å¼º**: æ”¯æŒKaggleæ•°æ®é›†ç»“æ„ (ID_1, ID_2...ID_31)
- **å®éªŒå¯é **: æœ€å°‘ä¿®æ”¹ç¡®ä¿ç»“æœå¯ä¿¡å’Œå¯å¯¹æ¯”

## ğŸ“ é¡¹ç›®ç»“æ„

```
VA-VAE/
â”œâ”€â”€ æ ¸å¿ƒä»£ç æ–‡ä»¶ (ä»…4ä¸ª)
â”‚   â”œâ”€â”€ minimal_micro_doppler_dataset.py    # æ•°æ®åŠ è½½å™¨
â”‚   â”œâ”€â”€ minimal_vavae_modification.py       # ç”¨æˆ·æ¡ä»¶åŒ–VA-VAEæ¨¡å‹
â”‚   â”œâ”€â”€ minimal_training_modification.py    # PyTorch Lightningè®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ data_split.py                       # æ•°æ®é›†åˆ’åˆ†å·¥å…·
â”‚
â”œâ”€â”€ é…ç½®å’Œæ–‡æ¡£
â”‚   â”œâ”€â”€ README.md                           # é¡¹ç›®è¯´æ˜ (æœ¬æ–‡ä»¶)
â”‚   â”œâ”€â”€ requirements.txt                    # ä¾èµ–åŒ…åˆ—è¡¨
â”‚   â””â”€â”€ .gitignore                         # Gitå¿½ç•¥æ–‡ä»¶
â”‚
â”œâ”€â”€ åŸå§‹é¡¹ç›® (æœªä¿®æ”¹)
â”‚   â””â”€â”€ LightningDiT/                      # å®Œæ•´çš„åŸå§‹VA-VAEé¡¹ç›®
â”‚
â””â”€â”€ æ•°æ®ç›®å½•
    â””â”€â”€ data/                              # æ•°æ®å­˜å‚¨ç›®å½•
        â”œâ”€â”€ raw/                           # åŸå§‹æ•°æ®
        â”œâ”€â”€ processed/                     # å¤„ç†åæ•°æ®
        â””â”€â”€ generated/                     # ç”Ÿæˆæ•°æ®
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚
- Python 3.10+
- PyTorch 2.0+
- PyTorch Lightning 2.0+
- CUDA 11.8+ (å¯é€‰ï¼Œç”¨äºGPUåŠ é€Ÿ)

### å®‰è£…ä¾èµ–
```bash
git clone git@github.com:heimaoqqq/VA-VAE.git
cd VA-VAE
pip install -r requirements.txt
```

## ğŸ¯ å®Œæ•´æµæ°´çº¿ (æ¨èä½¿ç”¨)

### ä¸€é”®è¿è¡Œ
```bash
# è¿è¡Œå®Œæ•´æµæ°´çº¿ (ç‰¹å¾æå– + è®­ç»ƒ + ç”Ÿæˆ)
python complete_pipeline.py

# è‡ªå®šä¹‰è®­ç»ƒè½®æ•°å’Œè¾“å‡ºç›®å½•
python complete_pipeline.py --max_epochs 100 --output_dir ./my_samples

# åªç”Ÿæˆæ ·æœ¬ (è·³è¿‡è®­ç»ƒï¼Œä½¿ç”¨ç°æœ‰æ¨¡å‹)
python complete_pipeline.py --skip_extract --skip_train

# å¼ºåˆ¶é‡æ–°è®­ç»ƒæ¨¡å‹
python complete_pipeline.py --force_retrain --max_epochs 100
```

### æµæ°´çº¿å‚æ•°è¯´æ˜
- `--max_epochs`: è®­ç»ƒè½®æ•° (é»˜è®¤50)
- `--checkpoint_dir`: æ¨¡å‹ä¿å­˜ç›®å½• (é»˜è®¤./checkpoints)
- `--output_dir`: ç”Ÿæˆæ ·æœ¬è¾“å‡ºç›®å½• (é»˜è®¤./generated_samples)
- `--skip_extract`: è·³è¿‡ç‰¹å¾æå–
- `--skip_train`: è·³è¿‡æ¨¡å‹è®­ç»ƒ
- `--skip_generate`: è·³è¿‡æ ·æœ¬ç”Ÿæˆ
- `--force_retrain`: å¼ºåˆ¶é‡æ–°è®­ç»ƒæ¨¡å‹

## ğŸ“‹ åˆ†æ­¥æ‰§è¡Œ (é«˜çº§ç”¨æˆ·)

### é˜¶æ®µ1: ç‰¹å¾æå–
```bash
python stage1_extract_features.py
```

### é˜¶æ®µ2: æ¨¡å‹è®­ç»ƒ
```bash
python stage2_train_dit.py \
    --latent_dir ./data/processed \
    --output_dir ./checkpoints \
    --max_epochs 50 \
    --batch_size 16
```

### é˜¶æ®µ3: æ ·æœ¬ç”Ÿæˆ
```bash
python stage3_inference.py \
    --dit_checkpoint ./checkpoints/best_model \
    --vavae_config vavae_config.yaml \
    --output_dir ./generated_samples \
    --user_ids 1 2 3 4 5 \
    --num_samples_per_user 4
```

## âš ï¸ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜1: ç”Ÿæˆçš„å›¾åƒè´¨é‡å¾ˆå·® (åƒå™ªå£°)
**åŸå› **: æ¨¡å‹æ²¡æœ‰æ­£ç¡®åŠ è½½è®­ç»ƒå¥½çš„æƒé‡ï¼Œä½¿ç”¨çš„æ˜¯éšæœºåˆå§‹åŒ–çš„æ¨¡å‹

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®ä¿è®­ç»ƒå®Œæˆå¹¶ä¿å­˜äº†æ£€æŸ¥ç‚¹:
   ```bash
   # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
   ls -la checkpoints/best_model/
   ```

2. å¦‚æœæ²¡æœ‰æ£€æŸ¥ç‚¹ï¼Œé‡æ–°è®­ç»ƒ:
   ```bash
   python complete_pipeline.py --force_retrain --max_epochs 100
   ```

3. å¦‚æœæœ‰æ£€æŸ¥ç‚¹ä½†ä»ç„¶è´¨é‡å·®ï¼Œå¢åŠ è®­ç»ƒè½®æ•°:
   ```bash
   python complete_pipeline.py --force_retrain --max_epochs 200
   ```

### é—®é¢˜2: è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯
**å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ**:
- `CUDA out of memory`: å‡å°‘batch_size
- `æ¨¡å—å¯¼å…¥é”™è¯¯`: æ£€æŸ¥ä¾èµ–å®‰è£…
- `æ•°æ®åŠ è½½é”™è¯¯`: æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„

### é—®é¢˜3: ç‰¹å¾æå–å¤±è´¥
**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥VA-VAEæ¨¡å‹æ˜¯å¦æ­£ç¡®ä¸‹è½½:
   ```bash
   python verify_vavae_setup.py
   ```

2. é‡æ–°ä¸‹è½½VA-VAEæ¨¡å‹:
   ```bash
   python download_vavae_model.py
   ```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### è®­ç»ƒä¼˜åŒ–
- ä½¿ç”¨æ›´å¤§çš„batch_size (å¦‚æœGPUå†…å­˜å…è®¸)
- å¢åŠ è®­ç»ƒè½®æ•°åˆ°100-200è½®
- ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨

### ç”Ÿæˆä¼˜åŒ–
- è°ƒæ•´guidance_scale (2.0-8.0)
- å¢åŠ é‡‡æ ·æ­¥æ•° (250-1000)
- å°è¯•ä¸åŒçš„ç”¨æˆ·ID

## ğŸ”§ åŸå§‹Kaggleæ–¹æ³• (å·²å¼ƒç”¨)

### Step 1: æ•°æ®é›†åˆ’åˆ†
```bash
# é’ˆå¯¹Kaggleæ•°æ®é›†ç»“æ„ (ID_1, ID_2...ID_31)
python data_split.py \
    --input_dir /kaggle/input/dataset \
    --output_dir data_split \
    --train_ratio 0.8 \
    --val_ratio 0.2 \
    --image_extensions png,jpg,jpeg

# åˆ’åˆ†åçš„ç»“æ„ï¼š
# data_split/
# â”œâ”€â”€ train/
# â”‚   â”œâ”€â”€ user_01_sample_001.png
# â”‚   â””â”€â”€ ...
# â”œâ”€â”€ val/
# â”‚   â”œâ”€â”€ user_01_sample_010.png
# â”‚   â””â”€â”€ ...
# â””â”€â”€ split_info.txt
```

### Step 2: æ¨¡å‹è®­ç»ƒ

#### å•GPUè®­ç»ƒ
```bash
python minimal_training_modification.py \
    --data_dir data_split \
    --original_vavae path/to/vavae.pth \
    --batch_size 16 \
    --max_epochs 100 \
    --devices 1
```

#### å¤šGPUè®­ç»ƒ (æ¨è)
```bash
# åŒGPUè®­ç»ƒ
python minimal_training_modification.py \
    --data_dir data_split \
    --original_vavae path/to/vavae.pth \
    --batch_size 16 \
    --max_epochs 100 \
    --devices 2 \
    --strategy ddp

# å››GPUè®­ç»ƒ
python minimal_training_modification.py \
    --data_dir data_split \
    --original_vavae path/to/vavae.pth \
    --batch_size 16 \
    --max_epochs 100 \
    --devices 4 \
    --strategy ddp_find_unused_parameters_true \
    --precision 16  # æ··åˆç²¾åº¦è®­ç»ƒ
```

#### Kaggleç¯å¢ƒè®­ç»ƒ
```bash
python minimal_training_modification.py \
    --data_dir /kaggle/working/data_split \
    --original_vavae /kaggle/input/pretrained/vavae.pth \
    --batch_size 12 \
    --max_epochs 50 \
    --devices 1 \
    --precision 16 \
    --output_dir /kaggle/working/outputs
```

## ğŸ”§ è¯¦ç»†é…ç½®è¯´æ˜

### è®­ç»ƒå‚æ•°
- `--data_dir`: æ•°æ®ç›®å½•è·¯å¾„
- `--original_vavae`: åŸå§‹VA-VAEæ¨¡å‹è·¯å¾„
- `--batch_size`: æ¯ä¸ªGPUçš„æ‰¹æ¬¡å¤§å° (é»˜è®¤16)
- `--max_epochs`: æœ€å¤§è®­ç»ƒè½®æ•° (é»˜è®¤100)
- `--lr`: å­¦ä¹ ç‡ (é»˜è®¤1e-4)
- `--condition_dim`: ç”¨æˆ·æ¡ä»¶å‘é‡ç»´åº¦ (é»˜è®¤128)
- `--kl_weight`: KLæ•£åº¦æŸå¤±æƒé‡ (é»˜è®¤1e-6)

### PyTorch Lightningå‚æ•°
- `--devices`: GPUæ•°é‡ (1, 2, 4, 8ç­‰)
- `--strategy`: è®­ç»ƒç­–ç•¥ (auto, ddp, ddp_find_unused_parameters_true)
- `--accelerator`: åŠ é€Ÿå™¨ç±»å‹ (gpu, cpu)
- `--precision`: ç²¾åº¦ (16, 32, bf16)

### æ•°æ®åˆ’åˆ†å‚æ•°
- `--train_ratio`: è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤0.8)
- `--val_ratio`: éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤0.2)
- `--image_extensions`: å›¾åƒæ–‡ä»¶æ‰©å±•å (é»˜è®¤png,jpg,jpeg)

## ğŸ“Š æŠ€æœ¯æ¶æ„

### åŸé¡¹ç›®å¤šGPUæ”¯æŒ
æœ¬é¡¹ç›®ä½¿ç”¨ä¸åŸVA-VAEé¡¹ç›®ç›¸åŒçš„å¤šGPUå®ç°æ–¹å¼ï¼š
- **PyTorch Lightning**: è‡ªåŠ¨å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒ
- **DDPç­–ç•¥**: DistributedDataParallelè¿›è¡Œæ•°æ®å¹¶è¡Œ
- **è‡ªåŠ¨åŒæ­¥**: æŸå¤±å€¼å’Œæ¢¯åº¦è‡ªåŠ¨åœ¨GPUé—´åŒæ­¥

### ç”¨æˆ·æ¡ä»¶åŒ–æ‰©å±•
- **ç”¨æˆ·åµŒå…¥**: å°†ç”¨æˆ·IDæ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ç©ºé—´
- **æ¡ä»¶æ³¨å…¥**: é€šè¿‡ç‰¹å¾ç›¸åŠ çš„æ–¹å¼æ³¨å…¥ç”¨æˆ·ä¿¡æ¯
- **æœ€å°ä¿®æ”¹**: åœ¨åŸVA-VAEåŸºç¡€ä¸Šä»…æ·»åŠ å¿…è¦çš„æ¡ä»¶åŠŸèƒ½

### æ•°æ®å¤„ç†
- **è‡ªåŠ¨è¯†åˆ«**: æ”¯æŒKaggleçš„ID_1...ID_31ç›®å½•ç»“æ„
- **æ ¼å¼æ”¯æŒ**: PNG, JPG, JPEGç­‰å›¾åƒæ ¼å¼
- **å°ºå¯¸æ ‡å‡†åŒ–**: è‡ªåŠ¨è°ƒæ•´åˆ°256Ã—256åˆ†è¾¨ç‡
- **RGBè½¬æ¢**: è‡ªåŠ¨è½¬æ¢ä¸º3é€šé“RGBæ ¼å¼

## ğŸ“ˆ æ€§èƒ½é¢„æœŸ

### å•GPU vs å¤šGPU
| é…ç½® | æ‰¹æ¬¡å¤§å° | è®­ç»ƒé€Ÿåº¦ | å†…å­˜ä½¿ç”¨ | æ€»ååé‡ |
|------|----------|----------|----------|----------|
| 1Ã—RTX 3080 | 16 | 3ç§’/æ‰¹æ¬¡ | 12GB | 5.3 æ ·æœ¬/ç§’ |
| 2Ã—RTX 3080 | 16Ã—2 | 3ç§’/æ‰¹æ¬¡ | 6GBÃ—2 | 10.6 æ ·æœ¬/ç§’ |

### Kaggleç¯å¢ƒ
- **GPU**: é€šå¸¸æä¾›å•ä¸ªGPU (P100/T4)
- **æ‰¹æ¬¡å¤§å°**: æ¨è12-16
- **è®­ç»ƒæ—¶é—´**: çº¦2-4å°æ—¶ (50 epochs)
- **å†…å­˜ä½¿ç”¨**: 8-12GB

## ğŸ” ç›‘æ§å’Œæ—¥å¿—

### TensorBoardå¯è§†åŒ–
```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir outputs/lightning_logs

# åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹è®­ç»ƒè¿›åº¦
# http://localhost:6006
```

### æ£€æŸ¥ç‚¹ç®¡ç†
- **æœ€ä½³æ¨¡å‹**: `outputs/checkpoints/best-*.ckpt`
- **æœ€åæ¨¡å‹**: `outputs/checkpoints/last.ckpt`
- **è®­ç»ƒæ—¥å¿—**: `outputs/lightning_logs/`

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: CUDAå†…å­˜ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°æ‰¹æ¬¡å¤§å°æˆ–ä½¿ç”¨æ··åˆç²¾åº¦
python minimal_training_modification.py --batch_size 8 --precision 16
```

### Q2: æ•°æ®åŠ è½½é”™è¯¯
```bash
# æ£€æŸ¥æ•°æ®æ–‡ä»¶æ ¼å¼å’Œå‘½å
ls your_data_dir/*.png | head -5

# ç¡®ä¿ç›®å½•ç»“æ„ä¸º ID_1/, ID_2/, ..., ID_31/
```

### Q3: å¤šGPUè®­ç»ƒå¤±è´¥
```bash
# æ£€æŸ¥GPUæ•°é‡
nvidia-smi

# ä½¿ç”¨æ¨èçš„ç­–ç•¥
python minimal_training_modification.py --devices 2 --strategy ddp_find_unused_parameters_true
```

## ğŸ¯ ä¸åŸé¡¹ç›®çš„å¯¹æ¯”

| é¡¹ç›® | æ–‡ä»¶æ•°é‡ | ä»£ç è¡Œæ•° | å¤šGPUæ–¹æ¡ˆ | å¤æ‚åº¦ |
|------|----------|----------|-----------|--------|
| åŸå§‹LightningDiT | 50+ | 10000+ | HuggingFace Accelerator | é«˜ |
| åŸå§‹VA-VAE | 30+ | 8000+ | PyTorch Lightning | ä¸­ |
| **æˆ‘ä»¬çš„ç‰ˆæœ¬** | **4** | **<600** | **PyTorch Lightning** | **ä½** |

## ğŸ“ å¼€å‘å†ç¨‹

- [x] é¡¹ç›®åˆå§‹åŒ–å’Œç¯å¢ƒæ­å»º
- [x] å¾®å¤šæ™®å‹’æ•°æ®é¢„å¤„ç†æ¨¡å—
- [x] æ¡ä»¶VA-VAEæ¨¡å‹è®¾è®¡
- [x] è®­ç»ƒç­–ç•¥ä¼˜åŒ–
- [x] æ¨¡å‹è®­ç»ƒå’ŒéªŒè¯
- [x] ç”Ÿæˆæ¥å£å¼€å‘
- [x] PyTorch Lightningé›†æˆ
- [x] å¤šGPUæ”¯æŒå®Œå–„
- [x] Kaggleç¯å¢ƒé€‚é…

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºåŸå§‹LightningDiTé¡¹ç›®ï¼Œéµå¾ªç›¸åº”çš„å¼€æºè®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- æ„Ÿè°¢LightningDiTé¡¹ç›®æä¾›çš„VA-VAEåŸºç¡€æ¶æ„
- æ„Ÿè°¢PyTorch Lightningå›¢é˜Ÿæä¾›çš„ä¼˜ç§€æ¡†æ¶
- æ„Ÿè°¢å¼€æºç¤¾åŒºçš„è´¡çŒ®å’Œæ”¯æŒ

---

**é¡¹ç›®åœ°å€**: https://github.com/heimaoqqq/VA-VAE  
**é—®é¢˜åé¦ˆ**: è¯·åœ¨GitHub Issuesä¸­æå‡ºé—®é¢˜å’Œå»ºè®®
