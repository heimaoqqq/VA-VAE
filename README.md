# å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•°æ®å¢å¹¿é¡¹ç›® (Micro-Doppler Spectrogram Data Augmentation)

åŸºäºVA-VAE (Vision foundation model Aligned Variational AutoEncoder) çš„å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•°æ®å¢å¹¿è§£å†³æ–¹æ¡ˆ

## ğŸ¯ é¡¹ç›®ç›®æ ‡

- è§£å†³å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•°æ®é‡ä¸è¶³çš„é—®é¢˜
- å®ç°æŒ‡å®šç”¨æˆ·çš„æ­¥æ€å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾ç”Ÿæˆ
- å¤„ç†31ä¸ªç”¨æˆ·é—´å·®å¼‚è¾ƒå°çš„æ•°æ®é›†
- æä¾›é«˜è´¨é‡çš„æ•°æ®å¢å¹¿æ–¹æ¡ˆ

## ğŸ“Š æ•°æ®ç‰¹ç‚¹

- **æ•°æ®ç±»å‹**: æ­¥æ€å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾
- **ç”¨æˆ·æ•°é‡**: 31ä¸ªç”¨æˆ·
- **æ•°æ®ç‰¹å¾**: ç”¨æˆ·é—´å·®å¼‚è¾ƒå°ï¼Œæ•°æ®é‡æœ‰é™
- **ç›®æ ‡**: æ¡ä»¶ç”ŸæˆæŒ‡å®šç”¨æˆ·çš„æ—¶é¢‘å›¾

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### æ ¸å¿ƒç»„ä»¶
1. **æ¡ä»¶VA-VAE**: åŸºäºç”¨æˆ·æ¡ä»¶çš„å˜åˆ†è‡ªç¼–ç å™¨
2. **æ—¶é¢‘å›¾é¢„å¤„ç†**: ä¸“é—¨çš„å¾®å¤šæ™®å‹’æ•°æ®å¤„ç†æ¨¡å—
3. **ç”¨æˆ·ç¼–ç å™¨**: ç”¨æˆ·ç‰¹å¾ç¼–ç å’Œæ¡ä»¶æ³¨å…¥
4. **ç”Ÿæˆæ¥å£**: æŒ‡å®šç”¨æˆ·çš„æ—¶é¢‘å›¾ç”ŸæˆAPI

### æŠ€æœ¯ä¼˜åŠ¿
- âœ… å°æ•°æ®é›†å‹å¥½çš„è®­ç»ƒç­–ç•¥
- âœ… 21å€è®­ç»ƒåŠ é€Ÿ (åŸºäºVA-VAE)
- âœ… æ¡ä»¶ç”Ÿæˆç‰¹å®šç”¨æˆ·æ•°æ®
- âœ… é«˜è´¨é‡æ—¶é¢‘å›¾é‡å»º

## ğŸ“ é¡¹ç›®ç»“æ„

```
micro_doppler_vavae/
â”œâ”€â”€ data/                          # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw/                       # åŸå§‹å¾®å¤šæ™®å‹’æ•°æ®
â”‚   â”œâ”€â”€ processed/                 # é¢„å¤„ç†åçš„æ•°æ®
â”‚   â””â”€â”€ generated/                 # ç”Ÿæˆçš„å¢å¹¿æ•°æ®
â”œâ”€â”€ src/                           # æºä»£ç 
â”‚   â”œâ”€â”€ models/                    # æ¨¡å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ conditional_vavae.py   # æ¡ä»¶VA-VAEæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ user_encoder.py        # ç”¨æˆ·ç¼–ç å™¨
â”‚   â”‚   â””â”€â”€ discriminator.py       # åˆ¤åˆ«å™¨(å¯é€‰)
â”‚   â”œâ”€â”€ data/                      # æ•°æ®å¤„ç†
â”‚   â”‚   â”œâ”€â”€ micro_doppler_dataset.py  # æ•°æ®é›†ç±»
â”‚   â”‚   â”œâ”€â”€ preprocessing.py       # é¢„å¤„ç†å·¥å…·
â”‚   â”‚   â””â”€â”€ augmentation.py        # æ•°æ®å¢å¼º
â”‚   â”œâ”€â”€ training/                  # è®­ç»ƒç›¸å…³
â”‚   â”‚   â”œâ”€â”€ trainer.py             # è®­ç»ƒå™¨
â”‚   â”‚   â”œâ”€â”€ losses.py              # æŸå¤±å‡½æ•°
â”‚   â”‚   â””â”€â”€ metrics.py             # è¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ visualization.py       # å¯è§†åŒ–å·¥å…·
â”‚       â”œâ”€â”€ evaluation.py          # è¯„ä¼°å·¥å…·
â”‚       â””â”€â”€ config.py              # é…ç½®ç®¡ç†
â”œâ”€â”€ configs/                       # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ model_config.yaml          # æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ training_config.yaml       # è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ data_config.yaml           # æ•°æ®é…ç½®
â”œâ”€â”€ scripts/                       # è„šæœ¬æ–‡ä»¶
â”‚   â”œâ”€â”€ train.py                   # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ inference.py               # æ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ evaluate.py                # è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ generate_data.py           # æ•°æ®ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â”œâ”€â”€ data_exploration.ipynb     # æ•°æ®æ¢ç´¢
â”‚   â”œâ”€â”€ model_analysis.ipynb       # æ¨¡å‹åˆ†æ
â”‚   â””â”€â”€ results_visualization.ipynb # ç»“æœå¯è§†åŒ–
â”œâ”€â”€ tests/                         # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ requirements.txt               # ä¾èµ–åŒ…
â””â”€â”€ README.md                      # é¡¹ç›®è¯´æ˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå®‰è£…
```bash
# åˆ›å»ºcondaç¯å¢ƒ
conda create -n micro_doppler_vavae python=3.10
conda activate micro_doppler_vavae

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### æ•°æ®å‡†å¤‡
```bash
# é¢„å¤„ç†å¾®å¤šæ™®å‹’æ•°æ®
python scripts/preprocess_data.py --input_dir data/raw --output_dir data/processed --create_stats --visualize

# æ•°æ®æ¢ç´¢
jupyter notebook notebooks/data_exploration.ipynb
```

### æ¨¡å‹è®­ç»ƒ
```bash
# è®­ç»ƒæ¡ä»¶VA-VAE
python scripts/train.py --config configs/training_config.yaml --data_dir data/processed

# æ¢å¤è®­ç»ƒï¼ˆå¯é€‰ï¼‰
python scripts/train.py --config configs/training_config.yaml --resume checkpoints/checkpoint_epoch_50.pth
```

### æ¨¡å‹è¯„ä¼°
```bash
# å…¨é¢è¯„ä¼°
python scripts/evaluate.py --checkpoint checkpoints/best_model.pth --data_dir data/processed --eval_all

# å•é¡¹è¯„ä¼°
python scripts/evaluate.py --checkpoint checkpoints/best_model.pth --eval_reconstruction
python scripts/evaluate.py --checkpoint checkpoints/best_model.pth --eval_generation
python scripts/evaluate.py --checkpoint checkpoints/best_model.pth --eval_user_specificity
```

### æ•°æ®ç”Ÿæˆ
```bash
# ç”ŸæˆæŒ‡å®šç”¨æˆ·çš„æ—¶é¢‘å›¾
python scripts/inference.py --checkpoint checkpoints/best_model.pth --user_id 1 --num_samples 5

# æ‰¹é‡ç”Ÿæˆæ•°æ®å¢å¹¿æ ·æœ¬
python scripts/generate_data.py --checkpoint checkpoints/best_model.pth --num_samples_per_user 50 --create_manifest

# æŒ‡å®šç”¨æˆ·æ‰¹é‡ç”Ÿæˆ
python scripts/generate_data.py --checkpoint checkpoints/best_model.pth --user_ids "0,1,2,5,10" --num_samples_per_user 20
```

### Webç•Œé¢ä½¿ç”¨
```bash
# å¯åŠ¨Webç•Œé¢
python scripts/web_interface.py --checkpoint checkpoints/best_model.pth --host 0.0.0.0 --port 5000

# è®¿é—® http://localhost:5000 ä½¿ç”¨å›¾å½¢ç•Œé¢ç”Ÿæˆæ—¶é¢‘å›¾
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

- **é‡å»ºè´¨é‡**: é«˜ä¿çœŸåº¦çš„æ—¶é¢‘å›¾é‡å»º
- **ç”¨æˆ·ç‰¹å¼‚æ€§**: å‡†ç¡®ç”ŸæˆæŒ‡å®šç”¨æˆ·çš„ç‰¹å¾
- **æ•°æ®å¤šæ ·æ€§**: ä¸°å¯Œçš„å˜åŒ–å’Œç»†èŠ‚
- **è®­ç»ƒæ•ˆç‡**: å¿«é€Ÿæ”¶æ•›ï¼Œé€‚åˆå°æ•°æ®é›†

## ğŸ”§ æ ¸å¿ƒç‰¹æ€§

### 1. æ¡ä»¶ç”Ÿæˆ
- ç”¨æˆ·IDæ¡ä»¶æ³¨å…¥
- ç”¨æˆ·ç‰¹å¾ç¼–ç 
- å¯æ§çš„ç”Ÿæˆè¿‡ç¨‹

### 2. å°æ•°æ®é›†ä¼˜åŒ–
- æ•°æ®å¢å¼ºç­–ç•¥
- æ­£åˆ™åŒ–æŠ€æœ¯
- è¿ç§»å­¦ä¹ 

### 3. è´¨é‡ä¿è¯
- å¤šå±‚æ¬¡æŸå¤±å‡½æ•°
- æ„ŸçŸ¥æŸå¤±
- ç”¨æˆ·ä¸€è‡´æ€§çº¦æŸ

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

- **é‡å»ºè´¨é‡**: PSNR, SSIM, LPIPS
- **ç”¨æˆ·ç‰¹å¼‚æ€§**: åˆ†ç±»å‡†ç¡®ç‡, ç‰¹å¾ç›¸ä¼¼åº¦
- **æ•°æ®å¤šæ ·æ€§**: FID, IS, ç‰¹å¾åˆ†å¸ƒ
- **æ—¶é¢‘ç‰¹æ€§**: é¢‘è°±ä¿çœŸåº¦, æ—¶é—´ä¸€è‡´æ€§

## ğŸ¯ åº”ç”¨åœºæ™¯

- æ­¥æ€è¯†åˆ«æ•°æ®å¢å¹¿
- é›·è¾¾ä¿¡å·å¤„ç†
- ç”Ÿç‰©ç‰¹å¾è¯†åˆ«
- è¿åŠ¨åˆ†æç ”ç©¶

## ğŸ“ å¼€å‘è®¡åˆ’

- [x] é¡¹ç›®åˆå§‹åŒ–å’Œç¯å¢ƒæ­å»º
- [x] å¾®å¤šæ™®å‹’æ•°æ®é¢„å¤„ç†æ¨¡å—
- [x] æ¡ä»¶VA-VAEæ¨¡å‹è®¾è®¡
- [x] è®­ç»ƒç­–ç•¥ä¼˜åŒ–
- [x] æ¨¡å‹è®­ç»ƒå’ŒéªŒè¯
- [x] ç”Ÿæˆæ¥å£å¼€å‘

## ğŸ”§ è¯¦ç»†ä½¿ç”¨è¯´æ˜

### é…ç½®æ–‡ä»¶è¯´æ˜

é¡¹ç›®æä¾›äº†ä¸‰ä¸ªä¸»è¦é…ç½®æ–‡ä»¶ï¼š

1. **æ¨¡å‹é…ç½®** (`configs/model_config.yaml`)
   - æ¨¡å‹æ¶æ„å‚æ•°
   - ç”¨æˆ·ç¼–ç å™¨è®¾ç½®
   - æŸå¤±å‡½æ•°æƒé‡

2. **è®­ç»ƒé…ç½®** (`configs/training_config.yaml`)
   - è®­ç»ƒè¶…å‚æ•°
   - ä¼˜åŒ–å™¨è®¾ç½®
   - æ•°æ®å¢å¼ºç­–ç•¥

3. **æ•°æ®é…ç½®** (`configs/data_config.yaml`)
   - æ•°æ®è·¯å¾„å’Œæ ¼å¼
   - é¢„å¤„ç†å‚æ•°
   - æ—¶é¢‘å›¾ç‰¹å®šè®¾ç½®

### æ•°æ®æ ¼å¼è¦æ±‚

æ”¯æŒçš„æ•°æ®æ ¼å¼ï¼š
- **NumPyæ ¼å¼** (`.npy`): æ¨èæ ¼å¼ï¼ŒåŠ è½½é€Ÿåº¦å¿«
- **HDF5æ ¼å¼** (`.h5`): é€‚åˆå¤§æ•°æ®é›†
- **å›¾åƒæ ¼å¼** (`.png`, `.jpg`): ä¾¿äºå¯è§†åŒ–

æ–‡ä»¶å‘½åè§„èŒƒï¼š
```
user_{user_id}_sample_{sample_id}.npy
# ä¾‹å¦‚: user_01_sample_001.npy, user_02_sample_015.npy
```

### è®­ç»ƒæŠ€å·§

1. **å°æ•°æ®é›†ä¼˜åŒ–**
   ```bash
   # ä½¿ç”¨æ›´å¼ºçš„æ•°æ®å¢å¼º
   python scripts/train.py --config configs/training_config.yaml --augment_prob 0.8

   # è°ƒæ•´å­¦ä¹ ç‡
   python scripts/train.py --learning_rate 5e-5 --epochs 200
   ```

2. **å¤šGPUè®­ç»ƒ**
   ```bash
   # ä½¿ç”¨å¤šGPUåŠ é€Ÿè®­ç»ƒ
   CUDA_VISIBLE_DEVICES=0,1 python scripts/train.py --config configs/training_config.yaml
   ```

3. **è°ƒè¯•æ¨¡å¼**
   ```bash
   # å¿«é€ŸéªŒè¯ä»£ç 
   python scripts/train.py --debug --epochs 2 --batch_size 8
   ```

### ç”Ÿæˆè´¨é‡æ§åˆ¶

1. **æ¸©åº¦å‚æ•°è°ƒèŠ‚**
   ```bash
   # æ›´éšæœºçš„ç”Ÿæˆ (temperature > 1.0)
   python scripts/generate_data.py --temperature 1.2 --num_samples_per_user 10

   # æ›´ç¡®å®šæ€§çš„ç”Ÿæˆ (temperature < 1.0)
   python scripts/generate_data.py --temperature 0.8 --num_samples_per_user 10
   ```

2. **ç§å­æ§åˆ¶**
   ```bash
   # å¯é‡ç°çš„ç”Ÿæˆ
   python scripts/inference.py --seed 42 --user_id 5 --num_samples 3
   ```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å†…å­˜ä¼˜åŒ–**
   - å‡å°‘batch_sizeå¦‚æœé‡åˆ°OOMé”™è¯¯
   - ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (`use_amp: true`)
   - å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹

2. **è®­ç»ƒåŠ é€Ÿ**
   - ä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹
   - è°ƒæ•´æ•°æ®åŠ è½½å™¨çš„num_workers
   - å¯ç”¨æ¨¡å‹ç¼–è¯‘ (PyTorch 2.0+)

### å¸¸è§é—®é¢˜è§£å†³

1. **CUDAå†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘æ‰¹æ¬¡å¤§å°
   python scripts/train.py --batch_size 16

   # å¯ç”¨æ¢¯åº¦ç´¯ç§¯
   python scripts/train.py --gradient_accumulation_steps 2
   ```

2. **è®­ç»ƒä¸æ”¶æ•›**
   ```bash
   # é™ä½å­¦ä¹ ç‡
   python scripts/train.py --learning_rate 1e-5

   # å¢åŠ warmupè½®æ•°
   python scripts/train.py --warmup_epochs 20
   ```

3. **ç”Ÿæˆè´¨é‡å·®**
   ```bash
   # å¢åŠ è®­ç»ƒè½®æ•°
   python scripts/train.py --epochs 300

   # è°ƒæ•´æŸå¤±æƒé‡
   python scripts/train.py --kl_weight 1e-5 --align_weight 2.0
   ```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›é¡¹ç›®ï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºMITè®¸å¯è¯å¼€æºã€‚

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹ä¼˜ç§€å·¥ä½œï¼š
- [LightningDiT](https://github.com/hustvl/LightningDiT) - VA-VAEåŸå§‹å®ç°
- [DiT](https://github.com/facebookresearch/DiT) - Diffusion Transformer
- [LDM](https://github.com/CompVis/latent-diffusion) - Latent Diffusion Models
