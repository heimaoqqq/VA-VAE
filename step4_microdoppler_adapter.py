#!/usr/bin/env python3
"""
æ­¥éª¤4: micro-Doppleræ•°æ®é€‚é…å™¨
å°†micro-Doppleræ—¶é¢‘å›¾åƒé€‚é…ä¸ºLightningDiTçš„è¾“å…¥æ ¼å¼
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
import numpy as np
from PIL import Image
import yaml
from typing import Dict, List, Optional, Tuple
import pandas as pd

class MicroDopplerDataset(Dataset):
    """micro-Doppleræ•°æ®é›†ç±»"""
    
    def __init__(
        self,
        data_dir: str,
        user_labels: Dict[str, int],
        image_size: int = 256,
        split: str = "train",
        transform=None
    ):
        self.data_dir = Path(data_dir)
        self.user_labels = user_labels
        self.image_size = image_size
        self.split = split
        self.transform = transform
        
        # åŠ è½½å›¾åƒè·¯å¾„å’Œæ ‡ç­¾
        self.samples = self._load_samples()
        print(f"âœ… åŠ è½½{split}æ•°æ®: {len(self.samples)}å¼ å›¾åƒï¼Œ{len(set(self.user_labels.values()))}ä¸ªç”¨æˆ·")
    
    def _load_samples(self) -> List[Dict]:
        """åŠ è½½æ ·æœ¬æ•°æ®"""
        samples = []
        
        for image_path in self.data_dir.rglob("*.jpg"):  # JPGæ ¼å¼çš„micro-Dopplerå›¾åƒ
            # ä»æ–‡ä»¶åæˆ–ç›®å½•ç»“æ„æå–ç”¨æˆ·ID
            # è¿™é‡Œéœ€è¦æ ¹æ®æ‚¨çš„æ•°æ®ç»„ç»‡æ–¹å¼è°ƒæ•´
            user_id = self._extract_user_id(image_path)
            
            if user_id in self.user_labels:
                samples.append({
                    'image_path': image_path,
                    'user_id': user_id,
                    'user_class': self.user_labels[user_id]
                })
        
        return samples
    
    def _extract_user_id(self, image_path: Path) -> str:
        """ä»æ–‡ä»¶è·¯å¾„æå–ç”¨æˆ·ID"""
        # æ ¹æ®æ‚¨çš„æ•°æ®ç»“æ„: /kaggle/input/dataset/ID_x/image.jpg
        # ç›´æ¥ä»çˆ¶ç›®å½•åè·å–ç”¨æˆ·ID
        return image_path.parent.name  # è¿”å› "ID_1", "ID_2", etc.
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx: int) -> Dict:
        sample = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        image = Image.open(sample['image_path'])
        
        # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœæ˜¯ç°åº¦å›¾ï¼‰
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # è°ƒæ•´å¤§å°
        image = image.resize((self.image_size, self.image_size), Image.LANCZOS)
        
        # è½¬æ¢ä¸ºå¼ é‡
        image_tensor = torch.from_numpy(np.array(image)).float()
        image_tensor = image_tensor.permute(2, 0, 1)  # HWC -> CHW
        
        # å½’ä¸€åŒ–åˆ°[-1, 1]
        image_tensor = (image_tensor / 255.0) * 2.0 - 1.0
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            image_tensor = self.transform(image_tensor)
        
        return {
            'image': image_tensor,
            'user_id': sample['user_id'],
            'user_class': sample['user_class'],
            'image_path': str(sample['image_path'])
        }

class UserConditionEncoder(nn.Module):
    """ç”¨æˆ·æ¡ä»¶ç¼–ç å™¨"""
    
    def __init__(
        self,
        num_users: int,
        embed_dim: int = 1152,  # âœ… ä¿®å¤ï¼šåŒ¹é…DiTçš„hidden_size
        hidden_dim: int = 512,
        dropout: float = 0.1
    ):
        super().__init__()
        self.num_users = num_users
        self.embed_dim = embed_dim
        
        # ç”¨æˆ·IDåµŒå…¥
        self.user_embedding = nn.Embedding(num_users, embed_dim)
        
        # ç‰¹å¾å¤„ç†ç½‘ç»œ
        self.feature_net = nn.Sequential(
            nn.Linear(embed_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, embed_dim),
            nn.LayerNorm(embed_dim)
        )
        
        # åˆå§‹åŒ–
        nn.init.normal_(self.user_embedding.weight, std=0.02)
    
    def forward(self, user_classes: torch.Tensor) -> torch.Tensor:
        """
        Args:
            user_classes: (batch_size,) ç”¨æˆ·ç±»åˆ«ID
        Returns:
            user_features: (batch_size, embed_dim) ç”¨æˆ·ç‰¹å¾å‘é‡
        """
        # è·å–ç”¨æˆ·åµŒå…¥
        user_embed = self.user_embedding(user_classes)
        
        # ç‰¹å¾å¤„ç†
        user_features = self.feature_net(user_embed)
        
        return user_features

class MicroDopplerDataModule:
    """æ•°æ®æ¨¡å—"""
    
    def __init__(
        self,
        data_dir: str,
        batch_size: int = 4,
        num_workers: int = 2,
        image_size: int = 256,
        val_split: float = 0.2
    ):
        self.data_dir = data_dir
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.image_size = image_size
        self.val_split = val_split
        
        # è‡ªåŠ¨å‘ç°ç”¨æˆ·æ ‡ç­¾
        self.user_labels = self._discover_users()
        self.num_users = len(self.user_labels)
        
        print(f"ğŸ“Š å‘ç°ç”¨æˆ·: {self.num_users}ä¸ª")
        for user_id, class_idx in self.user_labels.items():
            print(f"   - {user_id}: ç±»åˆ«{class_idx}")
    
    def _discover_users(self) -> Dict[str, int]:
        """è‡ªåŠ¨å‘ç°æ•°æ®ä¸­çš„ç”¨æˆ·"""
        data_path = Path(self.data_dir)
        user_ids = set()
        
        # æ‰«ææ‰€æœ‰å­ç›®å½•ï¼Œå¯»æ‰¾ID_xæ ¼å¼çš„ç”¨æˆ·æ–‡ä»¶å¤¹
        for subdir in data_path.iterdir():
            if subdir.is_dir() and subdir.name.startswith('ID_'):
                user_ids.add(subdir.name)
        
        # æŒ‰IDæ•°å­—æ’åº (ID_1, ID_2, ..., ID_31)
        def sort_key(user_id):
            return int(user_id.split('_')[1])
        
        sorted_user_ids = sorted(user_ids, key=sort_key)
        
        # åˆ†é…ç±»åˆ«ç´¢å¼•
        user_labels = {user_id: idx for idx, user_id in enumerate(sorted_user_ids)}
        return user_labels
    
    def setup(self):
        """è®¾ç½®æ•°æ®é›† - ä½¿ç”¨åˆ†å±‚ç”¨æˆ·åˆ’åˆ†ç­–ç•¥"""
        # åˆ›å»ºå®Œæ•´æ•°æ®é›†ä»¥è·å–æ‰€æœ‰æ ·æœ¬ä¿¡æ¯
        full_dataset = MicroDopplerDataset(
            data_dir=self.data_dir,
            user_labels=self.user_labels,
            image_size=self.image_size,
            split="full"
        )
        
        # âœ… æŒ‰ç”¨æˆ·åˆ†å±‚åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
        train_indices, val_indices = self._stratified_user_split(full_dataset.samples)
        
        # åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†
        self.train_dataset = torch.utils.data.Subset(full_dataset, train_indices)
        self.val_dataset = torch.utils.data.Subset(full_dataset, val_indices)
        
        print(f"ğŸ“Š åˆ†å±‚ç”¨æˆ·æ•°æ®åˆ†å‰²:")
        print(f"   - è®­ç»ƒé›†: {len(train_indices)}å¼ å›¾åƒ")
        print(f"   - éªŒè¯é›†: {len(val_indices)}å¼ å›¾åƒ")
        
        # éªŒè¯æ¯ä¸ªç”¨æˆ·éƒ½æœ‰è®­ç»ƒå’ŒéªŒè¯æ ·æœ¬
        self._validate_user_distribution(train_indices, val_indices, full_dataset.samples)
    
    def _stratified_user_split(self, samples: List[Dict]) -> Tuple[List[int], List[int]]:
        """
        æŒ‰ç”¨æˆ·åˆ†å±‚åˆ’åˆ†æ•°æ®é›†ï¼Œç¡®ä¿æ¯ä¸ªç”¨æˆ·éƒ½æœ‰è®­ç»ƒå’ŒéªŒè¯æ ·æœ¬
        
        Args:
            samples: å®Œæ•´æ ·æœ¬åˆ—è¡¨
            
        Returns:
            train_indices, val_indices: è®­ç»ƒå’ŒéªŒè¯æ ·æœ¬çš„ç´¢å¼•
        """
        import random
        random.seed(42)  # ç¡®ä¿å¯å¤ç°
        
        # æŒ‰ç”¨æˆ·ç»„ç»‡æ ·æœ¬ç´¢å¼•
        user_sample_indices = {}
        for idx, sample in enumerate(samples):
            user_id = sample['user_id']
            if user_id not in user_sample_indices:
                user_sample_indices[user_id] = []
            user_sample_indices[user_id].append(idx)
        
        train_indices = []
        val_indices = []
        
        print(f"ğŸ“‹ æ¯ç”¨æˆ·æ ·æœ¬åˆ†å¸ƒ:")
        for user_id, indices in user_sample_indices.items():
            user_total = len(indices)
            user_val_size = max(1, int(user_total * self.val_split))  # è‡³å°‘1ä¸ªéªŒè¯æ ·æœ¬
            user_train_size = user_total - user_val_size
            
            # éšæœºæ‰“ä¹±è¯¥ç”¨æˆ·çš„æ ·æœ¬
            random.shuffle(indices)
            
            # åˆ†é…è®­ç»ƒå’ŒéªŒè¯æ ·æœ¬
            user_train_indices = indices[:user_train_size]
            user_val_indices = indices[user_train_size:]
            
            train_indices.extend(user_train_indices)
            val_indices.extend(user_val_indices)
            
            print(f"   - {user_id}: æ€»è®¡{user_total}å¼  â†’ è®­ç»ƒ{user_train_size}å¼ , éªŒè¯{user_val_size}å¼ ")
        
        return train_indices, val_indices
    
    def _validate_user_distribution(self, train_indices: List[int], val_indices: List[int], samples: List[Dict]):
        """éªŒè¯æ¯ä¸ªç”¨æˆ·åœ¨è®­ç»ƒå’ŒéªŒè¯é›†ä¸­éƒ½æœ‰æ ·æœ¬"""
        # ç»Ÿè®¡è®­ç»ƒé›†ä¸­çš„ç”¨æˆ·
        train_users = set()
        for idx in train_indices:
            train_users.add(samples[idx]['user_id'])
        
        # ç»Ÿè®¡éªŒè¯é›†ä¸­çš„ç”¨æˆ·
        val_users = set()
        for idx in val_indices:
            val_users.add(samples[idx]['user_id'])
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç”¨æˆ·éƒ½åœ¨ä¸¤ä¸ªé›†åˆä¸­
        all_users = set(self.user_labels.keys())
        
        missing_train = all_users - train_users
        missing_val = all_users - val_users
        
        if missing_train:
            print(f"âš ï¸ è­¦å‘Š: ä»¥ä¸‹ç”¨æˆ·åœ¨è®­ç»ƒé›†ä¸­ç¼ºå¤±: {missing_train}")
        if missing_val:
            print(f"âš ï¸ è­¦å‘Š: ä»¥ä¸‹ç”¨æˆ·åœ¨éªŒè¯é›†ä¸­ç¼ºå¤±: {missing_val}")
        
        if not missing_train and not missing_val:
            print(f"âœ… æ•°æ®åˆ†å¸ƒéªŒè¯é€šè¿‡: æ‰€æœ‰{len(all_users)}ä¸ªç”¨æˆ·åœ¨è®­ç»ƒå’ŒéªŒè¯é›†ä¸­éƒ½æœ‰æ ·æœ¬")
    
    def train_dataloader(self):
        return DataLoader(
            self.train_dataset,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=self.num_workers,
            pin_memory=True,
            drop_last=True
        )
    
    def val_dataloader(self):
        return DataLoader(
            self.val_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=self.num_workers,
            pin_memory=True,
            drop_last=False
        )

def test_data_loading(data_dir: str):
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("ğŸ” æµ‹è¯•micro-Doppleræ•°æ®åŠ è½½...")
    
    try:
        # åˆ›å»ºæ•°æ®æ¨¡å—
        data_module = MicroDopplerDataModule(
            data_dir=data_dir,
            batch_size=2,
            num_workers=0,  # æµ‹è¯•æ—¶ä½¿ç”¨0é¿å…å¤šè¿›ç¨‹é—®é¢˜
        )
        
        # è®¾ç½®æ•°æ®
        data_module.setup()
        
        print(f"ğŸ“Š å‘ç°çš„ç”¨æˆ·æ˜ å°„:")
        for user_id, class_idx in data_module.user_labels.items():
            print(f"   - {user_id} â†’ ç±»åˆ«{class_idx}")
        
        # æµ‹è¯•è®­ç»ƒæ•°æ®åŠ è½½å™¨
        train_loader = data_module.train_dataloader()
        batch = next(iter(train_loader))
        
        print(f"âœ… è®­ç»ƒbatchåŠ è½½æˆåŠŸ:")
        print(f"   - å›¾åƒå½¢çŠ¶: {batch['image'].shape}")
        print(f"   - ç”¨æˆ·ç±»åˆ«: {batch['user_class']}")
        print(f"   - ç”¨æˆ·ID: {batch['user_id']}")
        
        # éªŒè¯ç”¨æˆ·æ ‡ç­¾èŒƒå›´
        user_classes = batch['user_class'].cpu().numpy()
        print(f"   - ç±»åˆ«èŒƒå›´: [{user_classes.min()}, {user_classes.max()}]")
        
        # æµ‹è¯•æ¡ä»¶ç¼–ç å™¨
        condition_encoder = UserConditionEncoder(
            num_users=data_module.num_users,
            embed_dim=768
        )
        
        user_features = condition_encoder(batch['user_class'])
        print(f"âœ… ç”¨æˆ·æ¡ä»¶ç¼–ç æˆåŠŸ: {user_features.shape}")
        
        # ç»Ÿè®¡æ•°æ®é›†å¤§å°
        print(f"ğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
        print(f"   - æ€»ç”¨æˆ·æ•°: {data_module.num_users}")
        print(f"   - è®­ç»ƒæ ·æœ¬: {len(data_module.train_dataset)}")
        print(f"   - éªŒè¯æ ·æœ¬: {len(data_module.val_dataset)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_config_template():
    """åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿"""
    config = {
        'model': {
            'target': 'ConditionalDiT',
            'params': {
                'model': 'LightningDiT-XL/1',
                'num_users': 31,  # ç”¨æˆ·æ•°é‡ (ID_1 åˆ° ID_31)
                'condition_dim': 768,
                'frozen_backbone': True,
                'dropout': 0.15
            }
        },
        'data': {
            'target': 'MicroDopplerDataModule',
            'params': {
                'data_dir': '/kaggle/input/dataset',  # Kaggleç¯å¢ƒæ•°æ®è·¯å¾„
                'batch_size': 2,
                'num_workers': 2,
                'image_size': 256,
                'val_split': 0.2
            }
        },
        'trainer': {
            'precision': 'bf16-mixed',
            'max_epochs': 50,
            'check_val_every_n_epoch': 2,
            'gradient_clip_val': 0.5,
            'accumulate_grad_batches': 4,
            'log_every_n_steps': 50
        },
        'optimizer': {
            'target': 'torch.optim.AdamW',
            'params': {
                'lr': 5e-6,
                'weight_decay': 1e-3,
                'betas': [0.9, 0.95]
            }
        },
        'scheduler': {
            'target': 'torch.optim.lr_scheduler.CosineAnnealingLR',
            'params': {
                'T_max': 50,
                'eta_min': 1e-7
            }
        }
    }
    
    return config

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ­¥éª¤4: micro-Doppleræ•°æ®é€‚é…")
    print("="*60)
    
    # åˆ›å»ºé…ç½®æ¨¡æ¿
    config = create_config_template()
    config_path = Path("configs/microdoppler_finetune.yaml")
    config_path.parent.mkdir(exist_ok=True)
    
    with open(config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, indent=2)
    print(f"âœ… é…ç½®æ¨¡æ¿å·²åˆ›å»º: {config_path}")
    
    # æµ‹è¯•æ•°æ®åŠ è½½ï¼ˆä½¿ç”¨é…ç½®ä¸­çš„å®é™…æ•°æ®ç›®å½•ï¼‰
    data_dir = "/kaggle/input/dataset"  # æ‚¨çš„æ•°æ®é›†è·¯å¾„
    if Path(data_dir).exists():
        if test_data_loading(data_dir):
            print("âœ… æ•°æ®åŠ è½½æµ‹è¯•é€šè¿‡")
        else:
            print("âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥")
    else:
        print(f"â„¹ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("â„¹ï¸ è¯·ç¡®ä¿æ‚¨çš„æ•°æ®åœ¨ /kaggle/input/dataset ç›®å½•ä¸‹")
    
    print("\n" + "="*60)
    print("âœ… micro-Doppleré€‚é…å™¨åˆ›å»ºå®Œæˆ")
    print(f"ğŸ“ é…ç½®æ–‡ä»¶å·²è®¾ç½®æ•°æ®è·¯å¾„: {data_dir}")
    print("ğŸš€ ä¸‹ä¸€æ­¥: ç›´æ¥è¿è¡Œæ¡ä»¶å¾®è°ƒè®­ç»ƒ")
    print("   python step5_conditional_dit_training.py --config configs/microdoppler_finetune.yaml")

if __name__ == "__main__":
    main()
