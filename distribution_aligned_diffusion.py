"""
åˆ†å¸ƒå¯¹é½çš„æ‰©æ•£æ¨¡å‹è®­ç»ƒå’Œæ¨ç†
å®ç°ä¸šç•Œæ ‡å‡†çš„latentåˆ†å¸ƒå½’ä¸€åŒ–æ–¹æ³•
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from diffusers import UNet2DConditionModel, DDPMScheduler
from typing import Optional, Tuple
import numpy as np


class DistributionAlignedDiffusion(nn.Module):
    """å¸¦åˆ†å¸ƒå¯¹é½çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹"""
    
    def __init__(
        self,
        vae,
        num_users: int = 31,
        prototype_dim: int = 768,
        enable_alignment: bool = True,
        track_statistics: bool = True
    ):
        super().__init__()
        
        # VAE (å†»ç»“)
        self.vae = vae
        for param in self.vae.parameters():
            param.requires_grad = False
        
        self.num_users = num_users
        self.prototype_dim = prototype_dim
        self.enable_alignment = enable_alignment
        self.track_statistics = track_statistics
        
        # åˆ†å¸ƒç»Ÿè®¡ï¼ˆä¼šåœ¨è®­ç»ƒæ—¶åŠ¨æ€æ›´æ–°ï¼‰
        self.register_buffer('latent_mean', torch.zeros(1))
        self.register_buffer('latent_std', torch.ones(1))
        self.register_buffer('n_samples', torch.tensor(0))
        
        # UNetæ¨¡å‹ - åŒ¹é…VA-VAEçš„latentç»´åº¦
        self.unet = UNet2DConditionModel(
            sample_size=16,  # VAE latent size
            in_channels=32,  # VAE latent channels
            out_channels=32,
            layers_per_block=2,
            block_out_channels=(128, 256, 512),
            down_block_types=(
                "CrossAttnDownBlock2D",
                "CrossAttnDownBlock2D",
                "CrossAttnDownBlock2D",
            ),
            up_block_types=(
                "CrossAttnUpBlock2D",
                "CrossAttnUpBlock2D",
                "CrossAttnUpBlock2D",
            ),
            cross_attention_dim=prototype_dim,
            attention_head_dim=8,
        )
        
        # å™ªå£°è°ƒåº¦å™¨
        self.noise_scheduler = DDPMScheduler(
            num_train_timesteps=1000,
            beta_start=0.00085,
            beta_end=0.012,
            beta_schedule="scaled_linear",
            clip_sample=False,
            prediction_type="epsilon",
        )
        
        # ç”¨æˆ·åŸå‹ç³»ç»Ÿ
        self.user_prototypes = nn.ParameterDict()
        for i in range(num_users):
            self.user_prototypes[str(i)] = nn.Parameter(torch.randn(prototype_dim))
        
        # å¯¹æ¯”å­¦ä¹ 
        self.contrastive_loss = nn.MSELoss()
        
    def update_statistics(self, latents: torch.Tensor, momentum: float = 0.99):
        """
        ä½¿ç”¨åŠ¨é‡æ›´æ–°latentåˆ†å¸ƒç»Ÿè®¡
        Args:
            latents: æœªå½’ä¸€åŒ–çš„VAE latents
            momentum: åŠ¨é‡ç³»æ•°ç”¨äºå¹³æ»‘æ›´æ–°
        """
        with torch.no_grad():
            batch_mean = latents.mean()
            batch_std = latents.std()
            
            if self.n_samples == 0:
                # é¦–æ¬¡æ›´æ–°
                self.latent_mean.copy_(batch_mean)
                self.latent_std.copy_(batch_std)
            else:
                # åŠ¨é‡æ›´æ–°
                self.latent_mean.mul_(momentum).add_(batch_mean, alpha=1-momentum)
                self.latent_std.mul_(momentum).add_(batch_std, alpha=1-momentum)
            
            self.n_samples += 1
            
    def normalize_latents(self, latents: torch.Tensor) -> torch.Tensor:
        """å½’ä¸€åŒ–latentsåˆ°N(0,1)"""
        return (latents - self.latent_mean) / (self.latent_std + 1e-8)
    
    def denormalize_latents(self, latents: torch.Tensor) -> torch.Tensor:
        """åå½’ä¸€åŒ–latentsåˆ°åŸå§‹åˆ†å¸ƒ"""
        return latents * self.latent_std + self.latent_mean
    
    def training_step(
        self, 
        latents: torch.Tensor, 
        user_ids: torch.Tensor,
        update_stats: bool = True
    ) -> dict:
        """
        è®­ç»ƒæ­¥éª¤withåˆ†å¸ƒå¯¹é½
        Args:
            latents: åŸå§‹VAEç¼–ç çš„latents
            user_ids: ç”¨æˆ·ID
            update_stats: æ˜¯å¦æ›´æ–°åˆ†å¸ƒç»Ÿè®¡
        """
        batch_size = latents.shape[0]
        
        # æ›´æ–°åˆ†å¸ƒç»Ÿè®¡
        if update_stats and self.track_statistics:
            self.update_statistics(latents)
        
        # å½’ä¸€åŒ–åˆ°N(0,1) (å¦‚æœå¯ç”¨å¯¹é½)
        if self.enable_alignment:
            normalized_latents = self.normalize_latents(latents)
        else:
            normalized_latents = latents
        
        # æ·»åŠ å™ªå£°
        noise = torch.randn_like(normalized_latents)
        timesteps = torch.randint(
            0, self.noise_scheduler.num_train_timesteps,
            (batch_size,), device=normalized_latents.device
        ).long()
        
        noisy_latents = self.noise_scheduler.add_noise(
            normalized_latents, noise, timesteps
        )
        
        # è·å–ç”¨æˆ·æ¡ä»¶
        user_conditions = self.get_user_condition(user_ids)
        
        # é¢„æµ‹å™ªå£°
        noise_pred = self.unet(
            noisy_latents,
            timesteps,
            encoder_hidden_states=user_conditions,
            return_dict=False
        )[0]
        
        # HuberæŸå¤±ï¼ˆæ¯”MSEæ›´é²æ£’ï¼‰
        diffusion_loss = F.huber_loss(noise_pred, noise, delta=1.0)
        
        # ç®€å•çš„å¯¹æ¯”æŸå¤±
        contrastive_loss = self.contrastive_loss(noise_pred.mean(dim=[1,2,3]), noise.mean(dim=[1,2,3]))
        
        total_loss = diffusion_loss + 0.1 * contrastive_loss
        
        return {
            'total_loss': total_loss,
            'diffusion_loss': diffusion_loss,
            'contrastive_loss': contrastive_loss
        }
    
    def get_user_condition(self, user_ids):
        """è·å–ç”¨æˆ·æ¡ä»¶å‘é‡"""
        # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥
        if isinstance(user_ids, torch.Tensor):
            # å¦‚æœæ˜¯tensorï¼Œè½¬æ¢ä¸ºlist
            if user_ids.dim() == 0:
                # æ ‡é‡tensor
                user_id_list = [user_ids.item()]
            else:
                # å‘é‡tensor - ç¡®ä¿æ˜¯æ•´æ•°ç±»å‹
                user_id_list = user_ids.cpu().long().tolist()
        else:
            # å¦‚æœå·²ç»æ˜¯list
            user_id_list = user_ids
        
        conditions = []
        for i, user_id in enumerate(user_id_list):
            # è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ” Debug user_id[{i}]: type={type(user_id)}, value={user_id}")
            
            # ç¡®ä¿user_idæ˜¯æ•´æ•°
            if isinstance(user_id, torch.Tensor):
                user_id = user_id.item()
                print(f"   è½¬æ¢tensorå: {user_id}")
            elif isinstance(user_id, list):
                print(f"   æ£€æµ‹åˆ°list: {user_id}")
                # å¦‚æœæ˜¯listï¼Œé€’å½’å¤„ç†
                while isinstance(user_id, list) and user_id:
                    user_id = user_id[0]
                    print(f"   é€’å½’å±•å¼€: {user_id}")
                if not user_id:
                    user_id = 1  # é»˜è®¤ç”¨æˆ·ID
            
            # ç¡®ä¿user_idæ˜¯æœ‰æ•ˆçš„æ•´æ•°
            try:
                user_id = int(user_id)
                print(f"   æœ€ç»ˆuser_id: {user_id}")
            except (ValueError, TypeError) as e:
                print(f"   âŒ è½¬æ¢é”™è¯¯: {e}, ä½¿ç”¨é»˜è®¤å€¼1")
                user_id = 1
            
            # è°ƒè¯•ä¿¡æ¯
            if str(user_id) not in self.user_prototypes:
                print(f"âŒ è­¦å‘Š: ç”¨æˆ·ID {user_id} ä¸å­˜åœ¨äºåŸå‹å­—å…¸ä¸­")
                print(f"   å¯ç”¨ç”¨æˆ·ID: {list(self.user_prototypes.keys())[:10]}...")
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„ç”¨æˆ·IDä½œä¸ºfallback
                user_id = int(list(self.user_prototypes.keys())[0])
                
            prototype = self.user_prototypes[str(user_id)]
            conditions.append(prototype)
        
        # Stack and add sequence dimension
        conditions = torch.stack(conditions).unsqueeze(1)  # [batch, 1, prototype_dim]
        return conditions
    
    def update_user_prototypes(self, user_latents_dict):
        """æ›´æ–°ç”¨æˆ·åŸå‹"""
        with torch.no_grad():
            for user_id, latents in user_latents_dict.items():
                # è®¡ç®—è¯¥ç”¨æˆ·latentsçš„å‡å€¼ä½œä¸ºåŸå‹
                prototype = latents.mean(dim=[0, 2, 3])  # å¯¹batchå’Œç©ºé—´ç»´åº¦æ±‚å‡å€¼
                self.user_prototypes[str(user_id)].data.copy_(prototype)
    
    def generate(self, user_ids, num_samples=1, num_inference_steps=50, guidance_scale=7.5):
        """ç”Ÿæˆlatents"""
        self.eval()
        device = next(self.parameters()).device
        
        with torch.no_grad():
            # å‡†å¤‡ç”¨æˆ·æ¡ä»¶
            if isinstance(user_ids, list):
                total_samples = len(user_ids) * num_samples // len(user_ids)
                user_ids_expanded = []
                for user_id in user_ids:
                    user_ids_expanded.extend([user_id] * (num_samples // len(user_ids)))
                user_ids_tensor = torch.tensor(user_ids_expanded, device=device)
            else:
                user_ids_tensor = torch.tensor([user_ids] * num_samples, device=device)
            
            # è·å–ç”¨æˆ·æ¡ä»¶
            user_conditions = self.get_user_condition(user_ids_tensor)
            
            # åˆå§‹åŒ–éšæœºå™ªå£°
            shape = (len(user_ids_tensor), 32, 16, 16)
            latents = torch.randn(shape, device=device)
            
            # è®¾ç½®è°ƒåº¦å™¨
            self.noise_scheduler.set_timesteps(num_inference_steps)
            
            # å»å™ªè¿‡ç¨‹
            for t in self.noise_scheduler.timesteps:
                # é¢„æµ‹å™ªå£°
                timesteps = t.expand(latents.shape[0]).to(device)
                noise_pred = self.unet(
                    latents,
                    timesteps,
                    encoder_hidden_states=user_conditions,
                    return_dict=False
                )[0]
                
                # å»å™ªæ­¥éª¤
                latents = self.noise_scheduler.step(
                    noise_pred, t, latents, return_dict=False
                )[0]
            
            # å¦‚æœå¯ç”¨äº†åˆ†å¸ƒå¯¹é½ï¼Œåå½’ä¸€åŒ–
            if self.enable_alignment and self.latent_std > 0:
                latents = self.denormalize_latents(latents)
            
            return latents
