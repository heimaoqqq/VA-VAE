# ğŸš€ Kaggle T4*2 åŒGPUè®­ç»ƒå®Œæ•´æŒ‡å—

## ğŸ¯ æ ¸å¿ƒå‘ç°

ç»è¿‡æ·±å…¥ç ”ç©¶ï¼Œå‘ç°Kaggleç¯å¢ƒä¸­ä½¿ç”¨åŒGPUçš„å…³é”®æ˜¯ï¼š
- âŒ **ä¸è¦ä½¿ç”¨** `accelerate launch` å‘½ä»¤
- âœ… **å¿…é¡»ä½¿ç”¨** `notebook_launcher` å‡½æ•°
- âœ… **å¿…é¡»è®¾ç½®** Kaggleç‰¹å®šçš„ç¯å¢ƒå˜é‡

## ğŸ“‹ å‰ç½®è¦æ±‚

### 1. Kaggleè®¾ç½®
- åœ¨Notebookè®¾ç½®ä¸­é€‰æ‹© **"GPU T4 x2"** åŠ é€Ÿå™¨
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„GPUé…é¢

### 2. æ•°æ®å‡†å¤‡
```
/kaggle/working/data_split/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ user1/
â”‚   â”œâ”€â”€ user2/
â”‚   â””â”€â”€ ...
â””â”€â”€ val/
    â”œâ”€â”€ user1/
    â”œâ”€â”€ user2/
    â””â”€â”€ ...
```

## ğŸ”§ ä¸€é”®è®¾ç½®

### æ­¥éª¤1: å…‹éš†é¡¹ç›®
```python
import os
os.chdir('/kaggle/working')

!git clone https://github.com/heimaoqqq/VA-VAE.git
os.chdir('/kaggle/working/VA-VAE')
!git submodule update --init --recursive
```

### æ­¥éª¤2: è¿è¡ŒKaggleä¸“ç”¨é…ç½®
```python
!python kaggle_dual_gpu_setup.py
```

### æ­¥éª¤3: éªŒè¯é…ç½®
```python
# åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¾“å‡º:
# ğŸ‰ Kaggle T4*2 é…ç½®å®Œæˆ!
# âœ… notebook_launcheræµ‹è¯•æˆåŠŸ
```

## ğŸš€ è®­ç»ƒæ–¹æ³•

### æ–¹æ³•1: å®Œæ•´æµç¨‹ (æ¨è)
```python
# ä¸€é”®è¿è¡Œå®Œæ•´çš„ä¸‰é˜¶æ®µè®­ç»ƒ
!python kaggle_training_wrapper.py complete
```

### æ–¹æ³•2: åˆ†æ­¥æ‰§è¡Œ
```python
# é˜¶æ®µ1: åŒGPUç‰¹å¾æå–
!python kaggle_training_wrapper.py stage1

# é˜¶æ®µ2: åŒGPU DiTè®­ç»ƒ  
!python kaggle_training_wrapper.py stage2

# é˜¶æ®µ3: å•GPUå›¾åƒç”Ÿæˆ
!python stage3_inference.py \
    --dit_checkpoint /kaggle/working/trained_models/best_model \
    --vavae_config vavae_config.yaml \
    --output_dir /kaggle/working/generated_images \
    --user_ids 1 2 3 4 5 \
    --num_samples_per_user 4 \
    --seed 42
```

### æ–¹æ³•3: åœ¨Notebookä¸­ç›´æ¥è°ƒç”¨
```python
# å¯¼å…¥å¹¶è¿è¡Œ
from kaggle_training_wrapper import kaggle_complete_pipeline
kaggle_complete_pipeline()
```

## ğŸ“Š ç›‘æ§åŒGPUä½¿ç”¨

### å®æ—¶GPUç›‘æ§
```python
import subprocess
import time
from IPython.display import clear_output

def monitor_kaggle_gpu(duration_minutes=10):
    """ç›‘æ§Kaggle GPUä½¿ç”¨æƒ…å†µ"""
    end_time = time.time() + duration_minutes * 60
    
    while time.time() < end_time:
        clear_output(wait=True)
        
        # è·å–GPUçŠ¶æ€
        result = subprocess.run([
            'nvidia-smi', 
            '--query-gpu=index,name,utilization.gpu,memory.used,memory.total,temperature.gpu',
            '--format=csv,noheader,nounits'
        ], capture_output=True, text=True)
        
        print(f"ğŸ• {time.strftime('%H:%M:%S')} - Kaggle GPUçŠ¶æ€")
        print("=" * 60)
        
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            for line in lines:
                parts = line.split(', ')
                if len(parts) >= 6:
                    idx, name, util, mem_used, mem_total, temp = parts[:6]
                    mem_percent = (int(mem_used) / int(mem_total)) * 100
                    print(f"GPU {idx}: {name}")
                    print(f"  ğŸ”¥ ä½¿ç”¨ç‡: {util}%")
                    print(f"  ğŸ’¾ å†…å­˜: {mem_used}MB/{mem_total}MB ({mem_percent:.1f}%)")
                    print(f"  ğŸŒ¡ï¸ æ¸©åº¦: {temp}Â°C")
                    print()
        
        print("æŒ‰ Kernel -> Interrupt åœæ­¢ç›‘æ§")
        time.sleep(5)

# åœ¨è®­ç»ƒå¼€å§‹åè¿è¡Œ
monitor_kaggle_gpu(duration_minutes=15)
```

## ğŸ¯ é¢„æœŸè¾“å‡º

### æ­£ç¡®çš„åŒGPUé…ç½®è¾“å‡º:
```
ğŸ”§ Acceleratoré…ç½®:
  è¿›ç¨‹æ•°: 2
  å½“å‰è¿›ç¨‹: 0
  è®¾å¤‡: cuda:0
  æ··åˆç²¾åº¦: fp16
  åˆ†å¸ƒå¼ç±»å‹: MULTI_GPU

è¿›ç¨‹ 0/2
è®¾å¤‡: cuda:0
åˆ†å¸ƒå¼ç±»å‹: DistributedType.MULTI_GPU

è¿›ç¨‹ 1/2  
è®¾å¤‡: cuda:1
åˆ†å¸ƒå¼ç±»å‹: DistributedType.MULTI_GPU
```

### GPUä½¿ç”¨ç‡ç›‘æ§:
```
GPU 0: Tesla T4
  ğŸ”¥ ä½¿ç”¨ç‡: 95%
  ğŸ’¾ å†…å­˜: 8234MB/15360MB (53.6%)
  ğŸŒ¡ï¸ æ¸©åº¦: 45Â°C

GPU 1: Tesla T4
  ğŸ”¥ ä½¿ç”¨ç‡: 94%
  ğŸ’¾ å†…å­˜: 8156MB/15360MB (53.1%)
  ğŸŒ¡ï¸ æ¸©åº¦: 44Â°C
```

## ğŸ” æ•…éšœæ’é™¤

### é—®é¢˜1: åªæ˜¾ç¤º1ä¸ªè¿›ç¨‹
**è§£å†³æ–¹æ¡ˆ:**
```python
# é‡å¯Notebookå†…æ ¸ (Kernel -> Restart & Clear Output)
# é‡æ–°è¿è¡Œé…ç½®
!python kaggle_dual_gpu_setup.py
```

### é—®é¢˜2: NCCLé€šä¿¡é”™è¯¯
**è§£å†³æ–¹æ¡ˆ:**
```python
# å·²è‡ªåŠ¨è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:
# NCCL_P2P_DISABLE=1
# NCCL_IB_DISABLE=1
# è¿™äº›è®¾ç½®ä¸“é—¨é’ˆå¯¹Kaggle T4ç¯å¢ƒ
```

### é—®é¢˜3: å†…å­˜ä¸è¶³
**è§£å†³æ–¹æ¡ˆ:**
```python
# å‡å°‘æ‰¹æ¬¡å¤§å°
# åœ¨kaggle_training_wrapper.pyä¸­ä¿®æ”¹:
# batch_size = 8  # ä»16æ”¹ä¸º8
```

### é—®é¢˜4: å¯¼å…¥é”™è¯¯
**è§£å†³æ–¹æ¡ˆ:**
```python
# ç¡®ä¿åœ¨æ­£ç¡®ç›®å½•
import os
os.chdir('/kaggle/working/VA-VAE')

# æ·»åŠ è·¯å¾„
import sys
sys.path.append('/kaggle/working/VA-VAE')
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### Kaggle T4*2 ä¼˜åŒ–è®¾ç½®:
- **æ‰¹æ¬¡å¤§å°**: æ¯GPU 16 (æ€»è®¡32)
- **æ··åˆç²¾åº¦**: FP16
- **æ¢¯åº¦ç´¯ç§¯**: 1æ­¥
- **å­¦ä¹ ç‡**: 1e-4
- **ä¼˜åŒ–å™¨**: AdamW

### é¢„æœŸè®­ç»ƒæ—¶é—´:
- **ç‰¹å¾æå–**: ~10åˆ†é’Ÿ (4000æ ·æœ¬)
- **DiTè®­ç»ƒ**: ~2å°æ—¶ (50è½®)
- **å›¾åƒç”Ÿæˆ**: ~5åˆ†é’Ÿ (40å¼ å›¾åƒ)

## ğŸ‰ æˆåŠŸæ ‡å¿—

è®­ç»ƒæˆåŠŸçš„æ ‡å¿—:
- âœ… ä¸¤ä¸ªGPUéƒ½æœ‰é«˜ä½¿ç”¨ç‡ (>90%)
- âœ… å†…å­˜ä½¿ç”¨å‡åŒ€åˆ†å¸ƒ
- âœ… è®­ç»ƒæŸå¤±æ­£å¸¸ä¸‹é™
- âœ… æ²¡æœ‰NCCLæˆ–åˆ†å¸ƒå¼é”™è¯¯
- âœ… ç”Ÿæˆçš„å›¾åƒè´¨é‡è‰¯å¥½

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜:
1. æ£€æŸ¥KaggleåŠ é€Ÿå™¨è®¾ç½® (å¿…é¡»æ˜¯GPU T4 x2)
2. ç¡®è®¤æ•°æ®è·¯å¾„æ­£ç¡®
3. é‡å¯Notebookå†…æ ¸
4. é‡æ–°è¿è¡Œé…ç½®è„šæœ¬
5. æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—

---

**å…³é”®æé†’**: Kaggleç¯å¢ƒä¸æœ¬åœ°ç¯å¢ƒä¸åŒï¼Œå¿…é¡»ä½¿ç”¨`notebook_launcher`è€Œä¸æ˜¯`accelerate launch`ï¼

ç°åœ¨æ‚¨å¯ä»¥åœ¨Kaggleä¸Šäº«å—çœŸæ­£çš„åŒGPUåˆ†å¸ƒå¼è®­ç»ƒäº†ï¼ğŸš€
