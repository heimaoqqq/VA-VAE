#!/usr/bin/env python3
"""
åˆ†å¸ƒå¼å¾®å¤šæ™®å‹’å›¾åƒç”Ÿæˆè„šæœ¬
åŸºäºåŸé¡¹ç›®inference.pyï¼Œæ”¯æŒåŒGPUæ¨ç†
"""

import torch
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
import argparse
import os
from pathlib import Path
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
from tqdm import tqdm
import math

# å¯¼å…¥LightningDiTç»„ä»¶
import sys
import os

# ç¡®ä¿æ­£ç¡®çš„è·¯å¾„è®¾ç½®
current_dir = os.path.dirname(os.path.abspath(__file__))
lightningdit_path = os.path.join(current_dir, 'LightningDiT')
if lightningdit_path not in sys.path:
    sys.path.insert(0, lightningdit_path)

from models.lightningdit import LightningDiT_models
from transport import create_transport
from tokenizer.vavae import VA_VAE

def main(accelerator):
    """åˆ†å¸ƒå¼æ¨ç†ä¸»å‡½æ•°"""
    
    # è§£æå‚æ•°
    parser = argparse.ArgumentParser(description='åˆ†å¸ƒå¼å¾®å¤šæ™®å‹’å›¾åƒç”Ÿæˆ')
    parser.add_argument('--dit_checkpoint', type=str, required=True, help='DiTæ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--vavae_config', type=str, required=True, help='VA-VAEé…ç½®æ–‡ä»¶')
    parser.add_argument('--output_dir', type=str, required=True, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--user_ids', type=int, nargs='+', required=True, help='ç”¨æˆ·IDåˆ—è¡¨')
    parser.add_argument('--num_samples_per_user', type=int, default=4, help='æ¯ç”¨æˆ·æ ·æœ¬æ•°')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--guidance_scale', type=float, default=4.0, help='å¼•å¯¼å°ºåº¦')
    parser.add_argument('--num_steps', type=int, default=250, help='é‡‡æ ·æ­¥æ•°')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    seed = args.seed * accelerator.num_processes + accelerator.process_index
    torch.manual_seed(seed)
    
    if accelerator.is_main_process:
        print("ğŸ¯ åˆ†å¸ƒå¼å¾®å¤šæ™®å‹’å›¾åƒç”Ÿæˆ")
        print("=" * 60)
        print(f"ğŸ”§ Acceleratoré…ç½®:")
        print(f"  è¿›ç¨‹æ•°: {accelerator.num_processes}")
        print(f"  å½“å‰è¿›ç¨‹: {accelerator.process_index}")
        print(f"  è®¾å¤‡: {accelerator.device}")
        print(f"  éšæœºç§å­: {seed}")
    
    device = accelerator.device
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    if accelerator.is_main_process:
        output_dir.mkdir(parents=True, exist_ok=True)
    accelerator.wait_for_everyone()
    
    # åŠ è½½VA-VAE
    if accelerator.is_main_process:
        print("ğŸ“¥ åŠ è½½VA-VAE...")
    vavae = VA_VAE(args.vavae_config)
    
    # åŠ è½½DiTæ¨¡å‹
    if accelerator.is_main_process:
        print("ğŸ“¥ åŠ è½½DiTæ¨¡å‹...")
    
    model = LightningDiT_models['LightningDiT-B/1'](
        input_size=16,
        num_classes=len(args.user_ids),
        use_rope=True,
        use_rmsnorm=True,
        wo_shift=False
    )
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint_path = Path(args.dit_checkpoint)
    if checkpoint_path.exists():
        if accelerator.is_main_process:
            print(f"ğŸ“¥ åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ£€æŸ¥ç‚¹æ ¼å¼è°ƒæ•´
        # checkpoint = torch.load(checkpoint_path / "pytorch_model.bin", map_location="cpu")
        # model.load_state_dict(checkpoint)
    else:
        if accelerator.is_main_process:
            print("âš ï¸  æ£€æŸ¥ç‚¹ä¸å­˜åœ¨ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
    
    model.eval()
    model.to(device)
    
    # åˆ›å»ºtransport
    transport = create_transport(
        path_type="Linear",
        prediction="velocity",
        loss_weight=None,
        train_eps=None,
        sample_eps=None,
    )
    
    # è®¡ç®—æ¯ä¸ªGPUéœ€è¦ç”Ÿæˆçš„æ ·æœ¬æ•°
    total_samples = len(args.user_ids) * args.num_samples_per_user
    samples_per_gpu = math.ceil(total_samples / accelerator.num_processes)
    
    if accelerator.is_main_process:
        print(f"ğŸ“Š ç”Ÿæˆé…ç½®:")
        print(f"  ç”¨æˆ·æ•°: {len(args.user_ids)}")
        print(f"  æ¯ç”¨æˆ·æ ·æœ¬æ•°: {args.num_samples_per_user}")
        print(f"  æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"  æ¯GPUæ ·æœ¬æ•°: {samples_per_gpu}")
    
    # åˆ†å¸ƒå¼ç”Ÿæˆ
    generated_images = []
    user_labels = []
    
    with torch.no_grad():
        # è®¡ç®—å½“å‰GPUè´Ÿè´£çš„ç”¨æˆ·èŒƒå›´
        start_idx = accelerator.process_index * samples_per_gpu
        end_idx = min(start_idx + samples_per_gpu, total_samples)
        
        current_sample = 0
        for user_id in args.user_ids:
            for sample_idx in range(args.num_samples_per_user):
                global_idx = len(args.user_ids) * sample_idx + (user_id - 1)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å½“å‰GPUè´Ÿè´£çš„æ ·æœ¬
                if global_idx < start_idx or global_idx >= end_idx:
                    continue
                
                if accelerator.is_main_process:
                    print(f"ğŸ¨ ç”Ÿæˆç”¨æˆ· {user_id} æ ·æœ¬ {sample_idx + 1}")
                
                # å‡†å¤‡æ¡ä»¶
                y = torch.tensor([user_id - 1], dtype=torch.long, device=device)  # 0-based
                
                # ç”Ÿæˆéšæœºå™ªå£°
                z = torch.randn(1, 32, 16, 16, device=device)
                
                # ç®€å•çš„é‡‡æ ·ï¼ˆè¿™é‡Œå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„é‡‡æ ·æ–¹æ³•ï¼‰
                model_kwargs = dict(y=y)
                
                # ç®€å•çš„æ¬§æ‹‰é‡‡æ ·
                dt = 1.0 / args.num_steps
                x = z.clone()
                
                for step in range(args.num_steps):
                    t = torch.full((x.shape[0],), step * dt, device=device)
                    
                    # æ¨¡å‹é¢„æµ‹
                    pred = model(x, t, **model_kwargs)
                    
                    # æ¬§æ‹‰æ­¥éª¤
                    x = x + pred * dt
                
                # è§£ç ä¸ºå›¾åƒ
                latent_features = x
                images = vavae.decode_to_images(latent_features)
                
                # ä¿å­˜å›¾åƒ
                for i, image in enumerate(images):
                    filename = f"user_{user_id}_sample_{sample_idx + 1}_gpu_{accelerator.process_index}.png"
                    Image.fromarray(image).save(output_dir / filename)
                    generated_images.append(image)
                    user_labels.append(user_id)
                
                current_sample += 1
    
    # ç­‰å¾…æ‰€æœ‰GPUå®Œæˆ
    accelerator.wait_for_everyone()
    
    if accelerator.is_main_process:
        print("âœ… åˆ†å¸ƒå¼æ¨ç†å®Œæˆ!")
        print(f"ğŸ“ å›¾åƒä¿å­˜åœ¨: {output_dir}")
        
        # ç»Ÿè®¡ç”Ÿæˆçš„å›¾åƒæ•°é‡
        png_files = list(output_dir.glob("*.png"))
        print(f"ğŸ“Š æ€»å…±ç”Ÿæˆäº† {len(png_files)} å¼ å›¾åƒ")

if __name__ == "__main__":
    from accelerate import Accelerator
    accelerator = Accelerator()
    main(accelerator)
