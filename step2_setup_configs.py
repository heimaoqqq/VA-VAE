#!/usr/bin/env python3
"""
æ­¥éª¤2: è®¾ç½®é…ç½®æ–‡ä»¶
ä¸¥æ ¼æŒ‰ç…§LightningDiT READMEå’Œtutorialæ­¥éª¤
"""

import os
import yaml
from pathlib import Path

def create_inference_config():
    """åˆ›å»ºæ¨ç†é…ç½®æ–‡ä»¶ - åŸºäºå®˜æ–¹reproductionsé…ç½®"""
    
    config_path = "inference_config.yaml"
    models_dir = Path("./official_models")
    
    # åŸºäºå®˜æ–¹configs/reproductions/lightningdit_xl_vavae_f16d32_800ep_cfg.yaml
    config = {
        'ckpt_path': str(models_dir / "lightningdit-xl-imagenet256-800ep.pt"),
        'data': {
            'data_path': str(models_dir / "latents_stats.pt"),
            'fid_reference_file': 'path/to/your/VIRTUAL_imagenet256_labeled.npz',
            'image_size': 256,
            'num_classes': 1000,
            'num_workers': 8,
            'latent_norm': True,
            'latent_multiplier': 1.0
        },
        'vae': {
            'model_name': 'vavae_f16d32',
            'downsample_ratio': 16
        },
        'model': {
            'model_type': 'LightningDiT-XL/1',
            'use_qknorm': False,
            'use_swiglu': True,
            'use_rope': True,
            'use_rmsnorm': True,
            'wo_shift': False,
            'in_chans': 32
        },
        'train': {
            'max_steps': 80000,
            'global_batch_size': 1024,
            'global_seed': 0,  # è¿™æ˜¯ç¼ºå¤±çš„å…³é”®å­—æ®µ
            'output_dir': 'output',
            'exp_name': 'lightningdit_xl_vavae_f16d32',
            'ckpt': None,
            'log_every': 100,
            'ckpt_every': 20000
        },
        'optimizer': {
            'lr': 0.0002,
            'beta2': 0.95
        },
        'transport': {
            'path_type': 'Linear',
            'prediction': 'velocity',
            'loss_weight': None,
            'sample_eps': None,
            'train_eps': None,
            'use_cosine_loss': True,
            'use_lognorm': True
        },
        'sample': {
            'mode': 'ODE',
            'sampling_method': 'euler',
            'atol': 0.000001,
            'rtol': 0.001,
            'reverse': False,
            'likelihood': False,
            'num_sampling_steps': 250,
            'cfg_scale': 6.7,  # å®˜æ–¹800epæ¨¡å‹ä½¿ç”¨6.7
            'per_proc_batch_size': 4,
            'cfg_interval_start': 0.125,
            'timestep_shift': 0.3
        }
    }
    
    with open(config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, indent=2)
    
    print(f"âœ… æ¨ç†é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_path}")
    return config_path

def update_vavae_config():
    """æ›´æ–°VA-VAEé…ç½® - å®˜æ–¹tutorialè¦æ±‚çš„æ­¥éª¤"""
    
    vavae_config_path = "LightningDiT/tokenizer/configs/vavae_f16d32.yaml"
    models_dir = Path("./official_models")
    
    if not os.path.exists(vavae_config_path):
        print(f"âŒ VA-VAEé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {vavae_config_path}")
        return False
    
    # è¯»å–ç°æœ‰é…ç½®
    with open(vavae_config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # æ›´æ–°æ£€æŸ¥ç‚¹è·¯å¾„ (å®˜æ–¹tutorialæ­¥éª¤)
    old_path = config.get('ckpt_path', 'N/A')
    new_path = str(models_dir / "vavae-imagenet256-f16d32-dinov2.pt")
    config['ckpt_path'] = new_path
    
    # ä¿å­˜æ›´æ–°åçš„é…ç½®
    with open(vavae_config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, indent=2)
    
    print(f"âœ… VA-VAEé…ç½®å·²æ›´æ–°:")
    print(f"   æ—§è·¯å¾„: {old_path}")
    print(f"   æ–°è·¯å¾„: {new_path}")
    
    return True

def main():
    """æ­¥éª¤2: è®¾ç½®é…ç½®æ–‡ä»¶"""
    
    print("âš™ï¸ æ­¥éª¤2: è®¾ç½®é…ç½®æ–‡ä»¶")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    models_dir = Path("./official_models")
    required_files = [
        "vavae-imagenet256-f16d32-dinov2.pt",
        "lightningdit-xl-imagenet256-800ep.pt",
        "latents_stats.pt"
    ]
    
    missing_files = []
    for filename in required_files:
        if not (models_dir / filename).exists():
            missing_files.append(filename)
    
    if missing_files:
        print("âŒ ç¼ºå°‘æ¨¡å‹æ–‡ä»¶:")
        for filename in missing_files:
            print(f"   - {filename}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ: python step1_download_models.py")
        return
    
    print("âœ… æ‰€æœ‰æ¨¡å‹æ–‡ä»¶å·²å­˜åœ¨")
    
    # åˆ›å»ºæ¨ç†é…ç½®æ–‡ä»¶
    print("\nğŸ“ åˆ›å»ºæ¨ç†é…ç½®æ–‡ä»¶...")
    config_path = create_inference_config()
    
    # æ›´æ–°VA-VAEé…ç½®
    print("\nğŸ”§ æ›´æ–°VA-VAEé…ç½®...")
    if update_vavae_config():
        print("\nâœ… æ­¥éª¤2å®Œæˆï¼é…ç½®æ–‡ä»¶å·²è®¾ç½®")
        print(f"ğŸ“„ æ¨ç†é…ç½®: {config_path}")
        print("ğŸ“„ VA-VAEé…ç½®: LightningDiT/tokenizer/configs/vavae_f16d32.yaml")
        print("\nğŸ¯ ä¸‹ä¸€æ­¥: è¿è¡Œ python step3_run_inference.py")
    else:
        print("\nâŒ VA-VAEé…ç½®æ›´æ–°å¤±è´¥")

if __name__ == "__main__":
    main()
