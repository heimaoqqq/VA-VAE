#!/usr/bin/env python3
"""
NCC è¡¥å……è¯„ä¼°
åªè¯„ä¼°ç¼ºå¤±çš„ NCC å’Œ LCCS+NCCï¼Œå¿«é€Ÿæµ‹è¯•temperature
"""

import torch
import pandas as pd
import json
from pathlib import Path
from tqdm import tqdm
from itertools import product
import sys
from torch.utils.data import DataLoader
import torchvision.transforms as transforms

sys.path.append(str(Path(__file__).parent))
from eval_utils import *
from eval_components import *
from strategic_dataset import StrategicDataset


def main():
    import argparse
    parser = argparse.ArgumentParser(description='NCCè¡¥å……è¯„ä¼°')
    parser.add_argument('--model-path', type=str,
                       default='/kaggle/working/VA-VAE/improved_classifier/best_improved_classifier.pth')
    parser.add_argument('--data-dir', type=str,
                       default='/kaggle/input/backpack/backpack')
    parser.add_argument('--output-dir', type=str,
                       default='./ncc_supplement_results')
    
    args = parser.parse_args()
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    output_path = Path(args.output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print("\n" + "="*80)
    print("ğŸ” NCC è¡¥å……è¯„ä¼°ï¼ˆåªè¯„ä¼°ç¼ºå¤±éƒ¨åˆ†ï¼‰")
    print("="*80)
    
    # æœ€ä½³é…ç½®
    best_strategy = 'diversity'
    best_lccs = {
        'momentum': 0.02,
        'iterations': 10
    }
    
    # æµ‹è¯•temperatureï¼ˆå¿«é€Ÿç­›é€‰ï¼‰
    temperatures = [0.005, 0.01, 0.05]
    
    print(f"\nğŸ“‹ å·²æœ‰è¯„ä¼°ç»“æœ:")
    print(f"  âœ… Baseline:       ~75%")
    print(f"  âœ… LCCS+Baseline:  ~79.44%")
    print(f"  âœ… PNC:            ~87.47%")
    print(f"  âœ… LCCS+PNC:       87.81-88.51%")
    
    print(f"\nğŸ“‹ å¾…è¯„ä¼°:")
    print(f"  âŒ NCC (æµ‹è¯• {len(temperatures)} ä¸ªtemperature)")
    print(f"  âŒ LCCS+NCC")
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ“¦ åŠ è½½åˆ†ç±»å™¨...")
    model = load_classifier(args.model_path, device)
    model.device = device
    
    # æµ‹è¯•é…ç½®ï¼ˆå…ˆç”¨support=3å¿«é€Ÿæµ‹è¯•ï¼‰
    support_sizes = [3]  # å…ˆåªæµ‹è¯•æœ€ä½³çš„support_size
    seeds = [42, 123, 456]
    
    results = []
    
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # æ€»å®éªŒæ•°
    total = len(support_sizes) * len(seeds) * (len(temperatures) + 1)  # NCCæ¸©åº¦æµ‹è¯• + LCCS+NCC
    
    print(f"\næ€»å…± {total} ä¸ªå®éªŒ")
    
    # ç¬¬ä¸€é˜¶æ®µï¼šæµ‹è¯•NCCçš„temperature
    print("\n" + "="*80)
    print("ğŸ“Š é˜¶æ®µ1: NCC Temperature æµ‹è¯•")
    print("="*80)
    
    ncc_temp_results = []
    
    with tqdm(total=len(temperatures) * len(support_sizes) * len(seeds), 
              desc="NCC Temp Test") as pbar:
        for support_size, seed, temp in product(support_sizes, seeds, temperatures):
            # åˆ›å»ºæ•°æ®é›†
            support_dataset = StrategicDataset(
                data_dir=args.data_dir,
                support_size=support_size,
                strategy=best_strategy,
                model=model,
                mode='support',
                seed=seed,
                device=device,
                transform=transform
            )
            
            test_dataset = StrategicDataset(
                data_dir=args.data_dir,
                support_size=support_size,
                strategy=best_strategy,
                model=model,
                mode='test',
                seed=seed,
                device=device,
                transform=transform
            )
            
            support_loader = DataLoader(support_dataset, batch_size=64, 
                                       shuffle=False, num_workers=0)
            test_loader = DataLoader(test_dataset, batch_size=64, 
                                    shuffle=False, num_workers=0)
            
            # æå–ç‰¹å¾å’Œæ„å»ºåŸå‹
            features, labels = extract_features(model, support_loader, device)
            prototypes = build_prototypes_simple_mean(features, labels)
            
            # NCCè¯„ä¼°
            ncc = NCCEvaluator(prototypes, device)
            ncc_acc, ncc_conf = ncc.predict(
                model, test_loader, 
                temperature=temp, 
                distance_metric='cosine'
            )
            
            ncc_temp_results.append({
                'method': 'NCC',
                'temperature': temp,
                'support_size': support_size,
                'seed': seed,
                'accuracy': ncc_acc,
                'confidence': ncc_conf
            })
            
            pbar.update(1)
    
    # æ‰¾æœ€ä½³temperature
    temp_df = pd.DataFrame(ncc_temp_results)
    best_temp_acc = {}
    for temp in temperatures:
        avg_acc = temp_df[temp_df['temperature']==temp]['accuracy'].mean()
        best_temp_acc[temp] = avg_acc
        print(f"  Temperature={temp}: å¹³å‡å‡†ç¡®ç‡={avg_acc:.4f}")
    
    best_temp = max(best_temp_acc, key=best_temp_acc.get)
    print(f"\nâœ¨ æœ€ä½³ Temperature: {best_temp} (å‡†ç¡®ç‡: {best_temp_acc[best_temp]:.4f})")
    
    # ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨æœ€ä½³temperatureè¯„ä¼°LCCS+NCC
    print("\n" + "="*80)
    print("ğŸ“Š é˜¶æ®µ2: LCCS+NCC è¯„ä¼°ï¼ˆä½¿ç”¨æœ€ä½³temperatureï¼‰")
    print("="*80)
    
    lccs_ncc_results = []
    
    # æµ‹è¯•æ‰€æœ‰support_size
    all_support_sizes = [3, 5, 10]
    
    with tqdm(total=len(all_support_sizes) * len(seeds), 
              desc="LCCS+NCC") as pbar:
        for support_size, seed in product(all_support_sizes, seeds):
            # åˆ›å»ºæ•°æ®é›†
            support_dataset = StrategicDataset(
                data_dir=args.data_dir,
                support_size=support_size,
                strategy=best_strategy,
                model=model,
                mode='support',
                seed=seed,
                device=device,
                transform=transform
            )
            
            test_dataset = StrategicDataset(
                data_dir=args.data_dir,
                support_size=support_size,
                strategy=best_strategy,
                model=model,
                mode='test',
                seed=seed,
                device=device,
                transform=transform
            )
            
            support_loader = DataLoader(support_dataset, batch_size=64, 
                                       shuffle=False, num_workers=0)
            test_loader = DataLoader(test_dataset, batch_size=64, 
                                    shuffle=False, num_workers=0)
            
            # LCCSé€‚åº”
            lccs = LCCSAdapter(model, device)
            lccs.adapt_progressive(
                support_loader,
                momentum=best_lccs['momentum'],
                iterations=best_lccs['iterations']
            )
            
            # åœ¨LCCSé€‚åº”åé‡æ–°æå–ç‰¹å¾å’Œæ„å»ºåŸå‹
            features_lccs, labels_lccs = extract_features(model, support_loader, device)
            prototypes_lccs = build_prototypes_simple_mean(features_lccs, labels_lccs)
            
            # LCCS+NCCè¯„ä¼°ï¼ˆä½¿ç”¨æœ€ä½³temperatureï¼‰
            ncc_lccs = NCCEvaluator(prototypes_lccs, device)
            lccs_ncc_acc, lccs_ncc_conf = ncc_lccs.predict(
                model, test_loader,
                temperature=best_temp,
                distance_metric='cosine'
            )
            
            lccs_ncc_results.append({
                'method': 'LCCS+NCC',
                'temperature': best_temp,
                'support_size': support_size,
                'seed': seed,
                'accuracy': lccs_ncc_acc,
                'confidence': lccs_ncc_conf
            })
            
            print(f"  Support={support_size}, Seed={seed}: {lccs_ncc_acc:.4f}")
            
            # æ¢å¤BN
            lccs.restore_bn_stats()
            
            pbar.update(1)
    
    # ä¿å­˜æ‰€æœ‰ç»“æœ
    all_results = ncc_temp_results + lccs_ncc_results
    results_df = pd.DataFrame(all_results)
    results_df.to_csv(output_path / 'ncc_results.csv', index=False)
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print("\n" + "="*80)
    print("ğŸ“Š æœ€ç»ˆå¯¹æ¯”æŠ¥å‘Š")
    print("="*80)
    
    # NCCç»“æœï¼ˆä½¿ç”¨æœ€ä½³temperatureï¼‰
    ncc_best = temp_df[temp_df['temperature']==best_temp]
    ncc_mean = ncc_best['accuracy'].mean()
    
    # LCCS+NCCç»“æœ
    lccs_ncc_df = pd.DataFrame(lccs_ncc_results)
    
    print("\næ€»ä½“å¹³å‡:")
    print("-" * 80)
    print(f"  Baseline:       ~75.00%")
    print(f"  LCCS+Baseline:  ~79.44%")
    print(f"  NCC:            {ncc_mean:.4f} (temperature={best_temp})")
    print(f"  PNC:            ~87.47%")
    
    # æŒ‰support_sizeåˆ†ç»„
    print("\nLCCS+NCC (æŒ‰ Support Size):")
    for size in [3, 5, 10]:
        subset = lccs_ncc_df[lccs_ncc_df['support_size']==size]
        mean_acc = subset['accuracy'].mean()
        print(f"  Support={size}: {mean_acc:.4f}")
    
    print(f"\n  LCCS+PNC:       87.81-88.51%")
    
    # å…³é”®å¯¹æ¯”
    print("\nå…³é”®å¯¹æ¯”:")
    print("-" * 80)
    lccs_ncc_mean = lccs_ncc_df['accuracy'].mean()
    print(f"  NCC vs PNC:           {ncc_mean:.4f} vs 87.47% (å·®å¼‚: {87.47-ncc_mean:+.4f})")
    print(f"  LCCS+NCC vs LCCS+PNC: {lccs_ncc_mean:.4f} vs 88.16% (å·®å¼‚: {88.16-lccs_ncc_mean:+.4f})")
    
    # ä¿å­˜æ€»ç»“
    summary = {
        'ncc': {
            'best_temperature': best_temp,
            'accuracy': float(ncc_mean),
            'temperature_comparison': {float(k): float(v) for k, v in best_temp_acc.items()}
        },
        'lccs_ncc': {
            'mean_accuracy': float(lccs_ncc_mean),
            'by_support_size': {
                str(size): float(lccs_ncc_df[lccs_ncc_df['support_size']==size]['accuracy'].mean())
                for size in [3, 5, 10]
            }
        },
        'comparison': {
            'NCC_vs_PNC': float(87.47 - ncc_mean),
            'LCCS_NCC_vs_LCCS_PNC': float(88.16 - lccs_ncc_mean)
        }
    }
    
    with open(output_path / 'summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")
    print(f"   - ncc_results.csv")
    print(f"   - summary.json")
    
    print("\n" + "="*80)
    print("âœ… è¡¥å……è¯„ä¼°å®Œæˆï¼")
    print("="*80)


if __name__ == '__main__':
    main() 
