#!/usr/bin/env python3
"""
NCC å®Œæ•´è¶…å‚æ•°è°ƒä¼˜
æµ‹è¯•æ‰€æœ‰å‚æ•°ç»„åˆï¼Œæ‰¾åˆ°NCCçš„æé™æ€§èƒ½
"""

import torch
import pandas as pd
import json
from pathlib import Path
from tqdm import tqdm
from itertools import product
import sys
from torch.utils.data import DataLoader
import torchvision.transforms as transforms

sys.path.append(str(Path(__file__).parent))
from eval_utils import *
from eval_components import *
from strategic_dataset import StrategicDataset


def main():
    import argparse
    parser = argparse.ArgumentParser(description='NCCå®Œæ•´è¶…å‚æ•°è°ƒä¼˜')
    parser.add_argument('--model-path', type=str,
                       default='/kaggle/working/VA-VAE/improved_classifier/best_improved_classifier.pth')
    parser.add_argument('--data-dir', type=str,
                       default='/kaggle/input/backpack/backpack')
    parser.add_argument('--output-dir', type=str,
                       default='./ncc_tuning_results')
    
    args = parser.parse_args()
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    output_path = Path(args.output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print("\n" + "="*80)
    print("ğŸ¯ NCC å®Œæ•´è¶…å‚æ•°è°ƒä¼˜")
    print("="*80)
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ“¦ åŠ è½½åˆ†ç±»å™¨...")
    model = load_classifier(args.model_path, device)
    model.device = device
    
    # è¶…å‚æ•°æœç´¢ç©ºé—´
    strategies = ['diversity']  # å·²çŸ¥æœ€ä½³
    support_sizes = [3, 5, 10]
    seeds = [42, 123, 456]
    
    # NCCè¶…å‚æ•°
    temperatures = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
    distance_metrics = ['cosine', 'euclidean']
    prototype_methods = ['simple_mean', 'weighted_mean']
    
    # LCCSå‚æ•°ï¼ˆå·²çŸ¥æœ€ä½³ï¼‰
    lccs_config = {
        'momentum': 0.02,
        'iterations': 10
    }
    
    total_configs = (len(temperatures) * len(distance_metrics) * 
                    len(prototype_methods) * len(support_sizes) * len(seeds))
    
    print(f"\nè¶…å‚æ•°æœç´¢ç©ºé—´:")
    print(f"  Temperature: {temperatures}")
    print(f"  Distance: {distance_metrics}")
    print(f"  Prototype: {prototype_methods}")
    print(f"  Support sizes: {support_sizes}")
    print(f"  Seeds: {seeds}")
    print(f"\næ€»è®¡: {total_configs} ä¸ªNCCé…ç½®")
    print(f"æ¯ä¸ªé…ç½®æµ‹è¯•: NCC å’Œ LCCS+NCC")
    print(f"æ€»å®éªŒæ•°: {total_configs * 2}")
    
    results = []
    
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    with tqdm(total=total_configs * 2, desc="NCC Tuning") as pbar:
        for (temp, metric, proto_method, support_size, seed) in product(
            temperatures, distance_metrics, prototype_methods, 
            support_sizes, seeds
        ):
            # åˆ›å»ºæ•°æ®é›†
            support_dataset = StrategicDataset(
                data_dir=args.data_dir,
                support_size=support_size,
                strategy='diversity',
                model=model,
                mode='support',
                seed=seed,
                device=device,
                transform=transform
            )
            
            test_dataset = StrategicDataset(
                data_dir=args.data_dir,
                support_size=support_size,
                strategy='diversity',
                model=model,
                mode='test',
                seed=seed,
                device=device,
                transform=transform
            )
            
            support_loader = DataLoader(support_dataset, batch_size=64, 
                                       shuffle=False, num_workers=0)
            test_loader = DataLoader(test_dataset, batch_size=64, 
                                    shuffle=False, num_workers=0)
            
            # æ„å»ºåŸå‹ï¼ˆæ ¹æ®æ–¹æ³•ï¼‰
            if proto_method == 'simple_mean':
                features, labels = extract_features(model, support_loader, device)
                prototypes = build_prototypes_simple_mean(features, labels)
            else:  # weighted_mean
                prototypes = build_prototypes_weighted(model, support_loader, device)
            
            # ========== 1. NCCï¼ˆæ— LCCSï¼‰==========
            ncc = NCCEvaluator(prototypes, device)
            ncc_acc, ncc_conf = ncc.predict(
                model, test_loader,
                temperature=temp,
                distance_metric=metric
            )
            
            results.append({
                'method': 'NCC',
                'temperature': temp,
                'distance_metric': metric,
                'prototype_method': proto_method,
                'support_size': support_size,
                'seed': seed,
                'accuracy': ncc_acc,
                'confidence': ncc_conf,
                'lccs_applied': False
            })
            
            pbar.update(1)
            
            # ========== 2. LCCS+NCC ==========
            lccs = LCCSAdapter(model, device)
            lccs.adapt_progressive(
                support_loader,
                momentum=lccs_config['momentum'],
                iterations=lccs_config['iterations']
            )
            
            # é‡æ–°æ„å»ºåŸå‹ï¼ˆåœ¨LCCSé€‚åº”åï¼‰
            if proto_method == 'simple_mean':
                features_lccs, labels_lccs = extract_features(model, support_loader, device)
                prototypes_lccs = build_prototypes_simple_mean(features_lccs, labels_lccs)
            else:
                prototypes_lccs = build_prototypes_weighted(model, support_loader, device)
            
            ncc_lccs = NCCEvaluator(prototypes_lccs, device)
            lccs_ncc_acc, lccs_ncc_conf = ncc_lccs.predict(
                model, test_loader,
                temperature=temp,
                distance_metric=metric
            )
            
            results.append({
                'method': 'LCCS+NCC',
                'temperature': temp,
                'distance_metric': metric,
                'prototype_method': proto_method,
                'support_size': support_size,
                'seed': seed,
                'accuracy': lccs_ncc_acc,
                'confidence': lccs_ncc_conf,
                'lccs_applied': True
            })
            
            # æ¢å¤BN
            lccs.restore_bn_stats()
            
            pbar.update(1)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    df = pd.DataFrame(results)
    df.to_csv(output_path / 'ncc_tuning_detailed.csv', index=False)
    
    # ==================== åˆ†æç»“æœ ====================
    print("\n" + "="*80)
    print("ğŸ“Š è¶…å‚æ•°è°ƒä¼˜ç»“æœåˆ†æ")
    print("="*80)
    
    # 1. NCCæœ€ä½³é…ç½®
    print("\nã€NCCã€‘æœ€ä½³é…ç½®:")
    print("-" * 80)
    ncc_df = df[df['method'] == 'NCC']
    best_ncc = ncc_df.loc[ncc_df['accuracy'].idxmax()]
    print(f"  âœ¨ æœ€é«˜å‡†ç¡®ç‡: {best_ncc['accuracy']:.4f}")
    print(f"  âœ¨ å¹³å‡ç½®ä¿¡åº¦: {best_ncc['confidence']:.4f}")
    print(f"  Temperature: {best_ncc['temperature']}")
    print(f"  Distance metric: {best_ncc['distance_metric']}")
    print(f"  Prototype method: {best_ncc['prototype_method']}")
    print(f"  Support size: {best_ncc['support_size']}")
    print(f"  Seed: {best_ncc['seed']}")
    
    # NCCå¹³å‡æ€§èƒ½ï¼ˆæŒ‰é…ç½®åˆ†ç»„ï¼‰
    print("\nã€NCCã€‘æŒ‰è¶…å‚æ•°å¹³å‡æ€§èƒ½:")
    print("-" * 80)
    
    # æŒ‰temperature
    print("\n  Temperature:")
    for temp in temperatures:
        subset = ncc_df[ncc_df['temperature'] == temp]
        avg_acc = subset['accuracy'].mean()
        avg_conf = subset['confidence'].mean()
        print(f"    {temp:6.3f}: Acc={avg_acc:.4f}, Conf={avg_conf:.4f}")
    
    # æŒ‰distance_metric
    print("\n  Distance Metric:")
    for metric in distance_metrics:
        subset = ncc_df[ncc_df['distance_metric'] == metric]
        avg_acc = subset['accuracy'].mean()
        avg_conf = subset['confidence'].mean()
        print(f"    {metric:10s}: Acc={avg_acc:.4f}, Conf={avg_conf:.4f}")
    
    # æŒ‰prototype_method
    print("\n  Prototype Method:")
    for method in prototype_methods:
        subset = ncc_df[ncc_df['prototype_method'] == method]
        avg_acc = subset['accuracy'].mean()
        avg_conf = subset['confidence'].mean()
        print(f"    {method:15s}: Acc={avg_acc:.4f}, Conf={avg_conf:.4f}")
    
    # 2. LCCS+NCCæœ€ä½³é…ç½®
    print("\n" + "="*80)
    print("ã€LCCS+NCCã€‘æœ€ä½³é…ç½®:")
    print("-" * 80)
    lccs_ncc_df = df[df['method'] == 'LCCS+NCC']
    best_lccs_ncc = lccs_ncc_df.loc[lccs_ncc_df['accuracy'].idxmax()]
    print(f"  âœ¨ æœ€é«˜å‡†ç¡®ç‡: {best_lccs_ncc['accuracy']:.4f}")
    print(f"  âœ¨ å¹³å‡ç½®ä¿¡åº¦: {best_lccs_ncc['confidence']:.4f}")
    print(f"  Temperature: {best_lccs_ncc['temperature']}")
    print(f"  Distance metric: {best_lccs_ncc['distance_metric']}")
    print(f"  Prototype method: {best_lccs_ncc['prototype_method']}")
    print(f"  Support size: {best_lccs_ncc['support_size']}")
    print(f"  Seed: {best_lccs_ncc['seed']}")
    
    # æŒ‰support_sizeç»Ÿè®¡
    print("\nã€LCCS+NCCã€‘æŒ‰ Support Size:")
    print("-" * 80)
    for size in [3, 5, 10]:
        subset = lccs_ncc_df[lccs_ncc_df['support_size'] == size]
        avg_acc = subset['accuracy'].mean()
        std_acc = subset['accuracy'].std()
        max_acc = subset['accuracy'].max()
        avg_conf = subset['confidence'].mean()
        print(f"  Support={size:2d}: Acc={avg_acc:.4f}Â±{std_acc:.4f} "
              f"(æœ€å¤§={max_acc:.4f}), Conf={avg_conf:.4f}")
    
    # 3. æ€»ä½“å¯¹æ¯”
    print("\n" + "="*80)
    print("ğŸ“ˆ æ€»ä½“æ€§èƒ½å¯¹æ¯”")
    print("="*80)
    
    ncc_mean = ncc_df['accuracy'].mean()
    ncc_max = ncc_df['accuracy'].max()
    ncc_conf_mean = ncc_df['confidence'].mean()
    
    lccs_ncc_mean = lccs_ncc_df['accuracy'].mean()
    lccs_ncc_max = lccs_ncc_df['accuracy'].max()
    lccs_ncc_conf_mean = lccs_ncc_df['confidence'].mean()
    
    print(f"\nNCC:")
    print(f"  å¹³å‡å‡†ç¡®ç‡: {ncc_mean:.4f}")
    print(f"  æœ€å¤§å‡†ç¡®ç‡: {ncc_max:.4f}")
    print(f"  å¹³å‡ç½®ä¿¡åº¦: {ncc_conf_mean:.4f}")
    
    print(f"\nLCCS+NCC:")
    print(f"  å¹³å‡å‡†ç¡®ç‡: {lccs_ncc_mean:.4f}")
    print(f"  æœ€å¤§å‡†ç¡®ç‡: {lccs_ncc_max:.4f}")
    print(f"  å¹³å‡ç½®ä¿¡åº¦: {lccs_ncc_conf_mean:.4f}")
    
    print(f"\nLCCS å¸¦æ¥çš„æå‡:")
    print(f"  å¹³å‡: +{lccs_ncc_mean - ncc_mean:.4f}")
    print(f"  æœ€å¤§: +{lccs_ncc_max - ncc_max:.4f}")
    print(f"  ç½®ä¿¡åº¦: +{lccs_ncc_conf_mean - ncc_conf_mean:.4f}")
    
    # ä¿å­˜æœ€ä½³é…ç½®
    summary = {
        'best_ncc': {
            'accuracy': float(best_ncc['accuracy']),
            'confidence': float(best_ncc['confidence']),
            'config': {
                'temperature': float(best_ncc['temperature']),
                'distance_metric': str(best_ncc['distance_metric']),
                'prototype_method': str(best_ncc['prototype_method']),
                'support_size': int(best_ncc['support_size']),
                'seed': int(best_ncc['seed'])
            }
        },
        'best_lccs_ncc': {
            'accuracy': float(best_lccs_ncc['accuracy']),
            'confidence': float(best_lccs_ncc['confidence']),
            'config': {
                'temperature': float(best_lccs_ncc['temperature']),
                'distance_metric': str(best_lccs_ncc['distance_metric']),
                'prototype_method': str(best_lccs_ncc['prototype_method']),
                'support_size': int(best_lccs_ncc['support_size']),
                'seed': int(best_lccs_ncc['seed']),
                'lccs': lccs_config
            }
        },
        'statistics': {
            'ncc': {
                'mean_accuracy': float(ncc_mean),
                'max_accuracy': float(ncc_max),
                'mean_confidence': float(ncc_conf_mean)
            },
            'lccs_ncc': {
                'mean_accuracy': float(lccs_ncc_mean),
                'max_accuracy': float(lccs_ncc_max),
                'mean_confidence': float(lccs_ncc_conf_mean)
            },
            'lccs_improvement': {
                'accuracy': float(lccs_ncc_mean - ncc_mean),
                'confidence': float(lccs_ncc_conf_mean - ncc_conf_mean)
            }
        }
    }
    
    with open(output_path / 'best_configs.json', 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")
    print(f"   - ncc_tuning_detailed.csv    # è¯¦ç»†ç»“æœ")
    print(f"   - best_configs.json          # æœ€ä½³é…ç½®")
    
    print("\n" + "="*80)
    print("ğŸ‰ NCCè¶…å‚æ•°è°ƒä¼˜å®Œæˆï¼")
    print("="*80)
    
    # æœ€ç»ˆæ¨è
    print(f"\nğŸ† æœ€ç»ˆæ¨èé…ç½®:")
    print(f"  æ–¹æ³•: LCCS+NCC")
    print(f"  å‡†ç¡®ç‡: {best_lccs_ncc['accuracy']:.4f}")
    print(f"  ç½®ä¿¡åº¦: {best_lccs_ncc['confidence']:.4f}")
    print(f"  Temperature: {best_lccs_ncc['temperature']}")
    print(f"  Distance: {best_lccs_ncc['distance_metric']}")
    print(f"  Prototype: {best_lccs_ncc['prototype_method']}")
    print(f"  Support size: {best_lccs_ncc['support_size']}")


if __name__ == '__main__':
    main() 
