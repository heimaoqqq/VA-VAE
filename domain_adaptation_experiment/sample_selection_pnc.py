#!/usr/bin/env python3
"""
æ ·æœ¬ç­›é€‰PNC - éªŒè¯ç­›é€‰ç­–ç•¥å¯¹PNCæ€§èƒ½çš„å½±å“
åŸºäºæ–‡çŒ®è°ƒç ”çš„ä¸åŒæ ·æœ¬é€‰æ‹©æ–¹æ³•
"""

import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset
import torchvision.transforms as transforms
import numpy as np
from pathlib import Path
import sys
import argparse
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import pairwise_distances

sys.path.append(str(Path(__file__).parent.parent))
from improved_classifier_training import ImprovedClassifier
from build_improved_prototypes_with_split import SplitTargetDomainDataset
from improved_pnc import ImprovedPNC


class SampleSelector:
    """æ ·æœ¬é€‰æ‹©ç­–ç•¥"""
    
    def __init__(self, model, device):
        self.model = model
        self.device = device
    
    def random_selection(self, dataset, support_size=3):
        """éšæœºé€‰æ‹©ï¼ˆbaselineï¼‰"""
        indices = np.random.choice(len(dataset), support_size, replace=False)
        return Subset(dataset, indices)
    
    def confidence_selection(self, dataset, support_size=3):
        """åŸºäºåˆ†ç±»å™¨ç½®ä¿¡åº¦é€‰æ‹©"""
        self.model.eval()
        confidences = []
        
        with torch.no_grad():
            for i in range(len(dataset)):
                if len(dataset[i]) == 3:
                    image, label, _ = dataset[i]
                else:
                    image, label = dataset[i]
                
                image = image.unsqueeze(0).to(self.device)
                output = self.model(image)
                prob = F.softmax(output, dim=1)
                conf = prob.max().item()
                confidences.append((i, conf))
        
        # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„support_sizeä¸ªæ ·æœ¬
        confidences.sort(key=lambda x: x[1], reverse=True)
        selected_indices = [idx for idx, _ in confidences[:support_size]]
        
        return Subset(dataset, selected_indices)
    
    def diversity_selection(self, dataset, support_size=3):
        """åŸºäºç‰¹å¾å¤šæ ·æ€§é€‰æ‹©"""
        self.model.eval()
        features = []
        
        with torch.no_grad():
            for i in range(len(dataset)):
                if len(dataset[i]) == 3:
                    image, label, _ = dataset[i]
                else:
                    image, label = dataset[i]
                
                image = image.unsqueeze(0).to(self.device)
                feature = self.model.backbone(image)
                features.append(feature.cpu().numpy().flatten())
        
        features = np.array(features)
        
        # ä½¿ç”¨K-meansèšç±»é€‰æ‹©å¤šæ ·åŒ–æ ·æœ¬
        if len(features) <= support_size:
            return Subset(dataset, list(range(len(dataset))))
        
        kmeans = KMeans(n_clusters=support_size, random_state=42, n_init=10)
        kmeans.fit(features)
        
        # é€‰æ‹©ç¦»èšç±»ä¸­å¿ƒæœ€è¿‘çš„æ ·æœ¬
        selected_indices = []
        for i in range(support_size):
            center = kmeans.cluster_centers_[i]
            distances = pairwise_distances([center], features)[0]
            closest_idx = np.argmin(distances)
            selected_indices.append(closest_idx)
        
        return Subset(dataset, selected_indices)
    
    def uncertainty_selection(self, dataset, support_size=3):
        """åŸºäºä¸ç¡®å®šæ€§é€‰æ‹©ï¼ˆé€‰æ‹©æ¨¡å‹æœ€ä¸ç¡®å®šçš„æ ·æœ¬ï¼‰"""
        self.model.eval()
        uncertainties = []
        
        with torch.no_grad():
            for i in range(len(dataset)):
                if len(dataset[i]) == 3:
                    image, label, _ = dataset[i]
                else:
                    image, label = dataset[i]
                
                image = image.unsqueeze(0).to(self.device)
                output = self.model(image)
                prob = F.softmax(output, dim=1)
                # ä½¿ç”¨entropyä½œä¸ºä¸ç¡®å®šæ€§åº¦é‡
                entropy = -torch.sum(prob * torch.log(prob + 1e-8)).item()
                uncertainties.append((i, entropy))
        
        # é€‰æ‹©ä¸ç¡®å®šæ€§æœ€é«˜çš„support_sizeä¸ªæ ·æœ¬
        uncertainties.sort(key=lambda x: x[1], reverse=True)
        selected_indices = [idx for idx, _ in uncertainties[:support_size]]
        
        return Subset(dataset, selected_indices)
    
    def balanced_selection(self, dataset, support_size=3):
        """å¹³è¡¡é€‰æ‹©ï¼šç»“åˆç½®ä¿¡åº¦å’Œå¤šæ ·æ€§"""
        self.model.eval()
        features = []
        confidences = []
        
        with torch.no_grad():
            for i in range(len(dataset)):
                if len(dataset[i]) == 3:
                    image, label, _ = dataset[i]
                else:
                    image, label = dataset[i]
                
                image = image.unsqueeze(0).to(self.device)
                feature = self.model.backbone(image)
                output = self.model(image)
                prob = F.softmax(output, dim=1)
                conf = prob.max().item()
                
                features.append(feature.cpu().numpy().flatten())
                confidences.append(conf)
        
        features = np.array(features)
        confidences = np.array(confidences)
        
        # å½’ä¸€åŒ–ç½®ä¿¡åº¦
        norm_conf = (confidences - confidences.min()) / (confidences.max() - confidences.min() + 1e-8)
        
        # è®¡ç®—å¤šæ ·æ€§åˆ†æ•°ï¼ˆåˆ°å…¶ä»–æ ·æœ¬çš„å¹³å‡è·ç¦»ï¼‰
        distances = pairwise_distances(features)
        diversity_scores = distances.mean(axis=1)
        norm_diversity = (diversity_scores - diversity_scores.min()) / (diversity_scores.max() - diversity_scores.min() + 1e-8)
        
        # ç»¼åˆåˆ†æ•°ï¼š0.7*ç½®ä¿¡åº¦ + 0.3*å¤šæ ·æ€§
        combined_scores = 0.7 * norm_conf + 0.3 * norm_diversity
        
        # é€‰æ‹©åˆ†æ•°æœ€é«˜çš„æ ·æœ¬
        selected_indices = np.argsort(combined_scores)[-support_size:].tolist()
        
        return Subset(dataset, selected_indices)


def test_sample_selection_strategies(model_path, data_dir, support_size=3, seed=42):
    """æµ‹è¯•ä¸åŒæ ·æœ¬é€‰æ‹©ç­–ç•¥"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # æ•°æ®å‡†å¤‡
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åŠ è½½å®Œæ•´ç›®æ ‡åŸŸæ•°æ®
    full_dataset = SplitTargetDomainDataset(
        data_dir=data_dir,
        transform=transform,
        support_size=100,  # ä½¿ç”¨æ›´å¤šæ ·æœ¬ç”¨äºé€‰æ‹©
        mode='support',
        seed=seed
    )
    
    test_dataset = SplitTargetDomainDataset(
        data_dir=data_dir,
        transform=transform,
        support_size=support_size,
        mode='test',
        seed=seed
    )
    
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    # åŠ è½½æ¨¡å‹
    model = ImprovedClassifier(num_classes=31).to(device)
    checkpoint = torch.load(model_path, map_location=device)
    
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    print(f"ğŸ“Š Testing sample selection with {len(full_dataset)} candidates")
    
    # åˆå§‹åŒ–æ ·æœ¬é€‰æ‹©å™¨
    selector = SampleSelector(model, device)
    
    # æŒ‰ç±»åˆ«ç»„ç»‡æ•°æ®
    class_datasets = {}
    for i in range(len(full_dataset)):
        if len(full_dataset[i]) == 3:
            _, label, _ = full_dataset[i]
        else:
            _, label = full_dataset[i]
        
        if label.item() not in class_datasets:
            class_datasets[label.item()] = []
        class_datasets[label.item()].append(i)
    
    results = {}
    
    # æµ‹è¯•ä¸åŒé€‰æ‹©ç­–ç•¥
    strategies = {
        'Random': 'random_selection',
        'High Confidence': 'confidence_selection', 
        'Diversity': 'diversity_selection',
        'High Uncertainty': 'uncertainty_selection',
        'Balanced': 'balanced_selection'
    }
    
    for strategy_name, method_name in strategies.items():
        print(f"\nğŸ¯ Testing {strategy_name} Selection...")
        
        # å¯¹æ¯ä¸ªç±»åˆ«åº”ç”¨é€‰æ‹©ç­–ç•¥
        selected_indices = []
        for class_id, indices in class_datasets.items():
            if len(indices) >= support_size:
                class_subset = Subset(full_dataset, indices)
                method = getattr(selector, method_name)
                selected_subset = method(class_subset, support_size)
                # æ˜ å°„å›åŸå§‹ç´¢å¼•
                for idx in selected_subset.indices:
                    selected_indices.append(indices[idx])
            else:
                selected_indices.extend(indices)  # å¦‚æœæ ·æœ¬ä¸å¤Ÿï¼Œå…¨éƒ¨é€‰æ‹©
        
        # åˆ›å»ºæ”¯æŒé›†
        support_dataset = Subset(full_dataset, selected_indices)
        support_loader = DataLoader(support_dataset, batch_size=32, shuffle=False)
        
        # ä½¿ç”¨PNCè¯„ä¼°
        pnc = ImprovedPNC(model, device, similarity_tau=0.005)
        pnc.compute_prototypes(support_loader)
        
        acc, conf = pnc.evaluate(test_loader, fusion_alpha=0.7, use_confidence_weight=False)
        results[strategy_name] = {'accuracy': acc, 'confidence': conf, 'samples': len(selected_indices)}
        
        print(f"{strategy_name}: {acc:.2%} (conf: {conf:.3f}, samples: {len(selected_indices)})")
    
    # æ€»ç»“
    print("\n" + "="*70)
    print("ğŸ“Š SUMMARY: Sample Selection Strategies")
    print("="*70)
    print(f"{'Strategy':<20} {'Accuracy':<12} {'Confidence':<12} {'Samples':<8} {'vs Random'}")
    print("-"*80)
    
    random_acc = results['Random']['accuracy']
    sorted_results = sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True)
    
    for strategy, metrics in sorted_results:
        improvement = metrics['accuracy'] - random_acc
        print(f"{strategy:<20} {metrics['accuracy']:<11.2%} {metrics['confidence']:<11.3f} {metrics['samples']:<8d} {improvement:+.2%}")
    
    return results


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Test Sample Selection Strategies for PNC')
    parser.add_argument('--model-path', type=str,
                       default='/kaggle/working/VA-VAE/improved_classifier/best_improved_classifier.pth')
    parser.add_argument('--data-dir', type=str,
                       default='/kaggle/working/organized_gait_dataset/Normal_free')
    parser.add_argument('--support-size', type=int, default=3)
    parser.add_argument('--seed', type=int, default=42)
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    
    test_sample_selection_strategies(
        model_path=args.model_path,
        data_dir=args.data_dir,
        support_size=args.support_size,
        seed=args.seed
    )
