#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆè¶…å‚æ•°æœç´¢
- æ¨¡å‹åªåŠ è½½ä¸€æ¬¡
- æ•°æ®æŒ‰ support_size åˆ†ç»„åŠ è½½
- é€Ÿåº¦æå‡ 5-10 å€
- ä¸¥æ ¼ä¿è¯æ— æ•°æ®æ³„éœ²
"""

import torch
import pandas as pd
import json
from pathlib import Path
from tqdm import tqdm
from itertools import product
import sys
import copy
from torch.utils.data import DataLoader
import torchvision.transforms as transforms

sys.path.append(str(Path(__file__).parent))
from eval_config import *
from eval_utils import *
from eval_components import *
from strategic_dataset import StrategicDataset


def evaluate_pnc_hyperparameters_optimized(model, data_loaders_dict, output_dir):
    """
    ä¼˜åŒ–ç‰ˆ PNC è¶…å‚æ•°æœç´¢
    
    Args:
        model: é¢„åŠ è½½çš„åˆ†ç±»å™¨ï¼ˆåªè¯»ï¼Œä¸ä¿®æ”¹ï¼‰
        data_loaders_dict: {(support_size, seed): (support_loader, test_loader)}
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        DataFrame: PNC ç»“æœ
    """
    print("\n" + "="*80)
    print("ğŸ” PNCè¶…å‚æ•°æœç´¢ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    print("="*80)
    
    results = []
    
    # è¶…å‚æ•°é…ç½®
    prototype_strategies = ['simple_mean', 'weighted_mean']
    fusion_alphas = [0.4, 0.5, 0.6, 0.7]
    similarity_taus = [0.005, 0.01, 0.02]
    use_adaptives = [False, True]
    
    # æ€»é…ç½®æ•°
    total_configs = (len(prototype_strategies) * len(fusion_alphas) * 
                    len(similarity_taus) * len(use_adaptives))
    total = total_configs * len(data_loaders_dict)
    
    print(f"è¶…å‚æ•°é…ç½®: {total_configs} ç§")
    print(f"æ•°æ®é…ç½®: {len(data_loaders_dict)} ç§")
    print(f"æ€»è®¡: {total} ä¸ªå®éªŒ\n")
    
    with tqdm(total=total, desc="PNC") as pbar:
        # æŒ‰æ•°æ®é›†åˆ†ç»„
        for key, (support_loader, test_loader) in data_loaders_dict.items():
            if len(key) == 3:  # (support_size, seed, strategy)
                support_size, seed, strategy = key
                print(f"\nğŸ“Š Support={support_size}, Seed={seed}, Strategy={strategy}")
            else:  # (support_size, seed)
                support_size, seed = key
                print(f"\nğŸ“Š Support={support_size}, Seed={seed}")
            
            # å¯¹åŒä¸€æ•°æ®é›†æµ‹è¯•æ‰€æœ‰è¶…å‚æ•°
            for proto_strat, alpha, tau, adaptive in product(
                prototype_strategies, fusion_alphas, similarity_taus, use_adaptives
            ):
                # 1. æ„å»ºåŸå‹ï¼ˆæ¯æ¬¡é‡æ–°æ„å»ºï¼Œé¿å…ç¼“å­˜ï¼‰
                if proto_strat == 'simple_mean':
                    features, labels = extract_features(model, support_loader, model.device)
                    prototypes = build_prototypes_simple_mean(features, labels)
                elif proto_strat == 'weighted_mean':
                    prototypes = build_prototypes_weighted(model, support_loader, model.device)
                else:
                    raise ValueError(f"Unknown strategy: {proto_strat}")
                
                # 2. PNC è¯„ä¼°ï¼ˆåªè¯»æ¨¡å‹ï¼Œä¸ä¿®æ”¹ï¼‰
                pnc = PNCEvaluator(model, prototypes, model.device)
                acc, conf = pnc.predict(test_loader, alpha, tau, adaptive)
                
                # 3. ä¿å­˜ç»“æœ
                results.append({
                    'method': 'pnc',
                    'prototype_strategy': proto_strat,
                    'fusion_alpha': alpha,
                    'similarity_tau': tau,
                    'use_adaptive': adaptive,
                    'support_size': support_size,
                    'seed': seed,
                    'accuracy': acc,
                    'confidence': conf
                })
                
                pbar.update(1)
    
    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    df.to_csv(Path(output_dir) / 'pnc_results.csv', index=False)
    
    # æ‰¾æœ€ä½³é…ç½®
    best = df.loc[df['accuracy'].idxmax()]
    print(f"\nğŸ† æœ€ä½³PNCé…ç½®:")
    print(f"   å‡†ç¡®ç‡: {best['accuracy']:.4f}")
    print(f"   åŸå‹ç­–ç•¥: {best['prototype_strategy']}")
    print(f"   Fusion Î±: {best['fusion_alpha']}")
    print(f"   Temperature Ï„: {best['similarity_tau']}")
    print(f"   è‡ªé€‚åº”: {best['use_adaptive']}")
    
    return df


def evaluate_lccs_hyperparameters_optimized(model, data_loaders_dict, output_dir):
    """
    ä¼˜åŒ–ç‰ˆ LCCS è¶…å‚æ•°æœç´¢
    
    å…³é”®ï¼šæ¯æ¬¡å®éªŒåæ¢å¤åŸå§‹ BN ç»Ÿè®¡é‡ï¼Œé¿å…çŠ¶æ€æ±¡æŸ“
    
    Args:
        model: é¢„åŠ è½½çš„åˆ†ç±»å™¨
        data_loaders_dict: æ•°æ®åŠ è½½å™¨å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        DataFrame: LCCS ç»“æœ
    """
    print("\n" + "="*80)
    print("ğŸ” LCCSè¶…å‚æ•°æœç´¢ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    print("="*80)
    
    results = []
    
    # Progressive é…ç½®
    progressive_configs = list(product(
        [0.005, 0.01, 0.02],  # momentum
        [3, 5, 10]             # iterations
    ))
    
    # Weighted é…ç½®
    weighted_configs = [0.2, 0.3, 0.4]  # alpha
    
    total_configs = len(progressive_configs) + len(weighted_configs)
    total = total_configs * len(data_loaders_dict)
    
    print(f"Progressive é…ç½®: {len(progressive_configs)} ç§")
    print(f"Weighted é…ç½®: {len(weighted_configs)} ç§")
    print(f"æ•°æ®é…ç½®: {len(data_loaders_dict)} ç§")
    print(f"æ€»è®¡: {total} ä¸ªå®éªŒ\n")
    
    with tqdm(total=total, desc="LCCS") as pbar:
        # æŒ‰æ•°æ®é›†åˆ†ç»„
        for key, (support_loader, test_loader) in data_loaders_dict.items():
            if len(key) == 3:  # (support_size, seed, strategy)
                support_size, seed, strategy = key
                print(f"\nğŸ“Š Support={support_size}, Seed={seed}, Strategy={strategy}")
            else:  # (support_size, seed)
                support_size, seed = key
                print(f"\nğŸ“Š Support={support_size}, Seed={seed}")
            
            # åˆ›å»º LCCS é€‚é…å™¨ï¼ˆä¿å­˜åŸå§‹ BN ç»Ÿè®¡é‡ï¼‰
            lccs = LCCSAdapter(model, model.device)
            
            # æµ‹è¯• Progressive
            for momentum, iterations in progressive_configs:
                # é€‚åº” BN
                lccs.adapt_progressive(support_loader, momentum, iterations)
                
                # è¯„ä¼°
                acc, conf = evaluate_baseline(model, test_loader, model.device)
                
                # ä¿å­˜ç»“æœ
                results.append({
                    'method': 'lccs',
                    'lccs_method': 'progressive',
                    'momentum': momentum,
                    'iterations': iterations,
                    'alpha': None,
                    'support_size': support_size,
                    'seed': seed,
                    'accuracy': acc,
                    'confidence': conf
                })
                
                # âš ï¸ å…³é”®ï¼šæ¢å¤åŸå§‹ BN ç»Ÿè®¡é‡
                lccs.restore_bn_stats()
                
                pbar.update(1)
            
            # æµ‹è¯• Weighted
            for alpha in weighted_configs:
                # é€‚åº” BN
                lccs.adapt_weighted(support_loader, alpha)
                
                # è¯„ä¼°
                acc, conf = evaluate_baseline(model, test_loader, model.device)
                
                # ä¿å­˜ç»“æœ
                results.append({
                    'method': 'lccs',
                    'lccs_method': 'weighted',
                    'momentum': None,
                    'iterations': None,
                    'alpha': alpha,
                    'support_size': support_size,
                    'seed': seed,
                    'accuracy': acc,
                    'confidence': conf
                })
                
                # âš ï¸ å…³é”®ï¼šæ¢å¤åŸå§‹ BN ç»Ÿè®¡é‡
                lccs.restore_bn_stats()
                
                pbar.update(1)
    
    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    df.to_csv(Path(output_dir) / 'lccs_results.csv', index=False)
    
    # æ‰¾æœ€ä½³é…ç½®
    best = df.loc[df['accuracy'].idxmax()]
    print(f"\nğŸ† æœ€ä½³LCCSé…ç½®:")
    print(f"   å‡†ç¡®ç‡: {best['accuracy']:.4f}")
    print(f"   æ–¹æ³•: {best['lccs_method']}")
    if best['lccs_method'] == 'progressive':
        print(f"   Momentum: {best['momentum']}")
        print(f"   Iterations: {best['iterations']}")
    else:
        print(f"   Alpha: {best['alpha']}")
    
    return df


def evaluate_pnc_lccs_combined_optimized(model, best_pnc, best_lccs, 
                                        data_dir, output_dir):
    """
    ä¼˜åŒ–ç‰ˆ PNC+LCCS ç»„åˆè¯„ä¼°
    
    Args:
        model: é¢„åŠ è½½çš„åˆ†ç±»å™¨
        best_pnc: æœ€ä½³ PNC é…ç½®
        best_lccs: æœ€ä½³ LCCS é…ç½®
        data_dir: æ•°æ®ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        DataFrame: ç»„åˆç»“æœ
    """
    print("\n" + "="*80)
    print("ğŸ” PNC+LCCSç»„åˆè¯„ä¼°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    print("="*80)
    
    results = []
    
    support_sizes = [3, 5, 10]
    seeds = [42, 123, 456]
    
    total = len(support_sizes) * len(seeds)
    
    print(f"æ€»å…± {total} ä¸ªé…ç½®")
    print(f"\næœ€ä½³PNCé…ç½®:")
    print(f"  åŸå‹ç­–ç•¥: {best_pnc['prototype_strategy']}")
    print(f"  Fusion Î±: {best_pnc['fusion_alpha']}")
    print(f"  Temperature Ï„: {best_pnc['similarity_tau']}")
    print(f"\næœ€ä½³LCCSé…ç½®:")
    print(f"  æ–¹æ³•: {best_lccs['lccs_method']}")
    
    with tqdm(total=total, desc="PNC+LCCS") as pbar:
        for support_size, seed in product(support_sizes, seeds):
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            support_loader, test_loader = create_data_loaders(
                data_dir, support_size, seed, batch_size=64, num_workers=0
            )
            
            # åˆ›å»º LCCS é€‚é…å™¨
            lccs = LCCSAdapter(model, model.device)
            
            # æ­¥éª¤1ï¼šLCCS é€‚åº”
            if best_lccs['lccs_method'] == 'progressive':
                lccs.adapt_progressive(
                    support_loader,
                    momentum=best_lccs['momentum'],
                    iterations=best_lccs['iterations']
                )
            else:
                lccs.adapt_weighted(support_loader, alpha=best_lccs['alpha'])
            
            # æ­¥éª¤2ï¼šæ„å»ºåŸå‹ï¼ˆåœ¨ LCCS é€‚åº”åçš„æ¨¡å‹ä¸Šï¼‰
            if best_pnc['prototype_strategy'] == 'simple_mean':
                features, labels = extract_features(model, support_loader, model.device)
                prototypes = build_prototypes_simple_mean(features, labels)
            else:
                prototypes = build_prototypes_weighted(model, support_loader, model.device)
            
            # æ­¥éª¤3ï¼šPNC è¯„ä¼°
            pnc = PNCEvaluator(model, prototypes, model.device)
            acc, conf = pnc.predict(
                test_loader,
                fusion_alpha=best_pnc['fusion_alpha'],
                similarity_tau=best_pnc['similarity_tau'],
                use_adaptive=best_pnc['use_adaptive']
            )
            
            # ä¿å­˜ç»“æœ
            results.append({
                'method': 'pnc_lccs',
                'support_size': support_size,
                'seed': seed,
                'accuracy': acc,
                'confidence': conf
            })
            
            # âš ï¸ å…³é”®ï¼šæ¢å¤åŸå§‹ BN ç»Ÿè®¡é‡
            lccs.restore_bn_stats()
            
            pbar.update(1)
    
    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    df.to_csv(Path(output_dir) / 'pnc_lccs_combined_results.csv', index=False)
    
    print(f"\nğŸ† PNC+LCCSç»„åˆç»“æœ:")
    print(f"   å¹³å‡å‡†ç¡®ç‡: {df['accuracy'].mean():.4f} Â± {df['accuracy'].std():.4f}")
    print(f"   æœ€å¤§å‡†ç¡®ç‡: {df['accuracy'].max():.4f}")
    
    return df


def compare_sample_selection_strategies(model, data_dir, output_dir):
    """
    å¯¹æ¯”ä¸åŒçš„æ ·æœ¬é€‰æ‹©ç­–ç•¥
    
    æµ‹è¯•ç­–ç•¥ï¼šRandomã€Confidenceã€Diversityã€Uncertaintyã€Hybrid
    
    Args:
        model: é¢„åŠ è½½çš„åˆ†ç±»å™¨
        data_dir: æ•°æ®ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        DataFrame: ç­–ç•¥å¯¹æ¯”ç»“æœ
    """
    print("\n" + "="*80)
    print("ğŸ¯ æ ·æœ¬é€‰æ‹©ç­–ç•¥å¯¹æ¯”")
    print("="*80)
    
    strategies = ['random', 'confidence', 'diversity', 'uncertainty', 'hybrid']
    support_sizes = [3, 5]
    seeds = [42]
    
    results = []
    
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    total = len(strategies) * len(support_sizes) * len(seeds)
    
    print(f"ç­–ç•¥: {len(strategies)} ç§")
    print(f"Support sizes: {support_sizes}")
    print(f"æ€»è®¡: {total} ä¸ªå®éªŒ\n")
    
    with tqdm(total=total, desc="Strategy Comparison") as pbar:
        for strategy in strategies:
            for support_size in support_sizes:
                for seed in seeds:
                    print(f"\nğŸ“Š Strategy={strategy}, Support={support_size}, Seed={seed}")
                    
                    # åˆ›å»ºæ•°æ®é›†
                    support_dataset = StrategicDataset(
                        data_dir=data_dir,
                        support_size=support_size,
                        strategy=strategy,
                        model=model,
                        mode='support',
                        seed=seed,
                        device=model.device,
                        transform=transform
                    )
                    
                    test_dataset = StrategicDataset(
                        data_dir=data_dir,
                        support_size=support_size,
                        strategy=strategy,
                        model=model,
                        mode='test',
                        seed=seed,
                        device=model.device,
                        transform=transform
                    )
                    
                    support_loader = DataLoader(
                        support_dataset,
                        batch_size=64,
                        shuffle=False,
                        num_workers=0
                    )
                    
                    test_loader = DataLoader(
                        test_dataset,
                        batch_size=64,
                        shuffle=False,
                        num_workers=0
                    )
                    
                    # è¯„ä¼°åŸºçº¿ï¼ˆä¸ä½¿ç”¨PNC/LCCSï¼‰
                    baseline_acc, baseline_conf = evaluate_baseline(
                        model, test_loader, model.device
                    )
                    
                    # è¯„ä¼°PNCï¼ˆç®€å•é…ç½®ï¼‰
                    features, labels = extract_features(model, support_loader, model.device)
                    prototypes = build_prototypes_simple_mean(features, labels)
                    pnc = PNCEvaluator(model, prototypes, model.device)
                    pnc_acc, pnc_conf = pnc.predict(test_loader, 
                                                    fusion_alpha=0.6, 
                                                    similarity_tau=0.01)
                    
                    # ä¿å­˜ç»“æœ
                    results.append({
                        'strategy': strategy,
                        'support_size': support_size,
                        'seed': seed,
                        'baseline_accuracy': baseline_acc,
                        'baseline_confidence': baseline_conf,
                        'pnc_accuracy': pnc_acc,
                        'pnc_confidence': pnc_conf,
                        'pnc_improvement': pnc_acc - baseline_acc
                    })
                    
                    print(f"  Baseline: {baseline_acc:.4f}, PNC: {pnc_acc:.4f} (+{pnc_acc-baseline_acc:.4f})")
                    
                    pbar.update(1)
    
    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    df.to_csv(Path(output_dir) / 'strategy_comparison.csv', index=False)
    
    # æ‰“å°æ€»ç»“
    print(f"\nğŸ† ç­–ç•¥å¯¹æ¯”æ€»ç»“:")
    print("="*80)
    
    for strategy in strategies:
        strategy_df = df[df['strategy'] == strategy]
        avg_baseline = strategy_df['baseline_accuracy'].mean()
        avg_pnc = strategy_df['pnc_accuracy'].mean()
        avg_improvement = strategy_df['pnc_improvement'].mean()
        
        print(f"{strategy:12s}: Baseline={avg_baseline:.4f}, PNC={avg_pnc:.4f}, "
              f"Improvement={avg_improvement:+.4f}")
    
    # æ‰¾æœ€ä½³ç­–ç•¥
    best_row = df.loc[df['pnc_accuracy'].idxmax()]
    print(f"\nâœ¨ æœ€ä½³ç­–ç•¥: {best_row['strategy']} (support_size={best_row['support_size']})")
    print(f"   PNCå‡†ç¡®ç‡: {best_row['pnc_accuracy']:.4f}")
    
    return df


def preload_data_loaders_with_strategy(model, data_dir, strategy, device='cuda'):
    """
    ä½¿ç”¨ç‰¹å®šç­–ç•¥é¢„åŠ è½½æ•°æ®åŠ è½½å™¨
    
    Args:
        model: åˆ†ç±»å™¨
        data_dir: æ•°æ®ç›®å½•
        strategy: æ ·æœ¬é€‰æ‹©ç­–ç•¥
        device: è®¾å¤‡
    
    Returns:
        dict: {(support_size, seed, strategy): (support_loader, test_loader)}
    """
    print(f"\nğŸ“‚ é¢„åŠ è½½æ•°æ® (Strategy: {strategy})")
    print("="*80)
    
    data_loaders = {}
    
    support_sizes = [3, 5]
    seeds = [42]
    
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    for support_size in support_sizes:
        for seed in seeds:
            print(f"\nåŠ è½½ support_size={support_size}, seed={seed}, strategy={strategy}")
            
            support_dataset = StrategicDataset(
                data_dir=data_dir,
                support_size=support_size,
                strategy=strategy,
                model=model,
                mode='support',
                seed=seed,
                device=device,
                transform=transform
            )
            
            test_dataset = StrategicDataset(
                data_dir=data_dir,
                support_size=support_size,
                strategy=strategy,
                model=model,
                mode='test',
                seed=seed,
                device=device,
                transform=transform
            )
            
            support_loader = DataLoader(support_dataset, batch_size=64, 
                                       shuffle=False, num_workers=0)
            test_loader = DataLoader(test_dataset, batch_size=64, 
                                    shuffle=False, num_workers=0)
            
            data_loaders[(support_size, seed, strategy)] = (support_loader, test_loader)
    
    print(f"\nâœ… é¢„åŠ è½½å®Œæˆï¼Œå…± {len(data_loaders)} ç»„æ•°æ®")
    
    return data_loaders


def preload_data_loaders(data_dir, device='cuda'):
    """
    é¢„åŠ è½½æ‰€æœ‰æ•°æ®åŠ è½½å™¨ï¼ˆéšæœºç­–ç•¥ï¼‰
    
    Args:
        data_dir: æ•°æ®ç›®å½•
        device: è®¾å¤‡
    
    Returns:
        dict: {(support_size, seed): (support_loader, test_loader)}
    """
    print("\n" + "="*80)
    print("ğŸ“‚ é¢„åŠ è½½æ•°æ®")
    print("="*80)
    
    data_loaders = {}
    
    support_sizes = [3, 5]
    seeds = [42]
    
    for support_size in support_sizes:
        for seed in seeds:
            print(f"\nåŠ è½½ support_size={support_size}, seed={seed}")
            support_loader, test_loader = create_data_loaders(
                data_dir, support_size, seed, batch_size=64, num_workers=0
            )
            data_loaders[(support_size, seed)] = (support_loader, test_loader)
    
    print(f"\nâœ… é¢„åŠ è½½å®Œæˆï¼Œå…± {len(data_loaders)} ç»„æ•°æ®")
    
    return data_loaders


def main():
    import argparse
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–ç‰ˆè¶…å‚æ•°æœç´¢')
    parser.add_argument('--model-path', type=str,
                       default='/kaggle/working/VA-VAE/improved_classifier/best_improved_classifier.pth')
    parser.add_argument('--data-dir', type=str,
                       default='/kaggle/input/backpack/backpack')
    parser.add_argument('--output-dir', type=str,
                       default='./optimized_search_results')
    parser.add_argument('--skip-pnc', action='store_true',
                       help='è·³è¿‡PNCè¯„ä¼°')
    parser.add_argument('--skip-lccs', action='store_true',
                       help='è·³è¿‡LCCSè¯„ä¼°')
    
    args = parser.parse_args()
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    output_path = Path(args.output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print("\n" + "="*80)
    print("ğŸš€ ä¼˜åŒ–ç‰ˆè¶…å‚æ•°æœç´¢")
    print("="*80)
    print(f"ğŸ’» è®¾å¤‡: {device}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_path}")
    
    # 1. åŠ è½½æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
    print("\n" + "="*80)
    print("ğŸ“¦ åŠ è½½åˆ†ç±»å™¨")
    print("="*80)
    model = load_classifier(args.model_path, device)
    model.device = device  # ä¿å­˜ device å±æ€§
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ\n")
    
    # 2. å…ˆå¯¹æ¯”æ ·æœ¬é€‰æ‹©ç­–ç•¥
    print("\n" + "="*80)
    print("ğŸ¯ æ­¥éª¤ 1: æ ·æœ¬é€‰æ‹©ç­–ç•¥å¯¹æ¯”")
    print("="*80)
    strategy_df = compare_sample_selection_strategies(model, args.data_dir, args.output_dir)
    
    # æ‰¾æœ€ä½³ç­–ç•¥
    best_strategy_row = strategy_df.loc[strategy_df['pnc_accuracy'].idxmax()]
    best_strategy = best_strategy_row['strategy']
    
    print(f"\nâœ¨ é€‰æ‹©æœ€ä½³ç­–ç•¥: {best_strategy}")
    print(f"   å°†ä½¿ç”¨æ­¤ç­–ç•¥è¿›è¡Œåç»­è¶…å‚æ•°æœç´¢\n")
    
    # 3. ä½¿ç”¨æœ€ä½³ç­–ç•¥é¢„åŠ è½½æ•°æ®
    data_loaders_dict = preload_data_loaders_with_strategy(
        model, args.data_dir, best_strategy, device
    )
    
    # 4. è¯„ä¼° PNCï¼ˆä½¿ç”¨æœ€ä½³ç­–ç•¥ï¼‰
    if not args.skip_pnc:
        print("\n" + "="*80)
        print("ğŸ¯ æ­¥éª¤ 2: PNC è¶…å‚æ•°æœç´¢")
        print("="*80)
        pnc_df = evaluate_pnc_hyperparameters_optimized(
            model, data_loaders_dict, args.output_dir
        )
        best_pnc = pnc_df.loc[pnc_df['accuracy'].idxmax()]
    else:
        print("\nâ­ï¸ è·³è¿‡PNCè¯„ä¼°")
        best_pnc = {
            'prototype_strategy': 'simple_mean',
            'fusion_alpha': 0.6,
            'similarity_tau': 0.01,
            'use_adaptive': False
        }
    
    # 5. è¯„ä¼° LCCSï¼ˆä½¿ç”¨æœ€ä½³ç­–ç•¥ï¼‰
    if not args.skip_lccs:
        print("\n" + "="*80)
        print("ğŸ¯ æ­¥éª¤ 3: LCCS è¶…å‚æ•°æœç´¢")
        print("="*80)
        lccs_df = evaluate_lccs_hyperparameters_optimized(
            model, data_loaders_dict, args.output_dir
        )
        best_lccs = lccs_df.loc[lccs_df['accuracy'].idxmax()]
    else:
        print("\nâ­ï¸ è·³è¿‡LCCSè¯„ä¼°")
        best_lccs = {
            'lccs_method': 'progressive',
            'momentum': 0.01,
            'iterations': 5
        }
    
    # 6. è¯„ä¼° PNC+LCCS ç»„åˆï¼ˆä½¿ç”¨æœ€ä½³ç­–ç•¥ï¼‰
    print("\n" + "="*80)
    print("ğŸ¯ æ­¥éª¤ 4: PNC+LCCS ç»„åˆè¯„ä¼°")
    print("="*80)
    combined_df = evaluate_pnc_lccs_combined_optimized(
        model, best_pnc, best_lccs, args.data_dir, args.output_dir
    )
    
    # 7. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    print("\n" + "="*80)
    print("ğŸ“Š æœ€ç»ˆæ€»ç»“")
    print("="*80)
    
    summary = {
        'best_strategy': best_strategy,
        'strategy_results': {
            strategy: {
                'avg_pnc_accuracy': float(strategy_df[strategy_df['strategy']==strategy]['pnc_accuracy'].mean()),
                'avg_improvement': float(strategy_df[strategy_df['strategy']==strategy]['pnc_improvement'].mean())
            }
            for strategy in ['random', 'confidence', 'diversity', 'uncertainty', 'hybrid']
        },
        'best_pnc': best_pnc.to_dict() if hasattr(best_pnc, 'to_dict') else best_pnc,
        'best_lccs': best_lccs.to_dict() if hasattr(best_lccs, 'to_dict') else best_lccs,
        'combined_results': {
            'mean_accuracy': float(combined_df['accuracy'].mean()),
            'std_accuracy': float(combined_df['accuracy'].std()),
            'max_accuracy': float(combined_df['accuracy'].max())
        }
    }
    
    with open(output_path / 'summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")
    print(f"   - strategy_comparison.csv         # æ ·æœ¬é€‰æ‹©ç­–ç•¥å¯¹æ¯”")
    print(f"   - pnc_results.csv                 # PNC è¶…å‚æ•°æœç´¢")
    print(f"   - lccs_results.csv                # LCCS è¶…å‚æ•°æœç´¢")
    print(f"   - pnc_lccs_combined_results.csv   # PNC+LCCS ç»„åˆç»“æœ")
    print(f"   - summary.json                    # æœ€ä½³é…ç½®æ€»ç»“")
    
    print(f"\nğŸ¯ æ€§èƒ½æ€»ç»“:")
    print("="*80)
    print(f"âœ¨ æœ€ä½³æ ·æœ¬é€‰æ‹©ç­–ç•¥: {best_strategy}")
    for strategy in ['random', 'confidence', 'diversity', 'uncertainty', 'hybrid']:
        avg_pnc = strategy_df[strategy_df['strategy']==strategy]['pnc_accuracy'].mean()
        print(f"   {strategy:12s}: {avg_pnc:.4f}")
    
    print(f"\nğŸ“ˆ æœ€ä½³è¶…å‚æ•°é…ç½®:")
    print(f"   æœ€ä½³PNC: {best_pnc['accuracy'] if 'accuracy' in best_pnc else 'N/A':.4f}" if isinstance(best_pnc.get('accuracy'), (int, float)) else "   æœ€ä½³PNC: è§CSV")
    print(f"   æœ€ä½³LCCS: {best_lccs['accuracy'] if 'accuracy' in best_lccs else 'N/A':.4f}" if isinstance(best_lccs.get('accuracy'), (int, float)) else "   æœ€ä½³LCCS: è§CSV")
    
    print(f"\nğŸ† æœ€ç»ˆç»„åˆæ•ˆæœ:")
    print(f"   PNC+LCCSå¹³å‡: {combined_df['accuracy'].mean():.4f} Â± {combined_df['accuracy'].std():.4f}")
    print(f"   PNC+LCCSæœ€å¤§: {combined_df['accuracy'].max():.4f}")


if __name__ == '__main__':
    main() 
