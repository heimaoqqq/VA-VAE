#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆLCCS - ä¸å®Œå…¨é‡ç½®BNç»Ÿè®¡é‡ï¼Œè€Œæ˜¯å¾®è°ƒ
"""

import torch
import torch.nn as nn
from copy import deepcopy
from tqdm import tqdm
import argparse
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent))
from improved_classifier_training import ImprovedClassifier
from build_improved_prototypes_with_split import SplitTargetDomainDataset
from torch.utils.data import DataLoader
import torchvision.transforms as transforms


class FixedLCCSAdapter:
    """ä¿®å¤ç‰ˆLCCSï¼šä¿ç•™åŸå§‹ç»Ÿè®¡é‡ï¼Œä»…å¾®è°ƒ"""
    
    def __init__(self, model, device='cuda'):
        self.device = device
        self.model = model.to(device)
        self.original_bn_stats = self._save_bn_stats()
        
    def _save_bn_stats(self):
        """ä¿å­˜åŸå§‹BNå±‚çš„ç»Ÿè®¡é‡"""
        bn_stats = {}
        for name, module in self.model.named_modules():
            if isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.BatchNorm1d):
                bn_stats[name] = {
                    'running_mean': module.running_mean.clone(),
                    'running_var': module.running_var.clone(),
                    'momentum': module.momentum,
                    'num_batches_tracked': module.num_batches_tracked.clone() if module.num_batches_tracked is not None else None
                }
        return bn_stats
    
    def _restore_bn_stats(self):
        """æ¢å¤åŸå§‹BNç»Ÿè®¡é‡"""
        for name, module in self.model.named_modules():
            if name in self.original_bn_stats:
                module.running_mean.data = self.original_bn_stats[name]['running_mean']
                module.running_var.data = self.original_bn_stats[name]['running_var']
                if module.num_batches_tracked is not None:
                    module.num_batches_tracked.data = self.original_bn_stats[name]['num_batches_tracked']
    
    def adapt_bn_stats_v1(self, support_loader, alpha=0.3):
        """æ–¹æ³•1ï¼šåŠ æƒèåˆåŸå§‹å’Œç›®æ ‡åŸŸç»Ÿè®¡é‡"""
        print(f"ğŸ”§ Method 1: Weighted fusion (Î±={alpha})...")
        
        # æ”¶é›†ç›®æ ‡åŸŸç»Ÿè®¡é‡ï¼ˆä¸é‡ç½®åŸå§‹ç»Ÿè®¡é‡ï¼‰
        self.model.train()
        
        # ä¿å­˜å½“å‰ç»Ÿè®¡é‡
        source_stats = self._save_bn_stats()
        
        # ä¸´æ—¶é‡ç½®ä»¥æ”¶é›†çº¯ç›®æ ‡åŸŸç»Ÿè®¡é‡
        for module in self.model.modules():
            if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                module.reset_running_stats()
                module.momentum = 1.0  # å¿«é€Ÿæ”¶é›†
        
        # æ”¶é›†ç›®æ ‡åŸŸç»Ÿè®¡é‡
        with torch.no_grad():
            for _ in range(10):  # å¤šæ¬¡è¿­ä»£ä»¥ç¨³å®š
                for batch in support_loader:
                    if len(batch) == 3:
                        images, _, _ = batch
                    else:
                        images, _ = batch
                    images = images.to(self.device)
                    _ = self.model(images)
        
        # ä¿å­˜ç›®æ ‡åŸŸç»Ÿè®¡é‡
        target_stats = self._save_bn_stats()
        
        # èåˆæºåŸŸå’Œç›®æ ‡åŸŸç»Ÿè®¡é‡
        for name, module in self.model.named_modules():
            if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                if name in source_stats and name in target_stats:
                    # åŠ æƒå¹³å‡
                    module.running_mean = (1-alpha) * source_stats[name]['running_mean'] + \
                                         alpha * target_stats[name]['running_mean']
                    module.running_var = (1-alpha) * source_stats[name]['running_var'] + \
                                        alpha * target_stats[name]['running_var']
        
        self.model.eval()
        print("âœ… BN stats adapted via weighted fusion!")
    
    def adapt_bn_stats_v2(self, support_loader, momentum=0.01, iterations=5):
        """æ–¹æ³•2ï¼šæ¸è¿›å¼æ›´æ–°ï¼ˆå°momentumï¼‰"""
        print(f"ğŸ”§ Method 2: Progressive update (momentum={momentum}, iter={iterations})...")
        
        # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ä½†ä¸æ›´æ–°å‚æ•°
        self.model.train()
        for param in self.model.parameters():
            param.requires_grad = False
        
        # ä½¿ç”¨å°momentumæ¸è¿›æ›´æ–°
        for module in self.model.modules():
            if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                module.momentum = momentum  # å°æ­¥æ›´æ–°
                # ä¸é‡ç½®ç»Ÿè®¡é‡ï¼ä¿ç•™åŸå§‹å€¼
        
        # å¤šæ¬¡è¿­ä»£æ¸è¿›æ›´æ–°
        with torch.no_grad():
            for iteration in range(iterations):
                for batch in tqdm(support_loader, desc=f"Iter {iteration+1}/{iterations}", leave=False):
                    if len(batch) == 3:
                        images, _, _ = batch
                    else:
                        images, _ = batch
                    images = images.to(self.device)
                    _ = self.model(images)
        
        self.model.eval()
        print("âœ… BN stats progressively updated!")
    
    def adapt_bn_stats_v3(self, support_loader):
        """æ–¹æ³•3ï¼šä»…è°ƒæ•´å‡å€¼åç§»"""
        print("ğŸ”§ Method 3: Mean-shift only...")
        
        self.model.eval()
        
        # è®¡ç®—æ”¯æŒé›†ç‰¹å¾çš„å‡å€¼åç§»
        with torch.no_grad():
            source_means = {}
            target_means = {}
            
            # æ”¶é›†æ¯å±‚çš„æ¿€æ´»å‡å€¼
            def hook_fn(name):
                def hook(module, input, output):
                    if name not in target_means:
                        target_means[name] = []
                    if isinstance(output, torch.Tensor):
                        # è®¡ç®—batchå‡å€¼
                        if len(output.shape) == 4:  # Convå±‚
                            mean = output.mean(dim=[0,2,3])
                        else:  # Linearå±‚
                            mean = output.mean(dim=0)
                        target_means[name].append(mean.cpu())
                return hook
            
            # æ³¨å†Œé’©å­
            hooks = []
            for name, module in self.model.named_modules():
                if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                    hooks.append(module.register_forward_hook(hook_fn(name)))
            
            # å‰å‘ä¼ æ’­æ”¶é›†ç»Ÿè®¡
            for batch in support_loader:
                if len(batch) == 3:
                    images, _, _ = batch
                else:
                    images, _ = batch
                images = images.to(self.device)
                _ = self.model(images)
            
            # ç§»é™¤é’©å­
            for hook in hooks:
                hook.remove()
            
            # è®¡ç®—å‡å€¼åç§»å¹¶åº”ç”¨
            for name, module in self.model.named_modules():
                if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                    if name in target_means and len(target_means[name]) > 0:
                        target_mean = torch.stack(target_means[name]).mean(dim=0)
                        source_mean = module.running_mean
                        # è°ƒæ•´å‡å€¼
                        shift = target_mean.to(self.device) - source_mean
                        module.running_mean = source_mean + 0.3 * shift  # éƒ¨åˆ†åç§»
        
        print("âœ… Mean-shift adaptation complete!")
    
    def evaluate(self, test_loader):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in tqdm(test_loader, desc="Evaluating"):
                if len(batch) == 3:
                    images, labels, _ = batch
                else:
                    images, labels = batch
                    
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                outputs = self.model(images)
                _, predicted = torch.max(outputs, 1)
                
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        accuracy = correct / total
        return accuracy


def test_all_methods(model_path, data_dir, support_size=3, seed=42):
    """æµ‹è¯•æ‰€æœ‰LCCSæ–¹æ³•"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # æ•°æ®å‡†å¤‡
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # æ”¯æŒé›†
    support_dataset = SplitTargetDomainDataset(
        data_dir=data_dir,
        transform=transform,
        support_size=support_size,
        mode='support',
        seed=seed
    )
    
    support_loader = DataLoader(
        support_dataset,
        batch_size=31,  # æ‰€æœ‰ç”¨æˆ·ä¸€ä¸ªbatch
        shuffle=True,
        num_workers=2
    )
    
    # æµ‹è¯•é›†
    test_dataset = SplitTargetDomainDataset(
        data_dir=data_dir,
        transform=transform,
        support_size=support_size,
        mode='test',
        seed=seed
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=64,
        shuffle=False,
        num_workers=4
    )
    
    print(f"ğŸ“Š Data split: {len(support_dataset)} support, {len(test_dataset)} test")
    
    results = {}
    
    # åŸºçº¿æµ‹è¯•
    print("\n" + "="*60)
    print("ğŸ“Š BASELINE (No adaptation)")
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    model = ImprovedClassifier(
        num_classes=checkpoint.get('num_classes', 31),
        backbone=checkpoint.get('backbone', 'resnet18')
    ).to(device)
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    adapter = FixedLCCSAdapter(model, device)
    baseline_acc = adapter.evaluate(test_loader)
    results['baseline'] = baseline_acc
    print(f"Baseline accuracy: {baseline_acc:.2%}")
    
    # æ–¹æ³•1ï¼šåŠ æƒèåˆ
    print("\n" + "="*60)
    print("ğŸ”¬ METHOD 1: Weighted Fusion")
    adapter._restore_bn_stats()  # æ¢å¤åŸå§‹
    adapter.adapt_bn_stats_v1(support_loader, alpha=0.3)
    method1_acc = adapter.evaluate(test_loader)
    results['weighted_fusion'] = method1_acc
    print(f"Method 1 accuracy: {method1_acc:.2%} ({method1_acc-baseline_acc:+.2%})")
    
    # æ–¹æ³•2ï¼šæ¸è¿›æ›´æ–°
    print("\n" + "="*60)
    print("ğŸ”¬ METHOD 2: Progressive Update")
    adapter._restore_bn_stats()  # æ¢å¤åŸå§‹
    adapter.adapt_bn_stats_v2(support_loader, momentum=0.01, iterations=5)
    method2_acc = adapter.evaluate(test_loader)
    results['progressive'] = method2_acc
    print(f"Method 2 accuracy: {method2_acc:.2%} ({method2_acc-baseline_acc:+.2%})")
    
    # æ–¹æ³•3ï¼šå‡å€¼åç§»
    print("\n" + "="*60)
    print("ğŸ”¬ METHOD 3: Mean-shift Only")
    adapter._restore_bn_stats()  # æ¢å¤åŸå§‹
    adapter.adapt_bn_stats_v3(support_loader)
    method3_acc = adapter.evaluate(test_loader)
    results['mean_shift'] = method3_acc
    print(f"Method 3 accuracy: {method3_acc:.2%} ({method3_acc-baseline_acc:+.2%})")
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š SUMMARY")
    print("="*60)
    for method, acc in results.items():
        improvement = acc - results['baseline'] if method != 'baseline' else 0
        print(f"{method:20s}: {acc:.2%} ({improvement:+.2%})")
    
    best_method = max(results, key=results.get)
    print(f"\nğŸ† Best method: {best_method} ({results[best_method]:.2%})")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-path', type=str,
                       default='/kaggle/working/VA-VAE/improved_classifier/best_improved_classifier.pth')
    parser.add_argument('--data-dir', type=str,
                       default='/kaggle/input/backpack/backpack')
    parser.add_argument('--support-size', type=int, default=3)
    parser.add_argument('--seed', type=int, default=42)
    
    args = parser.parse_args()
    test_all_methods(args.model_path, args.data_dir, args.support_size, args.seed)


if __name__ == '__main__':
    main()
