#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆLCCS - ä¸å®Œå…¨é‡ç½®BNç»Ÿè®¡é‡ï¼Œè€Œæ˜¯å¾®è°ƒ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from copy import deepcopy
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
from pathlib import Path
from PIL import Image
import numpy as np
from tqdm import tqdm
from collections import defaultdict
import argparse
import sys
sys.path.append(str(Path(__file__).parent.parent))
from improved_classifier_training import ImprovedClassifier
from build_improved_prototypes_with_split import SplitTargetDomainDataset


class FixedLCCSAdapter:
    """ä¿®å¤ç‰ˆLCCSï¼šä¿ç•™åŸå§‹ç»Ÿè®¡é‡ï¼Œä»…å¾®è°ƒ"""
    
    def __init__(self, model, device='cuda'):
        self.device = device
        self.model = model.to(device)
        self.original_bn_stats = self._save_bn_stats()
        
    def _save_bn_stats(self):
        """ä¿å­˜åŸå§‹BNå±‚çš„ç»Ÿè®¡é‡"""
        bn_stats = {}
        for name, module in self.model.named_modules():
            if isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.BatchNorm1d):
                bn_stats[name] = {
                    'running_mean': module.running_mean.clone(),
                    'running_var': module.running_var.clone(),
                    'momentum': module.momentum,
                    'num_batches_tracked': module.num_batches_tracked.clone() if module.num_batches_tracked is not None else None
                }
        return bn_stats
    
    def _restore_bn_stats(self):
        """æ¢å¤åŸå§‹BNç»Ÿè®¡é‡"""
        for name, module in self.model.named_modules():
            if name in self.original_bn_stats:
                module.running_mean.data = self.original_bn_stats[name]['running_mean']
                module.running_var.data = self.original_bn_stats[name]['running_var']
                if module.num_batches_tracked is not None:
                    module.num_batches_tracked.data = self.original_bn_stats[name]['num_batches_tracked']
    
    def adapt_bn_stats_v1(self, support_loader, alpha=0.3):
        """æ–¹æ³•1ï¼šåŠ æƒèåˆåŸå§‹å’Œç›®æ ‡åŸŸç»Ÿè®¡é‡"""
        print(f"ğŸ”§ Method 1: Weighted fusion (Î±={alpha})...")
        
        # æ”¶é›†ç›®æ ‡åŸŸç»Ÿè®¡é‡ï¼ˆä¸é‡ç½®åŸå§‹ç»Ÿè®¡é‡ï¼‰
        self.model.train()
        
        # ä¿å­˜å½“å‰ç»Ÿè®¡é‡
        source_stats = self._save_bn_stats()
        
        # ä¸´æ—¶é‡ç½®ä»¥æ”¶é›†çº¯ç›®æ ‡åŸŸç»Ÿè®¡é‡
        for module in self.model.modules():
            if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                module.reset_running_stats()
                module.momentum = 1.0  # å¿«é€Ÿæ”¶é›†
        
        # æ”¶é›†ç›®æ ‡åŸŸç»Ÿè®¡é‡
        with torch.no_grad():
            for _ in range(10):  # å¤šæ¬¡è¿­ä»£ä»¥ç¨³å®š
                for batch in support_loader:
                    if len(batch) == 3:
                        images, _, _ = batch
                    else:
                        images, _ = batch
                    images = images.to(self.device)
                    _ = self.model(images)
        
        # ä¿å­˜ç›®æ ‡åŸŸç»Ÿè®¡é‡
        target_stats = self._save_bn_stats()
        
        # èåˆæºåŸŸå’Œç›®æ ‡åŸŸç»Ÿè®¡é‡
        for name, module in self.model.named_modules():
            if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                if name in source_stats and name in target_stats:
                    # åŠ æƒå¹³å‡
                    module.running_mean = (1-alpha) * source_stats[name]['running_mean'] + \
                                         alpha * target_stats[name]['running_mean']
                    module.running_var = (1-alpha) * source_stats[name]['running_var'] + \
                                        alpha * target_stats[name]['running_var']
        
        self.model.eval()
        print("âœ… BN stats adapted via weighted fusion!")
    
    def adapt_bn_stats_v2(self, support_loader, momentum=0.01, iterations=5):
        """æ–¹æ³•2ï¼šæ¸è¿›å¼æ›´æ–°ï¼ˆå°momentumï¼‰"""
        print(f"ğŸ”§ Method 2: Progressive update (momentum={momentum}, iter={iterations})...")
        
        # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ä½†ä¸æ›´æ–°å‚æ•°
        self.model.train()
        for param in self.model.parameters():
            param.requires_grad = False
        
        # ä½¿ç”¨å°momentumæ¸è¿›æ›´æ–°
        for module in self.model.modules():
            if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                module.momentum = momentum  # å°æ­¥æ›´æ–°
                # ä¸é‡ç½®ç»Ÿè®¡é‡ï¼ä¿ç•™åŸå§‹å€¼
        
        # å¤šæ¬¡è¿­ä»£æ¸è¿›æ›´æ–°
        with torch.no_grad():
            for iteration in range(iterations):
                for batch in tqdm(support_loader, desc=f"Iter {iteration+1}/{iterations}", leave=False):
                    if len(batch) == 3:
                        images, _, _ = batch
                    else:
                        images, _ = batch
                    images = images.to(self.device)
                    _ = self.model(images)
        
        self.model.eval()
        print("âœ… BN stats progressively updated!")
    
    def adapt_bn_stats_v3(self, support_loader):
        """æ–¹æ³•3ï¼šä»…è°ƒæ•´å‡å€¼åç§»"""
        print("ğŸ”§ Method 3: Mean-shift only...")
        
        self.model.eval()
        
        # è®¡ç®—æ”¯æŒé›†ç‰¹å¾çš„å‡å€¼åç§»
        with torch.no_grad():
            source_means = {}
            target_means = {}
            
            # æ”¶é›†æ¯å±‚çš„æ¿€æ´»å‡å€¼
            def hook_fn(name):
                def hook(module, input, output):
                    if name not in target_means:
                        target_means[name] = []
                    if isinstance(output, torch.Tensor):
                        # è®¡ç®—batchå‡å€¼
                        if len(output.shape) == 4:  # Convå±‚
                            mean = output.mean(dim=[0,2,3])
                        else:  # Linearå±‚
                            mean = output.mean(dim=0)
                        target_means[name].append(mean.cpu())
                return hook
            
            # æ³¨å†Œé’©å­
            hooks = []
            for name, module in self.model.named_modules():
                if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                    hooks.append(module.register_forward_hook(hook_fn(name)))
            
            # å‰å‘ä¼ æ’­æ”¶é›†ç»Ÿè®¡
            for batch in support_loader:
                if len(batch) == 3:
                    images, _, _ = batch
                else:
                    images, _ = batch
                images = images.to(self.device)
                _ = self.model(images)
            
            # ç§»é™¤é’©å­
            for hook in hooks:
                hook.remove()
            
            # è®¡ç®—å‡å€¼åç§»å¹¶åº”ç”¨
            for name, module in self.model.named_modules():
                if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                    if name in target_means and len(target_means[name]) > 0:
                        target_mean = torch.stack(target_means[name]).mean(dim=0)
                        source_mean = module.running_mean
                        # è°ƒæ•´å‡å€¼
                        shift = target_mean.to(self.device) - source_mean
                        module.running_mean = source_mean + 0.3 * shift  # éƒ¨åˆ†åç§»
        
        print("âœ… Mean-shift adaptation complete!")
    
    def compute_class_prototypes(self, support_loader):
        """è®¡ç®—æ¯ä¸ªç±»çš„åŸå‹ï¼ˆè´¨å¿ƒï¼‰ç”¨äºNCCåˆ†ç±»"""
        print("ğŸ”§ Computing class prototypes for NCC...")
        
        self.model.eval()
        class_features = defaultdict(list)
        
        with torch.no_grad():
            for batch in support_loader:
                if len(batch) == 3:
                    images, labels, _ = batch
                else:
                    images, labels = batch
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                # æå–ç‰¹å¾ï¼ˆbackboneè¾“å‡ºï¼‰
                features = self.model.backbone(images)  # [B, 512] for ResNet18
                
                # æŒ‰ç±»æ”¶é›†ç‰¹å¾
                for feat, label in zip(features, labels):
                    class_features[label.item()].append(feat)
        
        # è®¡ç®—æ¯ä¸ªç±»çš„åŸå‹ï¼ˆå‡å€¼ï¼‰
        self.prototypes = {}
        for class_id, feats in class_features.items():
            if feats:
                class_prototype = torch.stack(feats).mean(dim=0)
                self.prototypes[class_id] = F.normalize(class_prototype, dim=0)
        
        print(f"âœ… Computed prototypes for {len(self.prototypes)} classes")
        return self.prototypes
    
    def ncc_predict(self, features):
        """ä½¿ç”¨æœ€è¿‘è´¨å¿ƒåˆ†ç±»å™¨é¢„æµ‹"""
        if not hasattr(self, 'prototypes'):
            raise ValueError("Prototypes not computed! Call compute_class_prototypes first.")
        
        # å½’ä¸€åŒ–ç‰¹å¾
        features = F.normalize(features, dim=1)
        
        # è®¡ç®—åˆ°æ¯ä¸ªåŸå‹çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆæ›´é€‚åˆå¯¹æ¯”å­¦ä¹ ç‰¹å¾ï¼‰
        similarities = []
        class_ids = []
        for class_id, prototype in self.prototypes.items():
            # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ›¿ä»£L2è·ç¦»
            sim = torch.matmul(features, prototype.unsqueeze(1))  # [batch, 1]
            similarities.append(sim)
            class_ids.append(class_id)
        
        # æ‰¾æœ€é«˜ç›¸ä¼¼åº¦çš„åŸå‹
        similarities = torch.cat(similarities, dim=1)  # [batch_size, num_classes]
        argmax_indices = similarities.argmax(dim=1)  # GPUä¸Šçš„ç´¢å¼•
        
        # å°†class_idsè½¬æ¢ä¸ºä¸ç›¸ä¼¼åº¦ç›¸åŒè®¾å¤‡çš„å¼ é‡
        class_ids_tensor = torch.tensor(class_ids, device=similarities.device)
        predictions = class_ids_tensor[argmax_indices]
        
        return predictions
    
    def ncc_predict_with_confidence(self, features, temperature=0.1):
        """ä½¿ç”¨æœ€è¿‘è´¨å¿ƒåˆ†ç±»å™¨é¢„æµ‹ï¼ˆå¸¦ç½®ä¿¡åº¦å’Œæ¸©åº¦ç¼©æ”¾ï¼‰"""
        if not hasattr(self, 'prototypes'):
            raise ValueError("Prototypes not computed! Call compute_class_prototypes first.")
        
        # å½’ä¸€åŒ–ç‰¹å¾
        features = F.normalize(features, dim=1)
        
        # è®¡ç®—åˆ°æ¯ä¸ªåŸå‹çš„ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = []
        class_ids = []
        for class_id, prototype in self.prototypes.items():
            # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
            sim = torch.matmul(features, prototype.unsqueeze(1))  # [batch, 1]
            similarities.append(sim)
            class_ids.append(class_id)
        
        # åˆå¹¶ç›¸ä¼¼åº¦
        similarities = torch.cat(similarities, dim=1)  # [batch_size, num_classes]
        
        # æ¸©åº¦ç¼©æ”¾åçš„softmaxï¼ˆè§£å†³ç½®ä¿¡åº¦è¿‡ä½çš„é—®é¢˜ï¼‰
        scaled_similarities = similarities / temperature
        probs = F.softmax(scaled_similarities, dim=1)
        
        # è·å–é¢„æµ‹å’Œç½®ä¿¡åº¦
        confidences, indices = probs.max(dim=1)
        
        # æ˜ å°„åˆ°ç±»åˆ«ID
        class_ids_tensor = torch.tensor(class_ids, device=similarities.device)
        predictions = class_ids_tensor[indices]
        
        return predictions, confidences
    
    def evaluate(self, test_loader, use_ncc=False, return_confidence=True):
        """è¯„ä¼°æ€§èƒ½ï¼ˆæ”¯æŒNCCå’ŒåŸå§‹åˆ†ç±»å™¨ï¼Œè¿”å›ç½®ä¿¡åº¦ï¼‰"""
        self.model.eval()
        
        correct = 0
        total = 0
        all_confidences = []
        
        with torch.no_grad():
            for batch in test_loader:
                if len(batch) == 3:
                    images, labels, _ = batch
                else:
                    images, labels = batch
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                if use_ncc:
                    # ä½¿ç”¨NCCåˆ†ç±»
                    features = self.model.backbone(images)
                    predicted, confidences = self.ncc_predict_with_confidence(features)
                else:
                    # ä½¿ç”¨åŸå§‹åˆ†ç±»å™¨
                    outputs = self.model(images)
                    probs = F.softmax(outputs, dim=1)
                    confidences, predicted = torch.max(probs, 1)
                
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                all_confidences.extend(confidences.cpu().numpy())
        
        accuracy = correct / total
        mean_confidence = np.mean(all_confidences)
        
        if return_confidence:
            return accuracy, mean_confidence
        return accuracy


def load_model(model_path, device, model_type='improved'):
    """åŠ è½½è®­ç»ƒå¥½çš„åˆ†ç±»å™¨æ¨¡å‹"""
    if model_type == 'standard':
        # ä½¿ç”¨æ ‡å‡†ResNet18
        from train_standard_resnet import StandardResNet18Classifier
        model = StandardResNet18Classifier(num_classes=31)
        # ä¿®æ”¹backboneè®¿é—®æ–¹å¼
        model.backbone = model.backbone  # ResNet18å·²ç»æ˜¯backbone
    else:
        # ä½¿ç”¨ImprovedClassifier
        model = ImprovedClassifier(num_classes=31)
    
    checkpoint = torch.load(model_path, map_location=device)
    
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model = model.to(device)
    return model


def test_all_methods(model_path, data_dir, support_size=3, seed=42, tune_params=False):
    """æµ‹è¯•æ‰€æœ‰LCCSæ–¹æ³•ï¼ˆåŒ…å«NCCï¼‰"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # æ•°æ®å‡†å¤‡
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # æ”¯æŒé›†
    support_dataset = SplitTargetDomainDataset(
        data_dir=data_dir,
        transform=transform,
        support_size=support_size,
        mode='support',
        seed=seed
    )
    
    support_loader = DataLoader(
        support_dataset,
        batch_size=31,  # æ‰€æœ‰ç”¨æˆ·ä¸€ä¸ªbatch
        shuffle=True,
        num_workers=2
    )
    
    # æµ‹è¯•é›†
    test_dataset = SplitTargetDomainDataset(
        data_dir=data_dir,
        transform=transform,
        support_size=support_size,
        mode='test',
        seed=seed
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=64,
        shuffle=False,
        num_workers=4
    )
    
    print(f"ğŸ“Š Data split: {len(support_dataset)} support, {len(test_dataset)} test")
    
    results = {}
    
    # åŸºçº¿æµ‹è¯•ï¼ˆæ— é€‚åº”ï¼‰
    print("\n" + "="*60)
    print("ğŸ”¬ BASELINE: No adaptation")
    model = load_model(model_path, device)
    adapter = FixedLCCSAdapter(model, device)
    baseline_acc, baseline_conf = adapter.evaluate(test_loader, use_ncc=False)
    results['baseline'] = {'accuracy': baseline_acc, 'confidence': baseline_conf}
    print(f"Baseline accuracy: {baseline_acc:.2%}, confidence: {baseline_conf:.3f}")
    
    # æµ‹è¯•æ‰€æœ‰æ–¹æ³•ç»„åˆ
    print("\n" + "="*60)
    print("ğŸ”¬ Testing LCCS methods with/without NCC")
    print("="*60)
    
    if tune_params:
        # å‚æ•°è°ƒä¼˜æ¨¡å¼ï¼šæµ‹è¯•å¤šä¸ªalphaå€¼
        print("\nğŸ”¬ Parameter Tuning Mode")
        alpha_values = [0.05, 0.1, 0.15, 0.2, 0.3]
        momentum_values = [0.001, 0.005, 0.01]
        
        for alpha in alpha_values:
            for use_ncc in [False, True]:
                method_name = f"weighted_a{alpha}{'_NCC' if use_ncc else ''}"
                print(f"\nğŸ“Š Testing {method_name}...")
                
                model = load_model(model_path, device)
                adapter = FixedLCCSAdapter(model, device)
                adapter.adapt_bn_stats_v1(support_loader, alpha=alpha)
                
                if use_ncc:
                    adapter.compute_class_prototypes(support_loader)
                
                acc, conf = adapter.evaluate(test_loader, use_ncc=use_ncc)
                results[method_name] = {'accuracy': acc, 'confidence': conf}
                print(f"   Accuracy: {acc:.2%}, Confidence: {conf:.3f}")
                
        for momentum in momentum_values:
            for use_ncc in [False, True]:
                method_name = f"prog_m{momentum}{'_NCC' if use_ncc else ''}"
                print(f"\nğŸ“Š Testing {method_name}...")
                
                model = load_model(model_path, device)
                adapter = FixedLCCSAdapter(model, device)
                adapter.adapt_bn_stats_v2(support_loader, momentum=momentum, iterations=3)
                
                if use_ncc:
                    adapter.compute_class_prototypes(support_loader)
                
                acc, conf = adapter.evaluate(test_loader, use_ncc=use_ncc)
                results[method_name] = {'accuracy': acc, 'confidence': conf}
                print(f"   Accuracy: {acc:.2%}, Confidence: {conf:.3f}")
    else:
        # æ ‡å‡†æµ‹è¯•æ¨¡å¼
        for method in ['weighted_gentle', 'progressive_conservative']:
            for use_ncc in [False, True]:
                method_name = f"{method}{'_NCC' if use_ncc else ''}"
                print(f"\nğŸ“Š Testing {method_name}...")
                
                # é‡æ–°åŠ è½½æ¨¡å‹
                model = load_model(model_path, device)
                adapter = FixedLCCSAdapter(model, device)
                
                # åº”ç”¨ä¸åŒçš„é€‚åº”æ–¹æ³•
                if method == 'weighted_gentle':
                    adapter.adapt_bn_stats_v1(support_loader, alpha=0.1)
                elif method == 'progressive_conservative':
                    adapter.adapt_bn_stats_v2(support_loader, momentum=0.005, iterations=3)
                
                # å¦‚æœä½¿ç”¨NCCï¼Œè®¡ç®—åŸå‹
                if use_ncc:
                    adapter.compute_class_prototypes(support_loader)
                
                # è¯„ä¼°
                acc, conf = adapter.evaluate(test_loader, use_ncc=use_ncc)
                results[method_name] = {'accuracy': acc, 'confidence': conf}
                improvement = acc - baseline_acc
                print(f"   Accuracy: {acc:.2%} ({improvement:+.2%}), Confidence: {conf:.3f}")
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š SUMMARY")
    print("="*60)
    print(f"{'Method':<25} {'Accuracy':>10} {'Confidence':>12} {'Improvement':>12}")
    print("-"*70)
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    sorted_results = sorted(results.items(), 
                           key=lambda x: x[1]['accuracy'] if isinstance(x[1], dict) else x[1], 
                           reverse=True)
    
    for method, metrics in sorted_results:
        if isinstance(metrics, dict):
            acc = metrics['accuracy']
            conf = metrics['confidence']
        else:
            # å…¼å®¹æ—§æ ¼å¼
            acc = metrics
            conf = 0.0
        
        improvement = acc - baseline_acc
        print(f"{method:<25} {acc:>9.2%} {conf:>11.3f} {improvement:>+11.2%}")
    
    # æ‰¾æœ€ä½³æ–¹æ³•
    best_method = max(results.items(), 
                     key=lambda x: x[1]['accuracy'] if isinstance(x[1], dict) else x[1])
    method_name = best_method[0]
    if isinstance(best_method[1], dict):
        best_acc = best_method[1]['accuracy']
        best_conf = best_method[1]['confidence']
        print(f"\nğŸ† Best method: {method_name} with {best_acc:.2%} (confidence: {best_conf:.3f})")
    else:
        best_acc = best_method[1]
        print(f"\nğŸ† Best method: {method_name} with {best_acc:.2%}")
    
    return results


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-path', type=str,
                       default='/kaggle/working/VA-VAE/improved_classifier/best_improved_classifier.pth')
    parser.add_argument('--data-dir', type=str,
                       default='/kaggle/input/backpack/backpack')
    parser.add_argument('--support-size', type=int, default=3)
    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--tune-params', action='store_true',
                       help='Enable parameter tuning mode to test multiple alpha/momentum values')
    
    args = parser.parse_args()
    test_all_methods(args.model_path, args.data_dir, args.support_size, args.seed, args.tune_params)


if __name__ == '__main__':
    main()
