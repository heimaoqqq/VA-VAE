#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆLCCS - ä¸å®Œå…¨é‡ç½®BNç»Ÿè®¡é‡ï¼Œè€Œæ˜¯å¾®è°ƒ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from copy import deepcopy
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
from pathlib import Path
from PIL import Image
import numpy as np
from tqdm import tqdm
from collections import defaultdict
import argparse
import sys
sys.path.append(str(Path(__file__).parent.parent))
from improved_classifier_training import ImprovedClassifier
from build_improved_prototypes_with_split import SplitTargetDomainDataset


class FixedLCCSAdapter:
    """ä¿®å¤ç‰ˆLCCSï¼šä¿ç•™åŸå§‹ç»Ÿè®¡é‡ï¼Œä»…å¾®è°ƒ"""
    
    def __init__(self, model, device='cuda'):
        self.device = device
        self.model = model.to(device)
        self.original_bn_stats = self._save_bn_stats()
        
    def _save_bn_stats(self):
        """ä¿å­˜åŸå§‹BNå±‚çš„ç»Ÿè®¡é‡"""
        bn_stats = {}
        for name, module in self.model.named_modules():
            if isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.BatchNorm1d):
                bn_stats[name] = {
                    'running_mean': module.running_mean.clone(),
                    'running_var': module.running_var.clone(),
                    'momentum': module.momentum,
                    'num_batches_tracked': module.num_batches_tracked.clone() if module.num_batches_tracked is not None else None
                }
        return bn_stats
    
    def _restore_bn_stats(self):
        """æ¢å¤åŸå§‹BNç»Ÿè®¡é‡"""
        for name, module in self.model.named_modules():
            if name in self.original_bn_stats:
                module.running_mean.data = self.original_bn_stats[name]['running_mean']
                module.running_var.data = self.original_bn_stats[name]['running_var']
                if module.num_batches_tracked is not None:
                    module.num_batches_tracked.data = self.original_bn_stats[name]['num_batches_tracked']
    
    def adapt_bn_stats_v1(self, support_loader, alpha=0.3):
        """æ–¹æ³•1ï¼šåŠ æƒèåˆåŸå§‹å’Œç›®æ ‡åŸŸç»Ÿè®¡é‡"""
        print(f"ğŸ”§ Method 1: Weighted fusion (Î±={alpha})...")
        
        # æ”¶é›†ç›®æ ‡åŸŸç»Ÿè®¡é‡ï¼ˆä¸é‡ç½®åŸå§‹ç»Ÿè®¡é‡ï¼‰
        self.model.train()
        
        # ä¿å­˜å½“å‰ç»Ÿè®¡é‡
        source_stats = self._save_bn_stats()
        
        # ä¸´æ—¶é‡ç½®ä»¥æ”¶é›†çº¯ç›®æ ‡åŸŸç»Ÿè®¡é‡
        for module in self.model.modules():
            if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                module.reset_running_stats()
                module.momentum = 1.0  # å¿«é€Ÿæ”¶é›†
        
        # æ”¶é›†ç›®æ ‡åŸŸç»Ÿè®¡é‡
        with torch.no_grad():
            for _ in range(10):  # å¤šæ¬¡è¿­ä»£ä»¥ç¨³å®š
                for batch in support_loader:
                    if len(batch) == 3:
                        images, _, _ = batch
                    else:
                        images, _ = batch
                    images = images.to(self.device)
                    _ = self.model(images)
        
        # ä¿å­˜ç›®æ ‡åŸŸç»Ÿè®¡é‡
        target_stats = self._save_bn_stats()
        
        # èåˆæºåŸŸå’Œç›®æ ‡åŸŸç»Ÿè®¡é‡
        for name, module in self.model.named_modules():
            if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                if name in source_stats and name in target_stats:
                    # åŠ æƒå¹³å‡
                    module.running_mean = (1-alpha) * source_stats[name]['running_mean'] + \
                                         alpha * target_stats[name]['running_mean']
                    module.running_var = (1-alpha) * source_stats[name]['running_var'] + \
                                        alpha * target_stats[name]['running_var']
        
        self.model.eval()
        print("âœ… BN stats adapted via weighted fusion!")
    
    def adapt_bn_stats_v2(self, support_loader, momentum=0.01, iterations=5):
        """æ–¹æ³•2ï¼šæ¸è¿›å¼æ›´æ–°ï¼ˆå°momentumï¼‰"""
        print(f"ğŸ”§ Method 2: Progressive update (momentum={momentum}, iter={iterations})...")
        
        # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ä½†ä¸æ›´æ–°å‚æ•°
        self.model.train()
        for param in self.model.parameters():
            param.requires_grad = False
        
        # ä½¿ç”¨å°momentumæ¸è¿›æ›´æ–°
        for module in self.model.modules():
            if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                module.momentum = momentum  # å°æ­¥æ›´æ–°
                # ä¸é‡ç½®ç»Ÿè®¡é‡ï¼ä¿ç•™åŸå§‹å€¼
        
        # å¤šæ¬¡è¿­ä»£æ¸è¿›æ›´æ–°
        with torch.no_grad():
            for iteration in range(iterations):
                for batch in tqdm(support_loader, desc=f"Iter {iteration+1}/{iterations}", leave=False):
                    if len(batch) == 3:
                        images, _, _ = batch
                    else:
                        images, _ = batch
                    images = images.to(self.device)
                    _ = self.model(images)
        
        self.model.eval()
        print("âœ… BN stats progressively updated!")
    
    def adapt_bn_stats_v3(self, support_loader):
        """æ–¹æ³•3ï¼šä»…è°ƒæ•´å‡å€¼åç§»"""
        print("ğŸ”§ Method 3: Mean-shift only...")
        
        self.model.eval()
        
        # è®¡ç®—æ”¯æŒé›†ç‰¹å¾çš„å‡å€¼åç§»
        with torch.no_grad():
            source_means = {}
            target_means = {}
            
            # æ”¶é›†æ¯å±‚çš„æ¿€æ´»å‡å€¼
            def hook_fn(name):
                def hook(module, input, output):
                    if name not in target_means:
                        target_means[name] = []
                    if isinstance(output, torch.Tensor):
                        # è®¡ç®—batchå‡å€¼
                        if len(output.shape) == 4:  # Convå±‚
                            mean = output.mean(dim=[0,2,3])
                        else:  # Linearå±‚
                            mean = output.mean(dim=0)
                        target_means[name].append(mean.cpu())
                return hook
            
            # æ³¨å†Œé’©å­
            hooks = []
            for name, module in self.model.named_modules():
                if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                    hooks.append(module.register_forward_hook(hook_fn(name)))
            
            # å‰å‘ä¼ æ’­æ”¶é›†ç»Ÿè®¡
            for batch in support_loader:
                if len(batch) == 3:
                    images, _, _ = batch
                else:
                    images, _ = batch
                images = images.to(self.device)
                _ = self.model(images)
            
            # ç§»é™¤é’©å­
            for hook in hooks:
                hook.remove()
            
            # è®¡ç®—å‡å€¼åç§»å¹¶åº”ç”¨
            for name, module in self.model.named_modules():
                if isinstance(module, (nn.BatchNorm2d, nn.BatchNorm1d)):
                    if name in target_means and len(target_means[name]) > 0:
                        target_mean = torch.stack(target_means[name]).mean(dim=0)
                        source_mean = module.running_mean
                        # è°ƒæ•´å‡å€¼
                        shift = target_mean.to(self.device) - source_mean
                        module.running_mean = source_mean + 0.3 * shift  # éƒ¨åˆ†åç§»
        
        print("âœ… Mean-shift adaptation complete!")
    
    def compute_class_prototypes(self, support_loader):
        """è®¡ç®—æ¯ä¸ªç±»çš„åŸå‹ï¼ˆè´¨å¿ƒï¼‰ç”¨äºNCCåˆ†ç±»"""
        print("ğŸ”§ Computing class prototypes for NCC...")
        
        self.model.eval()
        class_features = defaultdict(list)
        
        with torch.no_grad():
            for batch in support_loader:
                if len(batch) == 3:
                    images, labels, _ = batch
                else:
                    images, labels = batch
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                # æå–ç‰¹å¾ï¼ˆbackboneè¾“å‡ºï¼‰
                features = self.model.backbone(images)  # [B, 512] for ResNet18
                
                # æŒ‰ç±»æ”¶é›†ç‰¹å¾
                for feat, label in zip(features, labels):
                    class_features[label.item()].append(feat)
        
        # è®¡ç®—æ¯ä¸ªç±»çš„åŸå‹ï¼ˆå‡å€¼ï¼‰
        self.prototypes = {}
        for class_id, feats in class_features.items():
            if feats:
                class_prototype = torch.stack(feats).mean(dim=0)
                self.prototypes[class_id] = F.normalize(class_prototype, dim=0)
        
        print(f"âœ… Computed prototypes for {len(self.prototypes)} classes")
        return self.prototypes
    
    def ncc_predict(self, features):
        """ä½¿ç”¨æœ€è¿‘è´¨å¿ƒåˆ†ç±»å™¨é¢„æµ‹"""
        if not hasattr(self, 'prototypes'):
            raise ValueError("Prototypes not computed! Call compute_class_prototypes first.")
        
        # å½’ä¸€åŒ–ç‰¹å¾
        features = F.normalize(features, dim=1)
        
        # è®¡ç®—åˆ°æ¯ä¸ªåŸå‹çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆæ›´é€‚åˆå¯¹æ¯”å­¦ä¹ ç‰¹å¾ï¼‰
        similarities = []
        class_ids = []
        for class_id, prototype in self.prototypes.items():
            # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ›¿ä»£L2è·ç¦»
            sim = torch.matmul(features, prototype.unsqueeze(1))  # [batch, 1]
            similarities.append(sim)
            class_ids.append(class_id)
        
        # æ‰¾æœ€é«˜ç›¸ä¼¼åº¦çš„åŸå‹
        similarities = torch.cat(similarities, dim=1)  # [batch_size, num_classes]
        argmax_indices = similarities.argmax(dim=1)  # GPUä¸Šçš„ç´¢å¼•
        
        # å°†class_idsè½¬æ¢ä¸ºä¸ç›¸ä¼¼åº¦ç›¸åŒè®¾å¤‡çš„å¼ é‡
        class_ids_tensor = torch.tensor(class_ids, device=similarities.device)
        predictions = class_ids_tensor[argmax_indices]
        
        return predictions
    
    def evaluate(self, test_loader, use_ncc=False):
        """è¯„ä¼°æ€§èƒ½ï¼ˆæ”¯æŒNCCå’ŒåŸå§‹åˆ†ç±»å™¨ï¼‰"""
        self.model.eval()
        
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in test_loader:
                if len(batch) == 3:
                    images, labels, _ = batch
                else:
                    images, labels = batch
                images = images.to(self.device)
                labels = labels.to(self.device)
                
                if use_ncc:
                    # ä½¿ç”¨NCCåˆ†ç±»
                    features = self.model.backbone(images)
                    predicted = self.ncc_predict(features)  # å·²ç»åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
                else:
                    # ä½¿ç”¨åŸå§‹åˆ†ç±»å™¨
                    outputs = self.model(images)
                    _, predicted = torch.max(outputs, 1)
                
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        accuracy = correct / total
        return accuracy


def load_model(model_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„åˆ†ç±»å™¨æ¨¡å‹"""
    model = ImprovedClassifier(num_classes=31)
    checkpoint = torch.load(model_path, map_location=device)
    
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model = model.to(device)
    return model


def test_all_methods(model_path, data_dir, support_size=3, seed=42):
    """æµ‹è¯•æ‰€æœ‰LCCSæ–¹æ³•ï¼ˆåŒ…å«NCCï¼‰"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # æ•°æ®å‡†å¤‡
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # æ”¯æŒé›†
    support_dataset = SplitTargetDomainDataset(
        data_dir=data_dir,
        transform=transform,
        support_size=support_size,
        mode='support',
        seed=seed
    )
    
    support_loader = DataLoader(
        support_dataset,
        batch_size=31,  # æ‰€æœ‰ç”¨æˆ·ä¸€ä¸ªbatch
        shuffle=True,
        num_workers=2
    )
    
    # æµ‹è¯•é›†
    test_dataset = SplitTargetDomainDataset(
        data_dir=data_dir,
        transform=transform,
        support_size=support_size,
        mode='test',
        seed=seed
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=64,
        shuffle=False,
        num_workers=4
    )
    
    print(f"ğŸ“Š Data split: {len(support_dataset)} support, {len(test_dataset)} test")
    
    results = {}
    
    # åŸºçº¿æµ‹è¯•ï¼ˆæ— é€‚åº”ï¼‰
    print("\n" + "="*60)
    print("ğŸ”¬ BASELINE: No adaptation")
    model = load_model(model_path, device)
    adapter = FixedLCCSAdapter(model, device)
    baseline_acc = adapter.evaluate(test_loader, use_ncc=False)
    results['baseline'] = baseline_acc
    print(f"Baseline accuracy: {baseline_acc:.2%}")
    
    # æµ‹è¯•æ‰€æœ‰æ–¹æ³•ç»„åˆ
    print("\n" + "="*60)
    print("ğŸ”¬ Testing LCCS methods with/without NCC")
    print("="*60)
    
    for method in ['weighted', 'progressive']:  # ç§»é™¤ç ´åæ€§çš„mean_shift
        for use_ncc in [False, True]:
            method_name = f"{method}{'_NCC' if use_ncc else ''}"
            print(f"\nğŸ“Š Testing {method_name}...")
            
            # é‡æ–°åŠ è½½æ¨¡å‹
            model = load_model(model_path, device)
            adapter = FixedLCCSAdapter(model, device)
            
            # åº”ç”¨ä¸åŒçš„é€‚åº”æ–¹æ³•
            if method == 'weighted':
                adapter.adapt_bn_stats_v1(support_loader, alpha=0.3)
            elif method == 'progressive':
                adapter.adapt_bn_stats_v2(support_loader, momentum=0.01, iterations=5)
            else:  # mean_shift
                adapter.adapt_bn_stats_v3(support_loader)
            
            # å¦‚æœä½¿ç”¨NCCï¼Œè®¡ç®—åŸå‹
            if use_ncc:
                adapter.compute_class_prototypes(support_loader)
            
            # è¯„ä¼°
            accuracy = adapter.evaluate(test_loader, use_ncc=use_ncc)
            results[method_name] = accuracy
            improvement = accuracy - baseline_acc
            print(f"   Accuracy: {accuracy:.2%} ({improvement:+.2%})")
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š SUMMARY")
    print("="*60)
    print(f"{'Method':<25} {'Accuracy':>10} {'Improvement':>12}")
    print("-"*47)
    for method, acc in results.items():
        improvement = acc - baseline_acc
        print(f"{method:<25} {acc:>9.2%} {improvement:>+11.2%}")
    
    # æ‰¾æœ€ä½³æ–¹æ³•
    best_method = max(results, key=results.get)
    best_acc = results[best_method]
    print(f"\nğŸ† Best method: {best_method} with {best_acc:.2%}")
    
    return results


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-path', type=str,
                       default='/kaggle/working/VA-VAE/improved_classifier/best_improved_classifier.pth')
    parser.add_argument('--data-dir', type=str,
                       default='/kaggle/input/backpack/backpack')
    parser.add_argument('--support-size', type=int, default=3)
    parser.add_argument('--seed', type=int, default=42)
    
    args = parser.parse_args()
    test_all_methods(args.model_path, args.data_dir, args.support_size, args.seed)


if __name__ == '__main__':
    main()
