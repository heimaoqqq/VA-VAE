#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡å‡† ResNet18 åˆ†ç±»å™¨è®­ç»ƒè„šæœ¬ï¼ˆä¸ä½¿ç”¨å¯¹æ¯”å­¦ä¹ ï¼‰
ä½œä¸ºçœŸæ­£çš„ Baseline å¯¹æ¯”
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from pathlib import Path
from PIL import Image
import numpy as np
from tqdm import tqdm
import argparse
import json
from datetime import datetime


class StandardResNet18(nn.Module):
    """
    æ ‡å‡† ResNet18 åˆ†ç±»å™¨
    æ²¡æœ‰å¯¹æ¯”å­¦ä¹ ï¼Œæ²¡æœ‰ç‰¹æ®ŠæŠ€å·§ï¼Œçº¯ç²¹çš„åˆ†ç±»å™¨
    """
    def __init__(self, num_classes=31, pretrained=True):
        super(StandardResNet18, self).__init__()
        # ä½¿ç”¨é¢„è®­ç»ƒçš„ ResNet18
        self.resnet = models.resnet18(pretrained=pretrained)
        
        # æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚
        in_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Linear(in_features, num_classes)
        
        self.num_classes = num_classes
    
    def forward(self, x):
        return self.resnet(x)


class GaitDataset(Dataset):
    """ç®€å•çš„æ­¥æ€æ•°æ®é›†åŠ è½½å™¨"""
    
    def __init__(self, data_dir, transform=None):
        self.data_dir = Path(data_dir)
        self.transform = transform
        self.samples = []
        
        # åŠ è½½æ‰€æœ‰å›¾åƒ
        user_dirs = sorted([d for d in self.data_dir.iterdir() if d.is_dir()])
        
        for user_dir in user_dirs:
            if not user_dir.name.startswith('ID_'):
                continue
            
            user_id = int(user_dir.name.split('_')[1]) - 1  # ID_1 -> 0
            
            image_files = list(user_dir.glob('*.png')) + list(user_dir.glob('*.jpg'))
            
            for img_path in image_files:
                self.samples.append({
                    'path': img_path,
                    'label': user_id
                })
        
        print(f"âœ… åŠ è½½ {len(self.samples)} ä¸ªæ ·æœ¬ï¼Œ{len(user_dirs)} ä¸ªç”¨æˆ·")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        image = Image.open(sample['path']).convert('RGB')
        label = sample['label']
        
        if self.transform:
            image = self.transform(image)
        
        return image, label


def create_data_loaders(data_dir, batch_size=32, num_workers=4, val_split=0.2):
    """åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨"""
    
    # æ•°æ®å¢å¼ºï¼ˆè®­ç»ƒé›†ï¼‰
    train_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # éªŒè¯é›†ï¼ˆä¸å¢å¼ºï¼‰
    val_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºå®Œæ•´æ•°æ®é›†
    full_dataset = GaitDataset(data_dir, transform=train_transform)
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    dataset_size = len(full_dataset)
    indices = list(range(dataset_size))
    split = int(np.floor(val_split * dataset_size))
    
    np.random.seed(42)
    np.random.shuffle(indices)
    
    train_indices, val_indices = indices[split:], indices[:split]
    
    # åˆ›å»ºè®­ç»ƒé›†
    train_dataset = torch.utils.data.Subset(full_dataset, train_indices)
    
    # åˆ›å»ºéªŒè¯é›†ï¼ˆä½¿ç”¨ä¸åŒçš„transformï¼‰
    val_dataset_full = GaitDataset(data_dir, transform=val_transform)
    val_dataset = torch.utils.data.Subset(val_dataset_full, val_indices)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    print(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"âœ… éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
    
    return train_loader, val_loader


def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    
    running_loss = 0.0
    correct = 0
    total = 0
    
    pbar = tqdm(train_loader, desc=f"Epoch {epoch}")
    
    for images, labels in pbar:
        images = images.to(device)
        labels = labels.to(device)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        # ç»Ÿè®¡
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
        
        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({
            'loss': f'{running_loss/total:.4f}',
            'acc': f'{100.*correct/total:.2f}%'
        })
    
    epoch_loss = running_loss / len(train_loader)
    epoch_acc = 100. * correct / total
    
    return epoch_loss, epoch_acc


def validate(model, val_loader, criterion, device):
    """éªŒè¯æ¨¡å‹"""
    model.eval()
    
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc="Validating"):
            images = images.to(device)
            labels = labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
    
    val_loss = running_loss / len(val_loader)
    val_acc = 100. * correct / total
    
    return val_loss, val_acc


def train(model, train_loader, val_loader, criterion, optimizer, scheduler,
          device, epochs, save_dir, patience=10):
    """å®Œæ•´è®­ç»ƒæµç¨‹"""
    
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    best_val_acc = 0.0
    best_model_state = None
    epochs_no_improve = 0
    
    history = {
        'train_loss': [],
        'train_acc': [],
        'val_loss': [],
        'val_acc': []
    }
    
    print("\n" + "="*80)
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ ‡å‡† ResNet18 åˆ†ç±»å™¨")
    print("="*80)
    
    for epoch in range(1, epochs + 1):
        print(f"\nğŸ“ Epoch {epoch}/{epochs}")
        
        # è®­ç»ƒ
        train_loss, train_acc = train_one_epoch(
            model, train_loader, criterion, optimizer, device, epoch
        )
        
        # éªŒè¯
        val_loss, val_acc = validate(model, val_loader, criterion, device)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # è®°å½•å†å²
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š Epoch {epoch} ç»“æœ:")
        print(f"   è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%")
        print(f"   éªŒè¯ - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%")
        print(f"   å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict().copy()
            epochs_no_improve = 0
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': best_model_state,
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_acc': best_val_acc,
                'history': history
            }
            torch.save(checkpoint, save_dir / 'best_standard_resnet18.pth')
            print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%)")
        else:
            epochs_no_improve += 1
            print(f"   âš ï¸  éªŒè¯å‡†ç¡®ç‡æœªæå‡ ({epochs_no_improve}/{patience})")
        
        # Early stopping
        if epochs_no_improve >= patience:
            print(f"\nâ¹ï¸  Early stopping triggered after {epoch} epochs")
            break
    
    # ä¿å­˜è®­ç»ƒå†å²
    history_path = save_dir / 'training_history.json'
    with open(history_path, 'w') as f:
        json.dump(history, f, indent=2)
    
    print("\n" + "="*80)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    print("="*80)
    print(f"ğŸ“Š æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
    print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜åœ¨: {save_dir / 'best_standard_resnet18.pth'}")
    print(f"ğŸ“ˆ è®­ç»ƒå†å²ä¿å­˜åœ¨: {history_path}")
    
    return model, best_model_state, best_val_acc, history


def main():
    parser = argparse.ArgumentParser(description='æ ‡å‡† ResNet18 åˆ†ç±»å™¨è®­ç»ƒ')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data_dir', type=str, required=True,
                       help='è®­ç»ƒæ•°æ®ç›®å½•')
    parser.add_argument('--output_dir', type=str, default='./standard_classifier',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--num_classes', type=int, default=31,
                       help='ç±»åˆ«æ•°é‡')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=100,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--lr', type=float, default=1e-3,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-4,
                       help='æƒé‡è¡°å‡')
    parser.add_argument('--patience', type=int, default=10,
                       help='Early stopping patience')
    parser.add_argument('--val_split', type=float, default=0.2,
                       help='éªŒè¯é›†æ¯”ä¾‹')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--num_workers', type=int, default=4,
                       help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    parser.add_argument('--no_pretrain', action='store_true',
                       help='ä¸ä½¿ç”¨ImageNeté¢„è®­ç»ƒ')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print(f"\nğŸ“‚ åŠ è½½æ•°æ®ä»: {args.data_dir}")
    train_loader, val_loader = create_data_loaders(
        args.data_dir,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        val_split=args.val_split
    )
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  åˆ›å»ºæ ‡å‡† ResNet18 æ¨¡å‹")
    print(f"   ç±»åˆ«æ•°: {args.num_classes}")
    print(f"   é¢„è®­ç»ƒ: {'å¦' if args.no_pretrain else 'æ˜¯ (ImageNet)'}")
    
    model = StandardResNet18(
        num_classes=args.num_classes,
        pretrained=not args.no_pretrain
    ).to(device)
    
    # æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(
        model.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=args.epochs
    )
    
    # æ‰“å°é…ç½®
    print(f"\nâš™ï¸  è®­ç»ƒé…ç½®:")
    print(f"   æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"   å­¦ä¹ ç‡: {args.lr}")
    print(f"   æƒé‡è¡°å‡: {args.weight_decay}")
    print(f"   è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"   Early stopping patience: {args.patience}")
    
    # è®­ç»ƒæ¨¡å‹
    model, best_model_state, best_val_acc, history = train(
        model, train_loader, val_loader, criterion, optimizer, scheduler,
        device, args.epochs, args.output_dir, args.patience
    )
    
    # ä¿å­˜é…ç½®
    config = {
        'num_classes': args.num_classes,
        'pretrained': not args.no_pretrain,
        'best_val_acc': best_val_acc,
        'epochs_trained': len(history['train_loss']),
        'batch_size': args.batch_size,
        'lr': args.lr,
        'weight_decay': args.weight_decay,
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    config_path = Path(args.output_dir) / 'model_config.json'
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"âš™ï¸  é…ç½®ä¿å­˜åœ¨: {config_path}")


if __name__ == '__main__':
    main() 
