#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡å‡† ResNet18 åˆ†ç±»å™¨è®­ç»ƒè„šæœ¬ï¼ˆä¸ä½¿ç”¨å¯¹æ¯”å­¦ä¹ ï¼‰
ä½œä¸ºçœŸæ­£çš„ Baseline å¯¹æ¯”
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from pathlib import Path
from PIL import Image
import numpy as np
from tqdm import tqdm
import argparse
import json
from datetime import datetime


class StandardResNet18(nn.Module):
    """
    æ ‡å‡† ResNet18 åˆ†ç±»å™¨
    æ²¡æœ‰å¯¹æ¯”å­¦ä¹ ï¼Œæ²¡æœ‰ç‰¹æ®ŠæŠ€å·§ï¼Œçº¯ç²¹çš„åˆ†ç±»å™¨
    """
    def __init__(self, num_classes=31, pretrained=True):
        super(StandardResNet18, self).__init__()
        # ä½¿ç”¨é¢„è®­ç»ƒçš„ ResNet18
        self.resnet = models.resnet18(pretrained=pretrained)
        
        # æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚
        in_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Linear(in_features, num_classes)
        
        self.num_classes = num_classes
    
    def forward(self, x):
        return self.resnet(x)


def create_data_loaders(data_dir, batch_size=32, num_workers=4, train_ratio=0.8):
    """
    æŒ‰ç”¨æˆ·åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œé¿å…æ•°æ®æ³„éœ²
    è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„ç”¨æˆ·å®Œå…¨åˆ†ç¦»
    """
    
    # ä¸ä½¿ç”¨æ•°æ®å¢å¼ºçš„transform
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    data_dir = Path(data_dir)
    
    # è·å–æ‰€æœ‰ç”¨æˆ·
    user_dirs = sorted([d for d in data_dir.iterdir() if d.is_dir() and d.name.startswith('ID_')])
    total_users = len(user_dirs)
    
    print(f"âœ… å‘ç° {total_users} ä¸ªç”¨æˆ·")
    
    # æŒ‰ç”¨æˆ·åˆ’åˆ†ï¼š80% è®­ç»ƒï¼Œ20% éªŒè¯
    np.random.seed(42)
    user_indices = np.random.permutation(total_users)
    
    train_user_count = int(total_users * train_ratio)
    train_user_indices = user_indices[:train_user_count]
    val_user_indices = user_indices[train_user_count:]
    
    train_users = [user_dirs[i].name for i in train_user_indices]
    val_users = [user_dirs[i].name for i in val_user_indices]
    
    print(f"ğŸ“Š è®­ç»ƒç”¨æˆ· ({len(train_users)}): {', '.join(sorted(train_users)[:5])}...")
    print(f"ğŸ“Š éªŒè¯ç”¨æˆ· ({len(val_users)}): {', '.join(sorted(val_users))}")
    
    # åŠ è½½è®­ç»ƒé›†æ•°æ®
    train_samples = []
    for user_idx in train_user_indices:
        user_dir = user_dirs[user_idx]
        user_id = int(user_dir.name.split('_')[1]) - 1  # ID_1 -> 0
        
        image_files = list(user_dir.glob('*.png')) + list(user_dir.glob('*.jpg'))
        
        for img_path in image_files:
            train_samples.append({
                'path': img_path,
                'label': user_id
            })
    
    # åŠ è½½éªŒè¯é›†æ•°æ®
    val_samples = []
    for user_idx in val_user_indices:
        user_dir = user_dirs[user_idx]
        user_id = int(user_dir.name.split('_')[1]) - 1  # ID_1 -> 0
        
        image_files = list(user_dir.glob('*.png')) + list(user_dir.glob('*.jpg'))
        
        for img_path in image_files:
            val_samples.append({
                'path': img_path,
                'label': user_id
            })
    
    print(f"âœ… è®­ç»ƒé›†: {len(train_samples)} æ ·æœ¬ ({len(train_users)} ç”¨æˆ·)")
    print(f"âœ… éªŒè¯é›†: {len(val_samples)} æ ·æœ¬ ({len(val_users)} ç”¨æˆ·)")
    
    # åˆ›å»ºæ•°æ®é›†
    class SampleDataset(Dataset):
        def __init__(self, samples, transform):
            self.samples = samples
            self.transform = transform
        
        def __len__(self):
            return len(self.samples)
        
        def __getitem__(self, idx):
            sample = self.samples[idx]
            image = Image.open(sample['path']).convert('RGB')
            label = sample['label']
            
            if self.transform:
                image = self.transform(image)
            
            return image, label
    
    train_dataset = SampleDataset(train_samples, transform)
    val_dataset = SampleDataset(val_samples, transform)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True if num_workers > 0 else False
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True if num_workers > 0 else False
    )
    
    return train_loader, val_loader


def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    
    running_loss = 0.0
    correct = 0
    total = 0
    
    pbar = tqdm(train_loader, desc=f"Epoch {epoch}")
    
    for images, labels in pbar:
        images = images.to(device)
        labels = labels.to(device)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        # ç»Ÿè®¡
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
        
        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({
            'loss': f'{running_loss/total:.4f}',
            'acc': f'{100.*correct/total:.2f}%'
        })
    
    epoch_loss = running_loss / len(train_loader)
    epoch_acc = 100. * correct / total
    
    return epoch_loss, epoch_acc


def validate(model, val_loader, criterion, device):
    """éªŒè¯æ¨¡å‹"""
    model.eval()
    
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc="Validating"):
            images = images.to(device)
            labels = labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
    
    val_loss = running_loss / len(val_loader)
    val_acc = 100. * correct / total
    
    return val_loss, val_acc


def train(model, train_loader, val_loader, criterion, optimizer, scheduler,
          device, epochs, save_dir, patience=10):
    """å®Œæ•´è®­ç»ƒæµç¨‹"""
    
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    best_val_acc = 0.0
    best_model_state = None
    epochs_no_improve = 0
    
    history = {
        'train_loss': [],
        'train_acc': [],
        'val_loss': [],
        'val_acc': []
    }
    
    print("\n" + "="*80)
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ ‡å‡† ResNet18 åˆ†ç±»å™¨")
    print("="*80)
    
    for epoch in range(1, epochs + 1):
        print(f"\nğŸ“ Epoch {epoch}/{epochs}")
        
        # è®­ç»ƒ
        train_loss, train_acc = train_one_epoch(
            model, train_loader, criterion, optimizer, device, epoch
        )
        
        # éªŒè¯
        val_loss, val_acc = validate(model, val_loader, criterion, device)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # è®°å½•å†å²
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š Epoch {epoch} ç»“æœ:")
        print(f"   è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%")
        print(f"   éªŒè¯ - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%")
        print(f"   å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict().copy()
            epochs_no_improve = 0
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': best_model_state,
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_acc': best_val_acc,
                'history': history
            }
            torch.save(checkpoint, save_dir / 'best_standard_resnet18.pth')
            print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%)")
        else:
            epochs_no_improve += 1
            print(f"   âš ï¸  éªŒè¯å‡†ç¡®ç‡æœªæå‡ ({epochs_no_improve}/{patience})")
        
        # Early stopping
        if epochs_no_improve >= patience:
            print(f"\nâ¹ï¸  Early stopping triggered after {epoch} epochs")
            break
    
    # ä¿å­˜è®­ç»ƒå†å²
    history_path = save_dir / 'training_history.json'
    with open(history_path, 'w') as f:
        json.dump(history, f, indent=2)
    
    print("\n" + "="*80)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    print("="*80)
    print(f"ğŸ“Š æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
    print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜åœ¨: {save_dir / 'best_standard_resnet18.pth'}")
    print(f"ğŸ“ˆ è®­ç»ƒå†å²ä¿å­˜åœ¨: {history_path}")
    
    return model, best_model_state, best_val_acc, history


def main():
    parser = argparse.ArgumentParser(description='æ ‡å‡† ResNet18 åˆ†ç±»å™¨è®­ç»ƒ')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data_dir', type=str, 
                       default='/kaggle/input/dataset',
                       help='è®­ç»ƒæ•°æ®ç›®å½•')
    parser.add_argument('--output_dir', type=str, default='./standard_classifier',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--num_classes', type=int, default=31,
                       help='ç±»åˆ«æ•°é‡')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=100,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--lr', type=float, default=1e-3,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-4,
                       help='æƒé‡è¡°å‡')
    parser.add_argument('--patience', type=int, default=10,
                       help='Early stopping patience')
    parser.add_argument('--train_ratio', type=float, default=0.8,
                       help='è®­ç»ƒé›†ç”¨æˆ·æ¯”ä¾‹ï¼ˆæŒ‰ç”¨æˆ·åˆ’åˆ†ï¼‰')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--num_workers', type=int, default=4,
                       help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    parser.add_argument('--no_pretrain', action='store_true',
                       help='ä¸ä½¿ç”¨ImageNeté¢„è®­ç»ƒ')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print(f"\nğŸ“‚ åŠ è½½æ•°æ®ä»: {args.data_dir}")
    train_loader, val_loader = create_data_loaders(
        args.data_dir,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        train_ratio=args.train_ratio
    )
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  åˆ›å»ºæ ‡å‡† ResNet18 æ¨¡å‹")
    print(f"   ç±»åˆ«æ•°: {args.num_classes}")
    print(f"   é¢„è®­ç»ƒ: {'å¦' if args.no_pretrain else 'æ˜¯ (ImageNet)'}")
    
    model = StandardResNet18(
        num_classes=args.num_classes,
        pretrained=not args.no_pretrain
    ).to(device)
    
    # æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(
        model.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=args.epochs
    )
    
    # æ‰“å°é…ç½®
    print(f"\nâš™ï¸  è®­ç»ƒé…ç½®:")
    print(f"   æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"   å­¦ä¹ ç‡: {args.lr}")
    print(f"   æƒé‡è¡°å‡: {args.weight_decay}")
    print(f"   è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"   Early stopping patience: {args.patience}")
    
    # è®­ç»ƒæ¨¡å‹
    model, best_model_state, best_val_acc, history = train(
        model, train_loader, val_loader, criterion, optimizer, scheduler,
        device, args.epochs, args.output_dir, args.patience
    )
    
    # ä¿å­˜é…ç½®
    config = {
        'num_classes': args.num_classes,
        'pretrained': not args.no_pretrain,
        'best_val_acc': best_val_acc,
        'epochs_trained': len(history['train_loss']),
        'batch_size': args.batch_size,
        'lr': args.lr,
        'weight_decay': args.weight_decay,
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    config_path = Path(args.output_dir) / 'model_config.json'
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"âš™ï¸  é…ç½®ä¿å­˜åœ¨: {config_path}")


if __name__ == '__main__':
    main() 
