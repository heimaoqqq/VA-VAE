#!/usr/bin/env python3
"""
ç›®æ ‡åŸŸåŸå‹æ„å»ºè„šæœ¬
ç”¨äºæ„å»ºèƒŒåŒ…æ­¥æ€ï¼ˆç›®æ ‡åŸŸï¼‰çš„ç±»åŸå‹ï¼Œæ”¯æŒæ¨ç†æœŸåŸå‹æ ¡å‡†ï¼ˆPNCï¼‰
é€‚é…Kaggleç¯å¢ƒ
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from PIL import Image
import numpy as np
import random
from tqdm import tqdm
from datetime import datetime
import json
import argparse

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥åˆ†ç±»å™¨
import sys
sys.path.append(str(Path(__file__).parent.parent))
from train_calibrated_classifier import DomainAdaptiveClassifier


class TargetDomainDataset(Dataset):
    """ç›®æ ‡åŸŸï¼ˆèƒŒåŒ…æ­¥æ€ï¼‰æ•°æ®é›†"""
    
    def __init__(self, data_dir, transform=None, support_size=15, seed=42):
        """
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            transform: æ•°æ®å˜æ¢
            support_size: æ¯ä¸ªç”¨æˆ·çš„æ”¯æŒé›†å¤§å°
            seed: éšæœºç§å­
        """
        self.data_dir = Path(data_dir)
        self.transform = transform
        self.support_size = support_size
        self.samples = []
        
        # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤
        random.seed(seed)
        np.random.seed(seed)
        
        # åŠ è½½æ”¯æŒé›†
        self._load_support_set()
        
    def _load_support_set(self):
        """åŠ è½½æ¯ä¸ªç”¨æˆ·çš„æ”¯æŒé›†æ ·æœ¬"""
        # æ‰«ææ‰€æœ‰ç”¨æˆ·ç›®å½•ï¼ˆID_1 åˆ° ID_31ï¼‰
        user_dirs = sorted([d for d in self.data_dir.iterdir() if d.is_dir()])
        
        for user_dir in user_dirs:
            # æå–ç”¨æˆ·IDï¼ˆID_x -> x-1ï¼‰
            user_name = user_dir.name
            if user_name.startswith('ID_'):
                user_id = int(user_name.split('_')[1]) - 1  # ID_1 -> 0
            else:
                continue
            
            # è·å–è¯¥ç”¨æˆ·çš„æ‰€æœ‰å›¾åƒ
            image_files = list(user_dir.glob('*.png')) + list(user_dir.glob('*.jpg'))
            
            if len(image_files) == 0:
                print(f"âš ï¸ No images found for {user_name}")
                continue
            
            # éšæœºé‡‡æ ·support_sizeä¸ªæ ·æœ¬
            n_samples = min(self.support_size, len(image_files))
            selected_files = random.sample(image_files, n_samples)
            
            # æ·»åŠ åˆ°æ•°æ®é›†
            for img_path in selected_files:
                self.samples.append({
                    'path': img_path,
                    'label': user_id,
                    'user_name': user_name
                })
            
            print(f"âœ“ {user_name}: Selected {n_samples}/{len(image_files)} samples")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        image = Image.open(sample['path']).convert('RGB')
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            image = self.transform(image)
        
        return image, sample['label'], sample['user_name']


class PrototypeBuilder:
    """åŸå‹æ„å»ºå™¨"""
    
    def __init__(self, model_path, device='cuda'):
        """
        Args:
            model_path: åˆ†ç±»å™¨æ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device
        self.model = self._load_model(model_path)
        
    def _load_model(self, model_path):
        """åŠ è½½é¢„è®­ç»ƒåˆ†ç±»å™¨"""
        print(f"ğŸ“¦ Loading classifier from: {model_path}")
        
        # åŠ è½½æ¨¡å‹
        model = DomainAdaptiveClassifier(num_classes=31).to(self.device)
        # PyTorch 2.6+ éœ€è¦è®¾ç½® weights_only=False
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
        
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        
        model.eval()
        print("âœ“ Model loaded successfully")
        return model
    
    def extract_features(self, dataloader):
        """æå–ç‰¹å¾å‘é‡"""
        features = []
        labels = []
        user_names = []
        
        with torch.no_grad():
            for batch_images, batch_labels, batch_users in tqdm(dataloader, desc="Extracting features"):
                batch_images = batch_images.to(self.device)
                
                # æå–ç‰¹å¾ï¼šbackbone + feature_projector
                # è¿™æ˜¯åŸŸé€‚åº”æ¨¡å‹çš„ç‰¹å¾è¡¨ç¤ºå±‚
                backbone_features = self.model.backbone(batch_images)
                feat = self.model.feature_projector(backbone_features)
                
                features.append(feat.cpu())
                labels.extend(batch_labels.tolist())
                user_names.extend(batch_users)
        
        features = torch.cat(features, dim=0)
        return features, labels, user_names
    
    def compute_prototypes(self, features, labels, normalize=True):
        """è®¡ç®—æ¯ä¸ªç±»çš„åŸå‹"""
        num_classes = max(labels) + 1
        prototypes = []
        
        for class_id in range(num_classes):
            # è·å–è¯¥ç±»çš„æ‰€æœ‰ç‰¹å¾
            class_mask = [i for i, l in enumerate(labels) if l == class_id]
            if len(class_mask) == 0:
                print(f"âš ï¸ No samples for class {class_id}")
                prototypes.append(torch.zeros(features.shape[1]))
                continue
            
            class_features = features[class_mask]
            
            # è®¡ç®—å‡å€¼åŸå‹
            prototype = class_features.mean(dim=0)
            
            # L2å½’ä¸€åŒ–
            if normalize:
                prototype = prototype / prototype.norm(2)
            
            prototypes.append(prototype)
        
        prototypes = torch.stack(prototypes)
        return prototypes
    
    def build_and_save(self, data_dir, output_path, support_size=15):
        """æ„å»ºåŸå‹å¹¶ä¿å­˜"""
        print("\n" + "="*60)
        print("ğŸ”§ BUILDING TARGET DOMAIN PROTOTYPES")
        print("="*60)
        
        # æ•°æ®å˜æ¢ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])
        
        # åˆ›å»ºæ”¯æŒé›†æ•°æ®é›†
        dataset = TargetDomainDataset(
            data_dir=data_dir,
            transform=transform,
            support_size=support_size
        )
        
        dataloader = DataLoader(
            dataset,
            batch_size=32,
            shuffle=False,
            num_workers=2
        )
        
        print(f"\nğŸ“Š Support set statistics:")
        print(f"   â€¢ Total samples: {len(dataset)}")
        print(f"   â€¢ Samples per user: {support_size}")
        print(f"   â€¢ Number of users: {len(set([s['label'] for s in dataset.samples]))}")
        
        # æå–ç‰¹å¾
        print("\nğŸ¯ Extracting features...")
        features, labels, user_names = self.extract_features(dataloader)
        print(f"âœ“ Extracted features: {features.shape}")
        
        # è®¡ç®—åŸå‹
        print("\nğŸ“ Computing prototypes...")
        prototypes = self.compute_prototypes(features, labels, normalize=True)
        print(f"âœ“ Computed prototypes: {prototypes.shape}")
        
        # æ„å»ºå…ƒæ•°æ®
        samples_per_user = {}
        for label, user in zip(labels, user_names):
            if user not in samples_per_user:
                samples_per_user[user] = 0
            samples_per_user[user] += 1
        
        # ä¿å­˜åŸå‹
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        save_dict = {
            'prototypes': prototypes,
            'user_ids': list(range(prototypes.shape[0])),
            'feature_dim': prototypes.shape[1],
            'metadata': {
                'samples_per_user': samples_per_user,
                'model_path': str(self.model._get_name()),
                'data_path': str(data_dir),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'config': {
                    'support_size': support_size,
                    'normalize': True,
                    'aggregation': 'mean'
                }
            }
        }
        
        torch.save(save_dict, output_path)
        print(f"\nğŸ’¾ Prototypes saved to: {output_path}")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“ˆ Prototype statistics:")
        for i, (user_id, count) in enumerate(samples_per_user.items()):
            proto_norm = prototypes[i].norm(2).item()
            print(f"   â€¢ {user_id}: {count} samples, prototype norm: {proto_norm:.3f}")
        
        print("\nâœ… Prototype building completed successfully!")
        return save_dict


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Build target domain prototypes for PNC')
    
    # Kaggleç¯å¢ƒé»˜è®¤è·¯å¾„    
    parser.add_argument('--data-dir', type=str, 
                       default='/kaggle/input/backpack/backpack',
                       help='Path to target domain data (èƒŒåŒ…æ­¥æ€)')
    parser.add_argument('--model-path', type=str,
                       default='/kaggle/input/best-calibrated-model-pth/best_calibrated_model.pth',
                       help='Path to pretrained classifier')
    parser.add_argument('--output-path', type=str,
                       default='/kaggle/working/target_prototypes.pt',
                       help='Path to save prototypes')
    parser.add_argument('--support-size', type=int, default=15,
                       help='Number of support samples per user')
    parser.add_argument('--device', type=str, default='cuda',
                       choices=['cuda', 'cpu'],
                       help='Device for computation')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("âš ï¸ CUDA not available, using CPU")
        args.device = 'cpu'
    
    # æ„å»ºåŸå‹
    builder = PrototypeBuilder(
        model_path=args.model_path,
        device=args.device
    )
    
    builder.build_and_save(
        data_dir=args.data_dir,
        output_path=args.output_path,
        support_size=args.support_size
    )


if __name__ == '__main__':
    main()
