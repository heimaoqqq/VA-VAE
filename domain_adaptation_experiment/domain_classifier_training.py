"""
åŸŸé€‚åº”åˆ†ç±»å™¨è®­ç»ƒæ–¹æ¡ˆ
æ”¯æŒé€‰æ‹©åŸå§‹æ•°æ®é›†å’Œç”Ÿæˆæ•°æ®é›†è¿›è¡Œè®­ç»ƒ
ç”¨äºè¯„ä¼°ç”Ÿæˆæ•°æ®å¯¹è·¨åŸŸæ³›åŒ–æ€§èƒ½çš„æå‡æ•ˆæœ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, DistributedSampler
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.nn.parallel import DistributedDataParallel as DDP
import torchvision.transforms as transforms
import timm
import numpy as np
from PIL import Image
from pathlib import Path
import argparse
import json
from tqdm import tqdm
import matplotlib.pyplot as plt
from collections import defaultdict
import random
import os


def setup_distributed():
    """åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ"""
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        rank = int(os.environ['RANK'])
        world_size = int(os.environ['WORLD_SIZE'])
        local_rank = int(os.environ['LOCAL_RANK'])
        
        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)
        torch.cuda.set_device(local_rank)
        
        return rank, world_size, local_rank
    else:
        return 0, 1, 0


def cleanup_distributed():
    """æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒ"""
    if dist.is_initialized():
        try:
            # æ·»åŠ è¶…æ—¶ä¿æŠ¤
            import time
            start_time = time.time()
            dist.destroy_process_group()
            print(f"âœ… åˆ†å¸ƒå¼æ¸…ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - start_time:.2f}s")
        except Exception as e:
            print(f"âš ï¸ åˆ†å¸ƒå¼æ¸…ç†å¤±è´¥: {e}")


def is_main_process():
    """åˆ¤æ–­æ˜¯å¦ä¸ºä¸»è¿›ç¨‹"""
    return not dist.is_initialized() or dist.get_rank() == 0


class GlobalNegativeContrastiveLoss(nn.Module):
    """å…¨å±€è´Ÿæ ·æœ¬å¯¹æ¯”æŸå¤±å‡½æ•°"""
    
    def __init__(self, num_classes, temperature=0.07, margin=0.5, memory_size=200):
        super().__init__()
        self.num_classes = num_classes
        self.temperature = temperature
        self.margin = margin
        self.memory_size = memory_size
        
        # ä¸ºæ¯ä¸ªç±»åˆ«ç»´æŠ¤ç‰¹å¾memory bank
        self.register_buffer('memory_bank', torch.randn(num_classes, memory_size, 512))
        self.register_buffer('memory_ptr', torch.zeros(num_classes, dtype=torch.long))
        self.memory_bank = F.normalize(self.memory_bank, dim=2)
    
    @torch.no_grad()
    def update_memory_bank(self, features, labels):
        """æ›´æ–°memory bank"""
        features_normalized = F.normalize(features, dim=1)
        
        for i, label in enumerate(labels):
            label = label.item()
            ptr = self.memory_ptr[label].item()
            
            # ç›´æ¥æ›´æ–°ï¼Œå› ä¸ºå·²ç»åœ¨no_gradä¸Šä¸‹æ–‡ä¸­
            self.memory_bank[label, ptr] = features_normalized[i].detach()
            self.memory_ptr[label] = (ptr + 1) % self.memory_size
    
    def forward(self, features, labels):
        """
        features: [batch_size, feature_dim]
        labels: [batch_size] ç”¨æˆ·ID
        """
        batch_size = features.size(0)
        features = F.normalize(features, dim=1)
        
        # æ›´æ–°memory bank - ä½¿ç”¨detached featuresé¿å…æ¢¯åº¦é—®é¢˜
        with torch.no_grad():
            self.update_memory_bank(features.detach(), labels)
        
        total_loss = 0
        num_pairs = 0
        
        # å¯¹batchä¸­æ¯ä¸ªæ ·æœ¬è®¡ç®—ä¸å…¨å±€è´Ÿæ ·æœ¬çš„å¯¹æ¯”æŸå¤±
        for i, anchor_label in enumerate(labels):
            anchor_feature = features[i].unsqueeze(0)  # [1, feature_dim]
            
            # æ­£æ ·æœ¬ï¼šåŒç±»åˆ«çš„å…¶ä»–æ ·æœ¬ï¼ˆbatchå†… + memory bankï¼‰
            positive_features = []
            
            # batchå†…æ­£æ ·æœ¬
            batch_positives = features[labels == anchor_label]
            if len(batch_positives) > 1:  # é™¤äº†è‡ªå·±è¿˜æœ‰å…¶ä»–åŒç±»æ ·æœ¬
                mask = torch.arange(len(batch_positives)) != (labels == anchor_label).nonzero()[0]
                if mask.any():
                    positive_features.append(batch_positives[mask])
            
            # memory bankä¸­çš„æ­£æ ·æœ¬
            memory_positives = self.memory_bank[anchor_label]  # [memory_size, feature_dim]
            positive_features.append(memory_positives[:50])  # å–å‰50ä¸ªé¿å…è¿‡å¤š
            
            if positive_features:
                positive_features = torch.cat(positive_features, dim=0)
                pos_similarity = torch.matmul(anchor_feature, positive_features.T) / self.temperature
                pos_loss = -pos_similarity.mean()
            else:
                pos_loss = torch.tensor(0.0, device=features.device)
            
            # è´Ÿæ ·æœ¬ï¼šæ‰€æœ‰å…¶ä»–ç±»åˆ«çš„æ ·æœ¬ï¼ˆå…¨å±€ï¼‰
            negative_features = []
            for neg_label in range(self.num_classes):
                if neg_label != anchor_label:
                    # ä»memory bankä¸­é‡‡æ ·è´Ÿæ ·æœ¬
                    neg_samples = self.memory_bank[neg_label][:20]  # æ¯ä¸ªç±»åˆ«20ä¸ªæ ·æœ¬
                    negative_features.append(neg_samples)
            
            if negative_features:
                negative_features = torch.cat(negative_features, dim=0)  # [num_negatives, feature_dim]
                neg_similarity = torch.matmul(anchor_feature, negative_features.T) / self.temperature
                
                # Hard negative mining
                hard_mask = neg_similarity.squeeze() > self.margin
                if hard_mask.any():
                    neg_loss = neg_similarity.squeeze()[hard_mask].mean()
                else:
                    neg_loss = neg_similarity.mean()
            else:
                neg_loss = torch.tensor(0.0, device=features.device)
            
            # ç´¯ç§¯æŸå¤±
            total_loss += pos_loss + neg_loss
            num_pairs += 1
        
        return total_loss / num_pairs if num_pairs > 0 else torch.tensor(0.0, device=features.device)


class InterUserContrastiveLoss(nn.Module):
    """ç”¨æˆ·é—´å¯¹æ¯”æŸå¤±å‡½æ•° - ç®€åŒ–ç‰ˆæœ¬é¿å…æ¢¯åº¦é—®é¢˜"""
    
    def __init__(self, temperature=0.07, margin=0.5):
        super().__init__()
        self.temperature = temperature
        self.margin = margin
    
    def forward(self, features, labels):
        """
        features: [batch_size, feature_dim] 
        labels: [batch_size] ç”¨æˆ·ID
        """
        batch_size = features.size(0)
        if batch_size < 2:
            return torch.tensor(0.0, device=features.device, requires_grad=True)
        
        # å½’ä¸€åŒ–ç‰¹å¾
        features_norm = F.normalize(features, dim=1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        sim_matrix = torch.matmul(features_norm, features_norm.T) / self.temperature
        
        # åˆ›å»ºæ ‡ç­¾mask
        labels_expanded = labels.view(-1, 1)
        pos_mask = torch.eq(labels_expanded, labels_expanded.T).float()
        
        # ç§»é™¤å¯¹è§’çº¿ï¼ˆè‡ªå·±å’Œè‡ªå·±çš„ç›¸ä¼¼åº¦ï¼‰
        eye_mask = torch.eye(batch_size, device=features.device)
        pos_mask = pos_mask * (1.0 - eye_mask)
        neg_mask = (1.0 - torch.eq(labels_expanded, labels_expanded.T).float()) * (1.0 - eye_mask)
        
        # æ•°å€¼ç¨³å®šæ€§ï¼šå‡å»æœ€å¤§å€¼
        sim_max, _ = torch.max(sim_matrix, dim=1, keepdim=True)
        sim_matrix_stable = sim_matrix - sim_max.detach()
        
        # è®¡ç®—InfoNCEé£æ ¼çš„å¯¹æ¯”æŸå¤±
        exp_sim = torch.exp(sim_matrix_stable)
        
        # è®¡ç®—æ¯ä¸ªanchorçš„æŸå¤±
        pos_sum = torch.sum(exp_sim * pos_mask, dim=1, keepdim=True)
        neg_sum = torch.sum(exp_sim * neg_mask, dim=1, keepdim=True)
        
        # é¿å…é™¤é›¶
        pos_sum = torch.clamp(pos_sum, min=1e-8)
        total_sum = pos_sum + neg_sum + 1e-8
        
        # InfoNCEæŸå¤±ï¼š-log(pos_sum / total_sum)
        loss_per_sample = -torch.log(pos_sum / total_sum)
        
        # åªå¯¹æœ‰æ­£æ ·æœ¬çš„anchorè®¡ç®—æŸå¤±
        has_pos = (torch.sum(pos_mask, dim=1) > 0).float()
        valid_loss = loss_per_sample.squeeze() * has_pos
        
        if has_pos.sum() > 0:
            return valid_loss.sum() / has_pos.sum()
        else:
            return torch.tensor(0.0, device=features.device, requires_grad=True)
    

class SupConLoss(nn.Module):
    """ç›‘ç£å¯¹æ¯”æŸå¤± - é¿å…æ‰€æœ‰åŸåœ°æ“ä½œ"""
    
    def __init__(self, temperature=0.07):
        super().__init__()
        self.temperature = temperature
    
    def forward(self, features, labels):
        """
        features: [batch_size, feature_dim]
        labels: [batch_size]
        """
        device = features.device
        batch_size = features.shape[0]
        
        if batch_size < 2:
            return torch.tensor(0.0, device=device, requires_grad=True)
        
        # å½’ä¸€åŒ–ç‰¹å¾
        features_norm = F.normalize(features, dim=1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        sim_matrix = torch.matmul(features_norm, features_norm.T) / self.temperature
        
        # åˆ›å»ºæ­£æ ·æœ¬mask
        labels_expanded = labels.view(-1, 1)
        pos_mask = torch.eq(labels_expanded, labels_expanded.T).float()
        
        # ç§»é™¤å¯¹è§’çº¿ - é¿å…åŸåœ°æ“ä½œ
        eye_mask = torch.eye(batch_size, device=device)
        pos_mask = torch.sub(pos_mask, eye_mask)
        
        # è´Ÿæ ·æœ¬mask
        neg_mask = torch.ne(labels_expanded, labels_expanded.T).float()
        
        # æ•°å€¼ç¨³å®šæ€§
        sim_max, _ = torch.max(sim_matrix, dim=1, keepdim=True)
        sim_matrix = torch.sub(sim_matrix, sim_max.detach())
        
        # è®¡ç®—InfoNCEæŸå¤±
        exp_sim = torch.exp(sim_matrix)
        
        # åˆ†æ¯ï¼šæ‰€æœ‰è´Ÿæ ·æœ¬ + æ­£æ ·æœ¬
        denominator = torch.sum(exp_sim * neg_mask, dim=1, keepdim=True) + \
                     torch.sum(exp_sim * pos_mask, dim=1, keepdim=True)
        
        # åˆ†å­ï¼šæ­£æ ·æœ¬
        numerator = torch.sum(exp_sim * pos_mask, dim=1, keepdim=True)
        
        # é¿å…é™¤é›¶
        loss = torch.neg(torch.log(torch.div(numerator, denominator + 1e-8)))
        
        # åªè®¡ç®—æœ‰æ­£æ ·æœ¬çš„è¡Œ
        valid_mask = (pos_mask.sum(dim=1) > 0)
        if valid_mask.sum() > 0:
            return loss[valid_mask].mean()
        else:
            return torch.tensor(0.0, device=device, requires_grad=True)


class DomainAdaptationDataset(Dataset):
    """åŸŸé€‚åº”æ•°æ®é›†ï¼Œæ”¯æŒå¤šä¸ªæ•°æ®æº"""
    
    def __init__(self, real_data_dir=None, generated_data_dirs=None, split='train', 
                 transform=None, contrastive_pairs=False, use_generated=False, split_file=None):
        """
        Args:
            real_data_dir: çœŸå®æ•°æ®ç›®å½•
            generated_data_dirs: ç”Ÿæˆæ•°æ®ç›®å½•åˆ—è¡¨
            split: 'train' or 'val'
            use_generated: æ˜¯å¦ä½¿ç”¨ç”Ÿæˆæ•°æ®æ‰©å……è®­ç»ƒé›†
            split_file: é¢„åˆ’åˆ†æ–‡ä»¶è·¯å¾„ (dataset_split.json)
        """
        self.real_data_dir = Path(real_data_dir) if real_data_dir else None
        self.generated_data_dirs = [Path(d) for d in generated_data_dirs] if generated_data_dirs else []
        self.split = split
        self.contrastive_pairs = contrastive_pairs
        self.use_generated = use_generated
        self.split_file = split_file
        self.samples = []
        
        # æ”¶é›†æ‰€æœ‰æ ·æœ¬
        user_samples = defaultdict(list)
        
        # åŠ è½½çœŸå®æ•°æ® - ä½¿ç”¨é¢„åˆ’åˆ†æ–‡ä»¶
        if self.real_data_dir and self.real_data_dir.exists():
            if not dist.is_initialized() or dist.get_rank() == 0:
                print(f"Loading real data from: {self.real_data_dir}")
            if self.split_file:
                self._load_presplit_data(user_samples, "real", split)
            else:
                self._load_data_from_dir(self.real_data_dir, user_samples, "real", split)
        
        # åŠ è½½ç”Ÿæˆæ•°æ®ï¼ˆä»…åœ¨è®­ç»ƒæ—¶ä¸”å¯ç”¨æ—¶ï¼‰
        if self.use_generated and split == 'train' and self.generated_data_dirs:
            for i, generated_dir in enumerate(self.generated_data_dirs):
                if generated_dir.exists():
                    if not dist.is_initialized() or dist.get_rank() == 0:
                        print(f"Loading generated data from: {generated_dir}")
                    self._load_data_from_dir(generated_dir, user_samples, f"generated_{i+1}", split)
                else:
                    if not dist.is_initialized() or dist.get_rank() == 0:
                        print(f"âš ï¸ Generated data directory not found: {generated_dir}")
        
        if not user_samples:
            raise ValueError("æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
        
        # è¯¦ç»†æ•°æ®ç»Ÿè®¡æŠ¥å‘Š
        if not dist.is_initialized() or dist.get_rank() == 0:
            self._print_data_statistics(user_samples)
        
        # å¾®å¤šæ™®å‹’å›¾åƒä¸“ç”¨å˜æ¢ï¼ˆæœ€å°å¢å¼ºï¼Œä¿æŒé¢‘è°±ç»“æ„ï¼‰
        if split == 'train':
            self.transform = transforms.Compose([
                transforms.Resize((256, 256)),
                # åªä½¿ç”¨æè½»å¾®çš„å™ªå£°å¢å¼ºï¼Œä¸ç ´åé¢‘è°±ç»“æ„
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                # å¯é€‰ï¼šæå°çš„é«˜æ–¯å™ªå£°ï¼ˆæ¨¡æ‹Ÿæµ‹é‡å™ªå£°ï¼‰ - é¿å…åŸåœ°æ“ä½œ
                # transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.01 if torch.rand(1).item() < 0.3 else x)
            ])
        else:
            self.transform = transforms.Compose([
                transforms.Resize((256, 256)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        
        if transform:
            self.transform = transform
    
    def _load_presplit_data(self, user_samples, data_type, split):
        """ä»é¢„åˆ’åˆ†JSONæ–‡ä»¶åŠ è½½æ•°æ®"""
        import json
        
        if not self.split_file or not Path(self.split_file).exists():
            if not dist.is_initialized() or dist.get_rank() == 0:
                print(f"âš ï¸ é¢„åˆ’åˆ†æ–‡ä»¶ä¸å­˜åœ¨: {self.split_file}")
            return
        
        # åŠ è½½é¢„åˆ’åˆ†æ•°æ®
        with open(self.split_file, 'r') as f:
            data_split = json.load(f)
        
        split_data = data_split.get(split, {})
        if not split_data:
            if not dist.is_initialized() or dist.get_rank() == 0:
                print(f"âš ï¸ åœ¨é¢„åˆ’åˆ†æ–‡ä»¶ä¸­æœªæ‰¾åˆ°{split}æ•°æ®")
            return
        
        # è§£æç”¨æˆ·IDå’Œæ·»åŠ æ ·æœ¬
        for user_folder_name, image_paths in split_data.items():
            # ä»æ–‡ä»¶å¤¹åè§£æç”¨æˆ·ID
            if user_folder_name.startswith("ID_"):
                user_id = int(user_folder_name.split('_')[1]) - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
            elif user_folder_name.startswith(("User_", "user_")):
                user_id = int(user_folder_name.split('_')[1])  # User_å·²ç»æ˜¯0-based
            else:
                # å°è¯•ç›´æ¥è§£ææ•°å­—
                try:
                    user_id = int(user_folder_name)
                except ValueError:
                    if not dist.is_initialized() or dist.get_rank() == 0:
                        print(f"âš ï¸ æ— æ³•è§£æç”¨æˆ·ID: {user_folder_name}")
                    continue
            
            # éªŒè¯å›¾åƒæ–‡ä»¶å­˜åœ¨å¹¶æ·»åŠ åˆ°æ•°æ®é›†
            valid_paths = []
            for img_path in image_paths:
                if Path(img_path).exists():
                    valid_paths.append(img_path)
                    user_samples[user_id].append((img_path, data_type))
                    self.samples.append((img_path, user_id, data_type))
                else:
                    if not dist.is_initialized() or dist.get_rank() == 0:
                        print(f"âš ï¸ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
            
            if not dist.is_initialized() or dist.get_rank() == 0:
                print(f"   ç”¨æˆ· {user_id} ({user_folder_name}): {len(valid_paths)}/{len(image_paths)} å¼ å›¾åƒ")

    def _load_data_from_dir(self, data_dir, user_samples, data_type, split):
        """ä»æŒ‡å®šç›®å½•åŠ è½½æ•°æ®"""
        data_dir = Path(data_dir)
        if not data_dir.exists():
            print(f"âš ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
            return
            
        # æŸ¥æ‰¾ç”¨æˆ·ç›®å½•ï¼šæ”¯æŒID_*, User_*, user_*æ ¼å¼
        id_dirs = []
        for pattern in ["ID_*", "User_*", "user_*"]:
            id_dirs.extend(data_dir.glob(pattern))
        
        if len(id_dirs) == 0:
            print(f"Warning: åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ°ID_*ã€User_*æˆ–user_*æ ¼å¼çš„ç”¨æˆ·ç›®å½•")
            # æ‰“å°å®é™…æ‰¾åˆ°çš„ç›®å½•ç»“æ„ä»¥ä¾¿è°ƒè¯•
            all_dirs = [d.name for d in data_dir.iterdir() if d.is_dir()]
            print(f"å®é™…æ‰¾åˆ°çš„ç›®å½•: {all_dirs[:10]}...")  # åªæ˜¾ç¤ºå‰10ä¸ª
            return
        
        # ä¸´æ—¶å­˜å‚¨å½“å‰æ•°æ®æºçš„æ ·æœ¬
        current_data_samples = defaultdict(list)
        
        for user_dir in sorted(id_dirs):
            if user_dir.is_dir():
                # è§£æç”¨æˆ·ID
                if user_dir.name.startswith("ID_"):
                    user_id = int(user_dir.name.split('_')[1]) - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
                elif user_dir.name.startswith(("User_", "user_")):
                    user_id = int(user_dir.name.split('_')[1])  # User_å·²ç»æ˜¯0-based
                else:
                    continue
                    
                for ext in ['*.png', '*.jpg', '*.jpeg']:
                    for img_path in user_dir.glob(ext):
                        current_data_samples[user_id].append((str(img_path), data_type))
        
        # æ ¹æ®æ•°æ®ç±»å‹å†³å®šå¦‚ä½•æ·»åŠ åˆ°æ•°æ®é›†
        if data_type == 'real':
            # çœŸå®æ•°æ®éœ€è¦æŒ‰splitåˆ’åˆ† - ä½¿ç”¨å›ºå®šç§å­ç¡®ä¿ä¸€è‡´æ€§
            for user_id, paths in current_data_samples.items():
                # å°†å½“å‰çœŸå®æ•°æ®æ·»åŠ åˆ°user_samplesä»¥ä¾¿ç»Ÿè®¡
                user_samples[user_id].extend(paths)
                
                # ä½¿ç”¨å›ºå®šç§å­åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†ï¼Œç¡®ä¿è®­ç»ƒé›†å’ŒéªŒè¯é›†ä½¿ç”¨ç›¸åŒçš„åˆ’åˆ†
                random.Random(42 + user_id).shuffle(paths)  # æ¯ä¸ªç”¨æˆ·ä½¿ç”¨ä¸åŒä½†å›ºå®šçš„ç§å­
                split_idx = int(len(paths) * 0.8)
                
                if split == 'train':
                    selected_paths = paths[:split_idx]
                else:  # validation
                    selected_paths = paths[split_idx:]
                
                for path_info in selected_paths:
                    path, dtype = path_info
                    self.samples.append((path, user_id, dtype))
        else:
            # ç”Ÿæˆæ•°æ®åªæ·»åŠ åˆ°è®­ç»ƒé›†
            if split == 'train':
                for user_id, paths in current_data_samples.items():
                    # å°†åˆæˆæ•°æ®æ·»åŠ åˆ°user_samplesä»¥ä¾¿ç»Ÿè®¡
                    user_samples[user_id].extend(paths)
                    
                    # åˆæˆæ•°æ®å…¨éƒ¨æ·»åŠ åˆ°è®­ç»ƒé›†
                    for path_info in paths:
                        path, dtype = path_info
                        self.samples.append((path, user_id, dtype))

    def _print_data_statistics(self, user_samples):
        """æ‰“å°è¯¦ç»†çš„æ•°æ®ç»Ÿè®¡ä¿¡æ¯ - åŸºäºå®é™…åŠ è½½çš„æ•°æ®é›†"""
        print("\n" + "="*60)
        print(f"æ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š ({self.split.upper()})")
        print("="*60)
        
        # åŸºäºå®é™…åŠ è½½çš„self.samplesè¿›è¡Œç»Ÿè®¡
        data_type_counts = defaultdict(int)
        user_coverage = defaultdict(set)  # æ¯ç§æ•°æ®ç±»å‹è¦†ç›–çš„ç”¨æˆ·
        user_data_counts = defaultdict(lambda: defaultdict(int))  # ç”¨æˆ·çº§åˆ«çš„æ•°æ®ç±»å‹ç»Ÿè®¡
        
        for _, user_id, data_type in self.samples:
            data_type_counts[data_type] += 1
            user_coverage[data_type].add(user_id)
            user_data_counts[user_id][data_type] += 1
        
        # æ€»ä½“ç»Ÿè®¡
        total_real = data_type_counts.get('real', 0)
        total_generated = sum(count for dtype, count in data_type_counts.items() if dtype.startswith('generated'))
        
        print(f"ğŸ“Š {self.split}é›†ç»Ÿè®¡:")
        print(f"   çœŸå®æ ·æœ¬: {total_real}")
        print(f"   åˆæˆæ ·æœ¬: {total_generated}")
        if total_real > 0:
            print(f"   æ‰©å……å€æ•°: {total_generated / total_real:.2f}x")
        print(f"   æ€»æ ·æœ¬æ•°: {total_real + total_generated}")
        print(f"   è¦†ç›–ç”¨æˆ·æ•°: {len(user_data_counts)}")
        
        # æ•°æ®æºè¯¦ç»†ç»Ÿè®¡
        print(f"\nğŸ“ æ•°æ®æºç»Ÿè®¡:")
        for data_type, count in sorted(data_type_counts.items()):
            users_covered = len(user_coverage[data_type])
            print(f"   {data_type}: {count} æ ·æœ¬ (è¦†ç›– {users_covered} ç”¨æˆ·)")
        
        # ç”¨æˆ·çº§åˆ«ç»Ÿè®¡
        print(f"\nğŸ‘¥ ç”¨æˆ·çº§åˆ«ç»Ÿè®¡ ({self.split}):")
        user_real_counts = []
        user_generated_counts = []
        
        for user_id in sorted(user_data_counts.keys()):
            user_counts = user_data_counts[user_id]
            real_count = user_counts.get('real', 0)
            generated_count = sum(count for dtype, count in user_counts.items() if dtype.startswith('generated'))
            
            user_real_counts.append(real_count)
            user_generated_counts.append(generated_count)
            
            if user_id < 5:  # åªæ˜¾ç¤ºå‰5ä¸ªç”¨æˆ·çš„è¯¦ç»†ä¿¡æ¯
                if real_count > 0:
                    ratio = f"{generated_count/real_count:.1f}x"
                else:
                    ratio = "æ— çœŸå®æ•°æ®" if generated_count == 0 else f"ä»…åˆæˆ({generated_count})"
                print(f"   ç”¨æˆ· {user_id:02d}: çœŸå®={real_count}, åˆæˆ={generated_count} (æ‰©å……{ratio})")
        
        if len(user_data_counts) > 5:
            print(f"   ... (å…± {len(user_data_counts)} ç”¨æˆ·)")
        
        # ç»Ÿè®¡æ‘˜è¦
        if user_real_counts:
            avg_real = sum(user_real_counts) / len(user_real_counts)
            avg_generated = sum(user_generated_counts) / len(user_generated_counts)
            
            print(f"\nğŸ“ˆ å¹³å‡ç»Ÿè®¡:")
            print(f"   å¹³å‡çœŸå®æ ·æœ¬/ç”¨æˆ·: {avg_real:.1f}")
            print(f"   å¹³å‡åˆæˆæ ·æœ¬/ç”¨æˆ·: {avg_generated:.1f}")
            if avg_real > 0:
                print(f"   å¹³å‡æ‰©å……å€æ•°: {avg_generated/avg_real:.2f}x")
            else:
                print(f"   å¹³å‡æ‰©å……å€æ•°: æ— çœŸå®æ•°æ®")
        
        print("="*60)
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label, data_type = self.samples[idx]
        
        try:
            image = Image.open(img_path).convert('RGB')
            
            if self.contrastive_pairs and self.split == 'train':
                # ç”Ÿæˆå¯¹æ¯”æ ·æœ¬å¯¹
                image1 = self.transform(image)
                image2 = self.transform(image)  # åŒä¸€å›¾åƒçš„ä¸åŒå¢å¼º
                return (image1, image2), label
            else:
                image = self.transform(image)
                return image, label
                
        except Exception as e:
            print(f"Error loading {img_path}: {e}")
            # è¿”å›é›¶å¼ é‡ - å°ºå¯¸ä¸å®é™…å›¾åƒä¸€è‡´
            if self.contrastive_pairs:
                return (torch.zeros(3, 256, 256), torch.zeros(3, 256, 256)), label
            else:
                return torch.zeros(3, 256, 256), label


class ImprovedClassifier(nn.Module):
    """æ”¹è¿›çš„åˆ†ç±»å™¨ï¼Œä¸“ä¸ºå¾®å¤šæ™®å‹’ä¿¡å·ä¼˜åŒ– - å®Œå…¨é¿å…inplaceæ“ä½œ"""
    
    def __init__(self, num_classes, backbone='resnet18', dropout_rate=0.3, freeze_layers=True):
        super().__init__()
        
        # ä½¿ç”¨æ ‡å‡†ResNet18é¿å…TIMMçš„æ½œåœ¨inplaceé—®é¢˜
        import torchvision.models as models
        self.backbone = models.resnet18(pretrained=True)
        # ç§»é™¤æœ€åçš„åˆ†ç±»å±‚
        self.backbone.fc = nn.Identity()
        feature_dim = 512
        
        # é€’å½’ç¦ç”¨æ‰€æœ‰ReLUçš„inplaceæ“ä½œ
        self._disable_inplace_operations(self.backbone)
        
        # çµæ´»çš„å±‚å†»ç»“ç­–ç•¥
        if freeze_layers == 'minimal':
            # æœ€å°å†»ç»“ï¼šåªå†»ç»“æœ€æ—©çš„å·ç§¯å±‚
            for name, param in self.backbone.named_parameters():
                if any(x in name for x in ['conv1', 'bn1']):
                    param.requires_grad = False
        elif freeze_layers == 'moderate':
            # ä¸­ç­‰å†»ç»“ï¼šå†»ç»“æ—©æœŸå±‚ï¼Œä¿ç•™é€‚åº”æ€§
            for name, param in self.backbone.named_parameters():
                if any(x in name for x in ['conv1', 'bn1', 'layer1']):
                    param.requires_grad = False
        elif freeze_layers == 'aggressive':
            # æ¿€è¿›å†»ç»“ï¼šå†»ç»“æ›´å¤šå±‚ï¼ˆå°æ•°æ®é›†ï¼‰
            for name, param in self.backbone.named_parameters():
                if any(x in name for x in ['conv1', 'bn1', 'layer1', 'layer2']):
                    param.requires_grad = False
        elif freeze_layers == 'none':
            # ä¸å†»ç»“ä»»ä½•å±‚ï¼ˆé£é™©æ›´é«˜ä½†å¯èƒ½æ•ˆæœæ›´å¥½ï¼‰
            pass
        
        # åˆ†ç±»å¤´ - ç¡®ä¿æ‰€æœ‰æ¿€æ´»å‡½æ•°éƒ½ä¸æ˜¯inplace
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(feature_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=False),  # æ˜ç¡®ç¦ç”¨inplace
            nn.Dropout(dropout_rate * 0.5),
            nn.Linear(256, num_classes)
        )
        
        # å¯¹æ¯”å­¦ä¹ æŠ•å½±å¤´
        self.projection_head = nn.Sequential(
            nn.Linear(feature_dim, 128),
            nn.ReLU(inplace=False),  # æ˜ç¡®ç¦ç”¨inplace
            nn.Linear(128, 64)
        )
    
    def _disable_inplace_operations(self, module):
        """é€’å½’ç¦ç”¨æ¨¡å—ä¸­æ‰€æœ‰çš„inplaceæ“ä½œ"""
        for child_name, child in module.named_children():
            if isinstance(child, nn.ReLU):
                # æ›¿æ¢inplace=Trueçš„ReLU
                setattr(module, child_name, nn.ReLU(inplace=False))
            elif isinstance(child, nn.ReLU6):
                setattr(module, child_name, nn.ReLU6(inplace=False))
            elif isinstance(child, nn.LeakyReLU):
                setattr(module, child_name, nn.LeakyReLU(child.negative_slope, inplace=False))
            else:
                # é€’å½’å¤„ç†å­æ¨¡å—
                self._disable_inplace_operations(child)
    
    def forward(self, x, return_features=False):
        features = self.backbone(x)
        
        if return_features:
            projected = self.projection_head(features)
            return features, projected
        
        logits = self.classifier(features)
        return logits


class FocalLoss(nn.Module):
    """Focal Loss - å¤„ç†ç±»åˆ«ä¸å¹³è¡¡"""
    
    def __init__(self, alpha=1, gamma=2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()


class LabelSmoothingLoss(nn.Module):
    """æ ‡ç­¾å¹³æ»‘æŸå¤±"""
    
    def __init__(self, num_classes, smoothing=0.1):
        super().__init__()
        self.num_classes = num_classes
        self.smoothing = smoothing
    
    def forward(self, pred, target):
        confidence = 1.0 - self.smoothing
        smooth_target = torch.full_like(pred, self.smoothing / (self.num_classes - 1))
        smooth_target.scatter_(1, target.unsqueeze(1), confidence)
        return F.kl_div(F.log_softmax(pred, dim=1), smooth_target, reduction='batchmean')


def train_with_contrastive_learning(model, train_loader, val_loader, device, args, rank=0):
    """æ”¹è¿›çš„è®­ç»ƒå‡½æ•°ï¼Œé›†æˆå¯¹æ¯”å­¦ä¹ """
    
    # åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®
    def is_main_process():
        return rank == 0
    
    # éªŒè¯æ•°æ®é›†æ˜¯å¦ä¸ºç©º
    if len(train_loader.dataset) == 0:
        if is_main_process():
            print("âŒ è®­ç»ƒæ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•å¼€å§‹è®­ç»ƒ")
        return model, None, 0.0, {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'contrastive_loss': [], 'classification_loss': []}
    
    if len(val_loader.dataset) == 0:
        if is_main_process():
            print("âŒ éªŒè¯æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•å¼€å§‹è®­ç»ƒ")
        return model, None, 0.0, {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'contrastive_loss': [], 'classification_loss': []}
    
    if is_main_process():
        print(f"è®­ç»ƒé›†: {len(train_loader.dataset)} æ ·æœ¬, éªŒè¯é›†: {len(val_loader.dataset)} æ ·æœ¬")
    
    # æŸå¤±å‡½æ•°
    if args.use_focal_loss:
        classification_criterion = FocalLoss()
    elif args.use_label_smoothing:
        classification_criterion = LabelSmoothingLoss(args.num_classes)
    else:
        classification_criterion = nn.CrossEntropyLoss()
    
    # é‡æ–°å¯ç”¨å¯¹æ¯”å­¦ä¹  - æ ¹æ®ç±»å‹é€‰æ‹©æŸå¤±å‡½æ•°
    if args.use_contrastive:
        if args.contrastive_type == 'interuser':
            if is_main_process():
                print("âœ… å¯ç”¨InterUserContrastiveLosså¯¹æ¯”å­¦ä¹  - ä¼˜åŒ–ç”¨æˆ·é—´å·®å¼‚")
            contrastive_criterion = InterUserContrastiveLoss(
                temperature=args.contrastive_temperature,
                margin=args.contrastive_margin
            )
        elif args.contrastive_type == 'supcon':
            if is_main_process():
                print("âœ… å¯ç”¨SupConLosså¯¹æ¯”å­¦ä¹  - ç›‘ç£å¯¹æ¯”å­¦ä¹ ")
            contrastive_criterion = SupConLoss(temperature=args.contrastive_temperature)
        elif args.contrastive_type == 'global':
            if is_main_process():
                print("âœ… å¯ç”¨GlobalNegativeContrastiveLoss - å…¨å±€è´Ÿæ ·æœ¬å¯¹æ¯”")
            contrastive_criterion = GlobalNegativeContrastiveLoss(
                memory_size=64,
                temperature=args.contrastive_temperature
            )
        else:
            if is_main_process():
                print(f"âš ï¸ æœªçŸ¥å¯¹æ¯”å­¦ä¹ ç±»å‹: {args.contrastive_type}ï¼Œä½¿ç”¨SupConLoss")
            contrastive_criterion = SupConLoss(temperature=args.contrastive_temperature)
    else:
        contrastive_criterion = None
    
    # ä¼˜åŒ–å™¨ - ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡å’Œæ›´å¼ºçš„weight decay
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=args.lr, 
        weight_decay=args.weight_decay,
        betas=(0.9, 0.999)
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=10, T_mult=2, eta_min=1e-6
    )
    
    best_val_acc = 0
    patience_counter = 0
    
    history = {
        'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],
        'contrastive_loss': [], 'classification_loss': []
    }
    
    # ç¦ç”¨å¼‚å¸¸æ£€æµ‹ï¼Œé¿å…é¢å¤–å¼€é”€
    torch.autograd.set_detect_anomaly(False)
    
    for epoch in range(args.epochs):
        # è®­ç»ƒ
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        contrastive_losses = []
        classification_losses = []
        
        # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
        if is_main_process():
            pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}")
        else:
            pbar = train_loader
        
        for batch_idx, batch_data in enumerate(pbar):
            data, target = batch_data
            target = target.to(device)
            
            # å¯¹æ¯”å­¦ä¹ è®­ç»ƒå¾ªç¯
            if isinstance(data, (tuple, list)) and len(data) == 2:
                # å¯¹æ¯”å­¦ä¹ æ•°æ®å¯¹
                data1, data2 = data[0].to(device), data[1].to(device)
                
                if args.use_contrastive and contrastive_criterion is not None:
                    # å®Œå…¨åˆå¹¶è¾“å…¥ï¼Œå•æ¬¡æ¨¡å‹å‰å‘ä¼ æ’­é¿å…ä»»ä½•å‚æ•°é‡å¤ä½¿ç”¨
                    combined_data = torch.cat([data1, data2], dim=0)
                    batch_size = data1.size(0)
                    combined_target = torch.cat([target, target], dim=0)
                    
                    # å•æ¬¡å®Œæ•´å‰å‘ä¼ æ’­è·å–ç‰¹å¾å’ŒæŠ•å½±
                    combined_features, combined_proj = model(combined_data, return_features=True)
                    
                    # å•æ¬¡åˆ†ç±»å™¨è°ƒç”¨
                    if hasattr(model, 'module'):
                        combined_logits = model.module.classifier(combined_features)
                    else:
                        combined_logits = model.classifier(combined_features)
                    
                    # åˆ†å‰²ç»“æœ
                    logits1 = combined_logits[:batch_size]
                    logits2 = combined_logits[batch_size:]
                    proj1 = combined_proj[:batch_size] 
                    proj2 = combined_proj[batch_size:]
                    
                    # åˆ†ç±»æŸå¤±
                    cls_loss1 = classification_criterion(logits1, target)
                    cls_loss2 = classification_criterion(logits2, target)
                    classification_loss = (cls_loss1 + cls_loss2) / 2
                    
                    # å¯¹æ¯”æŸå¤±ï¼šä½¿ç”¨æŠ•å½±ç‰¹å¾
                    contrastive_loss = contrastive_criterion(combined_proj, combined_target)
                    
                    # æ€»æŸå¤±
                    total_loss = classification_loss + args.contrastive_weight * contrastive_loss
                    pred = logits1.argmax(dim=1)
                else:
                    # åªä½¿ç”¨ç¬¬ä¸€å¼ å›¾è¿›è¡Œåˆ†ç±»
                    logits = model(data1)
                    total_loss = classification_criterion(logits, target)
                    classification_loss = total_loss
                    contrastive_loss = torch.tensor(0.0, device=device)
                    pred = logits.argmax(dim=1)
            else:
                # å•å¼ å›¾åƒè®­ç»ƒ
                if isinstance(data, (tuple, list)):
                    data = data[0]
                
                data = data.to(device)
                logits = model(data)
                total_loss = classification_criterion(logits, target)
                classification_loss = total_loss
                contrastive_loss = torch.tensor(0.0, device=device)
                pred = logits.argmax(dim=1)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            total_loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # ç»Ÿè®¡
            train_loss += total_loss.item()
            train_correct += pred.eq(target).sum().item()
            train_total += target.size(0)
            
            contrastive_losses.append(contrastive_loss.item() if isinstance(contrastive_loss, torch.Tensor) else 0.0)
            classification_losses.append(classification_loss.item())
            
            # åªåœ¨ä¸»è¿›ç¨‹æ›´æ–°è¿›åº¦æ¡
            if is_main_process() and isinstance(pbar, tqdm):
                pbar.set_postfix({
                    'Loss': f'{total_loss.item():.4f}',
                    'Acc': f'{100.*train_correct/train_total:.1f}%'
                })
        
        # éªŒè¯
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(device), target.to(device)
                
                logits = model(data)
                loss = classification_criterion(logits, target)
                
                pred = logits.argmax(dim=1)
                val_loss += loss.item()
                val_correct += pred.eq(target).sum().item()
                val_total += target.size(0)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # é˜²æ­¢é™¤é›¶é”™è¯¯
        if len(train_loader) == 0:
            print("âŒ è®­ç»ƒæ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ ¼å¼")
            return model, None, 0.0, {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'contrastive_loss': [], 'classification_loss': []}
        
        if len(val_loader) == 0:
            print("âŒ éªŒè¯æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ ¼å¼")
            return model, None, 0.0, {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'contrastive_loss': [], 'classification_loss': []}
        
        # ç»Ÿè®¡
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_acc = 100. * train_correct / train_total if train_total > 0 else 0.0
        val_acc = 100. * val_correct / val_total if val_total > 0 else 0.0
        
        history['train_loss'].append(avg_train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(avg_val_loss)
        history['val_acc'].append(val_acc)
        history['contrastive_loss'].append(np.mean(contrastive_losses))
        history['classification_loss'].append(np.mean(classification_losses))
        
        # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
        if is_main_process():
            print(f"Epoch {epoch+1}/{args.epochs}")
            print(f"Train: Loss={avg_train_loss:.4f}, Acc={train_acc:.2f}%")
            print(f"Val: Loss={avg_val_loss:.4f}, Acc={val_acc:.2f}%")
            print(f"LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
        if is_main_process():
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_model_state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()
                patience_counter = 0
                print(f"ğŸ¯ New best validation accuracy: {best_val_acc:.2f}%")
            else:
                patience_counter += 1
            
            if patience_counter >= args.patience:
                print(f"ğŸ›‘ Early stopping at epoch {epoch+1}")
                break
    
    return model, best_model_state, best_val_acc, history


def main():
    parser = argparse.ArgumentParser(description='Domain adaptation classifier training')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--real_data_dir', type=str, required=True, help='Real dataset directory')
    parser.add_argument('--generated_data_dir', type=str, action='append', help='Generated dataset directory (can be specified multiple times)')
    parser.add_argument('--use_generated', action='store_true', 
                       help='Use generated data to augment training set')
    parser.add_argument('--split_file', type=str, default='/kaggle/working/dataset_split.json',
                       help='Pre-split dataset JSON file path')
    
    parser.add_argument('--output_dir', type=str, default='./domain_classifier', help='Output directory')
    parser.add_argument('--num_classes', type=int, default=31, help='Number of classes')
    parser.add_argument('--epochs', type=int, default=200, help='Number of epochs')
    parser.add_argument('--batch_size', type=int, default=16, help='Batch size per GPU')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate (smaller)')
    parser.add_argument('--weight_decay', type=float, default=0.01, help='Weight decay (stronger)')
    parser.add_argument('--dropout_rate', type=float, default=0.5, help='Dropout rate')
    parser.add_argument('--patience', type=int, default=10, help='Early stopping patience')
    
    # å¯¹æ¯”å­¦ä¹ å‚æ•°
    parser.add_argument('--use_contrastive', action='store_true', help='Use contrastive learning')
    parser.add_argument('--contrastive_weight', type=float, default=0.5, help='Contrastive loss weight')
    parser.add_argument('--contrastive_temperature', type=float, default=0.07, help='Contrastive temperature')
    parser.add_argument('--contrastive_type', type=str, default='supcon', 
                       choices=['global', 'interuser', 'supcon'],
                       help='Contrastive loss type: global(memory bank all users), interuser(hard negative mining), supcon(supervised contrastive)')
    parser.add_argument('--contrastive_margin', type=float, default=0.5, 
                       help='Margin for hard negative mining in interuser contrastive loss')
    
    # æŸå¤±å‡½æ•°é€‰æ‹©
    parser.add_argument('--use_focal_loss', action='store_true', help='Use focal loss')
    parser.add_argument('--use_label_smoothing', action='store_true', help='Use label smoothing')
    
    # æ¨¡å‹é€‰æ‹© - ResNet18ä¸“ä¸ºå¾®å¤šæ™®å‹’ä¼˜åŒ–
    parser.add_argument('--backbone', type=str, default='resnet18', help='Backbone architecture')
    parser.add_argument('--freeze_layers', type=str, default='moderate', 
                       choices=['none', 'minimal', 'moderate', 'aggressive'],
                       help='Layer freezing strategy: none(risk overfitting), minimal(conv1+bn1), moderate(+layer1), aggressive(+layer2)')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ
    rank, world_size, local_rank = setup_distributed()
    
    # è®¾ç½®è®¾å¤‡
    if torch.cuda.is_available():
        device = torch.device(f'cuda:{local_rank}')
        torch.cuda.set_device(local_rank)
    else:
        device = torch.device('cpu')
    
    if is_main_process():
        print(f"Using distributed training with {world_size} GPUs")
        print(f"Current device: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
    if is_main_process():
        output_dir = Path(args.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42 + rank)  # æ¯ä¸ªè¿›ç¨‹ä¸åŒçš„éšæœºç§å­
    np.random.seed(42 + rank)
    random.seed(42 + rank)
    
    # æ•°æ®é›†
    train_dataset = DomainAdaptationDataset(
        real_data_dir=args.real_data_dir,
        generated_data_dirs=args.generated_data_dir,  # ç°åœ¨æ˜¯åˆ—è¡¨
        split='train',
        contrastive_pairs=args.use_contrastive,
        use_generated=args.use_generated,
        split_file=args.split_file
    )
    
    val_dataset = DomainAdaptationDataset(
        real_data_dir=args.real_data_dir,
        generated_data_dirs=None,  # éªŒè¯é›†åªä½¿ç”¨çœŸå®æ•°æ®
        split='val',
        contrastive_pairs=False,
        use_generated=False,
        split_file=args.split_file
    )
    
    # åˆ†å¸ƒå¼é‡‡æ ·å™¨
    train_sampler = DistributedSampler(train_dataset) if world_size > 1 else None
    val_sampler = DistributedSampler(val_dataset, shuffle=False) if world_size > 1 else None
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=args.batch_size, 
        shuffle=(train_sampler is None), 
        sampler=train_sampler,
        num_workers=0,  # é¿å…å¤šè¿›ç¨‹å¡ä½
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=args.batch_size * 2, 
        shuffle=False,
        sampler=val_sampler,
        num_workers=0,  # é¿å…å¤šè¿›ç¨‹å¡ä½
        pin_memory=True
    )
    
    # æ¨¡å‹
    model = ImprovedClassifier(
        num_classes=args.num_classes,
        backbone=args.backbone,
        dropout_rate=args.dropout_rate,
        freeze_layers=args.freeze_layers
    ).to(device)
    
    # åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½® - ä½¿ç”¨static_graphè§£å†³å‚æ•°é‡å¤ä½¿ç”¨é—®é¢˜
    if dist.is_initialized():
        model = DDP(model, device_ids=[device], find_unused_parameters=True)
        # è®¾ç½®é™æ€å›¾æ¨¡å¼ï¼Œå…è®¸å‚æ•°åœ¨åŒä¸€æ¬¡åå‘ä¼ æ’­ä¸­å¤šæ¬¡ä½¿ç”¨
        model._set_static_graph()
    
    if is_main_process():
        total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"Model parameters: {total_params:,}")
    
    # è®­ç»ƒ
    model, best_state, best_acc, history = train_with_contrastive_learning(
        model, train_loader, val_loader, device, args, rank
    )
    
    # åªåœ¨ä¸»è¿›ç¨‹ä¿å­˜æ¨¡å‹
    if is_main_process():
        output_dir = Path(args.output_dir)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        model_path = output_dir / 'best_improved_classifier.pth'
        torch.save({
            'model_state_dict': best_state,
            'best_val_acc': best_acc,
            'num_classes': args.num_classes,
            'model_name': args.backbone,
            'args': vars(args)
        }, model_path)
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = output_dir / 'training_history.json'
        with open(history_path, 'w') as f:
            json.dump(history, f, indent=2)
        
        print(f"\nâœ… Training completed!")
        print(f"Best validation accuracy: {best_acc:.2f}%")
        print(f"Model saved to: {model_path}")
    
    # æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒ
    cleanup_distributed()
    
    # ç¡®ä¿ç¨‹åºæ­£å¸¸é€€å‡º
    if is_main_process():
        print("ğŸ‰ è®­ç»ƒæµç¨‹å®Œå…¨ç»“æŸï¼Œç¨‹åºå³å°†é€€å‡º")
    
    # æ˜¾å¼é€€å‡ºç¨‹åºé¿å…å¡ä½
    import sys
    sys.exit(0)


if __name__ == "__main__":
    main()
