#!/usr/bin/env python3
"""
ä¸ºImprovedClassifieræ„å»ºç›®æ ‡åŸŸåŸå‹ - å¸¦æ•°æ®é›†åˆ’åˆ†åŠŸèƒ½
ä¸¥æ ¼åˆ’åˆ†æ”¯æŒé›†å’Œæµ‹è¯•é›†ï¼Œé¿å…æ•°æ®æ³„æ¼
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from PIL import Image
import numpy as np
import random
from tqdm import tqdm
from datetime import datetime
import json
import argparse

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥åˆ†ç±»å™¨
import sys
sys.path.append(str(Path(__file__).parent.parent))
from improved_classifier_training import ImprovedClassifier


class SplitTargetDomainDataset(Dataset):
    """ç›®æ ‡åŸŸæ•°æ®é›† - ä¸¥æ ¼åˆ’åˆ†æ”¯æŒé›†å’Œæµ‹è¯•é›†"""
    
    def __init__(self, data_dir, transform=None, support_size=10, mode='support', seed=42):
        """
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            transform: æ•°æ®å˜æ¢
            support_size: æ¯ä¸ªç”¨æˆ·çš„æ”¯æŒé›†å¤§å°
            mode: 'support' or 'test'
            seed: éšæœºç§å­
        """
        self.data_dir = Path(data_dir)
        self.transform = transform
        self.support_size = support_size
        self.mode = mode
        self.samples = []
        
        # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤
        random.seed(seed)
        np.random.seed(seed)
        
        # åŠ è½½æ•°æ®é›†
        self._split_and_load()
        
    def _split_and_load(self):
        """ä¸¥æ ¼åˆ’åˆ†å¹¶åŠ è½½æ”¯æŒé›†æˆ–æµ‹è¯•é›†"""
        # æ‰«ææ‰€æœ‰ç”¨æˆ·ç›®å½•ï¼ˆID_1 åˆ° ID_31ï¼‰
        user_dirs = sorted([d for d in self.data_dir.iterdir() if d.is_dir()])
        
        for user_dir in user_dirs:
            # æå–ç”¨æˆ·IDï¼ˆID_x -> x-1ï¼‰
            user_name = user_dir.name
            if user_name.startswith('ID_'):
                user_id = int(user_name.split('_')[1]) - 1  # ID_1 -> 0
            else:
                continue
            
            # è·å–è¯¥ç”¨æˆ·çš„æ‰€æœ‰å›¾åƒ
            image_files = list(user_dir.glob('*.png')) + list(user_dir.glob('*.jpg'))
            
            if len(image_files) == 0:
                print(f"âš ï¸ No images found for {user_name}")
                continue
            
            # éšæœºæ‰“ä¹±å¹¶åˆ’åˆ†
            random.shuffle(image_files)
            
            # åˆ’åˆ†æ”¯æŒé›†å’Œæµ‹è¯•é›†
            support_files = image_files[:self.support_size]
            test_files = image_files[self.support_size:]
            
            # æ ¹æ®modeé€‰æ‹©æ•°æ®
            if self.mode == 'support':
                selected_files = support_files
                print(f"âœ“ {user_name}: Support set {len(support_files)} samples")
            else:  # test mode
                selected_files = test_files
                print(f"âœ“ {user_name}: Test set {len(test_files)} samples")
            
            # æ·»åŠ åˆ°æ•°æ®é›†
            for img_path in selected_files:
                self.samples.append({
                    'path': img_path,
                    'label': user_id,
                    'user_name': user_name
                })
        
        print(f"\nğŸ“Š {self.mode.capitalize()} dataset: {len(self.samples)} samples total")
        
    def __len__(self):
        return len(self.samples)
        
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        image = Image.open(sample['path']).convert('RGB')
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            image = self.transform(image)
        
        return image, sample['label'], sample['user_name']


class ImprovedPrototypeBuilderWithSplit:
    """ImprovedClassifierçš„åŸå‹æ„å»ºå™¨ - å¸¦æ•°æ®åˆ’åˆ†"""
    
    def __init__(self, model_path, device='cuda'):
        self.device = device
        self.model = self._load_model(model_path)
        
    def _load_model(self, model_path):
        """åŠ è½½ImprovedClassifier"""
        print(f"ğŸ“¦ Loading ImprovedClassifier from: {model_path}")
        
        # åŠ è½½checkpoint
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
        
        # è·å–æ¨¡å‹é…ç½®
        num_classes = checkpoint.get('num_classes', 31)
        backbone = checkpoint.get('backbone', 'resnet18')
        
        # åˆ›å»ºæ¨¡å‹
        model = ImprovedClassifier(
            num_classes=num_classes,
            backbone=backbone
        ).to(self.device)
        
        # åŠ è½½æƒé‡
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        
        model.eval()
        print(f"âœ“ Model loaded successfully: {backbone} with {num_classes} classes")
        
        if 'best_val_acc' in checkpoint:
            print(f"   Original validation accuracy: {checkpoint['best_val_acc']:.2f}%")
            
        return model
    
    def extract_features(self, dataloader):
        """æå–ç‰¹å¾å‘é‡"""
        features = []
        labels = []
        user_names = []
        
        with torch.no_grad():
            for batch_images, batch_labels, batch_users in tqdm(dataloader, desc="Extracting features"):
                batch_images = batch_images.to(self.device)
                
                # æå–ç‰¹å¾ï¼šç›´æ¥ä½¿ç”¨backboneè¾“å‡º
                feat = self.model.backbone(batch_images)
                
                features.append(feat.cpu())
                labels.extend(batch_labels.tolist())
                user_names.extend(batch_users)
        
        features = torch.cat(features, dim=0)
        return features, labels, user_names
    
    def compute_prototypes(self, features, labels, normalize=True):
        """è®¡ç®—æ¯ä¸ªç±»çš„åŸå‹"""
        num_classes = max(labels) + 1
        prototypes = []
        
        for class_id in range(num_classes):
            # è·å–è¯¥ç±»çš„æ‰€æœ‰ç‰¹å¾
            class_mask = [i for i, l in enumerate(labels) if l == class_id]
            if len(class_mask) == 0:
                print(f"âš ï¸ No samples for class {class_id}")
                prototypes.append(torch.zeros(features.shape[1]))
                continue
            
            class_features = features[class_mask]
            
            # è®¡ç®—å‡å€¼åŸå‹
            prototype = class_features.mean(dim=0)
            
            # L2å½’ä¸€åŒ–
            if normalize:
                prototype = prototype / prototype.norm(2)
            
            prototypes.append(prototype)
        
        prototypes = torch.stack(prototypes)
        return prototypes
    
    def build_and_save(self, data_dir, output_path, support_size=10, batch_size=32, seed=42):
        """æ„å»ºå¹¶ä¿å­˜åŸå‹ - åŒæ—¶ä¿å­˜æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ”§ BUILDING PROTOTYPES WITH DATA SPLIT")
        print("="*60)
        
        # æ•°æ®å˜æ¢ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])
        
        # åˆ›å»ºæ”¯æŒé›†æ•°æ®é›†
        support_dataset = SplitTargetDomainDataset(
            data_dir=data_dir,
            transform=transform,
            support_size=support_size,
            mode='support',
            seed=seed
        )
        
        support_loader = DataLoader(
            support_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=2,
            pin_memory=True
        )
        
        # æå–ç‰¹å¾
        print("\nğŸ¯ Extracting features from support set...")
        features, labels, user_names = self.extract_features(support_loader)
        print(f"âœ“ Extracted features: {features.shape}")
        
        # è®¡ç®—åŸå‹
        print("\nğŸ“ Computing prototypes...")
        prototypes = self.compute_prototypes(features, labels)
        print(f"âœ“ Computed prototypes: {prototypes.shape}")
        
        # ä¿å­˜æ”¯æŒé›†æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºæ’é™¤ï¼‰
        support_paths = [str(sample['path']) for sample in support_dataset.samples]
        
        # ä¿å­˜
        save_dict = {
            'prototypes': prototypes,
            'user_ids': list(range(prototypes.shape[0])),
            'feature_dim': prototypes.shape[1],
            'metadata': {
                'model_type': 'ImprovedClassifier',
                'support_size': support_size,
                'num_support_samples': len(support_dataset),
                'feature_extraction': 'backbone_direct',
                'timestamp': datetime.now().isoformat(),
                'seed': seed,
                'data_split': 'strict_split'
            },
            'support_paths': support_paths,  # å…³é”®ï¼šä¿å­˜æ”¯æŒé›†è·¯å¾„
            'user_stats': {}
        }
        
        # ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„ä¿¡æ¯
        print("\nğŸ“ˆ Prototype statistics:")
        for i in range(prototypes.shape[0]):
            user_samples = sum(1 for l in labels if l == i)
            norm = prototypes[i].norm(2).item()
            save_dict['user_stats'][f'ID_{i+1}'] = {
                'support_samples': user_samples,
                'prototype_norm': norm
            }
            print(f"   â€¢ ID_{i+1}: {user_samples} support samples, prototype norm: {norm:.3f}")
        
        # ä¿å­˜æ–‡ä»¶
        torch.save(save_dict, output_path)
        print(f"\nğŸ’¾ Prototypes saved to: {output_path}")
        print(f"   Support set paths saved for exclusion during testing")
        
        # åˆ›å»ºæµ‹è¯•é›†ä¿¡æ¯
        test_dataset = SplitTargetDomainDataset(
            data_dir=data_dir,
            transform=transform,
            support_size=support_size,
            mode='test',
            seed=seed
        )
        
        print(f"\nğŸ“Š Data split summary:")
        print(f"   Support set: {len(support_dataset)} samples (for prototypes)")
        print(f"   Test set: {len(test_dataset)} samples (for evaluation)")
        print(f"   No overlap between sets!")
        
        print("\nâœ… Prototype building with strict data split completed!")
        return save_dict


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Build prototypes with strict data split')
    
    # Kaggleç¯å¢ƒé»˜è®¤è·¯å¾„
    parser.add_argument('--data-dir', type=str, 
                       default='/kaggle/input/backpack/backpack',
                       help='Path to target domain data')
    parser.add_argument('--model-path', type=str,
                       default='/kaggle/working/VA-VAE/improved_classifier/best_improved_classifier.pth',
                       help='Path to ImprovedClassifier model')
    parser.add_argument('--output-path', type=str,
                       default='/kaggle/working/improved_prototypes_split.pt',
                       help='Path to save prototypes')
    parser.add_argument('--support-size', type=int, default=10,
                       help='Number of support samples per user')
    parser.add_argument('--batch-size', type=int, default=32,
                       help='Batch size for feature extraction')
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed for data split')
    parser.add_argument('--device', type=str, default='cuda',
                       help='Device to use (cuda/cpu)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåŸå‹æ„å»ºå™¨
    builder = ImprovedPrototypeBuilderWithSplit(
        model_path=args.model_path,
        device=args.device
    )
    
    # æ„å»ºå¹¶ä¿å­˜åŸå‹
    builder.build_and_save(
        data_dir=args.data_dir,
        output_path=args.output_path,
        support_size=args.support_size,
        batch_size=args.batch_size,
        seed=args.seed
    )


if __name__ == '__main__':
    main()
