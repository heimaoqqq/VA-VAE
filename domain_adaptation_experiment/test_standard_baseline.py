#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡å‡† ResNet18 Baseline è¯„ä¼°
è¯„ä¼°æ ‡å‡†ResNet18ï¼ˆæ— å¯¹æ¯”å­¦ä¹ ï¼‰åœ¨å¤šä¸ªç›®æ ‡åŸŸä¸Šçš„è¡¨ç°
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from pathlib import Path
from PIL import Image
import argparse
from tqdm import tqdm
import pandas as pd


class StandardResNet18Classifier(nn.Module):
    """
    æ ‡å‡† ResNet18 åˆ†ç±»å™¨ï¼ˆç”¨äºåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰
    ç»“æ„éœ€è¦ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
    """
    def __init__(self, num_classes=31):
        super(StandardResNet18Classifier, self).__init__()
        self.resnet = models.resnet18(pretrained=False)
        in_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Linear(in_features, num_classes)
        self.num_classes = num_classes
    
    def forward(self, x):
        return self.resnet(x)
    
    @property
    def backbone(self):
        """æä¾›backboneæ¥å£ï¼Œç”¨äºç‰¹å¾æå–ï¼ˆå…¼å®¹NCCï¼‰"""
        # è¿”å›ä¸€ä¸ªå»æ‰æœ€åfcå±‚çš„æ¨¡å‹
        class BackboneWrapper(nn.Module):
            def __init__(self, resnet):
                super().__init__()
                self.resnet = resnet
            
            def forward(self, x):
                # æ‰§è¡ŒResNeté™¤äº†fcå±‚ä¹‹å¤–çš„æ‰€æœ‰æ“ä½œ
                x = self.resnet.conv1(x)
                x = self.resnet.bn1(x)
                x = self.resnet.relu(x)
                x = self.resnet.maxpool(x)
                
                x = self.resnet.layer1(x)
                x = self.resnet.layer2(x)
                x = self.resnet.layer3(x)
                x = self.resnet.layer4(x)
                
                x = self.resnet.avgpool(x)
                x = torch.flatten(x, 1)
                return x
        
        return BackboneWrapper(self.resnet)


def load_standard_classifier(checkpoint_path, num_classes=31, device='cuda'):
    """åŠ è½½æ ‡å‡†ResNet18åˆ†ç±»å™¨"""
    model = StandardResNet18Classifier(num_classes=num_classes)
    
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # å…¼å®¹ä¸åŒçš„ä¿å­˜æ ¼å¼
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"âœ… åŠ è½½æ¨¡å‹ï¼ŒéªŒè¯å‡†ç¡®ç‡: {checkpoint.get('best_val_acc', 'N/A'):.2f}%")
    else:
        model.load_state_dict(checkpoint)
        print(f"âœ… åŠ è½½æ¨¡å‹æˆåŠŸ")
    
    model = model.to(device)
    model.eval()
    
    return model


def evaluate_baseline(model, test_loader, device):
    """è¯„ä¼°baselineå‡†ç¡®ç‡ï¼ˆç›´æ¥ç”¨åˆ†ç±»å™¨é¢„æµ‹ï¼‰"""
    model.eval()
    
    correct = 0
    total = 0
    all_probs = []
    
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            
            outputs = model(images)
            probs = torch.softmax(outputs, dim=1)
            _, predicted = outputs.max(1)
            
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
            # æ”¶é›†é¢„æµ‹æ¦‚ç‡çš„æœ€å¤§å€¼ï¼ˆç½®ä¿¡åº¦ï¼‰
            max_probs = probs.max(dim=1)[0]
            all_probs.extend(max_probs.cpu().numpy())
    
    accuracy = correct / total
    avg_confidence = sum(all_probs) / len(all_probs)
    
    return accuracy, avg_confidence


def main():
    parser = argparse.ArgumentParser(description='æ ‡å‡†ResNet18 Baselineè¯„ä¼°')
    
    # æ¨¡å‹å’Œæ•°æ®
    parser.add_argument('--model_path', type=str,
                       default='/kaggle/working/VA-VAE/improved_classifier/best_improved_classifier.pth',
                       help='æ ‡å‡†ResNet18æ¨¡å‹è·¯å¾„')
    parser.add_argument('--num_classes', type=int, default=31)
    
    # å…¶ä»–
    parser.add_argument('--batch_size', type=int, default=256)
    parser.add_argument('--num_workers', type=int, default=0)
    
    args = parser.parse_args()
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  è®¾å¤‡: {device}")
    
    # æ•°æ®é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    print("\n" + "="*80)
    print("ğŸ“Š æ ‡å‡† ResNet18 Baseline è¯„ä¼°")
    print("="*80)
    
    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“¦ åŠ è½½æ ‡å‡†ResNet18: {args.model_path}")
    model = load_standard_classifier(args.model_path, args.num_classes, device)
    
    # å®šä¹‰æ‰€æœ‰æµ‹è¯•æ•°æ®é›†
    datasets = {
        'Backpack_free': '/kaggle/input/organized-gait-dataset/Backpack_free',
        'Backpack_line': '/kaggle/input/organized-gait-dataset/Backpack_line',
        'Bag_free': '/kaggle/input/organized-gait-dataset/Bag_free',
        'Bag_line': '/kaggle/input/organized-gait-dataset/Bag_line',
        'Bag_Phone_free': '/kaggle/input/organized-gait-dataset/Bag_Phone_free',
        'Bag_Phone_line': '/kaggle/input/organized-gait-dataset/Bag_Phone_line',
        'Normal_free': '/kaggle/input/organized-gait-dataset/Normal_free'
    }
    
    all_results = []
    
    # å¾ªç¯è¯„ä¼°æ¯ä¸ªæ•°æ®é›†
    for dataset_name, data_dir in datasets.items():
        print("\n" + "="*80)
        print(f"ğŸ” è¯„ä¼°æ•°æ®é›†: {dataset_name}")
        print("="*80)
        print(f"ğŸ“‚ è·¯å¾„: {data_dir}")
        
        # åˆ›å»ºæ•°æ®é›†ï¼ˆåŠ è½½æ‰€æœ‰æ•°æ®ï¼‰
        class SimpleGaitDataset(Dataset):
            def __init__(self, data_dir, transform):
                self.data_dir = Path(data_dir)
                self.transform = transform
                self.samples = []
                
                user_dirs = sorted([d for d in self.data_dir.iterdir() 
                                  if d.is_dir() and d.name.startswith('ID_')])
                
                for user_dir in user_dirs:
                    user_id = int(user_dir.name.split('_')[1]) - 1
                    image_files = list(user_dir.glob('*.png')) + list(user_dir.glob('*.jpg'))
                    
                    for img_path in image_files:
                        self.samples.append({
                            'path': img_path,
                            'label': user_id
                        })
            
            def __len__(self):
                return len(self.samples)
            
            def __getitem__(self, idx):
                sample = self.samples[idx]
                image = Image.open(sample['path']).convert('RGB')
                label = sample['label']
                
                if self.transform:
                    image = self.transform(image)
                
                return image, label
        
        # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
        if not Path(data_dir).exists():
            print(f"âš ï¸  æ•°æ®é›†ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue
        
        test_dataset = SimpleGaitDataset(data_dir, transform)
        print(f"âœ… æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
        
        test_loader = DataLoader(
            test_dataset,
            batch_size=args.batch_size,
            shuffle=False,
            num_workers=args.num_workers
        )
        
        # è¯„ä¼° Baseline
        baseline_acc, baseline_conf = evaluate_baseline(model, test_loader, device)
        
        print(f"\nğŸ“Š ç»“æœ:")
        print(f"   å‡†ç¡®ç‡: {baseline_acc*100:.2f}%")
        print(f"   ç½®ä¿¡åº¦: {baseline_conf*100:.2f}%")
        
        all_results.append({
            'dataset': dataset_name,
            'accuracy': baseline_acc * 100,
            'confidence': baseline_conf * 100,
            'num_samples': len(test_dataset)
        })
    
    # ========== æ±‡æ€»æ‰€æœ‰ç»“æœ ==========
    print("\n" + "="*80)
    print("ğŸ“ˆ æ‰€æœ‰æ•°æ®é›†ç»“æœæ±‡æ€»")
    print("="*80)
    
    print(f"\n{'æ•°æ®é›†':<20} {'æ ·æœ¬æ•°':<10} {'å‡†ç¡®ç‡':<12} {'ç½®ä¿¡åº¦':<10}")
    print("-"*80)
    
    for res in all_results:
        print(f"{res['dataset']:<20} "
              f"{res['num_samples']:<10} "
              f"{res['accuracy']:>6.2f}%     "
              f"{res['confidence']:>6.2f}%")
    
    # è®¡ç®—å¹³å‡
    avg_acc = sum(r['accuracy'] for r in all_results) / len(all_results)
    avg_conf = sum(r['confidence'] for r in all_results) / len(all_results)
    
    print("-"*80)
    print(f"{'å¹³å‡':<20} {'':<10} {avg_acc:>6.2f}%     {avg_conf:>6.2f}%")
    
    # ä¿å­˜ç»“æœ
    output_dir = Path(args.model_path).parent
    results_path = output_dir / 'baseline_results.csv'
    
    df = pd.DataFrame(all_results)
    df.to_csv(results_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {results_path}")


if __name__ == '__main__':
    main() 
