#!/usr/bin/env python3
"""
è¯„ä¼°å·¥å…·å‡½æ•°
ä¸¥æ ¼é¿å…æ•°æ®æ³„éœ²ï¼Œå¤ç”¨å·²éªŒè¯çš„SplitTargetDomainDataset
"""

import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
import numpy as np
from pathlib import Path
import sys
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import pairwise_distances

sys.path.append(str(Path(__file__).parent.parent))
from improved_classifier_training import ImprovedClassifier
from build_improved_prototypes_with_split import SplitTargetDomainDataset


def load_classifier(model_path, device='cuda'):
    """
    åŠ è½½ImprovedClassifier
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        device: è®¾å¤‡
    
    Returns:
        model: åŠ è½½çš„æ¨¡å‹
    """
    print(f"ğŸ“¦ Loading classifier from: {model_path}")
    
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    # è·å–æ¨¡å‹é…ç½®
    num_classes = checkpoint.get('num_classes', 31)
    backbone = checkpoint.get('backbone', 'resnet18')
    
    print(f"   Model config: {num_classes} classes, backbone={backbone}")
    
    # åˆ›å»ºæ¨¡å‹
    model = ImprovedClassifier(
        num_classes=num_classes,
        backbone=backbone
    ).to(device)
    
    # åŠ è½½æƒé‡
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model.eval()
    print(f"âœ… Classifier loaded successfully")
    
    return model


def create_data_loaders(data_dir, support_size, seed, batch_size=64, num_workers=4):
    """
    åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä¸¥æ ¼åˆ†ç¦»supportå’Œtestï¼‰
    
    Args:
        data_dir: æ•°æ®ç›®å½•ï¼ˆèƒŒåŒ…æ­¥æ€ï¼‰
        support_size: æ¯ä¸ªç”¨æˆ·çš„supportæ ·æœ¬æ•°
        seed: éšæœºç§å­
        batch_size: æ‰¹å¤§å°
        num_workers: å·¥ä½œçº¿ç¨‹æ•°
    
    Returns:
        support_loader: æ”¯æŒé›†åŠ è½½å™¨
        test_loader: æµ‹è¯•é›†åŠ è½½å™¨
    """
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    print(f"\nğŸ“‚ Loading data from: {data_dir}")
    print(f"   Support size: {support_size}/user, Seed: {seed}")
    
    # åˆ›å»ºæ”¯æŒé›†ï¼ˆå‰support_sizeå¼ ï¼‰
    support_dataset = SplitTargetDomainDataset(
        data_dir=data_dir,
        transform=transform,
        support_size=support_size,
        mode='support',
        seed=seed
    )
    
    # åˆ›å»ºæµ‹è¯•é›†ï¼ˆåé¢çš„æ‰€æœ‰æ ·æœ¬ï¼‰
    test_dataset = SplitTargetDomainDataset(
        data_dir=data_dir,
        transform=transform,
        support_size=support_size,
        mode='test',
        seed=seed
    )
    
    support_loader = DataLoader(
        support_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    print(f"âœ… Support: {len(support_dataset)} samples, Test: {len(test_dataset)} samples")
    
    return support_loader, test_loader


def extract_features(model, data_loader, device='cuda'):
    """
    æå–ç‰¹å¾
    
    Args:
        model: åˆ†ç±»å™¨
        data_loader: æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
    
    Returns:
        features: ç‰¹å¾ [N, D]
        labels: æ ‡ç­¾ [N]
    """
    model.eval()
    all_features = []
    all_labels = []
    
    with torch.no_grad():
        for batch in data_loader:
            if len(batch) == 3:
                images, labels, _ = batch
            else:
                images, labels = batch
            
            images = images.to(device)
            features = model.backbone(images)
            
            all_features.append(features.cpu())
            all_labels.append(labels)
    
    features = torch.cat(all_features, dim=0)
    labels = torch.cat(all_labels, dim=0)
    
    return features, labels


def build_prototypes_simple_mean(features, labels, num_classes=31):
    """
    æ„å»ºåŸå‹ï¼šç®€å•å‡å€¼
    
    Args:
        features: ç‰¹å¾ [N, D]
        labels: æ ‡ç­¾ [N]
        num_classes: ç±»åˆ«æ•°
    
    Returns:
        prototypes: åŸå‹ [num_classes, D]
    """
    prototypes = []
    
    for class_id in range(num_classes):
        class_mask = (labels == class_id)
        class_features = features[class_mask]
        
        if len(class_features) > 0:
            prototype = class_features.mean(dim=0)
            prototype = F.normalize(prototype, dim=0)
        else:
            # å¦‚æœæ²¡æœ‰æ ·æœ¬ï¼Œä½¿ç”¨é›¶å‘é‡
            prototype = torch.zeros(features.shape[1])
        
        prototypes.append(prototype)
    
    prototypes = torch.stack(prototypes)
    return prototypes


def build_prototypes_weighted(model, data_loader, device='cuda', num_classes=31):
    """
    æ„å»ºåŸå‹ï¼šåŠ æƒå‡å€¼ï¼ˆåŸºäºåˆ†ç±»å™¨ç½®ä¿¡åº¦ï¼‰
    
    Args:
        model: åˆ†ç±»å™¨
        data_loader: æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
        num_classes: ç±»åˆ«æ•°
    
    Returns:
        prototypes: åŸå‹ [num_classes, D]
    """
    model.eval()
    class_features = {i: [] for i in range(num_classes)}
    class_weights = {i: [] for i in range(num_classes)}
    
    with torch.no_grad():
        for batch in data_loader:
            if len(batch) == 3:
                images, labels, _ = batch
            else:
                images, labels = batch
            
            images = images.to(device)
            labels = labels.to(device)
            
            # æå–ç‰¹å¾
            features = model.backbone(images)
            
            # è®¡ç®—ç½®ä¿¡åº¦
            outputs = model(images)
            probs = F.softmax(outputs, dim=1)
            confidences = probs.max(dim=1)[0]
            
            # æŒ‰ç±»åˆ«æ”¶é›†
            for feat, label, conf in zip(features, labels, confidences):
                label_id = label.item()
                class_features[label_id].append(feat.cpu())
                class_weights[label_id].append(conf.cpu().item())
    
    # è®¡ç®—åŠ æƒåŸå‹
    prototypes = []
    for class_id in range(num_classes):
        if len(class_features[class_id]) > 0:
            feats = torch.stack(class_features[class_id])
            weights = torch.tensor(class_weights[class_id]).unsqueeze(1)
            
            # å½’ä¸€åŒ–æƒé‡
            weights = weights / weights.sum()
            
            # åŠ æƒå¹³å‡
            prototype = (feats * weights).sum(dim=0)
            prototype = F.normalize(prototype, dim=0)
        else:
            prototype = torch.zeros(512)  # ResNet18ç‰¹å¾ç»´åº¦
        
        prototypes.append(prototype)
    
    prototypes = torch.stack(prototypes)
    return prototypes


def build_prototypes_diversity(features, labels, num_classes=31, num_select=None):
    """
    æ„å»ºåŸå‹ï¼šå¤šæ ·æ€§é€‰æ‹©ï¼ˆK-meansï¼‰
    
    Args:
        features: ç‰¹å¾ [N, D]
        labels: æ ‡ç­¾ [N]
        num_classes: ç±»åˆ«æ•°
        num_select: æ¯ä¸ªç±»é€‰æ‹©çš„æ ·æœ¬æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰
    
    Returns:
        prototypes: åŸå‹ [num_classes, D]
    """
    prototypes = []
    
    for class_id in range(num_classes):
        class_mask = (labels == class_id)
        class_features = features[class_mask].numpy()
        
        if len(class_features) == 0:
            prototypes.append(torch.zeros(features.shape[1]))
            continue
        
        if num_select is None or len(class_features) <= num_select:
            # ä½¿ç”¨å…¨éƒ¨æ ·æœ¬
            selected_features = class_features
        else:
            # K-meansé€‰æ‹©å¤šæ ·åŒ–æ ·æœ¬
            kmeans = KMeans(n_clusters=num_select, random_state=42, n_init=10)
            kmeans.fit(class_features)
            
            # é€‰æ‹©ç¦»èšç±»ä¸­å¿ƒæœ€è¿‘çš„æ ·æœ¬
            selected_indices = []
            for i in range(num_select):
                center = kmeans.cluster_centers_[i]
                distances = pairwise_distances([center], class_features)[0]
                closest_idx = np.argmin(distances)
                selected_indices.append(closest_idx)
            
            selected_features = class_features[selected_indices]
        
        # è®¡ç®—å‡å€¼åŸå‹
        prototype = torch.tensor(selected_features).mean(dim=0)
        prototype = F.normalize(prototype, dim=0)
        prototypes.append(prototype)
    
    prototypes = torch.stack(prototypes)
    return prototypes


def build_prototypes_uncertainty(model, data_loader, device='cuda', num_classes=31):
    """
    æ„å»ºåŸå‹ï¼šåŸºäºä¸ç¡®å®šæ€§é€‰æ‹©
    
    é€‰æ‹©åˆ†ç±»å™¨ä¸ç¡®å®šæ€§æœ€é«˜çš„æ ·æœ¬æ„å»ºåŸå‹
    ç†ç”±ï¼šé«˜ä¸ç¡®å®šæ€§æ ·æœ¬é€šå¸¸åœ¨å†³ç­–è¾¹ç•Œé™„è¿‘ï¼Œæ›´èƒ½ä»£è¡¨ç±»åˆ«è¾¹ç•Œ
    
    Args:
        model: åˆ†ç±»å™¨
        data_loader: æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
        num_classes: ç±»åˆ«æ•°
    
    Returns:
        prototypes: åŸå‹ [num_classes, D]
    """
    model.eval()
    class_samples = {i: [] for i in range(num_classes)}
    
    with torch.no_grad():
        for batch in data_loader:
            if len(batch) == 3:
                images, labels, _ = batch
            else:
                images, labels = batch
            
            images = images.to(device)
            labels = labels.to(device)
            
            # æå–ç‰¹å¾
            features = model.backbone(images)
            
            # è®¡ç®—ä¸ç¡®å®šæ€§ï¼ˆç†µï¼‰
            outputs = model(images)
            probs = F.softmax(outputs, dim=1)
            entropy = -(probs * torch.log(probs + 1e-8)).sum(dim=1)
            
            # æŒ‰ç±»åˆ«æ”¶é›†
            for feat, label, unc in zip(features, labels, entropy):
                label_id = label.item()
                class_samples[label_id].append({
                    'feature': feat.cpu(),
                    'uncertainty': unc.cpu().item()
                })
    
    # é€‰æ‹©é«˜ä¸ç¡®å®šæ€§æ ·æœ¬æ„å»ºåŸå‹
    prototypes = []
    for class_id in range(num_classes):
        samples = class_samples[class_id]
        
        if len(samples) == 0:
            prototypes.append(torch.zeros(512))
            continue
        
        # æŒ‰ä¸ç¡®å®šæ€§æ’åº
        samples.sort(key=lambda x: x['uncertainty'], reverse=True)
        
        # é€‰æ‹©top-Kï¼ˆæˆ–å…¨éƒ¨ï¼‰
        top_k = min(len(samples), max(1, len(samples) // 2))  # é€‰æ‹©ä¸€åŠ
        selected_features = [s['feature'] for s in samples[:top_k]]
        
        # è®¡ç®—å‡å€¼åŸå‹
        prototype = torch.stack(selected_features).mean(dim=0)
        prototype = F.normalize(prototype, dim=0)
        prototypes.append(prototype)
    
    prototypes = torch.stack(prototypes)
    return prototypes


def evaluate_baseline(model, test_loader, device='cuda'):
    """
    è¯„ä¼°åŸºçº¿ï¼ˆç›´æ¥åˆ†ç±»ï¼‰
    
    Args:
        model: åˆ†ç±»å™¨
        test_loader: æµ‹è¯•é›†åŠ è½½å™¨
        device: è®¾å¤‡
    
    Returns:
        accuracy: å‡†ç¡®ç‡
        confidence: å¹³å‡ç½®ä¿¡åº¦
    """
    model.eval()
    correct = 0
    total = 0
    all_confidences = []
    
    with torch.no_grad():
        for batch in test_loader:
            if len(batch) == 3:
                images, labels, _ = batch
            else:
                images, labels = batch
            
            images = images.to(device)
            labels = labels.to(device)
            
            outputs = model(images)
            probs = F.softmax(outputs, dim=1)
            confidences, predictions = probs.max(dim=1)
            
            correct += (predictions == labels).sum().item()
            total += labels.size(0)
            all_confidences.extend(confidences.cpu().numpy())
    
    accuracy = correct / total
    mean_confidence = np.mean(all_confidences)
    
    return accuracy, mean_confidence 
