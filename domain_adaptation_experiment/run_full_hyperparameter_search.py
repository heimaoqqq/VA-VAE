#!/usr/bin/env python3
"""
å®Œæ•´è¶…å‚æ•°æœç´¢è¯„ä¼°
æµ‹è¯•æ‰€æœ‰æ–¹æ³•å’Œè¶…å‚æ•°ç»„åˆ
"""

import torch
import pandas as pd
import json
from pathlib import Path
from tqdm import tqdm
from itertools import product
import sys

sys.path.append(str(Path(__file__).parent))
from eval_config import *
from eval_utils import *
from eval_components import *
from run_comprehensive_eval import run_single_experiment


def evaluate_pnc_hyperparameters(model_path, data_dir, output_dir):
    """è¯„ä¼°PNCçš„è¶…å‚æ•°"""
    print("\n" + "="*80)
    print("ğŸ” PNCè¶…å‚æ•°æœç´¢")
    print("="*80)
    
    results = []
    
    # æµ‹è¯•é…ç½®
    prototype_strategies = ['simple_mean', 'weighted_mean']
    fusion_alphas = [0.4, 0.5, 0.6, 0.7]
    similarity_taus = [0.005, 0.01, 0.02]
    use_adaptives = [False, True]
    support_sizes = [3, 5]
    seeds = [42]
    
    total = (len(prototype_strategies) * len(fusion_alphas) * 
             len(similarity_taus) * len(use_adaptives) * 
             len(support_sizes) * len(seeds))
    
    print(f"æ€»å…± {total} ä¸ªé…ç½®")
    
    with tqdm(total=total, desc="PNC") as pbar:
        for (proto_strat, alpha, tau, adaptive, support_size, seed) in product(
            prototype_strategies, fusion_alphas, similarity_taus,
            use_adaptives, support_sizes, seeds
        ):
            params = {
                'prototype_strategy': proto_strat,
                'fusion_alpha': alpha,
                'similarity_tau': tau,
                'use_adaptive': adaptive
            }
            
            result = run_single_experiment(
                model_path, data_dir, support_size, seed,
                method='pnc', params=params, device='cuda'
            )
            
            results.append({
                'method': 'pnc',
                'prototype_strategy': proto_strat,
                'fusion_alpha': alpha,
                'similarity_tau': tau,
                'use_adaptive': adaptive,
                'support_size': support_size,
                'seed': seed,
                'accuracy': result['accuracy'],
                'confidence': result['confidence']
            })
            
            pbar.update(1)
    
    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    df.to_csv(Path(output_dir) / 'pnc_results.csv', index=False)
    
    # æ‰¾æœ€ä½³é…ç½®
    best = df.loc[df['accuracy'].idxmax()]
    print(f"\nğŸ† æœ€ä½³PNCé…ç½®:")
    print(f"   å‡†ç¡®ç‡: {best['accuracy']:.4f}")
    print(f"   åŸå‹ç­–ç•¥: {best['prototype_strategy']}")
    print(f"   Fusion Î±: {best['fusion_alpha']}")
    print(f"   Temperature Ï„: {best['similarity_tau']}")
    print(f"   è‡ªé€‚åº”: {best['use_adaptive']}")
    
    return df


def evaluate_lccs_hyperparameters(model_path, data_dir, output_dir):
    """è¯„ä¼°LCCSçš„è¶…å‚æ•°"""
    print("\n" + "="*80)
    print("ğŸ” LCCSè¶…å‚æ•°æœç´¢")
    print("="*80)
    
    results = []
    
    support_sizes = [3, 5]
    seeds = [42]
    
    # Progressiveæ–¹æ³•
    prog_configs = list(product(
        [0.005, 0.01, 0.02],  # momentum
        [3, 5, 10]  # iterations
    ))
    
    # Weightedæ–¹æ³•
    weighted_configs = [0.2, 0.3, 0.4]  # alpha
    
    total = (len(prog_configs) + len(weighted_configs)) * len(support_sizes) * len(seeds)
    
    print(f"æ€»å…± {total} ä¸ªé…ç½®")
    
    with tqdm(total=total, desc="LCCS") as pbar:
        # Progressive
        for (momentum, iterations, support_size, seed) in product(
            *zip(*prog_configs), support_sizes, seeds
        ):
            params = {
                'lccs_method': 'progressive',
                'lccs_params': {
                    'momentum': momentum,
                    'iterations': iterations
                }
            }
            
            result = run_single_experiment(
                model_path, data_dir, support_size, seed,
                method='lccs', params=params, device='cuda'
            )
            
            results.append({
                'method': 'lccs',
                'lccs_method': 'progressive',
                'momentum': momentum,
                'iterations': iterations,
                'alpha': None,
                'support_size': support_size,
                'seed': seed,
                'accuracy': result['accuracy'],
                'confidence': result['confidence']
            })
            
            pbar.update(1)
        
        # Weighted
        for (alpha, support_size, seed) in product(
            weighted_configs, support_sizes, seeds
        ):
            params = {
                'lccs_method': 'weighted',
                'lccs_params': {'alpha': alpha}
            }
            
            result = run_single_experiment(
                model_path, data_dir, support_size, seed,
                method='lccs', params=params, device='cuda'
            )
            
            results.append({
                'method': 'lccs',
                'lccs_method': 'weighted',
                'momentum': None,
                'iterations': None,
                'alpha': alpha,
                'support_size': support_size,
                'seed': seed,
                'accuracy': result['accuracy'],
                'confidence': result['confidence']
            })
            
            pbar.update(1)
    
    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    df.to_csv(Path(output_dir) / 'lccs_results.csv', index=False)
    
    # æ‰¾æœ€ä½³é…ç½®
    best = df.loc[df['accuracy'].idxmax()]
    print(f"\nğŸ† æœ€ä½³LCCSé…ç½®:")
    print(f"   å‡†ç¡®ç‡: {best['accuracy']:.4f}")
    print(f"   æ–¹æ³•: {best['lccs_method']}")
    if best['lccs_method'] == 'progressive':
        print(f"   Momentum: {best['momentum']}")
        print(f"   Iterations: {best['iterations']}")
    else:
        print(f"   Alpha: {best['alpha']}")
    
    return df


def evaluate_pnc_lccs_combined(model_path, data_dir, output_dir,
                               best_pnc, best_lccs):
    """
    è¯„ä¼°PNC+LCCSç»„åˆ
    ä½¿ç”¨æœ€ä½³è¶…å‚æ•°é…ç½®
    """
    print("\n" + "="*80)
    print("ğŸ” PNC+LCCSç»„åˆè¯„ä¼°ï¼ˆä½¿ç”¨æœ€ä½³é…ç½®ï¼‰")
    print("="*80)
    
    results = []
    
    support_sizes = [3, 5, 10]
    seeds = [42, 123, 456]
    
    total = len(support_sizes) * len(seeds)
    
    print(f"æ€»å…± {total} ä¸ªé…ç½®")
    print(f"\næœ€ä½³PNCé…ç½®:")
    print(f"  åŸå‹ç­–ç•¥: {best_pnc['prototype_strategy']}")
    print(f"  Fusion Î±: {best_pnc['fusion_alpha']}")
    print(f"  Temperature Ï„: {best_pnc['similarity_tau']}")
    print(f"\næœ€ä½³LCCSé…ç½®:")
    print(f"  æ–¹æ³•: {best_lccs['lccs_method']}")
    
    with tqdm(total=total, desc="PNC+LCCS") as pbar:
        for support_size, seed in product(support_sizes, seeds):
            # å‡†å¤‡LCCSå‚æ•°
            if best_lccs['lccs_method'] == 'progressive':
                lccs_params = {
                    'momentum': best_lccs['momentum'],
                    'iterations': best_lccs['iterations']
                }
            else:
                lccs_params = {'alpha': best_lccs['alpha']}
            
            params = {
                'prototype_strategy': best_pnc['prototype_strategy'],
                'fusion_alpha': best_pnc['fusion_alpha'],
                'similarity_tau': best_pnc['similarity_tau'],
                'use_adaptive': best_pnc['use_adaptive'],
                'lccs_method': best_lccs['lccs_method'],
                'lccs_params': lccs_params
            }
            
            result = run_single_experiment(
                model_path, data_dir, support_size, seed,
                method='pnc_lccs', params=params, device='cuda'
            )
            
            results.append({
                'method': 'pnc_lccs',
                'support_size': support_size,
                'seed': seed,
                'accuracy': result['accuracy'],
                'confidence': result['confidence']
            })
            
            pbar.update(1)
    
    # ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    df.to_csv(Path(output_dir) / 'pnc_lccs_combined_results.csv', index=False)
    
    print(f"\nğŸ† PNC+LCCSç»„åˆç»“æœ:")
    print(f"   å¹³å‡å‡†ç¡®ç‡: {df['accuracy'].mean():.4f} Â± {df['accuracy'].std():.4f}")
    
    return df


def main():
    import argparse
    parser = argparse.ArgumentParser(description='å®Œæ•´è¶…å‚æ•°æœç´¢')
    parser.add_argument('--model-path', type=str,
                       default='/kaggle/working/VA-VAE/improved_classifier/best_improved_classifier.pth')
    parser.add_argument('--data-dir', type=str,
                       default='/kaggle/input/backpack/backpack')
    parser.add_argument('--output-dir', type=str,
                       default='./hyperparameter_search_results')
    parser.add_argument('--skip-pnc', action='store_true',
                       help='è·³è¿‡PNCè¯„ä¼°')
    parser.add_argument('--skip-lccs', action='store_true',
                       help='è·³è¿‡LCCSè¯„ä¼°')
    
    args = parser.parse_args()
    
    output_path = Path(args.output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # 1. è¯„ä¼°PNC
    if not args.skip_pnc:
        pnc_df = evaluate_pnc_hyperparameters(
            args.model_path, args.data_dir, args.output_dir
        )
        best_pnc = pnc_df.loc[pnc_df['accuracy'].idxmax()]
    else:
        print("â­ï¸ è·³è¿‡PNCè¯„ä¼°")
        best_pnc = {
            'prototype_strategy': 'simple_mean',
            'fusion_alpha': 0.6,
            'similarity_tau': 0.01,
            'use_adaptive': False
        }
    
    # 2. è¯„ä¼°LCCS
    if not args.skip_lccs:
        lccs_df = evaluate_lccs_hyperparameters(
            args.model_path, args.data_dir, args.output_dir
        )
        best_lccs = lccs_df.loc[lccs_df['accuracy'].idxmax()]
    else:
        print("â­ï¸ è·³è¿‡LCCSè¯„ä¼°")
        best_lccs = {
            'lccs_method': 'progressive',
            'momentum': 0.01,
            'iterations': 5
        }
    
    # 3. è¯„ä¼°PNC+LCCSç»„åˆ
    combined_df = evaluate_pnc_lccs_combined(
        args.model_path, args.data_dir, args.output_dir,
        best_pnc, best_lccs
    )
    
    # 4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    print("\n" + "="*80)
    print("ğŸ“Š æœ€ç»ˆæ€»ç»“")
    print("="*80)
    
    summary = {
        'best_pnc': best_pnc.to_dict() if hasattr(best_pnc, 'to_dict') else best_pnc,
        'best_lccs': best_lccs.to_dict() if hasattr(best_lccs, 'to_dict') else best_lccs,
        'combined_results': {
            'mean_accuracy': float(combined_df['accuracy'].mean()),
            'std_accuracy': float(combined_df['accuracy'].std()),
            'max_accuracy': float(combined_df['accuracy'].max())
        }
    }
    
    with open(output_path / 'summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")
    print(f"   - pnc_results.csv")
    print(f"   - lccs_results.csv")
    print(f"   - pnc_lccs_combined_results.csv")
    print(f"   - summary.json")


if __name__ == '__main__':
    main() 
