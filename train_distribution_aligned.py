#!/usr/bin/env python3
"""
è®­ç»ƒåˆ†å¸ƒå¯¹é½çš„æ‰©æ•£æ¨¡å‹ - é›†æˆç‰ˆæœ¬
è§£å†³VA-VAEä¸æ‰©æ•£æ¨¡å‹ä¹‹é—´çš„latentåˆ†å¸ƒä¸åŒ¹é…é—®é¢˜
"""

import torch
import torch.nn as nn
from pathlib import Path
import json
import argparse
from datetime import datetime
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from torchvision.utils import make_grid, save_image
from microdoppler_data_loader import (
    MicroDopplerLatentDataset, 
    BalancedBatchSampler,
    prepare_latent_dataset,
    create_balanced_dataloader
)
from distribution_aligned_diffusion import DistributionAlignedDiffusion
from simplified_vavae import SimplifiedVAVAE

def compute_latent_statistics(dataloader, device, max_batches=50):
    """
    è®¡ç®—è®­ç»ƒæ•°æ®çš„latentåˆ†å¸ƒç»Ÿè®¡
    """
    print(f"   ğŸ” åˆ†æå‰{max_batches}ä¸ªæ‰¹æ¬¡çš„latentåˆ†å¸ƒ...")
    
    all_latents = []
    batch_count = 0
    
    for batch_idx, (latents, user_ids) in enumerate(dataloader):
        if batch_count >= max_batches:
            break
            
        latents = latents.to(device)
        all_latents.append(latents.cpu().flatten())
        batch_count += 1
        
        if batch_count % 10 == 0:
            print(f"   ğŸ“Š å·²å¤„ç† {batch_count}/{max_batches} æ‰¹æ¬¡...")
    
    # åˆå¹¶æ‰€æœ‰latentæ•°æ®
    all_latents = torch.cat(all_latents, dim=0)
    
    # è®¡ç®—ç»Ÿè®¡é‡
    latent_mean = all_latents.mean().item()
    latent_std = all_latents.std().item()
    latent_min = all_latents.min().item()
    latent_max = all_latents.max().item()
    
    print(f"   âœ… ç»Ÿè®¡å®Œæˆï¼šåˆ†æäº† {len(all_latents):,} ä¸ªlatentå€¼")
    
    return {
        'mean': latent_mean,
        'std': latent_std, 
        'min': latent_min,
        'max': latent_max
    }

def train_distribution_aligned_diffusion(args):
    """è®­ç»ƒåˆ†å¸ƒå¯¹é½çš„æ‰©æ•£æ¨¡å‹"""
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    checkpoint_dir = output_dir / 'checkpoints'
    checkpoint_dir.mkdir(exist_ok=True)
    
    sample_dir = output_dir / 'samples'
    sample_dir.mkdir(exist_ok=True)
    
    # åˆå§‹åŒ–VAE - ä½¿ç”¨æ­£ç¡®çš„VFé…ç½®
    print("\nğŸ“¦ åŠ è½½é¢„è®­ç»ƒVA-VAE...")
    vae_path = args.vae_checkpoint if hasattr(args, 'vae_checkpoint') else "/kaggle/input/stage3/vavae-stage3-epoch26-val_rec_loss0.0000.ckpt"
    vae = SimplifiedVAVAE(vae_path, use_vf='dinov2')  # å¯ç”¨VFä»¥åŒ¹é…é¢„è®­ç»ƒæ¨¡å‹
    vae.eval()
    vae.freeze()
    vae = vae.to(device)
    print(f"âœ… VAEåŠ è½½å®Œæˆï¼Œç¼©æ”¾å› å­: {vae.scale_factor}")
    print(f"âœ… VFæ¨¡å¼: {'å¯ç”¨ (dinov2)' if vae.use_vf else 'ç¦ç”¨'}")
    
    # å‡†å¤‡latentæ•°æ®é›†
    latent_dir = Path(args.latent_dir)
    
    # æ£€æŸ¥latentæ•°æ®é›†æ˜¯å¦å®Œæ•´
    def check_latent_dataset_complete(latent_dir, split_file):
        """æ£€æŸ¥latentæ•°æ®é›†æ˜¯å¦å®Œæ•´"""
        if not latent_dir.exists():
            return False, "ç›®å½•ä¸å­˜åœ¨"
        
        if not (latent_dir / "train").exists() or not (latent_dir / "val").exists():
            return False, "ç¼ºå°‘trainæˆ–valå­ç›®å½•"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰latentæ–‡ä»¶
        train_files = list((latent_dir / "train").glob("*.pt"))
        val_files = list((latent_dir / "val").glob("*.pt"))
        
        if len(train_files) == 0 or len(val_files) == 0:
            return False, f"latentæ–‡ä»¶ä¸è¶³: train={len(train_files)}, val={len(val_files)}"
        
        return True, f"æ•°æ®é›†å®Œæ•´: train={len(train_files)}, val={len(val_files)} files"
    
    is_complete, status_msg = check_latent_dataset_complete(latent_dir, args.split_file)
    
    if not is_complete or args.prepare_latents:
        if args.prepare_latents:
            print("\nğŸ”„ å¼ºåˆ¶é‡æ–°å‡†å¤‡latentæ•°æ®é›†...")
        else:
            print(f"\nğŸ”„ æ•°æ®é›†ä¸å®Œæ•´({status_msg})ï¼Œå¼€å§‹å‡†å¤‡latentæ•°æ®é›†...")
            
        latent_dir = prepare_latent_dataset(
            image_dir=args.image_dir,
            vae_model=vae,
            output_dir=args.latent_dir,
            split_file=args.split_file,
            device=device
        )
    else:
        print(f"\nâœ… å‘ç°å®Œæ•´çš„latentæ•°æ®é›†: {status_msg}")
        print(f"   è·¯å¾„: {latent_dir}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader = create_balanced_dataloader(
        latent_dir=latent_dir,
        batch_size=args.batch_size,
        num_users_per_batch=args.num_users_per_batch,
        split='train',
        num_workers=args.num_workers
    )
    
    val_loader = create_balanced_dataloader(
        latent_dir=latent_dir,
        batch_size=args.batch_size,
        num_users_per_batch=args.num_users_per_batch,
        split='val',
        shuffle=False,
        num_workers=args.num_workers
    )
    
    # è®¡ç®—è®­ç»ƒæ•°æ®çš„å®é™…latentåˆ†å¸ƒç»Ÿè®¡
    print("\nğŸ“Š è®¡ç®—è®­ç»ƒæ•°æ®latentåˆ†å¸ƒç»Ÿè®¡...")
    latent_stats = compute_latent_statistics(train_loader, device, max_batches=50)
    
    print(f"ğŸ“ˆ å®é™…è®­ç»ƒlatentåˆ†å¸ƒ:")
    print(f"   Mean: {latent_stats['mean']:.6f}")
    print(f"   Std:  {latent_stats['std']:.6f}")
    print(f"   Range: [{latent_stats['min']:.2f}, {latent_stats['max']:.2f}]")
    print(f"   3Ïƒ Range: [{latent_stats['mean']-3*latent_stats['std']:.2f}, {latent_stats['mean']+3*latent_stats['std']:.2f}]")
    
    # ğŸ”‘ å…³é”®ï¼šæ£€æµ‹æ˜¯å¦éœ€è¦åˆ†å¸ƒå¯¹é½
    if abs(latent_stats['std'] - 1.0) > 0.2 or abs(latent_stats['mean']) > 0.1:
        print(f"\nâš ï¸ æ£€æµ‹åˆ°latentåˆ†å¸ƒåç¦»æ ‡å‡†æ­£æ€åˆ†å¸ƒ!")
        print(f"   éœ€è¦åˆ†å¸ƒå¯¹é½ï¼šmean={latent_stats['mean']:.4f} (æœŸæœ›0), std={latent_stats['std']:.4f} (æœŸæœ›1)")
        use_distribution_alignment = True
    else:
        print(f"\nâœ… Latentåˆ†å¸ƒæ¥è¿‘æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œå¯é€‰æ‹©æ˜¯å¦ä½¿ç”¨åˆ†å¸ƒå¯¹é½")
        use_distribution_alignment = args.force_alignment
    
    # åˆ›å»ºåˆ†å¸ƒå¯¹é½çš„æ‰©æ•£æ¨¡å‹
    print(f"\nğŸš€ åˆ›å»º{'åˆ†å¸ƒå¯¹é½' if use_distribution_alignment else 'æ ‡å‡†'}æ‰©æ•£æ¨¡å‹...")
    model = DistributionAlignedDiffusion(
        vae=vae,
        num_users=args.num_users,
        prototype_dim=args.prototype_dim,
        enable_alignment=use_distribution_alignment,  # æ ¹æ®æ£€æµ‹ç»“æœå¯ç”¨å¯¹é½
        track_statistics=True  # å§‹ç»ˆè·Ÿè¸ªç»Ÿè®¡ä¿¡æ¯
    )
    
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡
    model = model.to(device)
    print(f"âœ… æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: {device}")
    
    if use_distribution_alignment:
        print(f"ğŸ“Š åˆ†å¸ƒå¯¹é½å·²å¯ç”¨")
        print(f"   - è®­ç»ƒæ—¶å°†å½’ä¸€åŒ–latentåˆ°N(0,1)")
        print(f"   - ç”Ÿæˆæ—¶å°†åå½’ä¸€åŒ–ä»¥åŒ¹é…VAEåˆ†å¸ƒ")
    else:
        print(f"ğŸ“Š åˆ†å¸ƒå¯¹é½å·²ç¦ç”¨ï¼ˆlatentå·²æ¥è¿‘æ ‡å‡†åˆ†å¸ƒï¼‰")
    
    # è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(), 
        lr=args.learning_rate,
        weight_decay=args.weight_decay
    )
    
    # ä½¿ç”¨ä½™å¼¦é€€ç«è°ƒåº¦å™¨ï¼Œä¿ç•™æœ€å°å­¦ä¹ ç‡
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, 
        T_max=args.num_epochs,
        eta_min=1e-6  # ä¿æŒæœ€å°å­¦ä¹ ç‡
    )
    
    # è®­ç»ƒå¾ªç¯
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    best_val_loss = float('inf')
    
    for epoch in range(args.num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_losses = {
            'total': 0.0,
            'diffusion': 0.0, 
            'contrastive': 0.0
        }
        
        train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{args.num_epochs}')
        for batch_idx, (latents, user_ids) in enumerate(train_bar):
            latents = latents.to(device)
            user_ids = user_ids.to(device)
            
            # ç¬¬ä¸€ä¸ªepochçš„ç¬¬ä¸€ä¸ªbatchæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            if epoch == 0 and batch_idx == 0:
                print(f"\nğŸ“Š ç¬¬ä¸€æ‰¹è®­ç»ƒæ•°æ®åˆ†æ:")
                print(f"   Shape: {latents.shape}")
                print(f"   åŸå§‹åˆ†å¸ƒ: Mean={latents.mean():.6f}, Std={latents.std():.6f}")
                print(f"   Range: [{latents.min():.2f}, {latents.max():.2f}]")
                
                if use_distribution_alignment:
                    # æµ‹è¯•å½’ä¸€åŒ–æ•ˆæœ
                    with torch.no_grad():
                        normalized = model.normalize_latents(latents)
                        print(f"   å½’ä¸€åŒ–å: Mean={normalized.mean():.6f}, Std={normalized.std():.6f}")
                        print(f"   âœ… åˆ†å¸ƒå¯¹é½{'æˆåŠŸ' if abs(normalized.std()-1.0)<0.1 else 'éœ€è¦è°ƒæ•´'}")
            
            # è·å–ç”¨æˆ·æ¡ä»¶
            user_conditions = model.get_user_condition(user_ids)
            
            # å‰å‘ä¼ æ’­ - å†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç†å½’ä¸€åŒ–
            loss_dict = model.training_step(latents, user_conditions)
            total_loss = loss_dict['total_loss']
            diff_loss = loss_dict['diffusion_loss']
            contrastive_loss = loss_dict['contrastive_loss']
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            
            # æ›´æ–°ç»Ÿè®¡
            train_losses['total'] += total_loss.item()
            train_losses['diffusion'] += diff_loss.item()
            train_losses['contrastive'] += contrastive_loss.item()
            
            # æ›´æ–°è¿›åº¦æ¡
            train_bar.set_postfix({
                'loss': total_loss.item(),
                'diff': diff_loss.item(),
                'cont': contrastive_loss.item()
            })
        
        # è®¡ç®—å¹³å‡æŸå¤±
        num_batches = len(train_loader)
        for key in train_losses:
            train_losses[key] /= num_batches
        
        # åœ¨epochç»“æŸæ—¶æ›´æ–°ç”¨æˆ·åŸå‹
        if (epoch + 1) % 5 == 0:
            print("   ğŸ”„ æ›´æ–°ç”¨æˆ·åŸå‹...")
            update_user_prototypes(model, train_loader, device)
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_losses = {'total': 0.0, 'diffusion': 0.0, 'contrastive': 0.0}
        
        with torch.no_grad():
            for latents, user_ids in val_loader:
                latents = latents.to(device)
                user_ids = user_ids.to(device)
                
                user_conditions = model.get_user_condition(user_ids)
                loss_dict = model.training_step(latents, user_conditions)
                
                val_losses['total'] += loss_dict['total_loss'].item()
                val_losses['diffusion'] += loss_dict['diffusion_loss'].item()
                val_losses['contrastive'] += loss_dict['contrastive_loss'].item()
        
        for key in val_losses:
            val_losses[key] /= len(val_loader)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        
        # æ‰“å°epochæ€»ç»“å’Œåˆ†å¸ƒç»Ÿè®¡
        print(f"\nğŸ“Š Epoch {epoch+1} Summary:")
        print(f"   Train Loss: {train_losses['total']:.4f} "
              f"(Diff: {train_losses['diffusion']:.4f}, "
              f"Cont: {train_losses['contrastive']:.4f})")
        print(f"   Val Loss: {val_losses['total']:.4f} "
              f"(Diff: {val_losses['diffusion']:.4f}, "
              f"Cont: {val_losses['contrastive']:.4f})")
        print(f"   LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # æ˜¾ç¤ºå½“å‰ç»Ÿè®¡ä¿¡æ¯
        if use_distribution_alignment and hasattr(model, 'latent_mean'):
            print(f"ğŸ“ˆ å½“å‰Latentç»Ÿè®¡ (è¿è¡Œå¹³å‡):")
            print(f"   Mean: {model.latent_mean:.6f}, Std: {model.latent_std:.6f}")
            print(f"   æ ·æœ¬æ•°: {model.n_samples}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_losses['total'] < best_val_loss:
            best_val_loss = val_losses['total']
            save_path = checkpoint_dir / 'best_model.pth'
            
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'train_losses': train_losses,
                'val_losses': val_losses,
                'user_prototypes': model.user_prototypes,
                'best_val_loss': best_val_loss,
                'latent_mean': model.latent_mean if hasattr(model, 'latent_mean') else 0.0,
                'latent_std': model.latent_std if hasattr(model, 'latent_std') else 1.0
            }, save_path)
            print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: {save_path} (Val Loss: {best_val_loss:.4f})")
        
        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % args.save_freq == 0:
            save_path = checkpoint_dir / f'checkpoint_epoch_{epoch+1}.pth'
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'train_losses': train_losses,
                'val_losses': val_losses,
                'user_prototypes': model.user_prototypes,
                'latent_mean': model.latent_mean if hasattr(model, 'latent_mean') else 0.0,
                'latent_std': model.latent_std if hasattr(model, 'latent_std') else 1.0
            }, save_path)
        
        # ç”Ÿæˆæ ·æœ¬
        if (epoch + 1) % args.sample_freq == 0:
            generate_samples(model, vae, epoch+1, sample_dir, device, args.num_users)
    
    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    
    # ä¿å­˜æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
    if use_distribution_alignment:
        stats_path = output_dir / 'latent_statistics.json'
        with open(stats_path, 'w') as f:
            json.dump({
                'latent_mean': float(model.latent_mean),
                'latent_std': float(model.latent_std),
                'n_samples': int(model.n_samples)
            }, f, indent=2)
        print(f"ğŸ“Š å·²ä¿å­˜latentç»Ÿè®¡ä¿¡æ¯: {stats_path}")
    
    return model


def update_user_prototypes(model, dataloader, device):
    """æ›´æ–°ç”¨æˆ·åŸå‹"""
    user_latents = {}
    
    with torch.no_grad():
        for latents, user_ids in dataloader:
            latents = latents.to(device)
            
            for i, user_id in enumerate(user_ids):
                user_id = user_id.item()
                if user_id not in user_latents:
                    user_latents[user_id] = []
                user_latents[user_id].append(latents[i:i+1])
    
    # åˆå¹¶æ¯ä¸ªç”¨æˆ·çš„latents
    for user_id in user_latents:
        user_latents[user_id] = torch.cat(user_latents[user_id], dim=0)
    
    # æ›´æ–°æ¨¡å‹ä¸­çš„åŸå‹
    model.update_user_prototypes(user_latents)


def generate_samples(model, vae, epoch, sample_dir, device, num_users):
    """ç”Ÿæˆå¹¶ä¿å­˜æ ·æœ¬"""
    print(f"\nğŸ¨ ç”Ÿæˆæ ·æœ¬ (Epoch {epoch})...")
    
    # é€‰æ‹©å‡ ä¸ªç”¨æˆ·ç”Ÿæˆ
    sample_users = list(range(min(4, num_users)))
    
    # ç”Ÿæˆlatents - ä½¿ç”¨åˆ†å¸ƒå¯¹é½çš„ç”Ÿæˆæ–¹æ³•
    with torch.no_grad():
        latents = model.generate(
            user_ids=sample_users,
            num_samples=len(sample_users) * 4,  # æ¯ä¸ªç”¨æˆ·4ä¸ªæ ·æœ¬
            num_inference_steps=50,
            guidance_scale=7.5  # ä½¿ç”¨æ ‡å‡†CFGå¼ºåº¦
        )
        
        # æ˜¾ç¤ºç”Ÿæˆçš„latentåˆ†å¸ƒ
        print(f"ğŸ“Š ç”Ÿæˆlatentåˆ†å¸ƒ: mean={latents.mean():.4f}, std={latents.std():.4f}")
        
        # å¦‚æœå¯ç”¨äº†åˆ†å¸ƒå¯¹é½ï¼Œlatentåº”è¯¥å·²ç»è¢«åå½’ä¸€åŒ–åˆ°VAEçš„åˆ†å¸ƒ
        if hasattr(model, 'enable_alignment') and model.enable_alignment:
            print(f"   âœ… å·²åå½’ä¸€åŒ–åˆ°VAEåˆ†å¸ƒ (æœŸæœ›stdâ‰ˆ{model.latent_std:.2f})")
        
        # è§£ç åˆ°å›¾åƒ
        print(f"ğŸ¨ è§£ç  {len(latents)} ä¸ªlatentåˆ°å›¾åƒ...")
        images = []
        for i in range(0, len(latents), 8):
            batch = latents[i:i+8]
            decoded = vae.decode(batch)
            images.append(decoded)
        
        images = torch.cat(images, dim=0)
    
    # æ£€æŸ¥å›¾åƒèŒƒå›´
    print(f"ğŸ” å›¾åƒèŒƒå›´: [{images.min():.3f}, {images.max():.3f}]")
    
    # SimplifiedVAVAE.decode()è¾“å‡º[0,1]èŒƒå›´
    if images.max() > 1.1 or images.min() < -0.1:
        print(f"âš ï¸ å›¾åƒå€¼è¶…å‡ºé¢„æœŸèŒƒå›´ï¼Œè¿›è¡Œè£å‰ª")
        images = torch.clamp(images, 0, 1)
    
    # ä¿å­˜å›¾åƒç½‘æ ¼
    grid = make_grid(images, nrow=4, normalize=False, value_range=(0, 1))
    save_path = sample_dir / f'samples_epoch_{epoch:04d}.png'
    save_image(grid, save_path)
    
    print(f"   âœ… æ ·æœ¬å·²ä¿å­˜: {save_path}")


def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒåˆ†å¸ƒå¯¹é½çš„æ‰©æ•£æ¨¡å‹')
    
    # æ•°æ®ç›¸å…³
    parser.add_argument('--image_dir', type=str, default='/kaggle/input/microdoppler',
                      help='åŸå§‹å›¾åƒç›®å½•')
    parser.add_argument('--latent_dir', type=str, default='/kaggle/working/latents',
                      help='Latentæ•°æ®ç›®å½•')
    parser.add_argument('--split_file', type=str, default='/kaggle/working/dataset_split.json',
                      help='æ•°æ®åˆ’åˆ†æ–‡ä»¶')
    parser.add_argument('--prepare_latents', action='store_true', 
                       help='å¼ºåˆ¶é‡æ–°å‡†å¤‡latentæ•°æ®é›†')
    
    # VAEç›¸å…³
    parser.add_argument('--vae_checkpoint', type=str, 
                      default='/kaggle/input/stage3/vavae-stage3-epoch26-val_rec_loss0.0000.ckpt',
                      help='VA-VAEæ£€æŸ¥ç‚¹è·¯å¾„')
    
    # æ¨¡å‹ç›¸å…³
    parser.add_argument('--num_users', type=int, default=31,
                      help='ç”¨æˆ·æ•°é‡')
    parser.add_argument('--prototype_dim', type=int, default=768,
                      help='åŸå‹ç»´åº¦')
    parser.add_argument('--force_alignment', action='store_true',
                      help='å¼ºåˆ¶å¯ç”¨åˆ†å¸ƒå¯¹é½ï¼ˆå³ä½¿latentå·²æ¥è¿‘æ ‡å‡†åˆ†å¸ƒï¼‰')
    
    # è®­ç»ƒç›¸å…³
    parser.add_argument('--num_epochs', type=int, default=100,
                      help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32,
                      help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_users_per_batch', type=int, default=4,
                      help='æ¯æ‰¹ç”¨æˆ·æ•°')
    parser.add_argument('--learning_rate', type=float, default=1e-4,
                      help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-5,
                      help='æƒé‡è¡°å‡')
    parser.add_argument('--num_workers', type=int, default=2,
                      help='æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°')
    
    # è¾“å‡ºç›¸å…³
    parser.add_argument('--output_dir', type=str, 
                      default='/kaggle/working/distribution_aligned_diffusion',
                      help='è¾“å‡ºç›®å½•')
    parser.add_argument('--save_freq', type=int, default=10,
                      help='ä¿å­˜æ£€æŸ¥ç‚¹é¢‘ç‡')
    parser.add_argument('--sample_freq', type=int, default=5,
                      help='ç”Ÿæˆæ ·æœ¬é¢‘ç‡')
    parser.add_argument('--seed', type=int, default=42,
                      help='éšæœºç§å­')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # è®­ç»ƒæ¨¡å‹
    model = train_distribution_aligned_diffusion(args)
    
    print("\nâœ… è®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    main()
