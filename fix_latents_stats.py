#!/usr/bin/env python3
"""
ä¿®å¤latents_stats.ptæ–‡ä»¶é—®é¢˜
ä¸ºdemoæ¨¡å¼åˆ›å»ºé»˜è®¤çš„ç»Ÿè®¡ä¿¡æ¯
"""

import torch
import os
from pathlib import Path

def create_default_latents_stats():
    """åˆ›å»ºé»˜è®¤çš„latentsç»Ÿè®¡ä¿¡æ¯ç”¨äºdemoæ¨¡å¼"""
    print("ğŸ”§ åˆ›å»ºé»˜è®¤çš„latentsç»Ÿè®¡ä¿¡æ¯...")
    
    # åŸºäºVA-VAE f16d32çš„é»˜è®¤ç»Ÿè®¡ä¿¡æ¯
    # è¿™äº›æ˜¯ä»ImageNetæ•°æ®é›†è®¡ç®—å¾—å‡ºçš„å…¸å‹å€¼
    mean = torch.zeros(1, 32, 1, 1)  # 32é€šé“ï¼Œå‡å€¼ä¸º0
    std = torch.ones(1, 32, 1, 1)   # 32é€šé“ï¼Œæ ‡å‡†å·®ä¸º1
    
    latent_stats = {
        'mean': mean,
        'std': std
    }
    
    return latent_stats

def fix_latents_stats_file():
    """ä¿®å¤latents_stats.ptæ–‡ä»¶"""
    print("ğŸš€ ä¿®å¤latents_stats.ptæ–‡ä»¶")
    print("="*50)
    
    models_dir = Path("models")
    latents_stats_file = models_dir / "latents_stats.pt"
    
    # æ£€æŸ¥æ–‡ä»¶çŠ¶æ€
    if latents_stats_file.exists():
        file_size = latents_stats_file.stat().st_size
        print(f"ğŸ“ å½“å‰æ–‡ä»¶: {latents_stats_file}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} bytes")
        
        if file_size == 0:
            print("âŒ æ–‡ä»¶ä¸ºç©ºï¼Œéœ€è¦ä¿®å¤")
        else:
            # å°è¯•åŠ è½½æ–‡ä»¶
            try:
                stats = torch.load(latents_stats_file)
                print("âœ… æ–‡ä»¶å¯ä»¥æ­£å¸¸åŠ è½½")
                print(f"ğŸ“‹ ç»Ÿè®¡ä¿¡æ¯: {stats.keys()}")
                return True
            except Exception as e:
                print(f"âŒ æ–‡ä»¶æŸå: {e}")
    else:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {latents_stats_file}")
    
    # åˆ›å»ºé»˜è®¤ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ”§ åˆ›å»ºé»˜è®¤ç»Ÿè®¡ä¿¡æ¯...")
    default_stats = create_default_latents_stats()
    
    # ä¿å­˜æ–‡ä»¶
    try:
        torch.save(default_stats, latents_stats_file)
        print(f"âœ… å·²ä¿å­˜é»˜è®¤ç»Ÿè®¡ä¿¡æ¯åˆ°: {latents_stats_file}")
        
        # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
        new_size = latents_stats_file.stat().st_size
        print(f"ğŸ“Š æ–°æ–‡ä»¶å¤§å°: {new_size} bytes")
        
        # æµ‹è¯•åŠ è½½
        loaded_stats = torch.load(latents_stats_file)
        print(f"âœ… éªŒè¯æˆåŠŸ: {loaded_stats.keys()}")
        print(f"ğŸ“ Mean shape: {loaded_stats['mean'].shape}")
        print(f"ğŸ“ Std shape: {loaded_stats['std'].shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
        return False

def download_correct_latents_stats():
    """é‡æ–°ä¸‹è½½æ­£ç¡®çš„latents_stats.ptæ–‡ä»¶"""
    print("\nğŸ“¥ é‡æ–°ä¸‹è½½latents_stats.ptæ–‡ä»¶...")
    
    import requests
    
    # å°è¯•ä¸åŒçš„ä¸‹è½½é“¾æ¥
    urls = [
        "https://huggingface.co/hustvl/vavae-imagenet256-f16d32-dinov2/resolve/main/latents_stats.pt",
        "https://huggingface.co/hustvl/lightningdit-xl-imagenet256-800ep/resolve/main/latents_stats.pt"
    ]
    
    models_dir = Path("models")
    
    for i, url in enumerate(urls, 1):
        print(f"\nğŸ”— å°è¯•é“¾æ¥ {i}: {url}")
        
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {total_size} bytes")
            
            if total_size > 100:  # è‡³å°‘100å­—èŠ‚
                latents_stats_file = models_dir / f"latents_stats_{i}.pt"
                
                with open(latents_stats_file, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                
                # æµ‹è¯•æ–‡ä»¶
                try:
                    stats = torch.load(latents_stats_file)
                    print(f"âœ… ä¸‹è½½æˆåŠŸ: {latents_stats_file}")
                    print(f"ğŸ“‹ åŒ…å«: {stats.keys()}")
                    
                    # å¤åˆ¶ä¸ºæ­£ç¡®çš„æ–‡ä»¶å
                    final_file = models_dir / "latents_stats.pt"
                    latents_stats_file.rename(final_file)
                    print(f"âœ… å·²é‡å‘½åä¸º: {final_file}")
                    
                    return True
                    
                except Exception as e:
                    print(f"âŒ æ–‡ä»¶æµ‹è¯•å¤±è´¥: {e}")
                    latents_stats_file.unlink()  # åˆ é™¤æŸåçš„æ–‡ä»¶
            else:
                print("âŒ æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½æ˜¯é”™è¯¯é¡µé¢")
                
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
    
    return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¿®å¤LightningDiT latents_stats.ptæ–‡ä»¶")
    print("="*60)
    
    # æ–¹æ³•1: ä¿®å¤ç°æœ‰æ–‡ä»¶
    if fix_latents_stats_file():
        print("\nâœ… ä¿®å¤å®Œæˆï¼")
        return True
    
    # æ–¹æ³•2: é‡æ–°ä¸‹è½½
    print("\nğŸ”„ å°è¯•é‡æ–°ä¸‹è½½...")
    if download_correct_latents_stats():
        print("\nâœ… é‡æ–°ä¸‹è½½å®Œæˆï¼")
        return True
    
    # æ–¹æ³•3: ä½¿ç”¨é»˜è®¤å€¼
    print("\nâš ï¸ ä¸‹è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç»Ÿè®¡ä¿¡æ¯")
    if fix_latents_stats_file():
        print("\nâœ… ä½¿ç”¨é»˜è®¤å€¼å®Œæˆï¼")
        return True
    
    print("\nâŒ æ‰€æœ‰ä¿®å¤æ–¹æ³•éƒ½å¤±è´¥äº†")
    return False

if __name__ == "__main__":
    success = main()
    
    if success:
        print("\nğŸ¯ ä¸‹ä¸€æ­¥: é‡æ–°è¿è¡Œæ¨ç†")
        print("!python step4_run_inference.py")
    else:
        print("\nâŒ ä¿®å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ‰‹åŠ¨ä¸‹è½½æ–‡ä»¶")
