#!/usr/bin/env python3
"""
é˜¶æ®µ1: VA-VAEé‡å»ºæ•ˆæœæµ‹è¯•
æµ‹è¯•é¢„è®­ç»ƒVA-VAEåœ¨å¾®å¤šæ™®å‹’æ•°æ®ä¸Šçš„ç›´æ¥ä½¿ç”¨æ•ˆæœ
ä¸“æ³¨äºé‡å»ºè´¨é‡è¯„ä¼°ï¼Œä¸æ¶‰åŠç”¨æˆ·æ ‡ç­¾
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F

# æ·»åŠ LightningDiTè·¯å¾„
sys.path.append('LightningDiT')
from tokenizer.vavae import VA_VAE

class MicroDopplerDataset(Dataset):
    """å¾®å¤šæ™®å‹’æ•°æ®é›†åŠ è½½å™¨ - æ”¯æŒåµŒå¥—ç”¨æˆ·ç›®å½•ç»“æ„"""

    def __init__(self, data_dir, transform=None, max_images_per_user=None):
        self.data_dir = Path(data_dir)
        self.transform = transform
        self.max_images_per_user = max_images_per_user

        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        self.image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
        self.image_files = []
        self.user_labels = []  # å­˜å‚¨ç”¨æˆ·IDä¿¡æ¯

        # æ”¶é›†æ‰€æœ‰ç”¨æˆ·ç›®å½•ä¸‹çš„å›¾åƒæ–‡ä»¶
        self._collect_images()

        print(f"ğŸ“ æ‰¾åˆ° {len(self.image_files)} å¼ å›¾åƒï¼Œæ¥è‡ª {len(set(self.user_labels))} ä¸ªç”¨æˆ·")

    def _collect_images(self):
        """æ”¶é›†æ‰€æœ‰ç”¨æˆ·ç›®å½•ä¸‹çš„å›¾åƒ"""
        user_dirs = [d for d in self.data_dir.iterdir() if d.is_dir() and d.name.startswith('ID_')]
        user_dirs.sort()  # æŒ‰ç”¨æˆ·IDæ’åº

        print(f"ğŸ” å‘ç° {len(user_dirs)} ä¸ªç”¨æˆ·ç›®å½•")

        for user_dir in user_dirs:
            user_id = user_dir.name  # ID_1, ID_2, etc.
            user_images = []

            # æ”¶é›†è¯¥ç”¨æˆ·çš„æ‰€æœ‰å›¾åƒ
            for ext in self.image_extensions:
                user_images.extend(list(user_dir.glob(f'*{ext}')))
                user_images.extend(list(user_dir.glob(f'*{ext.upper()}')))

            # é™åˆ¶æ¯ä¸ªç”¨æˆ·çš„å›¾åƒæ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
            if self.max_images_per_user and len(user_images) > self.max_images_per_user:
                user_images = user_images[:self.max_images_per_user]

            # æ·»åŠ åˆ°æ€»åˆ—è¡¨
            self.image_files.extend(user_images)
            self.user_labels.extend([user_id] * len(user_images))

            print(f"   {user_id}: {len(user_images)} å¼ å›¾åƒ")
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        image_path = self.image_files[idx]
        user_id = self.user_labels[idx]

        try:
            # åŠ è½½å›¾åƒ
            image = Image.open(image_path)

            # ç¡®ä¿æ˜¯RGBæ ¼å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')

            # åº”ç”¨å˜æ¢
            if self.transform:
                image = self.transform(image)

            return image, str(image_path), user_id

        except Exception as e:
            print(f"âŒ åŠ è½½å›¾åƒå¤±è´¥ {image_path}: {e}")
            # è¿”å›ä¸€ä¸ªé»‘è‰²å›¾åƒä½œä¸ºfallback
            black_image = Image.new('RGB', (256, 256), (0, 0, 0))
            if self.transform:
                black_image = self.transform(black_image)
            return black_image, str(image_path), user_id

class VAEReconstructionTester:
    """VA-VAEé‡å»ºæµ‹è¯•å™¨"""
    
    def __init__(self, vae_model_path, device='cuda'):
        self.device = device
        self.vae_model_path = vae_model_path
        
        # åŠ è½½VA-VAEæ¨¡å‹
        print("ğŸ”§ åŠ è½½é¢„è®­ç»ƒVA-VAEæ¨¡å‹...")
        self.vae = self.load_vae_model()
        
        # å›¾åƒé¢„å¤„ç†ï¼ˆä¸ImageNetè®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        self.transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # [-1, 1]
        ])
        
        # åå½’ä¸€åŒ–ç”¨äºæ˜¾ç¤º
        self.denormalize = transforms.Compose([
            transforms.Normalize(mean=[-1, -1, -1], std=[2, 2, 2]),  # [0, 1]
        ])
    
    def load_vae_model(self):
        """åŠ è½½é¢„è®­ç»ƒçš„VA-VAEæ¨¡å‹"""
        try:
            # é¦–å…ˆæ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹è·¯å¾„
            config_path = "LightningDiT/tokenizer/configs/vavae_f16d32.yaml"

            # è¯»å–é…ç½®
            import yaml
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)

            # æ›´æ–°æ¨¡å‹è·¯å¾„
            config['ckpt_path'] = self.vae_model_path

            # ä¿å­˜ä¸´æ—¶é…ç½®
            temp_config_path = "temp_vavae_config.yaml"
            with open(temp_config_path, 'w') as f:
                yaml.dump(config, f)

            # ä½¿ç”¨æ­£ç¡®çš„åˆå§‹åŒ–æ–¹å¼
            vae = VA_VAE(config=temp_config_path)

            print(f"âœ… VA-VAEæ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in vae.model.parameters()) / 1e6:.1f}M")
            return vae

        except Exception as e:
            print(f"âŒ VA-VAEæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def test_single_image(self, image_tensor, image_path, user_id=None):
        """æµ‹è¯•å•å¼ å›¾åƒçš„é‡å»º"""
        with torch.no_grad():
            # ç¼–ç åˆ°æ½œåœ¨ç©ºé—´
            latent = self.vae.encode_images(image_tensor.unsqueeze(0))

            # ä»æ½œåœ¨ç©ºé—´è§£ç 
            reconstructed = self.vae.model.decode(latent)

            # è®¡ç®—é‡å»ºè¯¯å·®
            mse_loss = F.mse_loss(image_tensor.to(self.device), reconstructed.squeeze(0)).item()

            return {
                'original': image_tensor,
                'reconstructed': reconstructed.squeeze(0).cpu(),
                'latent': latent.cpu(),
                'mse_loss': mse_loss,
                'image_path': image_path,
                'user_id': user_id
            }
    
    def test_batch_reconstruction(self, data_dir, output_dir, batch_size=8, max_images=50):
        """æ‰¹é‡æµ‹è¯•é‡å»ºæ•ˆæœ"""
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡é‡å»ºæµ‹è¯•")
        print(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
        dataset = MicroDopplerDataset(data_dir, transform=self.transform, max_images_per_user=max_images//31 if max_images else None)

        if len(dataset) == 0:
            print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return None

        # é™åˆ¶æµ‹è¯•å›¾åƒæ•°é‡
        if len(dataset) > max_images:
            indices = np.random.choice(len(dataset), max_images, replace=False)
            dataset.image_files = [dataset.image_files[i] for i in indices]
            dataset.user_labels = [dataset.user_labels[i] for i in indices]

        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

        all_results = []
        total_mse = 0
        processed_count = 0
        user_stats = {}  # ç»Ÿè®¡æ¯ä¸ªç”¨æˆ·çš„ç»“æœ

        print(f"ğŸ” å¼€å§‹å¤„ç† {len(dataset)} å¼ å›¾åƒ...")

        for batch_idx, (images, image_paths, user_ids) in enumerate(dataloader):
            print(f"å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{len(dataloader)}")

            batch_results = []

            for i in range(images.size(0)):
                result = self.test_single_image(images[i], image_paths[i], user_ids[i])
                batch_results.append(result)
                total_mse += result['mse_loss']
                processed_count += 1

                # ç»Ÿè®¡ç”¨æˆ·ç»“æœ
                user_id = user_ids[i]
                if user_id not in user_stats:
                    user_stats[user_id] = []
                user_stats[user_id].append(result['mse_loss'])

            # ä¿å­˜æ‰¹æ¬¡å¯¹æ¯”å›¾
            self.save_batch_comparison(batch_results, output_path / f"batch_{batch_idx + 1:03d}.png")
            all_results.extend(batch_results)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        avg_mse = total_mse / processed_count
        mse_values = [r['mse_loss'] for r in all_results]

        print(f"\nğŸ“Š é‡å»ºæµ‹è¯•ç»“æœ:")
        print(f"   å¤„ç†å›¾åƒæ•°é‡: {processed_count}")
        print(f"   ç”¨æˆ·æ•°é‡: {len(user_stats)}")
        print(f"   å¹³å‡MSE: {avg_mse:.6f}")
        print(f"   MSEæ ‡å‡†å·®: {np.std(mse_values):.6f}")
        print(f"   MSEèŒƒå›´: {np.min(mse_values):.6f} - {np.max(mse_values):.6f}")

        # æ‰“å°æ¯ä¸ªç”¨æˆ·çš„ç»Ÿè®¡
        print(f"\nğŸ‘¥ å„ç”¨æˆ·é‡å»ºè´¨é‡:")
        for user_id in sorted(user_stats.keys()):
            user_mse = user_stats[user_id]
            print(f"   {user_id}: {len(user_mse)}å¼ å›¾åƒ, å¹³å‡MSE={np.mean(user_mse):.6f}")

        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        self.save_statistics(all_results, user_stats, output_path / "reconstruction_stats.txt")

        return all_results

    def save_batch_comparison(self, batch_results, save_path):
        """ä¿å­˜æ‰¹æ¬¡å¯¹æ¯”å›¾"""
        batch_size = len(batch_results)
        fig, axes = plt.subplots(2, batch_size, figsize=(3 * batch_size, 6))

        if batch_size == 1:
            axes = axes.reshape(2, 1)

        for i, result in enumerate(batch_results):
            # åŸå›¾
            original = self.denormalize(result['original'])
            original = torch.clamp(original, 0, 1)
            axes[0, i].imshow(original.permute(1, 2, 0))
            user_id = result.get('user_id', 'Unknown')
            axes[0, i].set_title(f'{user_id}\nOriginal')
            axes[0, i].axis('off')

            # é‡å»ºå›¾
            reconstructed = self.denormalize(result['reconstructed'])
            reconstructed = torch.clamp(reconstructed, 0, 1)
            axes[1, i].imshow(reconstructed.permute(1, 2, 0))
            axes[1, i].set_title(f'Reconstructed\nMSE: {result["mse_loss"]:.4f}')
            axes[1, i].axis('off')

        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()

    def save_statistics(self, results, user_stats, save_path):
        """ä¿å­˜ç»Ÿè®¡ç»“æœåˆ°æ–‡ä»¶"""
        mse_values = [r['mse_loss'] for r in results]

        with open(save_path, 'w') as f:
            f.write("VA-VAEé‡å»ºæµ‹è¯•ç»Ÿè®¡ç»“æœ\n")
            f.write("=" * 50 + "\n")
            f.write(f"æµ‹è¯•å›¾åƒæ•°é‡: {len(results)}\n")
            f.write(f"ç”¨æˆ·æ•°é‡: {len(user_stats)}\n")
            f.write(f"å¹³å‡MSE: {np.mean(mse_values):.6f}\n")
            f.write(f"MSEæ ‡å‡†å·®: {np.std(mse_values):.6f}\n")
            f.write(f"MSEæœ€å°å€¼: {np.min(mse_values):.6f}\n")
            f.write(f"MSEæœ€å¤§å€¼: {np.max(mse_values):.6f}\n")
            f.write(f"MSEä¸­ä½æ•°: {np.median(mse_values):.6f}\n")

            f.write("\nå„ç”¨æˆ·ç»Ÿè®¡:\n")
            f.write("-" * 30 + "\n")
            for user_id in sorted(user_stats.keys()):
                user_mse = user_stats[user_id]
                f.write(f"{user_id}: {len(user_mse)}å¼ å›¾åƒ, å¹³å‡MSE={np.mean(user_mse):.6f}, æ ‡å‡†å·®={np.std(user_mse):.6f}\n")

            f.write("\nè¯¦ç»†ç»“æœ:\n")
            f.write("-" * 30 + "\n")
            for i, result in enumerate(results):
                filename = Path(result['image_path']).name
                user_id = result.get('user_id', 'Unknown')
                f.write(f"{i+1:3d}. {user_id}/{filename}: MSE={result['mse_loss']:.6f}\n")

        print(f"ğŸ“Š ç»Ÿè®¡ç»“æœå·²ä¿å­˜: {save_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é˜¶æ®µ1: VA-VAEé‡å»ºæ•ˆæœæµ‹è¯•")
    print("="*60)

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    vae_model_path = "models/vavae-imagenet256-f16d32-dinov2.pt"
    if not Path(vae_model_path).exists():
        print(f"âŒ VA-VAEæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {vae_model_path}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ step2_download_models.py ä¸‹è½½æ¨¡å‹")
        return False

    # æ£€æŸ¥CUDA
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}")

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = VAEReconstructionTester(vae_model_path, device)
    if tester.vae is None:
        return False

    print("\nğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print("1. å°†æ‚¨çš„å¾®å¤šæ™®å‹’å›¾åƒæ”¾åœ¨ä¸€ä¸ªç›®å½•ä¸­ï¼ˆå¦‚ 'micro_doppler_data/'ï¼‰")
    print("2. è°ƒç”¨æµ‹è¯•å‡½æ•°:")
    print("   results = tester.test_batch_reconstruction('micro_doppler_data/', 'vae_test_output/')")
    print("\nğŸ’¡ ç¤ºä¾‹ç”¨æ³•:")
    print("   # åœ¨Pythonä¸­è¿è¡Œ:")
    print("   from vae_reconstruction_test import VAEReconstructionTester")
    print("   tester = VAEReconstructionTester('models/vavae-imagenet256-f16d32-dinov2.pt')")
    print("   results = tester.test_batch_reconstruction('your_data_dir/', 'output_dir/')")

    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
