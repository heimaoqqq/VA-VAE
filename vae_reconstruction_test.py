#!/usr/bin/env python3
"""
é˜¶æ®µ1: VA-VAEé‡å»ºæ•ˆæœæµ‹è¯•
æµ‹è¯•é¢„è®­ç»ƒVA-VAEåœ¨å¾®å¤šæ™®å‹’æ•°æ®ä¸Šçš„ç›´æ¥ä½¿ç”¨æ•ˆæœ
ä¸“æ³¨äºé‡å»ºè´¨é‡è¯„ä¼°ï¼Œä¸æ¶‰åŠç”¨æˆ·æ ‡ç­¾
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F

# æ·»åŠ LightningDiTè·¯å¾„
sys.path.append('LightningDiT')
from tokenizer.vavae import VA_VAE

class MicroDopplerDataset(Dataset):
    """å¾®å¤šæ™®å‹’æ•°æ®é›†åŠ è½½å™¨"""
    
    def __init__(self, data_dir, transform=None):
        self.data_dir = Path(data_dir)
        self.transform = transform
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        self.image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
        self.image_files = []
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
        for ext in self.image_extensions:
            self.image_files.extend(list(self.data_dir.glob(f'*{ext}')))
            self.image_files.extend(list(self.data_dir.glob(f'*{ext.upper()}')))
        
        print(f"ğŸ“ æ‰¾åˆ° {len(self.image_files)} å¼ å›¾åƒ")
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        image_path = self.image_files[idx]
        
        try:
            # åŠ è½½å›¾åƒ
            image = Image.open(image_path)
            
            # ç¡®ä¿æ˜¯RGBæ ¼å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # åº”ç”¨å˜æ¢
            if self.transform:
                image = self.transform(image)
            
            return image, str(image_path)
            
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾åƒå¤±è´¥ {image_path}: {e}")
            # è¿”å›ä¸€ä¸ªé»‘è‰²å›¾åƒä½œä¸ºfallback
            black_image = Image.new('RGB', (256, 256), (0, 0, 0))
            if self.transform:
                black_image = self.transform(black_image)
            return black_image, str(image_path)

class VAEReconstructionTester:
    """VA-VAEé‡å»ºæµ‹è¯•å™¨"""
    
    def __init__(self, vae_model_path, device='cuda'):
        self.device = device
        self.vae_model_path = vae_model_path
        
        # åŠ è½½VA-VAEæ¨¡å‹
        print("ğŸ”§ åŠ è½½é¢„è®­ç»ƒVA-VAEæ¨¡å‹...")
        self.vae = self.load_vae_model()
        
        # å›¾åƒé¢„å¤„ç†ï¼ˆä¸ImageNetè®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        self.transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # [-1, 1]
        ])
        
        # åå½’ä¸€åŒ–ç”¨äºæ˜¾ç¤º
        self.denormalize = transforms.Compose([
            transforms.Normalize(mean=[-1, -1, -1], std=[2, 2, 2]),  # [0, 1]
        ])
    
    def load_vae_model(self):
        """åŠ è½½é¢„è®­ç»ƒçš„VA-VAEæ¨¡å‹"""
        try:
            vae = VA_VAE(
                model_name='vavae_f16d32',
                ckpt_path=self.vae_model_path
            ).to(self.device)
            vae.eval()
            
            print(f"âœ… VA-VAEæ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in vae.parameters()) / 1e6:.1f}M")
            return vae
            
        except Exception as e:
            print(f"âŒ VA-VAEæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def test_single_image(self, image_tensor, image_path):
        """æµ‹è¯•å•å¼ å›¾åƒçš„é‡å»º"""
        with torch.no_grad():
            # ç¼–ç åˆ°æ½œåœ¨ç©ºé—´
            latent = self.vae.encode(image_tensor.unsqueeze(0).to(self.device))
            
            # ä»æ½œåœ¨ç©ºé—´è§£ç 
            reconstructed = self.vae.decode(latent)
            
            # è®¡ç®—é‡å»ºè¯¯å·®
            mse_loss = F.mse_loss(image_tensor.to(self.device), reconstructed.squeeze(0)).item()
            
            return {
                'original': image_tensor,
                'reconstructed': reconstructed.squeeze(0).cpu(),
                'latent': latent.cpu(),
                'mse_loss': mse_loss,
                'image_path': image_path
            }
    
    def test_batch_reconstruction(self, data_dir, output_dir, batch_size=8, max_images=50):
        """æ‰¹é‡æµ‹è¯•é‡å»ºæ•ˆæœ"""
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡é‡å»ºæµ‹è¯•")
        print(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
        dataset = MicroDopplerDataset(data_dir, transform=self.transform)
        
        if len(dataset) == 0:
            print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return None
        
        # é™åˆ¶æµ‹è¯•å›¾åƒæ•°é‡
        if len(dataset) > max_images:
            indices = np.random.choice(len(dataset), max_images, replace=False)
            dataset.image_files = [dataset.image_files[i] for i in indices]
        
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)
        
        all_results = []
        total_mse = 0
        processed_count = 0
        
        print(f"ğŸ” å¼€å§‹å¤„ç† {len(dataset)} å¼ å›¾åƒ...")
        
        for batch_idx, (images, image_paths) in enumerate(dataloader):
            print(f"å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{len(dataloader)}")
            
            batch_results = []
            
            for i in range(images.size(0)):
                result = self.test_single_image(images[i], image_paths[i])
                batch_results.append(result)
                total_mse += result['mse_loss']
                processed_count += 1
            
            # ä¿å­˜æ‰¹æ¬¡å¯¹æ¯”å›¾
            self.save_batch_comparison(batch_results, output_path / f"batch_{batch_idx + 1:03d}.png")
            all_results.extend(batch_results)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        avg_mse = total_mse / processed_count
        mse_values = [r['mse_loss'] for r in all_results]
        
        print(f"\nğŸ“Š é‡å»ºæµ‹è¯•ç»“æœ:")
        print(f"   å¤„ç†å›¾åƒæ•°é‡: {processed_count}")
        print(f"   å¹³å‡MSE: {avg_mse:.6f}")
        print(f"   MSEæ ‡å‡†å·®: {np.std(mse_values):.6f}")
        print(f"   MSEèŒƒå›´: {np.min(mse_values):.6f} - {np.max(mse_values):.6f}")
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        self.save_statistics(all_results, output_path / "reconstruction_stats.txt")
        
        return all_results

    def save_batch_comparison(self, batch_results, save_path):
        """ä¿å­˜æ‰¹æ¬¡å¯¹æ¯”å›¾"""
        batch_size = len(batch_results)
        fig, axes = plt.subplots(2, batch_size, figsize=(3 * batch_size, 6))

        if batch_size == 1:
            axes = axes.reshape(2, 1)

        for i, result in enumerate(batch_results):
            # åŸå›¾
            original = self.denormalize(result['original'])
            original = torch.clamp(original, 0, 1)
            axes[0, i].imshow(original.permute(1, 2, 0))
            axes[0, i].set_title(f'Original {i+1}')
            axes[0, i].axis('off')

            # é‡å»ºå›¾
            reconstructed = self.denormalize(result['reconstructed'])
            reconstructed = torch.clamp(reconstructed, 0, 1)
            axes[1, i].imshow(reconstructed.permute(1, 2, 0))
            axes[1, i].set_title(f'Recon {i+1}\nMSE: {result["mse_loss"]:.4f}')
            axes[1, i].axis('off')

        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()

    def save_statistics(self, results, save_path):
        """ä¿å­˜ç»Ÿè®¡ç»“æœåˆ°æ–‡ä»¶"""
        mse_values = [r['mse_loss'] for r in results]

        with open(save_path, 'w') as f:
            f.write("VA-VAEé‡å»ºæµ‹è¯•ç»Ÿè®¡ç»“æœ\n")
            f.write("=" * 40 + "\n")
            f.write(f"æµ‹è¯•å›¾åƒæ•°é‡: {len(results)}\n")
            f.write(f"å¹³å‡MSE: {np.mean(mse_values):.6f}\n")
            f.write(f"MSEæ ‡å‡†å·®: {np.std(mse_values):.6f}\n")
            f.write(f"MSEæœ€å°å€¼: {np.min(mse_values):.6f}\n")
            f.write(f"MSEæœ€å¤§å€¼: {np.max(mse_values):.6f}\n")
            f.write(f"MSEä¸­ä½æ•°: {np.median(mse_values):.6f}\n")
            f.write("\nè¯¦ç»†ç»“æœ:\n")

            for i, result in enumerate(results):
                filename = Path(result['image_path']).name
                f.write(f"{i+1:3d}. {filename}: MSE={result['mse_loss']:.6f}\n")

        print(f"ğŸ“Š ç»Ÿè®¡ç»“æœå·²ä¿å­˜: {save_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é˜¶æ®µ1: VA-VAEé‡å»ºæ•ˆæœæµ‹è¯•")
    print("="*60)

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    vae_model_path = "models/vavae-imagenet256-f16d32-dinov2.pt"
    if not Path(vae_model_path).exists():
        print(f"âŒ VA-VAEæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {vae_model_path}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ step2_download_models.py ä¸‹è½½æ¨¡å‹")
        return False

    # æ£€æŸ¥CUDA
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}")

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = VAEReconstructionTester(vae_model_path, device)
    if tester.vae is None:
        return False

    print("\nğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print("1. å°†æ‚¨çš„å¾®å¤šæ™®å‹’å›¾åƒæ”¾åœ¨ä¸€ä¸ªç›®å½•ä¸­ï¼ˆå¦‚ 'micro_doppler_data/'ï¼‰")
    print("2. è°ƒç”¨æµ‹è¯•å‡½æ•°:")
    print("   results = tester.test_batch_reconstruction('micro_doppler_data/', 'vae_test_output/')")
    print("\nğŸ’¡ ç¤ºä¾‹ç”¨æ³•:")
    print("   # åœ¨Pythonä¸­è¿è¡Œ:")
    print("   from vae_reconstruction_test import VAEReconstructionTester")
    print("   tester = VAEReconstructionTester('models/vavae-imagenet256-f16d32-dinov2.pt')")
    print("   results = tester.test_batch_reconstruction('your_data_dir/', 'output_dir/')")

    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
