#!/usr/bin/env python3
"""
éªŒè¯å®˜æ–¹æ–¹æ³•è®¾ç½®
ä¸¥æ ¼æŒ‰ç…§LightningDiTå®˜æ–¹READMEå’Œæ•™ç¨‹æ£€æŸ¥
"""

import os
import sys
import yaml
from pathlib import Path

def verify_official_setup():
    """éªŒè¯å®˜æ–¹æ–¹æ³•è®¾ç½®"""
    
    print("ğŸ” éªŒè¯LightningDiTå®˜æ–¹æ–¹æ³•è®¾ç½®")
    print("=" * 60)
    
    checks = [
        ("ğŸ“ æ£€æŸ¥æ¨¡å‹æ–‡ä»¶", check_model_files),
        ("âš™ï¸  æ£€æŸ¥é…ç½®æ–‡ä»¶", check_config_files),
        ("ğŸ“œ æ£€æŸ¥è„šæœ¬æ–‡ä»¶", check_script_files),
        ("ğŸ”§ æ£€æŸ¥VA-VAEé…ç½®", check_vavae_config),
        ("ğŸ“‹ å¯¹æ¯”å®˜æ–¹é…ç½®", compare_with_official),
        ("ğŸ¯ æ£€æŸ¥æ¨ç†æµç¨‹", check_inference_flow)
    ]
    
    passed = 0
    total = len(checks)
    
    for check_name, check_func in checks:
        print(f"\n{check_name}")
        print("-" * 40)
        
        try:
            if check_func():
                print(f"âœ… {check_name}: é€šè¿‡")
                passed += 1
            else:
                print(f"âŒ {check_name}: å¤±è´¥")
        except Exception as e:
            print(f"âŒ {check_name}: å¼‚å¸¸ - {e}")
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š éªŒè¯ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ å®Œå…¨ç¬¦åˆå®˜æ–¹æ–¹æ³•ï¼")
        print("ğŸš€ å¯ä»¥è¿è¡Œ: python run_official_inference.py")
    else:
        print("âš ï¸  éƒ¨åˆ†æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®æ­£åé‡è¯•")

def check_model_files():
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"""
    models_dir = Path("./official_models")
    
    if not models_dir.exists():
        print("âŒ official_modelsç›®å½•ä¸å­˜åœ¨")
        return False
    
    # å®˜æ–¹è¦æ±‚çš„æ–‡ä»¶
    required_files = {
        "vavae-imagenet256-f16d32-dinov2.pt": "VA-VAE tokenizer",
        "lightningdit-xl-imagenet256-800ep.pt": "LightningDiT-XL 800ep",
        "latents_stats.pt": "Latent statistics"
    }
    
    all_exist = True
    for file_name, description in required_files.items():
        file_path = models_dir / file_name
        if file_path.exists():
            size_mb = file_path.stat().st_size / (1024*1024)
            print(f"âœ… {description}: {size_mb:.1f} MB")
        else:
            print(f"âŒ {description}: æ–‡ä»¶ä¸å­˜åœ¨")
            all_exist = False
    
    return all_exist

def check_config_files():
    """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
    
    # æ£€æŸ¥æˆ‘ä»¬çš„é…ç½®æ–‡ä»¶
    config_path = "official_inference_config.yaml"
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # æ£€æŸ¥å…³é”®é…ç½®é¡¹
    required_keys = [
        'ckpt_path', 'data', 'vae', 'model', 'transport', 'sample'
    ]
    
    for key in required_keys:
        if key in config:
            print(f"âœ… é…ç½®é¡¹ {key}: å­˜åœ¨")
        else:
            print(f"âŒ é…ç½®é¡¹ {key}: ç¼ºå¤±")
            return False
    
    # æ£€æŸ¥å…³é”®å‚æ•°å€¼
    sample_config = config.get('sample', {})
    expected_values = {
        'num_sampling_steps': 250,
        'cfg_scale': 6.7,
        'sampling_method': 'euler',
        'mode': 'ODE'
    }
    
    for key, expected in expected_values.items():
        actual = sample_config.get(key)
        if actual == expected:
            print(f"âœ… {key}: {actual} (æ­£ç¡®)")
        else:
            print(f"âš ï¸  {key}: {actual} (æœŸæœ›: {expected})")
    
    return True

def check_script_files():
    """æ£€æŸ¥è„šæœ¬æ–‡ä»¶"""
    
    # æ£€æŸ¥LightningDiTå®˜æ–¹è„šæœ¬
    lightning_dir = Path("LightningDiT")
    if not lightning_dir.exists():
        print("âŒ LightningDiTç›®å½•ä¸å­˜åœ¨")
        return False
    
    required_scripts = [
        "run_fast_inference.sh",
        "inference.py"
    ]
    
    for script in required_scripts:
        script_path = lightning_dir / script
        if script_path.exists():
            print(f"âœ… å®˜æ–¹è„šæœ¬: {script}")
        else:
            print(f"âŒ å®˜æ–¹è„šæœ¬ç¼ºå¤±: {script}")
            return False
    
    # æ£€æŸ¥æˆ‘ä»¬çš„è„šæœ¬
    our_scripts = [
        "setup_official_models.py",
        "test_official_models.py"
    ]
    
    for script in our_scripts:
        if os.path.exists(script):
            print(f"âœ… æˆ‘ä»¬çš„è„šæœ¬: {script}")
        else:
            print(f"âŒ æˆ‘ä»¬çš„è„šæœ¬ç¼ºå¤±: {script}")
            return False
    
    return True

def check_vavae_config():
    """æ£€æŸ¥VA-VAEé…ç½®"""
    
    vavae_config_path = "LightningDiT/tokenizer/configs/vavae_f16d32.yaml"
    
    if not os.path.exists(vavae_config_path):
        print(f"âŒ VA-VAEé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {vavae_config_path}")
        return False
    
    with open(vavae_config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    ckpt_path = config.get('ckpt_path', '')
    
    # æ£€æŸ¥æ˜¯å¦æŒ‡å‘æˆ‘ä»¬çš„æ¨¡å‹æ–‡ä»¶
    expected_path = '../official_models/vavae-imagenet256-f16d32-dinov2.pt'
    
    if ckpt_path == expected_path:
        print(f"âœ… VA-VAEæ£€æŸ¥ç‚¹è·¯å¾„: {ckpt_path}")
        return True
    elif 'official_models' in ckpt_path:
        print(f"âš ï¸  VA-VAEæ£€æŸ¥ç‚¹è·¯å¾„: {ckpt_path} (å¯èƒ½æ­£ç¡®)")
        return True
    else:
        print(f"âŒ VA-VAEæ£€æŸ¥ç‚¹è·¯å¾„: {ckpt_path}")
        print(f"   æœŸæœ›: {expected_path}")
        return False

def compare_with_official():
    """å¯¹æ¯”å®˜æ–¹é…ç½®"""
    
    # æ£€æŸ¥å®˜æ–¹reproductionsé…ç½®
    official_config_path = "LightningDiT/configs/reproductions/lightningdit_xl_vavae_f16d32_800ep_cfg.yaml"
    
    if not os.path.exists(official_config_path):
        print(f"âŒ å®˜æ–¹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {official_config_path}")
        return False
    
    with open(official_config_path, 'r') as f:
        official_config = yaml.safe_load(f)
    
    our_config_path = "official_inference_config.yaml"
    with open(our_config_path, 'r') as f:
        our_config = yaml.safe_load(f)
    
    # å¯¹æ¯”å…³é”®é…ç½®
    key_comparisons = [
        ('model.model_type', 'LightningDiT-XL/1'),
        ('model.in_chans', 32),
        ('vae.model_name', 'vavae_f16d32'),
        ('vae.downsample_ratio', 16),
        ('sample.num_sampling_steps', 250),
        ('sample.cfg_scale', 6.7),
        ('sample.sampling_method', 'euler')
    ]
    
    all_match = True
    for key_path, expected in key_comparisons:
        keys = key_path.split('.')
        
        # è·å–æˆ‘ä»¬é…ç½®ä¸­çš„å€¼
        our_value = our_config
        for key in keys:
            our_value = our_value.get(key, None)
        
        if our_value == expected:
            print(f"âœ… {key_path}: {our_value}")
        else:
            print(f"âŒ {key_path}: {our_value} (æœŸæœ›: {expected})")
            all_match = False
    
    return all_match

def check_inference_flow():
    """æ£€æŸ¥æ¨ç†æµç¨‹"""
    
    print("ğŸ“‹ æ¨ç†æµç¨‹æ£€æŸ¥:")
    print("1. ä¸‹è½½æ¨¡å‹: python setup_official_models.py")
    print("2. æµ‹è¯•åŠ è½½: python test_official_models.py") 
    print("3. è¿è¡Œæ¨ç†: python run_official_inference.py")
    print("4. å®˜æ–¹å‘½ä»¤: bash run_fast_inference.sh config_path")
    print("5. è¾“å‡ºä½ç½®: LightningDiT/demo_images/demo_samples.png")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰run_official_inference.py
    if os.path.exists("run_official_inference.py"):
        print("âœ… æ¨ç†è„šæœ¬å·²ç”Ÿæˆ")
        return True
    else:
        print("âŒ æ¨ç†è„šæœ¬æœªç”Ÿæˆ")
        return False

if __name__ == "__main__":
    verify_official_setup()
