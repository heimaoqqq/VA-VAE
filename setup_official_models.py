#!/usr/bin/env python3
"""
ä¸¥æ ¼æŒ‰ç…§LightningDiTå®˜æ–¹READMEæ–¹æ³•
ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹å¹¶è¿è¡Œæ¨ç†
"""

import os
import requests
import yaml
import subprocess
from pathlib import Path

def download_file(url, local_path):
    """ä¸‹è½½æ–‡ä»¶"""
    try:
        response = requests.get(url, stream=True)
        response.raise_for_status()

        with open(local_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)

        print(f"âœ… ä¸‹è½½å®Œæˆ")
        return True

    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°ï¼šæŒ‰ç…§å®˜æ–¹READMEæ­¥éª¤æ‰§è¡Œ"""

    print("ğŸš€ æŒ‰ç…§LightningDiTå®˜æ–¹READMEæ–¹æ³•")
    print("=" * 50)

    # æ­¥éª¤1: ä¸‹è½½å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹
    print("\nğŸ“¥ æ­¥éª¤1: ä¸‹è½½å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹")
    models_dir = download_official_models()

    # æ­¥éª¤2: ä¿®æ”¹é…ç½®æ–‡ä»¶ (å®˜æ–¹è¦æ±‚)
    print("\nâš™ï¸ æ­¥éª¤2: ä¿®æ”¹é…ç½®æ–‡ä»¶")
    config_path = create_config(models_dir)
    update_vavae_config(models_dir)

    # æ­¥éª¤3: è¿è¡Œå®˜æ–¹æ¨ç†è„šæœ¬
    print("\nğŸš€ æ­¥éª¤3: è¿è¡Œå®˜æ–¹æ¨ç†")
    run_official_inference(config_path)

def download_official_models():
    """ä¸‹è½½å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹"""

    models_dir = Path("./official_models")
    models_dir.mkdir(exist_ok=True)

    # å®˜æ–¹READMEä¸­çš„ä¸‹è½½é“¾æ¥
    models = {
        "VA-VAE": "https://huggingface.co/hustvl/vavae-imagenet256-f16d32-dinov2/resolve/main/vavae-imagenet256-f16d32-dinov2.pt",
        "LightningDiT-XL-800ep": "https://huggingface.co/hustvl/lightningdit-xl-imagenet256-800ep/resolve/main/lightningdit-xl-imagenet256-800ep.pt",
        "Latent Statistics": "https://huggingface.co/hustvl/vavae-imagenet256-f16d32-dinov2/resolve/main/latents_stats.pt"
    }

    for name, url in models.items():
        filename = url.split('/')[-1]
        filepath = models_dir / filename

        if filepath.exists():
            print(f"âœ… {name}: å·²å­˜åœ¨")
        else:
            print(f"ğŸ“¥ ä¸‹è½½ {name}...")
            download_file(url, str(filepath))

    return models_dir

def create_config(models_dir):
    """åˆ›å»ºé…ç½®æ–‡ä»¶ - åŸºäºå®˜æ–¹reproductionsé…ç½®"""

    config_path = "inference_config.yaml"

    # åŸºäºå®˜æ–¹configs/reproductions/lightningdit_xl_vavae_f16d32_800ep_cfg.yaml
    config = {
        'ckpt_path': str(models_dir / "lightningdit-xl-imagenet256-800ep.pt"),
        'data': {
            'data_path': str(models_dir / "latents_stats.pt"),
            'fid_reference_file': 'path/to/your/VIRTUAL_imagenet256_labeled.npz',
            'image_size': 256,
            'num_classes': 1000,
            'num_workers': 8,
            'latent_norm': True,
            'latent_multiplier': 1.0
        },
        'vae': {
            'model_name': 'vavae_f16d32',
            'downsample_ratio': 16
        },
        'model': {
            'model_type': 'LightningDiT-XL/1',
            'use_qknorm': False,
            'use_swiglu': True,
            'use_rope': True,
            'use_rmsnorm': True,
            'wo_shift': False,
            'in_chans': 32
        },
        'train': {
            'output_dir': 'output',
            'exp_name': 'lightningdit_xl_vavae_f16d32'
        },
        'transport': {
            'path_type': 'Linear',
            'prediction': 'velocity',
            'use_cosine_loss': True,
            'use_lognorm': True
        },
        'sample': {
            'mode': 'ODE',
            'sampling_method': 'euler',
            'atol': 0.000001,
            'rtol': 0.001,
            'reverse': False,
            'likelihood': False,
            'num_sampling_steps': 250,
            'cfg_scale': 6.7,
            'per_proc_batch_size': 4,
            'cfg_interval_start': 0.125,
            'timestep_shift': 0.3
        }
    }

    with open(config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, indent=2)

    print(f"âœ… é…ç½®æ–‡ä»¶: {config_path}")
    return config_path

def update_vavae_config(models_dir):
    """æ›´æ–°VA-VAEé…ç½® (å®˜æ–¹æ•™ç¨‹è¦æ±‚)"""

    vavae_config_path = "LightningDiT/tokenizer/configs/vavae_f16d32.yaml"

    with open(vavae_config_path, 'r') as f:
        config = yaml.safe_load(f)

    # æ›´æ–°æ£€æŸ¥ç‚¹è·¯å¾„
    config['ckpt_path'] = str(models_dir / "vavae-imagenet256-f16d32-dinov2.pt")

    with open(vavae_config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, indent=2)

    print(f"âœ… VA-VAEé…ç½®å·²æ›´æ–°")

def run_official_inference(config_path):
    """è¿è¡Œå®˜æ–¹æ¨ç†è„šæœ¬"""

    print("ğŸš€ è¿è¡Œå®˜æ–¹æ¨ç†è„šæœ¬")

    # åˆ‡æ¢åˆ°LightningDiTç›®å½•
    os.chdir("LightningDiT")

    # è¿è¡Œå®˜æ–¹å‘½ä»¤: bash run_fast_inference.sh config_path
    cmd = f"bash run_fast_inference.sh ../{config_path}"

    print(f"ğŸ¯ æ‰§è¡Œ: {cmd}")

    try:
        result = subprocess.run(cmd, shell=True, check=True)
        print("âœ… æ¨ç†å®Œæˆ!")
        print("ğŸ“ è¾“å‡º: demo_images/demo_samples.png")

    except subprocess.CalledProcessError as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥ç¯å¢ƒå’Œä¾èµ–")

if __name__ == "__main__":
    main()
