#!/usr/bin/env python3
"""
VAEé‡å»ºéªŒè¯è„šæœ¬
æµ‹è¯•VA-VAEçš„ç¼–ç /è§£ç åŠŸèƒ½å’Œåˆ†å¸ƒå¯¹é½çš„æ•ˆæœ
è¿™æ¯”æœªè®­ç»ƒçš„æ‰©æ•£æ ·æœ¬æ›´æœ‰æ„ä¹‰
"""

import torch
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from PIL import Image
from simplified_vavae import SimplifiedVAVAE
from distribution_aligned_diffusion import DistributionAlignedDiffusion
import argparse


def create_sample_images(batch_size=8, image_size=256, channels=3):
    """åˆ›å»ºç¤ºä¾‹å›¾åƒç”¨äºæµ‹è¯•"""
    # åˆ›å»ºä¸€äº›æœ‰æ„ä¹‰çš„æµ‹è¯•å›¾åƒ
    images = []
    
    for i in range(batch_size):
        # åˆ›å»ºä¸åŒçš„å‡ ä½•å›¾æ¡ˆ
        img = np.zeros((channels, image_size, image_size), dtype=np.float32)
        
        if i % 4 == 0:
            # æ¸å˜å›¾æ¡ˆ
            for c in range(channels):
                img[c] = np.linspace(0, 1, image_size).reshape(1, -1)
        elif i % 4 == 1:
            # æ£‹ç›˜å›¾æ¡ˆ
            for y in range(0, image_size, 32):
                for x in range(0, image_size, 32):
                    if (y//32 + x//32) % 2 == 0:
                        img[:, y:y+32, x:x+32] = 0.8
        elif i % 4 == 2:
            # åœ†å½¢å›¾æ¡ˆ
            center = image_size // 2
            y, x = np.ogrid[:image_size, :image_size]
            mask = (x - center)**2 + (y - center)**2 < (image_size//4)**2
            img[:, mask] = 0.7
        else:
            # å™ªå£°å›¾æ¡ˆ
            img = np.random.rand(channels, image_size, image_size).astype(np.float32) * 0.5 + 0.25
        
        images.append(img)
    
    return torch.tensor(np.stack(images))


def save_comparison_grid(original, reconstructed, filepath, titles=None):
    """ä¿å­˜åŸå›¾ä¸é‡å»ºå›¾çš„å¯¹æ¯”ç½‘æ ¼"""
    batch_size = original.shape[0]
    
    # ç¡®ä¿å›¾åƒåœ¨[0,1]èŒƒå›´å†…
    original = torch.clamp(original, 0, 1)
    reconstructed = torch.clamp(reconstructed, 0, 1)
    
    # è½¬æ¢ä¸ºnumpy
    orig_np = original.cpu().numpy().transpose(0, 2, 3, 1)  # [B,C,H,W] -> [B,H,W,C]
    recon_np = reconstructed.cpu().numpy().transpose(0, 2, 3, 1)
    
    # åˆ›å»ºå¯¹æ¯”ç½‘æ ¼ (2è¡Œ: åŸå›¾ + é‡å»º)
    fig, axes = plt.subplots(2, batch_size, figsize=(batch_size*3, 6))
    
    if batch_size == 1:
        axes = axes.reshape(2, 1)
    
    for i in range(batch_size):
        # åŸå›¾
        ax_orig = axes[0, i] if batch_size > 1 else axes[0]
        if orig_np.shape[-1] == 3:  # RGB
            ax_orig.imshow(orig_np[i])
        else:  # ç°åº¦
            ax_orig.imshow(orig_np[i, :, :, 0], cmap='gray')
        ax_orig.axis('off')
        ax_orig.set_title(f'Original {i+1}' if titles is None else f'Orig: {titles[i]}')
        
        # é‡å»ºå›¾
        ax_recon = axes[1, i] if batch_size > 1 else axes[1]
        if recon_np.shape[-1] == 3:  # RGB
            ax_recon.imshow(recon_np[i])
        else:  # ç°åº¦
            ax_recon.imshow(recon_np[i, :, :, 0], cmap='gray')
        ax_recon.axis('off')
        ax_recon.set_title(f'Reconstructed {i+1}')
    
    plt.tight_layout()
    plt.savefig(filepath, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ… å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {filepath}")


def analyze_latent_distribution(latents, title="Latent Distribution"):
    """åˆ†ælatentåˆ†å¸ƒå¹¶å¯è§†åŒ–"""
    print(f"\nğŸ“Š {title}")
    print("-" * 50)
    
    # åŸºæœ¬ç»Ÿè®¡
    mean = latents.mean().item()
    std = latents.std().item()
    min_val = latents.min().item()
    max_val = latents.max().item()
    
    print(f"   å‡å€¼ (Mean): {mean:.4f}")
    print(f"   æ ‡å‡†å·® (Std): {std:.4f}")
    print(f"   æœ€å°å€¼ (Min): {min_val:.4f}")
    print(f"   æœ€å¤§å€¼ (Max): {max_val:.4f}")
    print(f"   å½¢çŠ¶ (Shape): {latents.shape}")
    
    # æ£€æŸ¥åˆ†å¸ƒç‰¹æ€§
    if abs(mean) < 0.1:
        print("   âœ… å‡å€¼æ¥è¿‘0")
    else:
        print(f"   âš ï¸ å‡å€¼åç¦»0: {mean:.4f}")
    
    if 0.8 < std < 2.0:
        print("   âœ… æ ‡å‡†å·®åœ¨åˆç†èŒƒå›´")
    else:
        print(f"   âš ï¸ æ ‡å‡†å·®å¼‚å¸¸: {std:.4f}")
    
    return {"mean": mean, "std": std, "min": min_val, "max": max_val}


def test_vae_reconstruction(vae_checkpoint, output_dir="./vae_validation", device=None):
    """æµ‹è¯•VAEé‡å»ºåŠŸèƒ½"""
    
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print(f"ğŸ¨ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    # åŠ è½½VAE
    print("ğŸ“¦ åŠ è½½VA-VAE...")
    vae = SimplifiedVAVAE(checkpoint_path=vae_checkpoint)
    vae = vae.to(device)
    vae.eval()
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    print("ğŸ¯ åˆ›å»ºæµ‹è¯•å›¾åƒ...")
    test_images = create_sample_images(batch_size=8, image_size=256, channels=3)
    test_images = test_images.to(device)
    
    print(f"   æµ‹è¯•å›¾åƒå½¢çŠ¶: {test_images.shape}")
    print(f"   å›¾åƒèŒƒå›´: [{test_images.min().item():.3f}, {test_images.max().item():.3f}]")
    
    # VAEç¼–ç è§£ç æµ‹è¯•
    print("\nğŸ”„ æ‰§è¡ŒVAEç¼–ç -è§£ç æµ‹è¯•...")
    
    with torch.no_grad():
        # ç¼–ç åˆ°latent
        latents = vae.encode(test_images)
        print(f"   ç¼–ç latentå½¢çŠ¶: {latents.shape}")
        
        # åˆ†ælatentåˆ†å¸ƒ
        latent_stats = analyze_latent_distribution(latents, "VAEç¼–ç çš„Latentåˆ†å¸ƒ")
        
        # è§£ç å›å›¾åƒ
        reconstructed = vae.decode(latents)
        print(f"   é‡å»ºå›¾åƒå½¢çŠ¶: {reconstructed.shape}")
        print(f"   é‡å»ºå›¾åƒèŒƒå›´: [{reconstructed.min().item():.3f}, {reconstructed.max().item():.3f}]")
        
        # è®¡ç®—é‡å»ºè¯¯å·®
        mse_error = torch.nn.functional.mse_loss(test_images, reconstructed).item()
        mae_error = torch.nn.functional.l1_loss(test_images, reconstructed).item()
        
        print(f"\nğŸ“ é‡å»ºè¯¯å·®:")
        print(f"   MSE: {mse_error:.6f}")
        print(f"   MAE: {mae_error:.6f}")
        
        if mse_error < 0.01:
            print("   âœ… é‡å»ºè´¨é‡ä¼˜ç§€")
        elif mse_error < 0.05:
            print("   âœ… é‡å»ºè´¨é‡è‰¯å¥½")
        else:
            print("   âš ï¸ é‡å»ºè¯¯å·®è¾ƒå¤§")
    
    # ä¿å­˜å¯¹æ¯”å›¾
    comparison_path = output_path / "vae_reconstruction_comparison.png"
    save_comparison_grid(test_images, reconstructed, comparison_path)
    
    return latent_stats, mse_error, mae_error


def test_distribution_alignment(vae_checkpoint, output_dir="./vae_validation", device=None):
    """æµ‹è¯•åˆ†å¸ƒå¯¹é½åŠŸèƒ½"""
    
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print("\n" + "="*60)
    print("ğŸ”§ æµ‹è¯•åˆ†å¸ƒå¯¹é½åŠŸèƒ½")
    print("="*60)
    
    # åŠ è½½VAE
    vae = SimplifiedVAVAE(checkpoint_path=vae_checkpoint)
    vae = vae.to(device)
    vae.eval()
    
    # åˆ›å»ºåˆ†å¸ƒå¯¹é½æ¨¡å‹ï¼ˆä»…ç”¨äºæµ‹è¯•å½’ä¸€åŒ–åŠŸèƒ½ï¼‰
    alignment_model = DistributionAlignedDiffusion(
        unet_config={
            'sample_size': (16, 16),
            'in_channels': 32,
            'out_channels': 32,
            'down_block_types': ['CrossAttnDownBlock2D'] * 3,
            'up_block_types': ['CrossAttnUpBlock2D'] * 3,
            'block_out_channels': [320, 640, 1280],
            'cross_attention_dim': 768,
            'layers_per_block': 2,
            'attention_head_dim': 8
        }
    ).to(device)
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒå¹¶ç¼–ç 
    test_images = create_sample_images(batch_size=16, image_size=256, channels=3)
    test_images = test_images.to(device)
    
    with torch.no_grad():
        # è·å–VAE latents
        original_latents = vae.encode(test_images)
        
        # æ›´æ–°åˆ†å¸ƒç»Ÿè®¡
        alignment_model._update_latent_stats(original_latents)
        
        print(f"ğŸ¯ æ£€æµ‹åˆ°çš„latentåˆ†å¸ƒ:")
        print(f"   å‡å€¼: {alignment_model.latent_mean.item():.4f}")
        print(f"   æ ‡å‡†å·®: {alignment_model.latent_std.item():.4f}")
        print(f"   åˆ†å¸ƒå¯¹é½çŠ¶æ€: {'å¯ç”¨' if alignment_model.enable_alignment else 'ç¦ç”¨'}")
        
        if alignment_model.enable_alignment:
            # æµ‹è¯•å½’ä¸€åŒ–
            normalized = alignment_model.normalize_latents(original_latents)
            norm_stats = analyze_latent_distribution(normalized, "å½’ä¸€åŒ–åçš„Latentåˆ†å¸ƒ")
            
            # æµ‹è¯•åå½’ä¸€åŒ–
            denormalized = alignment_model.denormalize_latents(normalized)
            
            # æ£€æŸ¥å¯é€†æ€§
            error = torch.nn.functional.mse_loss(original_latents, denormalized).item()
            print(f"\nğŸ”„ å½’ä¸€åŒ–å¯é€†æ€§æµ‹è¯•:")
            print(f"   åŸå§‹ -> å½’ä¸€åŒ– -> åå½’ä¸€åŒ– è¯¯å·®: {error:.8f}")
            
            if error < 1e-6:
                print("   âœ… å®Œç¾å¯é€†")
            elif error < 1e-4:
                print("   âœ… é«˜ç²¾åº¦å¯é€†")
            else:
                print("   âš ï¸ å¯é€†æ€§è¯¯å·®è¾ƒå¤§")
            
            # éªŒè¯å½’ä¸€åŒ–åçš„åˆ†å¸ƒ
            if abs(norm_stats["mean"]) < 0.1 and abs(norm_stats["std"] - 1.0) < 0.1:
                print("   âœ… å½’ä¸€åŒ–ååˆ†å¸ƒæ¥è¿‘N(0,1)")
            else:
                print("   âš ï¸ å½’ä¸€åŒ–ååˆ†å¸ƒåç¦»N(0,1)")
        
        else:
            print("   â„¹ï¸ latentåˆ†å¸ƒæ¥è¿‘æ ‡å‡†åˆ†å¸ƒï¼Œæ— éœ€å¯¹é½")
    
    return alignment_model.enable_alignment


def main():
    parser = argparse.ArgumentParser(description='VAEé‡å»ºå’Œåˆ†å¸ƒå¯¹é½éªŒè¯')
    parser.add_argument('--vae_checkpoint', type=str, 
                      default='/kaggle/input/stage3/vavae-stage3-epoch26-val_rec_loss0.0000.ckpt',
                      help='VA-VAEæ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./vae_validation',
                      help='è¾“å‡ºç›®å½•')
    parser.add_argument('--device', type=str, default=None,
                      help='è®¡ç®—è®¾å¤‡ (cuda/cpu)')
    
    args = parser.parse_args()
    
    print("ğŸ” VA-VAEé‡å»ºå’Œåˆ†å¸ƒå¯¹é½éªŒè¯")
    print("="*60)
    
    try:
        # æµ‹è¯•VAEé‡å»º
        latent_stats, mse_error, mae_error = test_vae_reconstruction(
            vae_checkpoint=args.vae_checkpoint,
            output_dir=args.output_dir,
            device=args.device
        )
        
        # æµ‹è¯•åˆ†å¸ƒå¯¹é½
        alignment_enabled = test_distribution_alignment(
            vae_checkpoint=args.vae_checkpoint,
            output_dir=args.output_dir,
            device=args.device
        )
        
        # æ€»ç»“
        print("\n" + "="*60)
        print("ğŸ“‹ éªŒè¯æ€»ç»“")
        print("="*60)
        print(f"âœ… VAEé‡å»ºåŠŸèƒ½: {'æ­£å¸¸' if mse_error < 0.05 else 'å¼‚å¸¸'}")
        print(f"âœ… Latentåˆ†å¸ƒ: std={latent_stats['std']:.3f}")
        print(f"âœ… åˆ†å¸ƒå¯¹é½: {'éœ€è¦å¯ç”¨' if alignment_enabled else 'æ— éœ€å¯ç”¨'}")
        print(f"âœ… é‡å»ºè¯¯å·®: MSE={mse_error:.6f}, MAE={mae_error:.6f}")
        
        if alignment_enabled:
            print(f"\nğŸ’¡ å»ºè®®: VAE latentåˆ†å¸ƒåç¦»æ ‡å‡†åˆ†å¸ƒï¼Œè®­ç»ƒæ—¶å°†è‡ªåŠ¨å¯ç”¨åˆ†å¸ƒå¯¹é½")
        else:
            print(f"\nğŸ’¡ å»ºè®®: VAE latentåˆ†å¸ƒæ¥è¿‘æ ‡å‡†åˆ†å¸ƒï¼Œå¯ç›´æ¥è®­ç»ƒ")
        
        print(f"\nğŸ“ éªŒè¯ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
