#!/usr/bin/env python3
"""
åˆ†æç”Ÿæˆæ ·æœ¬çš„å¤šæ ·æ€§ï¼šéªŒè¯æ˜¯å¦ä¸ºç®€å•é‡æ„vsçœŸæ­£çš„æ–°æ ·æœ¬
"""

import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from PIL import Image
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.metrics.pairwise import cosine_similarity
import argparse
from tqdm import tqdm

class DiversityAnalyzer:
    def __init__(self, feature_extractor_path, real_data_dir, generated_data_dir):
        """
        å¤šæ ·æ€§åˆ†æå™¨
        
        Args:
            feature_extractor_path: è®­ç»ƒå¥½çš„åˆ†ç±»å™¨è·¯å¾„
            real_data_dir: çœŸå®æ•°æ®ç›®å½•
            generated_data_dir: ç”Ÿæˆæ•°æ®ç›®å½•
        """
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åŠ è½½ç‰¹å¾æå–å™¨ï¼ˆä½¿ç”¨è®­ç»ƒå¥½çš„åˆ†ç±»å™¨ï¼‰
        self.feature_extractor = self.load_feature_extractor(feature_extractor_path)
        
        self.real_data_dir = Path(real_data_dir)
        self.generated_data_dir = Path(generated_data_dir)
        
    def load_feature_extractor(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„åˆ†ç±»å™¨ä½œä¸ºç‰¹å¾æå–å™¨"""
        from improved_classifier_training import ImprovedClassifier
        
        model = ImprovedClassifier(num_classes=31)
        checkpoint = torch.load(model_path, map_location=self.device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        model.eval()
        
        return model
    
    def extract_features(self, image_paths):
        """æå–å›¾åƒç‰¹å¾å‘é‡"""
        features = []
        
        with torch.no_grad():
            for img_path in tqdm(image_paths, desc="Extracting features"):
                # åŠ è½½å›¾åƒ
                img = Image.open(img_path).convert('RGB')
                img = img.resize((256, 256))
                
                # è½¬æ¢ä¸ºtensor
                img_tensor = torch.from_numpy(np.array(img)).float()
                img_tensor = img_tensor.permute(2, 0, 1) / 255.0
                img_tensor = img_tensor.unsqueeze(0).to(self.device)
                
                # æå–ç‰¹å¾
                feature = self.feature_extractor.extract_features(img_tensor)
                features.append(feature.cpu().numpy().flatten())
        
        return np.array(features)
    
    def compute_nearest_neighbor_distances(self, generated_features, real_features):
        """
        è®¡ç®—æ¯ä¸ªç”Ÿæˆæ ·æœ¬åˆ°æœ€è¿‘çœŸå®æ ·æœ¬çš„è·ç¦»
        è·ç¦»è¶Šå° = è¶Šåƒé‡æ„ï¼Œè·ç¦»è¶Šå¤§ = è¶Šæœ‰æ–°é¢–æ€§
        """
        distances = []
        
        for gen_feat in generated_features:
            # è®¡ç®—ä¸æ‰€æœ‰çœŸå®æ ·æœ¬çš„ä½™å¼¦ç›¸ä¼¼åº¦
            similarities = cosine_similarity([gen_feat], real_features)[0]
            # è½¬æ¢ä¸ºè·ç¦»ï¼ˆ1 - ç›¸ä¼¼åº¦ï¼‰
            min_distance = 1 - np.max(similarities)
            distances.append(min_distance)
            
        return np.array(distances)
    
    def analyze_intra_class_diversity(self, features, user_ids):
        """åˆ†ææ¯ä¸ªç”¨æˆ·å†…éƒ¨ç”Ÿæˆæ ·æœ¬çš„å¤šæ ·æ€§"""
        user_diversities = {}
        
        for user_id in np.unique(user_ids):
            user_mask = user_ids == user_id
            user_features = features[user_mask]
            
            if len(user_features) < 2:
                user_diversities[user_id] = 0.0
                continue
                
            # è®¡ç®—ç”¨æˆ·å†…éƒ¨æ ·æœ¬çš„å¹³å‡è·ç¦»
            similarities = cosine_similarity(user_features)
            # æ’é™¤å¯¹è§’çº¿ï¼ˆè‡ªå·±ä¸è‡ªå·±ï¼‰
            np.fill_diagonal(similarities, 0)
            
            # å¹³å‡è·ç¦» = 1 - å¹³å‡ç›¸ä¼¼åº¦
            avg_distance = 1 - np.mean(similarities[similarities > 0])
            user_diversities[user_id] = avg_distance
            
        return user_diversities
    
    def plot_diversity_analysis(self, real_features, gen_features, gen_user_ids, 
                               real_user_ids, output_dir):
        """å¯è§†åŒ–å¤šæ ·æ€§åˆ†æç»“æœ"""
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. t-SNEå¯è§†åŒ–ç‰¹å¾åˆ†å¸ƒ
        print("Computing t-SNE visualization...")
        all_features = np.vstack([real_features, gen_features])
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        embedded = tsne.fit_transform(all_features)
        
        real_embedded = embedded[:len(real_features)]
        gen_embedded = embedded[len(real_features):]
        
        plt.figure(figsize=(12, 8))
        
        # ç»˜åˆ¶çœŸå®æ•°æ®ç‚¹
        scatter_real = plt.scatter(real_embedded[:, 0], real_embedded[:, 1], 
                                  c=real_user_ids, cmap='tab20', alpha=0.6, 
                                  s=20, label='Real Data')
        
        # ç»˜åˆ¶ç”Ÿæˆæ•°æ®ç‚¹  
        scatter_gen = plt.scatter(gen_embedded[:, 0], gen_embedded[:, 1],
                                 c=gen_user_ids, cmap='tab20', alpha=0.8,
                                 s=40, marker='^', label='Generated Data')
        
        plt.colorbar(scatter_real, label='User ID')
        plt.legend()
        plt.title('Feature Distribution: Real vs Generated Data')
        plt.xlabel('t-SNE Dimension 1')
        plt.ylabel('t-SNE Dimension 2')
        plt.tight_layout()
        plt.savefig(output_dir / 'tsne_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. æœ€è¿‘é‚»è·ç¦»åˆ†å¸ƒ
        nn_distances = self.compute_nearest_neighbor_distances(gen_features, real_features)
        
        plt.figure(figsize=(10, 6))
        plt.hist(nn_distances, bins=50, alpha=0.7, edgecolor='black')
        plt.axvline(np.mean(nn_distances), color='red', linestyle='--', 
                   label=f'Mean Distance: {np.mean(nn_distances):.3f}')
        plt.axvline(np.median(nn_distances), color='green', linestyle='--',
                   label=f'Median Distance: {np.median(nn_distances):.3f}')
        plt.xlabel('Distance to Nearest Real Sample')
        plt.ylabel('Number of Generated Samples')
        plt.title('Generated Samples: Distance to Nearest Real Sample')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(output_dir / 'nearest_neighbor_distances.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. ç”¨æˆ·å†…å¤šæ ·æ€§åˆ†æ
        gen_diversities = self.analyze_intra_class_diversity(gen_features, gen_user_ids)
        real_diversities = self.analyze_intra_class_diversity(real_features, real_user_ids)
        
        user_ids = sorted(gen_diversities.keys())
        gen_div_values = [gen_diversities[uid] for uid in user_ids]
        real_div_values = [real_diversities.get(uid, 0) for uid in user_ids]
        
        plt.figure(figsize=(12, 6))
        x = np.arange(len(user_ids))
        width = 0.35
        
        plt.bar(x - width/2, real_div_values, width, label='Real Data', alpha=0.7)
        plt.bar(x + width/2, gen_div_values, width, label='Generated Data', alpha=0.7)
        
        plt.xlabel('User ID')
        plt.ylabel('Intra-class Diversity Score')
        plt.title('Intra-class Diversity: Real vs Generated Data')
        plt.xticks(x, user_ids)
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(output_dir / 'intra_class_diversity.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        return {
            'nearest_neighbor_distances': nn_distances,
            'generated_diversities': gen_diversities,
            'real_diversities': real_diversities,
            'tsne_embedding': embedded
        }
    
    def compute_diversity_metrics(self, real_data_dir, generated_data_dir, confidence_threshold=0.95):
        """è®¡ç®—å…¨é¢çš„å¤šæ ·æ€§æŒ‡æ ‡"""
        print(f"Analyzing diversity for pre-selected samples...")
        
        # æ”¶é›†å›¾åƒè·¯å¾„ - æ”¯æŒjpgå’Œpngæ ¼å¼
        real_paths = list(self.real_data_dir.glob("**/*.jpg")) + list(self.real_data_dir.glob("**/*.png"))
        
        # å¯¹äºå·²ç»ç­›é€‰å¥½çš„æ ·æœ¬ï¼Œç›´æ¥è·å–æ‰€æœ‰pngæ–‡ä»¶
        gen_paths = list(self.generated_data_dir.glob("**/*.png"))
        
        if len(gen_paths) == 0:
            print(f"No generated samples found in {generated_data_dir}")
            return None
            
        print(f"Found {len(real_paths)} real samples and {len(gen_paths)} pre-selected generated samples")
        
        # æå–ç‰¹å¾
        print("Extracting features from real data...")
        real_features = self.extract_features(real_paths)
        
        print("Extracting features from generated data...")  
        gen_features = self.extract_features(gen_paths)
        
        # æå–ç”¨æˆ·ID
        real_user_ids = np.array([self.extract_user_id_from_path(p) for p in real_paths])
        gen_user_ids = np.array([self.extract_user_id_from_path(p) for p in gen_paths])
        
        # åˆ†æç»“æœ
        results = self.plot_diversity_analysis(
            real_features, gen_features, gen_user_ids, real_user_ids,
            f"diversity_analysis_conf_{confidence_threshold}"
        )
        
        # è®¡ç®—æ€»ç»“æŒ‡æ ‡
        nn_distances = results['nearest_neighbor_distances']
        
        diversity_summary = {
            'confidence_threshold': confidence_threshold,
            'num_generated_samples': len(gen_paths),
            'mean_distance_to_real': np.mean(nn_distances),
            'median_distance_to_real': np.median(nn_distances),
            'std_distance_to_real': np.std(nn_distances),
            'reconstruction_ratio': np.sum(nn_distances < 0.1) / len(nn_distances),  # å¾ˆç›¸ä¼¼çš„æ¯”ä¾‹
            'novel_ratio': np.sum(nn_distances > 0.3) / len(nn_distances),  # æ–°é¢–æ ·æœ¬æ¯”ä¾‹
        }
        
        return diversity_summary
    
    def extract_user_id_from_path(self, path):
        """ä»æ–‡ä»¶è·¯å¾„æå–ç”¨æˆ·ID"""
        # å¯¹äºå·²ä¿å­˜çš„æ ·æœ¬ç»“æ„: /user_XX/sample_XXXXXX_confX.XXX.png
        path_parts = Path(path).parts
        
        # æŸ¥æ‰¾åŒ…å«user_çš„éƒ¨åˆ†
        for part in path_parts:
            if 'user_' in part:
                try:
                    return int(part.split('user_')[1])
                except:
                    continue
        
        # å¯¹äºåŸå§‹æ•°æ®æ ¼å¼: ID1_case1_1_Doppler1.jpg
        stem = Path(path).stem
        if stem.startswith('ID'):
            try:
                # æå–IDåé¢çš„æ•°å­—ï¼Œæ˜ å°„åˆ°0-30èŒƒå›´
                id_num = int(stem.split('_')[0][2:])  # ID1 -> 1, ID10 -> 10
                return id_num - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
            except:
                pass
        
        # å¦‚æœè·¯å¾„ä¸­æœ‰user_ï¼Œå°è¯•æå–
        if 'user_' in stem:
            try:
                return int(stem.split('user_')[1].split('_')[0])
            except:
                pass
        
        return 0
    
    def analyze_single_threshold(self, threshold=0.95):
        """åˆ†æå•ä¸ªç½®ä¿¡åº¦é˜ˆå€¼çš„å¤šæ ·æ€§"""
        print(f"Analyzing diversity for confidence threshold: {threshold}")
        
        result = self.compute_diversity_metrics(
            self.real_data_dir, self.generated_data_dir, threshold
        )
        
        return result
    
    def compare_multiple_thresholds(self, thresholds=[0.99, 0.95, 0.9, 0.8, 0.7]):
        """æ¯”è¾ƒä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„å¤šæ ·æ€§"""
        results = []
        
        for threshold in thresholds:
            result = self.compute_diversity_metrics(
                self.real_data_dir, self.generated_data_dir, threshold
            )
            if result:
                results.append(result)
        
        # ç»˜åˆ¶æ¯”è¾ƒå›¾
        if results:
            self.plot_threshold_comparison(results)
        
        return results
    
    def plot_threshold_comparison(self, results):
        """ç»˜åˆ¶ä¸åŒé˜ˆå€¼çš„æ¯”è¾ƒç»“æœ"""
        thresholds = [r['confidence_threshold'] for r in results]
        mean_distances = [r['mean_distance_to_real'] for r in results]
        novel_ratios = [r['novel_ratio'] for r in results]
        reconstruction_ratios = [r['reconstruction_ratio'] for r in results]
        
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # å¹³å‡è·ç¦»
        axes[0].plot(thresholds, mean_distances, 'o-', linewidth=2, markersize=8)
        axes[0].set_xlabel('Confidence Threshold')
        axes[0].set_ylabel('Mean Distance to Real Data')
        axes[0].set_title('Novelty vs Confidence Threshold')
        axes[0].grid(True, alpha=0.3)
        
        # æ–°é¢–æ ·æœ¬æ¯”ä¾‹
        axes[1].plot(thresholds, novel_ratios, 'o-', color='green', linewidth=2, markersize=8)
        axes[1].set_xlabel('Confidence Threshold')
        axes[1].set_ylabel('Novel Samples Ratio')
        axes[1].set_title('Novel Samples vs Confidence Threshold')
        axes[1].grid(True, alpha=0.3)
        
        # é‡æ„æ ·æœ¬æ¯”ä¾‹
        axes[2].plot(thresholds, reconstruction_ratios, 'o-', color='red', linewidth=2, markersize=8)
        axes[2].set_xlabel('Confidence Threshold')
        axes[2].set_ylabel('Reconstruction Samples Ratio')
        axes[2].set_title('Reconstruction vs Confidence Threshold')
        axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('threshold_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()

def main():
    parser = argparse.ArgumentParser(description='Analyze generation diversity')
    parser.add_argument('--model_path', required=True, 
                       help='Path to trained classifier (e.g., best_classifier_model.pth)')
    parser.add_argument('--real_data_dir', required=True, 
                       help='Real data directory (original dataset)')
    parser.add_argument('--generated_data_dir', required=True, 
                       help='Generated data directory (where high-confidence samples are saved)')
    parser.add_argument('--threshold', type=float, default=0.95,
                       help='Single confidence threshold to analyze (default: 0.95)')
    parser.add_argument('--compare_multiple', action='store_true',
                       help='Compare multiple thresholds instead of single')
    parser.add_argument('--thresholds', nargs='+', type=float, 
                       default=[0.99, 0.95, 0.9, 0.8, 0.7],
                       help='Multiple confidence thresholds to compare')
    
    args = parser.parse_args()
    
    analyzer = DiversityAnalyzer(args.model_path, args.real_data_dir, args.generated_data_dir)
    
    if args.compare_multiple:
        print("Starting multi-threshold diversity analysis...")
        results = analyzer.compare_multiple_thresholds(args.thresholds)
        
        # è¾“å‡ºæ€»ç»“
        print("\n" + "="*50)
        print("MULTI-THRESHOLD DIVERSITY SUMMARY")
        print("="*50)
        
        for result in results:
            conf = result['confidence_threshold']
            mean_dist = result['mean_distance_to_real']
            novel_ratio = result['novel_ratio']
            recon_ratio = result['reconstruction_ratio']
            
            print(f"\nConfidence {conf}:")
            print(f"  Samples: {result['num_generated_samples']}")
            print(f"  Mean distance to real: {mean_dist:.3f}")
            print(f"  Novel samples (>0.3 dist): {novel_ratio:.1%}")
            print(f"  Reconstruction samples (<0.1 dist): {recon_ratio:.1%}")
            
            # åˆ¤æ–­è´¨é‡
            if recon_ratio > 0.5:
                print("  âŒ HIGH RECONSTRUCTION - mostly memorizing training data")
            elif novel_ratio > 0.3:
                print("  âœ… GOOD DIVERSITY - generating novel samples")
            else:
                print("  ğŸŸ¡ MODERATE DIVERSITY - balanced but could be better")
    else:
        print(f"Starting single-threshold diversity analysis for confidence {args.threshold}...")
        result = analyzer.analyze_single_threshold(args.threshold)
        
        if result:
            print("\n" + "="*50)
            print(f"DIVERSITY ANALYSIS FOR CONFIDENCE {args.threshold}")
            print("="*50)
            
            mean_dist = result['mean_distance_to_real']
            novel_ratio = result['novel_ratio']
            recon_ratio = result['reconstruction_ratio']
            
            print(f"Total samples analyzed: {result['num_generated_samples']}")
            print(f"Mean distance to real data: {mean_dist:.3f}")
            print(f"Novel samples (distance >0.3): {novel_ratio:.1%}")
            print(f"Reconstruction samples (distance <0.1): {recon_ratio:.1%}")
            print(f"Standard deviation: {result['std_distance_to_real']:.3f}")
            
            # è¯¦ç»†åˆ¤æ–­
            print(f"\nğŸ“Š QUALITY ASSESSMENT:")
            if recon_ratio > 0.6:
                print("âŒ POOR DIVERSITY: Mostly reconstructing training data")
                print("   Recommendation: Lower confidence threshold or use balanced selection")
            elif recon_ratio > 0.3:
                print("ğŸŸ¡ MODERATE DIVERSITY: Some reconstruction, some novelty")
                print("   Recommendation: Consider balanced selection to improve novelty")
            else:
                print("âœ… GOOD DIVERSITY: Low reconstruction, good novelty")
                
            if novel_ratio > 0.4:
                print("âœ… EXCELLENT NOVELTY: Many truly new samples")
            elif novel_ratio > 0.2:
                print("ğŸŸ¡ MODERATE NOVELTY: Some new samples")
            else:
                print("âŒ LOW NOVELTY: Few truly new samples")
        else:
            print("âŒ No samples found for analysis. Check your paths and confidence threshold.")

if __name__ == "__main__":
    main()
