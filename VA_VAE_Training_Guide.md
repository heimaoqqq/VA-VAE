# VA-VAEè®­ç»ƒæŒ‡å—ï¼šå¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ‰©æ•£æ¨¡å‹

## ğŸ¯ ç›®æ ‡
åŸºäºLightningDiTçš„VA-VAEæ¶æ„ï¼Œè®­ç»ƒé€‚ç”¨äºå¾®å¤šæ™®å‹’æ—¶é¢‘å›¾çš„æ‰©æ•£æ¨¡å‹ã€‚

## ğŸ“š VA-VAEè®­ç»ƒè¯´æ˜æ€»ç»“

### ğŸ”§ ç¯å¢ƒå®‰è£…

1. **åŸºç¡€ç¯å¢ƒ**ï¼š
   ```bash
   # å®‰è£…LightningDiTç¯å¢ƒ
   python install_dependencies.py
   ```

2. **VA-VAEä¸“ç”¨ä¾èµ–**ï¼š
   ```bash
   pip install -r LightningDiT/vavae/vavae_requirements.txt
   ```

3. **Taming-Transformers**ï¼ˆå¿…éœ€ï¼‰ï¼š
   ```bash
   git clone https://github.com/CompVis/taming-transformers.git
   cd taming-transformers
   pip install -e .
   
   # ä¿®å¤torch 2.xå…¼å®¹æ€§
   export FILE_PATH=./taming-transformers/taming/data/utils.py
   sed -i 's/from torch._six import string_classes/from six import string_types as string_classes/' "$FILE_PATH"
   ```

### ğŸ—ï¸ æ¨¡å‹æ¶æ„é…ç½®

#### æ ¸å¿ƒå‚æ•°è¯´æ˜ï¼š

| å‚æ•° | å«ä¹‰ | å¾®å¤šæ™®å‹’é€‚é…å»ºè®® |
|------|------|------------------|
| `embed_dim` | æ½œåœ¨ç©ºé—´ç»´åº¦ | 32 (æ ‡å‡†) / 16 (è½»é‡) / 64 (é«˜è´¨é‡) |
| `z_channels` | æ½œåœ¨ç‰¹å¾é€šé“æ•° | ä¸embed_dimç›¸åŒ |
| `resolution` | è¾“å…¥å›¾åƒåˆ†è¾¨ç‡ | 256 (é€‚åˆæ—¶é¢‘å›¾) |
| `in_channels` | è¾“å…¥é€šé“æ•° | **1 (ç°åº¦æ—¶é¢‘å›¾) æˆ– 3 (ä¼ªå½©è‰²)** |
| `out_ch` | è¾“å‡ºé€šé“æ•° | **ä¸in_channelsç›¸åŒ** |

#### è§†è§‰ç‰¹å¾å¯¹é½é€‰é¡¹ï¼š

1. **DINOv2** (`use_vf: dinov2`)ï¼š
   - æ›´å¼ºçš„è¯­ä¹‰ç†è§£
   - é€‚åˆå¤æ‚æ¨¡å¼è¯†åˆ«
   - **æ¨èç”¨äºå¾®å¤šæ™®å‹’ç‰¹å¾æå–**

2. **MAE** (`use_vf: mae`)ï¼š
   - æ›´å¥½çš„é‡å»ºèƒ½åŠ›
   - é€‚åˆç»†èŠ‚ä¿æŒ
   - é€‚åˆæ—¶é¢‘å›¾çº¹ç†ä¿æŒ

3. **æ— ç‰¹å¾å¯¹é½** (æ ‡å‡†LDM)ï¼š
   - æœ€è½»é‡çº§
   - è®­ç»ƒæœ€å¿«
   - åŸºç¡€ç‰ˆæœ¬

## ğŸ”¬ HuggingFaceé¢„è®­ç»ƒæ¨¡å‹å˜ä½“åˆ†æ

### VA-VAEæ¨¡å‹ (1.5GB+)
| æ¨¡å‹ | é…ç½® | ç‰¹å¾ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| `vavae-imagenet256-f16d32-dinov2-50ep.ckpt` | f16d32 + DINOv2 | è¯­ä¹‰å¯¹é½ | **å¾®å¤šæ™®å‹’æ¨¡å¼è¯†åˆ«** |
| `vavae-imagenet256-f16d32-mae-50ep.ckpt` | f16d32 + MAE | é‡å»ºä¼˜åŒ– | æ—¶é¢‘å›¾ç»†èŠ‚ä¿æŒ |
| `vavae-imagenet256-f16d64-dinov2-50ep.ckpt` | f16d64 + DINOv2 | é«˜ç»´è¯­ä¹‰ | å¤æ‚å¾®å¤šæ™®å‹’åœºæ™¯ |
| `vavae-imagenet256-f16d64-mae-50ep.ckpt` | f16d64 + MAE | é«˜ç»´é‡å»º | é«˜è´¨é‡æ—¶é¢‘å›¾ç”Ÿæˆ |

### LDMæ¨¡å‹ (349MB)
| æ¨¡å‹ | é…ç½® | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| `ldm-imagenet256-f16d16-50ep.ckpt` | f16d16 | è½»é‡çº§ | å¿«é€ŸåŸå‹éªŒè¯ |
| `ldm-imagenet256-f16d32-50ep.ckpt` | f16d32 | æ ‡å‡†ç‰ˆ | åŸºç¡€æ—¶é¢‘å›¾ç”Ÿæˆ |
| `ldm-imagenet256-f16d64-50ep.ckpt` | f16d64 | é«˜è´¨é‡ | ç²¾ç»†æ—¶é¢‘å›¾ç”Ÿæˆ |

## ğŸ¯ å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾è®­ç»ƒå»ºè®®

### **é‡è¦æ¾„æ¸…**ï¼š
- **æˆ‘ä»¬ä½¿ç”¨çš„æ¨¡å‹**ï¼š`vavae-imagenet256-f16d32-dinov2.pt` (800è½®ï¼Œç”Ÿäº§çº§)
- **HuggingFaceå®éªŒç‰ˆ**ï¼š`vavae-imagenet256-f16d32-dinov2-50ep.ckpt` (50è½®ï¼Œå®éªŒçº§)

### **è®­ç»ƒç­–ç•¥ï¼šå…ˆå¾®è°ƒVA-VAEï¼Œå†è®­ç»ƒæ‰©æ•£æ¨¡å‹**

#### é˜¶æ®µ1ï¼šVA-VAEå¾®è°ƒï¼ˆå¿…éœ€ï¼‰
```yaml
# micro_doppler_vavae_config.yaml
ckpt_path: /path/to/vavae-imagenet256-f16d32-dinov2.pt  # ä½¿ç”¨800è½®ç‰ˆæœ¬
weight_init: /path/to/vavae-imagenet256-f16d32-dinov2.pt  # é¢„è®­ç»ƒæƒé‡

model:
  base_learning_rate: 1.0e-05  # è¾ƒå°å­¦ä¹ ç‡ï¼Œå¾®è°ƒ
  target: ldm.models.autoencoder.AutoencoderKL
  params:
    monitor: val/rec_loss
    embed_dim: 32
    use_vf: dinov2  # ä¿æŒDINOv2ç‰¹å¾å¯¹é½
    reverse_proj: true
    lossconfig:
      target: ldm.modules.losses.LPIPSWithDiscriminator
      params:
        disc_start: 1000  # å»¶è¿Ÿåˆ¤åˆ«å™¨å¯åŠ¨
        kl_weight: 1.0e-06
        disc_weight: 0.3  # é™ä½åˆ¤åˆ«å™¨æƒé‡
        vf_weight: 0.05   # é™ä½è§†è§‰ç‰¹å¾æƒé‡ï¼Œé¿å…è¿‡åº¦çº¦æŸ
        adaptive_vf: true
    ddconfig:
      double_z: true
      z_channels: 32
      resolution: 256
      in_channels: 3    # å½©è‰²æ—¶é¢‘å›¾
      out_ch: 3
      ch: 128
      ch_mult: [1, 1, 2, 2, 4]
      num_res_blocks: 2
      attn_resolutions: [16]
      dropout: 0.0

data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 2  # å°æ‰¹æ¬¡ï¼Œé€‚åˆå°æ•°æ®é›†
    wrap: false    # ä¸é‡å¤æ•°æ®
    train:
      target: your.custom.MicroDopplerDataset
      params:
        data_root: /path/to/micro_doppler_data
        size: 256
        user_conditioning: true  # å¯ç”¨ç”¨æˆ·æ¡ä»¶
    validation:
      target: your.custom.MicroDopplerDataset
      params:
        data_root: /path/to/micro_doppler_val_data
        size: 256
        user_conditioning: true

lightning:
  trainer:
    devices: 1
    num_nodes: 1
    strategy: auto
    accelerator: gpu
    max_epochs: 100  # å¾®è°ƒè½®æ•°
    precision: 16    # æ··åˆç²¾åº¦
    check_val_every_n_epoch: 5
    log_every_n_steps: 10
```

### 1. æ•°æ®å‡†å¤‡ï¼ˆæ— æ•°æ®å¢å¼ºï¼‰
```python
# åˆ›å»ºè‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨ (å‚è€ƒ ldm/data/imagenet.py)
class MicroDopplerDataset(Dataset):
    def __init__(self, data_root, size=256, user_conditioning=True):
        self.data_root = data_root
        self.size = size
        self.user_conditioning = user_conditioning

        # åŠ è½½31ä¸ªç”¨æˆ·çš„æ—¶é¢‘å›¾æ–‡ä»¶
        self.samples = []
        for user_id in range(31):
            user_path = os.path.join(data_root, f"user_{user_id:02d}")
            if os.path.exists(user_path):
                for img_file in os.listdir(user_path):
                    if img_file.endswith(('.png', '.jpg', '.jpeg')):
                        self.samples.append({
                            'path': os.path.join(user_path, img_file),
                            'user_id': user_id
                        })

        print(f"Loaded {len(self.samples)} micro-Doppler samples from {data_root}")

    def __getitem__(self, idx):
        sample = self.samples[idx]

        # åŠ è½½æ—¶é¢‘å›¾ (256x256x3)
        image = Image.open(sample['path']).convert('RGB')
        image = image.resize((self.size, self.size), Image.LANCZOS)

        # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–åˆ°[-1, 1]
        image = np.array(image).astype(np.float32) / 127.5 - 1.0
        image = torch.from_numpy(image).permute(2, 0, 1)

        result = {'image': image}

        if self.user_conditioning:
            result['user_id'] = sample['user_id']
            result['class_label'] = sample['user_id']  # ç”¨äºæ¡ä»¶ç”Ÿæˆ

        return result

    def __len__(self):
        return len(self.samples)
```

### 2. VA-VAEå¾®è°ƒè®­ç»ƒå‘½ä»¤
```bash
# è¿›å…¥vavaeç›®å½•
cd LightningDiT/vavae

# å¯åŠ¨VA-VAEå¾®è°ƒè®­ç»ƒ
bash run_train.sh configs/micro_doppler_vavae_config.yaml
```

### 3. ç›‘æ§è®­ç»ƒè¿‡ç¨‹
```python
# å…³é”®æŒ‡æ ‡ç›‘æ§
- val/rec_loss: é‡å»ºæŸå¤±ï¼ˆä¸»è¦æŒ‡æ ‡ï¼‰
- train/vf_loss: è§†è§‰ç‰¹å¾å¯¹é½æŸå¤±
- train/disc_loss: åˆ¤åˆ«å™¨æŸå¤±
- train/kl_loss: KLæ•£åº¦æŸå¤±

# é¢„æœŸè®­ç»ƒæ›²çº¿ï¼š
# - å‰10è½®ï¼šå¿«é€Ÿä¸‹é™ï¼ˆé€‚é…æ—¶é¢‘å›¾åŸŸï¼‰
# - 10-50è½®ï¼šç¼“æ…¢ä¼˜åŒ–ï¼ˆç»†èŠ‚è°ƒæ•´ï¼‰
# - 50è½®åï¼šæ”¶æ•›ï¼ˆç”¨æˆ·ç‰¹å¾å­¦ä¹ ï¼‰
```

#### é˜¶æ®µ2ï¼šæ‰©æ•£æ¨¡å‹è®­ç»ƒï¼ˆVA-VAEå¾®è°ƒå®Œæˆåï¼‰
```yaml
# lightningdit_micro_doppler_config.yaml
ckpt_path: /path/to/finetuned_vavae.ckpt  # ä½¿ç”¨å¾®è°ƒåçš„VA-VAE

model:
  model_type: LightningDiT-XL
  in_chans: 32  # VA-VAEæ½œåœ¨ç©ºé—´ç»´åº¦

vae:
  ckpt_path: /path/to/finetuned_vavae.ckpt  # å…³é”®ï¼šä½¿ç”¨å¾®è°ƒåçš„VA-VAE
  downsample_ratio: 16

data:
  data_path: /path/to/micro_doppler_latents  # é¢„æå–çš„æ½œåœ¨ç‰¹å¾
  image_size: 256
  num_classes: 31  # 31ä¸ªç”¨æˆ·

sample:
  num_sampling_steps: 50
  cfg_scale: 4.0  # åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼
```

### 4. å®Œæ•´è®­ç»ƒæµç¨‹

#### æ­¥éª¤1ï¼šVA-VAEå¾®è°ƒï¼ˆ2-3å¤©ï¼‰
```bash
# 1. å‡†å¤‡æ•°æ®é›†
mkdir -p /data/micro_doppler/{train,val}
# ç»„ç»‡ä¸º user_00, user_01, ..., user_30 ç›®å½•ç»“æ„

# 2. å¯åŠ¨VA-VAEå¾®è°ƒ
cd LightningDiT/vavae
bash run_train.sh configs/micro_doppler_vavae_config.yaml

# 3. éªŒè¯å¾®è°ƒæ•ˆæœ
python ../evaluate_tokenizer.py --config configs/micro_doppler_vavae_config.yaml
```

#### æ­¥éª¤2ï¼šæå–æ½œåœ¨ç‰¹å¾ï¼ˆ1å¤©ï¼‰
```bash
# ä½¿ç”¨å¾®è°ƒåçš„VA-VAEæå–æ‰€æœ‰è®­ç»ƒæ•°æ®çš„æ½œåœ¨ç‰¹å¾
cd LightningDiT
python extract_features.py --config configs/micro_doppler_vavae_config.yaml
```

#### æ­¥éª¤3ï¼šæ‰©æ•£æ¨¡å‹è®­ç»ƒï¼ˆ1-2å‘¨ï¼‰
```bash
# è®­ç»ƒLightningDiTæ‰©æ•£æ¨¡å‹
bash run_train.sh configs/lightningdit_micro_doppler_config.yaml
```

## ğŸ” å…³é”®æŠ€æœ¯ç‚¹

### 1. é€šé“æ•°é€‚é…
- **ç°åº¦æ—¶é¢‘å›¾**ï¼šä¿®æ”¹ `in_channels: 1, out_ch: 1`
- **ä¼ªå½©è‰²æ—¶é¢‘å›¾**ï¼šä¿æŒ `in_channels: 3, out_ch: 3`

### 2. è§†è§‰ç‰¹å¾é€‰æ‹©
- **DINOv2**ï¼šæ›´é€‚åˆå¾®å¤šæ™®å‹’çš„æ¨¡å¼è¯†åˆ«
- **MAE**ï¼šæ›´é€‚åˆæ—¶é¢‘å›¾çš„çº¹ç†é‡å»º

### 3. æŸå¤±å‡½æ•°è°ƒæ•´
- `vf_weight: 0.1`ï¼šè§†è§‰ç‰¹å¾å¯¹é½æƒé‡
- `kl_weight: 1e-6`ï¼šKLæ•£åº¦æƒé‡
- `disc_weight: 0.5`ï¼šåˆ¤åˆ«å™¨æƒé‡

### 4. è®­ç»ƒèµ„æº
- **å®˜æ–¹é…ç½®**ï¼š4x8 H800 GPUs
- **æœ€å°é…ç½®**ï¼š1x8 V100/A100 GPUs
- **batch_size**ï¼šæ ¹æ®GPUå†…å­˜è°ƒæ•´

## ğŸ“‹ å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾è®­ç»ƒè¡ŒåŠ¨è®¡åˆ’

### **é˜¶æ®µ1ï¼šVA-VAEå¾®è°ƒï¼ˆå¿…éœ€ï¼Œ2-3å¤©ï¼‰**
1. **å‡†å¤‡æ•°æ®é›†**ï¼š
   ```
   /data/micro_doppler/
   â”œâ”€â”€ train/
   â”‚   â”œâ”€â”€ user_00/ (ç”¨æˆ·0çš„æ—¶é¢‘å›¾)
   â”‚   â”œâ”€â”€ user_01/
   â”‚   â””â”€â”€ ... user_30/
   â””â”€â”€ val/
       â”œâ”€â”€ user_00/
       â””â”€â”€ ...
   ```

2. **é…ç½®VA-VAEå¾®è°ƒ**ï¼š
   - ä½¿ç”¨ `vavae-imagenet256-f16d32-dinov2.pt` (800è½®ç‰ˆæœ¬)
   - å­¦ä¹ ç‡ï¼š1e-5 (å¾®è°ƒ)
   - æ‰¹æ¬¡å¤§å°ï¼š2 (å°æ•°æ®é›†)
   - è®­ç»ƒè½®æ•°ï¼š100è½®

3. **å¯åŠ¨è®­ç»ƒ**ï¼š
   ```bash
   cd LightningDiT/vavae
   bash run_train.sh configs/micro_doppler_vavae_config.yaml
   ```

### **é˜¶æ®µ2ï¼šæ‰©æ•£æ¨¡å‹è®­ç»ƒï¼ˆ1-2å‘¨ï¼‰**
1. **æå–æ½œåœ¨ç‰¹å¾**
2. **è®­ç»ƒLightningDiT**
3. **æ¡ä»¶ç”Ÿæˆæµ‹è¯•**

### **å…³é”®è¦ç‚¹**
- âœ… **ä¸ä½¿ç”¨æ•°æ®å¢å¼º** (ä¼šç ´åæ—¶é¢‘å›¾ç‰¹å¾)
- âœ… **å…ˆå¾®è°ƒVA-VAE** (é¢†åŸŸé€‚é…)
- âœ… **ä½¿ç”¨800è½®é¢„è®­ç»ƒæ¨¡å‹** (ä¸æ˜¯50è½®å®éªŒç‰ˆ)
- âœ… **ä¿æŒå½©è‰²3é€šé“** (256Ã—256Ã—3)
- âœ… **ç”¨æˆ·æ¡ä»¶ç”Ÿæˆ** (31ä¸ªç”¨æˆ·ID)

è¿™æ ·å°±å¯ä»¥è®­ç»ƒå‡ºä¸“é—¨çš„å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•°æ®å¢å¹¿æ¨¡å‹äº†ï¼
