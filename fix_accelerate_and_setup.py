#!/usr/bin/env python3
"""
ä¿®å¤Accelerateé…ç½®å¹¶è®¾ç½®åŒGPUåˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ
è§£å†³torchvision::nmsé”™è¯¯å’Œaccelerate configå¤±è´¥é—®é¢˜
"""

import os
import sys
import subprocess
import shutil
from pathlib import Path
import torch

def print_step(step, description):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    print(f"\n{'='*60}")
    print(f"ğŸ”„ æ­¥éª¤{step}: {description}")
    print('='*60)

def run_command(cmd, description="", ignore_error=False):
    """è¿è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯"""
    print(f"\nğŸ”§ {description}")
    print(f"æ‰§è¡Œå‘½ä»¤: {cmd}")
    
    try:
        result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)
        print("âœ… æ‰§è¡ŒæˆåŠŸ")
        if result.stdout.strip():
            print(f"è¾“å‡º: {result.stdout.strip()}")
        return True, result.stdout
    except subprocess.CalledProcessError as e:
        if ignore_error:
            print(f"âš ï¸  å‘½ä»¤å¤±è´¥ä½†å¿½ç•¥: {e}")
            return False, e.stderr
        else:
            print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
            if e.stderr:
                print(f"é”™è¯¯: {e.stderr}")
            return False, e.stderr

def check_gpu_environment():
    """æ£€æŸ¥GPUç¯å¢ƒ"""
    print_step(1, "æ£€æŸ¥GPUç¯å¢ƒ")
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨")
        return False
    
    gpu_count = torch.cuda.device_count()
    print(f"âœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    for i in range(gpu_count):
        gpu_name = torch.cuda.get_device_name(i)
        print(f"  GPU {i}: {gpu_name}")
    
    return gpu_count >= 2

def fix_torch_dependencies():
    """ä¿®å¤PyTorchç›¸å…³ä¾èµ–"""
    print_step(2, "ä¿®å¤PyTorchå’Œtorchvisionä¾èµ–")
    
    # å¸è½½å¯èƒ½æœ‰é—®é¢˜çš„åŒ…
    packages_to_remove = ["torchvision", "accelerate"]
    for package in packages_to_remove:
        run_command(f"pip uninstall {package} -y", f"å¸è½½ {package}", ignore_error=True)
    
    # é‡æ–°å®‰è£…å…¼å®¹ç‰ˆæœ¬
    print("\nğŸ“¦ é‡æ–°å®‰è£…å…¼å®¹ç‰ˆæœ¬...")
    
    # å®‰è£…torchvision
    success, _ = run_command(
        "pip install torchvision==0.16.0+cu121 --index-url https://download.pytorch.org/whl/cu121",
        "å®‰è£…å…¼å®¹çš„torchvision"
    )
    
    if not success:
        print("âš ï¸  å°è¯•å®‰è£…é»˜è®¤ç‰ˆæœ¬çš„torchvision")
        run_command("pip install torchvision", "å®‰è£…é»˜è®¤torchvision")
    
    # å®‰è£…accelerate
    run_command("pip install accelerate==0.25.0", "å®‰è£…Accelerate")
    
    # æ¸…ç†ç¼“å­˜
    run_command("pip cache purge", "æ¸…ç†pipç¼“å­˜", ignore_error=True)
    
    return True

def create_accelerate_config():
    """æ‰‹åŠ¨åˆ›å»ºAccelerateé…ç½®æ–‡ä»¶"""
    print_step(3, "åˆ›å»ºAccelerateé…ç½®")
    
    # åˆ›å»ºé…ç½®ç›®å½•
    config_dir = Path.home() / ".cache" / "huggingface" / "accelerate"
    config_dir.mkdir(parents=True, exist_ok=True)
    
    # åŒGPUé…ç½®
    config_content = """compute_environment: LOCAL_MACHINE
distributed_type: MULTI_GPU
downcast_bf16: 'no'
gpu_ids: all
machine_rank: 0
main_training_function: main
mixed_precision: fp16
num_machines: 1
num_processes: 2
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
"""
    
    config_file = config_dir / "default_config.yaml"
    with open(config_file, 'w') as f:
        f.write(config_content)
    
    print(f"âœ… Accelerateé…ç½®å·²åˆ›å»º: {config_file}")
    return config_file

def test_accelerate():
    """æµ‹è¯•Accelerateé…ç½®"""
    print_step(4, "æµ‹è¯•Accelerateé…ç½®")
    
    try:
        from accelerate import Accelerator
        accelerator = Accelerator()
        
        print("âœ… Accelerateå·¥ä½œæ­£å¸¸")
        print(f"  è¿›ç¨‹æ•°: {accelerator.num_processes}")
        print(f"  è®¾å¤‡: {accelerator.device}")
        print(f"  åˆ†å¸ƒå¼ç±»å‹: {accelerator.distributed_type}")
        print(f"  æ··åˆç²¾åº¦: {accelerator.mixed_precision}")
        
        return True
    except Exception as e:
        print(f"âŒ Accelerateæµ‹è¯•å¤±è´¥: {e}")
        return False

def install_additional_dependencies():
    """å®‰è£…é¢å¤–çš„å¿…éœ€ä¾èµ–"""
    print_step(5, "å®‰è£…LightningDiTä¾èµ–")
    
    # å¿…éœ€çš„ä¾èµ–åŒ…
    required_packages = [
        "safetensors>=0.3.0",
        "fairscale>=0.4.13",
        "einops>=0.6.0",
        "timm>=0.9.0",
        "torchdiffeq>=0.2.3",
        "omegaconf>=2.3.0",
        "diffusers>=0.20.0",
        "pytorch-fid>=0.3.0",
        "scipy>=1.9.0"
    ]
    
    success_count = 0
    for package in required_packages:
        success, _ = run_command(f"pip install {package}", f"å®‰è£… {package}")
        if success:
            success_count += 1
    
    print(f"âœ… æˆåŠŸå®‰è£… {success_count}/{len(required_packages)} ä¸ªä¾èµ–åŒ…")
    return success_count == len(required_packages)

def download_pretrained_model():
    """ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹"""
    print_step(6, "ä¸‹è½½é¢„è®­ç»ƒVA-VAEæ¨¡å‹")
    
    pretrained_dir = Path("/kaggle/working/pretrained")
    pretrained_dir.mkdir(parents=True, exist_ok=True)
    
    model_url = "https://huggingface.co/hustvl/vavae-imagenet256-f16d32-dinov2/resolve/main/vavae-imagenet256-f16d32-dinov2.pt"
    model_path = pretrained_dir / "vavae-imagenet256-f16d32-dinov2.pt"
    
    if model_path.exists():
        print(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {model_path}")
        return True
    
    success, _ = run_command(f"wget -O {model_path} {model_url}", "ä¸‹è½½VA-VAEæ¨¡å‹")
    
    if success and model_path.exists():
        print(f"âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ: {model_path}")
        return True
    else:
        print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
        return False

def create_training_script():
    """åˆ›å»ºè®­ç»ƒå¯åŠ¨è„šæœ¬"""
    print_step(7, "åˆ›å»ºè®­ç»ƒå¯åŠ¨è„šæœ¬")
    
    script_content = '''#!/bin/bash
# åŒGPUåˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨è„šæœ¬

echo "ğŸ¯ å¯åŠ¨åŒGPUåˆ†å¸ƒå¼è®­ç»ƒ"
echo "=========================="

# æ£€æŸ¥GPU
echo "ğŸ” æ£€æŸ¥GPUçŠ¶æ€:"
nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total --format=csv

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0,1
export NCCL_DEBUG=INFO

# è¿è¡Œè®­ç»ƒ
echo "ğŸš€ å¼€å§‹è®­ç»ƒ..."
accelerate launch --config_file ~/.cache/huggingface/accelerate/default_config.yaml \\
    run_complete_pipeline.py \\
    --data_dir /kaggle/working/data_split \\
    --output_dir /kaggle/working/outputs \\
    --vavae_config vavae_config.yaml \\
    --batch_size 16 \\
    --max_epochs 50 \\
    --lr 1e-4 \\
    --seed 42 \\
    --user_ids 1 2 3 4 5 \\
    --num_samples_per_user 4

echo "âœ… è®­ç»ƒå®Œæˆ!"
'''
    
    script_path = Path("start_dual_gpu_training.sh")
    with open(script_path, 'w') as f:
        f.write(script_content)
    
    # æ·»åŠ æ‰§è¡Œæƒé™
    os.chmod(script_path, 0o755)
    
    print(f"âœ… è®­ç»ƒè„šæœ¬å·²åˆ›å»º: {script_path}")
    return script_path

def create_single_gpu_fallback():
    """åˆ›å»ºå•GPUå¤‡ç”¨è„šæœ¬"""
    print_step(8, "åˆ›å»ºå•GPUå¤‡ç”¨è„šæœ¬")
    
    script_content = '''#!/bin/bash
# å•GPUè®­ç»ƒå¤‡ç”¨è„šæœ¬ (å¦‚æœåŒGPUæœ‰é—®é¢˜)

echo "ğŸ¯ å¯åŠ¨å•GPUè®­ç»ƒ (å¤‡ç”¨æ–¹æ¡ˆ)"
echo "============================="

# æ£€æŸ¥GPU
echo "ğŸ” æ£€æŸ¥GPUçŠ¶æ€:"
nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total --format=csv

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0

# è¿è¡Œè®­ç»ƒ
echo "ğŸš€ å¼€å§‹å•GPUè®­ç»ƒ..."
python run_complete_pipeline.py \\
    --data_dir /kaggle/working/data_split \\
    --output_dir /kaggle/working/outputs_single_gpu \\
    --vavae_config vavae_config.yaml \\
    --batch_size 32 \\
    --max_epochs 50 \\
    --lr 1e-4 \\
    --seed 42 \\
    --user_ids 1 2 3 4 5 \\
    --num_samples_per_user 4

echo "âœ… å•GPUè®­ç»ƒå®Œæˆ!"
'''
    
    script_path = Path("start_single_gpu_training.sh")
    with open(script_path, 'w') as f:
        f.write(script_content)
    
    # æ·»åŠ æ‰§è¡Œæƒé™
    os.chmod(script_path, 0o755)
    
    print(f"âœ… å•GPUå¤‡ç”¨è„šæœ¬å·²åˆ›å»º: {script_path}")
    return script_path

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ä¿®å¤Accelerateé…ç½®å¹¶è®¾ç½®åŒGPUåˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ")
    print("=" * 70)
    print("è§£å†³torchvision::nmsé”™è¯¯å’Œaccelerate configå¤±è´¥é—®é¢˜")
    print("=" * 70)
    
    # æ£€æŸ¥GPUç¯å¢ƒ
    if not check_gpu_environment():
        print("âŒ GPUç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return False
    
    # ä¿®å¤ä¾èµ–
    if not fix_torch_dependencies():
        print("âŒ ä¾èµ–ä¿®å¤å¤±è´¥")
        return False
    
    # åˆ›å»ºé…ç½®
    config_file = create_accelerate_config()
    
    # æµ‹è¯•é…ç½®
    if not test_accelerate():
        print("âŒ Accelerateé…ç½®æµ‹è¯•å¤±è´¥")
        return False
    
    # å®‰è£…é¢å¤–ä¾èµ–
    install_additional_dependencies()
    
    # ä¸‹è½½æ¨¡å‹
    download_pretrained_model()
    
    # åˆ›å»ºè®­ç»ƒè„šæœ¬
    dual_gpu_script = create_training_script()
    single_gpu_script = create_single_gpu_fallback()
    
    # å®Œæˆæ€»ç»“
    print("\n" + "="*70)
    print("ğŸ‰ ç¯å¢ƒè®¾ç½®å®Œæˆ!")
    print("="*70)
    print(f"ğŸ“ Accelerateé…ç½®: {config_file}")
    print(f"ğŸš€ åŒGPUè®­ç»ƒè„šæœ¬: {dual_gpu_script}")
    print(f"ğŸ”„ å•GPUå¤‡ç”¨è„šæœ¬: {single_gpu_script}")
    
    print("\nğŸ¯ ä½¿ç”¨æ–¹æ³•:")
    print("1. åŒGPUè®­ç»ƒ (æ¨è):")
    print("   ./start_dual_gpu_training.sh")
    print("\n2. å•GPUè®­ç»ƒ (å¤‡ç”¨):")
    print("   ./start_single_gpu_training.sh")
    print("\n3. æ‰‹åŠ¨è¿è¡Œ:")
    print("   accelerate launch --config_file ~/.cache/huggingface/accelerate/default_config.yaml run_complete_pipeline.py ...")
    
    print("\nğŸ“Š ç›‘æ§GPUä½¿ç”¨:")
    print("   watch -n 1 nvidia-smi")
    
    return True

if __name__ == "__main__":
    success = main()
    if success:
        print("\nâœ… æ‰€æœ‰è®¾ç½®å®Œæˆï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒäº†!")
    else:
        print("\nâŒ è®¾ç½®è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
        sys.exit(1)
