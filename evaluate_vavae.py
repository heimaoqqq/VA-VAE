#!/usr/bin/env python3
"""
VA-VAEå¾®è°ƒæ•ˆæœè¯„ä¼°è„šæœ¬
è®¡ç®—FIDåˆ†æ•°æ¥è¯„ä¼°å¾®è°ƒåçš„æ¨¡å‹æ€§èƒ½
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
from PIL import Image
import argparse

def load_vavae_model(checkpoint_path):
    """åŠ è½½VA-VAEæ¨¡å‹"""
    print(f"ğŸ”§ åŠ è½½æ¨¡å‹: {checkpoint_path}")
    
    try:
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ¨¡å‹åŠ è½½æ–¹å¼è°ƒæ•´
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        return checkpoint
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

def encode_images(model, image_dir, batch_size=8):
    """ç¼–ç å›¾åƒåˆ°æ½œåœ¨ç©ºé—´"""
    print(f"ğŸ” ç¼–ç å›¾åƒç›®å½•: {image_dir}")
    
    image_paths = list(Path(image_dir).glob("*.png")) + list(Path(image_dir).glob("*.jpg"))
    print(f"ğŸ“Š æ‰¾åˆ° {len(image_paths)} å¼ å›¾åƒ")
    
    if len(image_paths) == 0:
        print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return None
    
    # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„ç¼–ç é€»è¾‘
    # æš‚æ—¶è¿”å›éšæœºæ•°æ®ä½œä¸ºç¤ºä¾‹
    latents = np.random.randn(len(image_paths), 32, 16, 16)  # ç¤ºä¾‹ç»´åº¦
    
    print("âœ… å›¾åƒç¼–ç å®Œæˆ")
    return latents

def calculate_fid(real_features, fake_features):
    """è®¡ç®—FIDåˆ†æ•°"""
    print("ğŸ“Š è®¡ç®—FIDåˆ†æ•°...")
    
    # è®¡ç®—å‡å€¼å’Œåæ–¹å·®
    mu1, sigma1 = real_features.mean(axis=0), np.cov(real_features, rowvar=False)
    mu2, sigma2 = fake_features.mean(axis=0), np.cov(fake_features, rowvar=False)
    
    # è®¡ç®—FID
    diff = mu1 - mu2
    covmean = np.sqrt(sigma1.dot(sigma2))
    
    if np.iscomplexobj(covmean):
        covmean = covmean.real
    
    fid = diff.dot(diff) + np.trace(sigma1 + sigma2 - 2 * covmean)
    
    return fid

def evaluate_model(checkpoint_path, test_data_dir):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    print("=" * 60)
    print("ğŸ¯ VA-VAEå¾®è°ƒæ•ˆæœè¯„ä¼°")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    model = load_vavae_model(checkpoint_path)
    if model is None:
        return False
    
    # ç¼–ç æµ‹è¯•å›¾åƒ
    test_features = encode_images(model, test_data_dir)
    if test_features is None:
        return False
    
    # è¿™é‡Œåº”è¯¥ä¸åŸå§‹æ•°æ®é›†æˆ–é¢„è®­ç»ƒæ¨¡å‹çš„ç‰¹å¾è¿›è¡Œæ¯”è¾ƒ
    # æš‚æ—¶ä½¿ç”¨éšæœºæ•°æ®ä½œä¸ºåŸºå‡†
    reference_features = np.random.randn(1000, test_features.shape[1])
    
    # è®¡ç®—FID
    fid_score = calculate_fid(reference_features, test_features)
    
    print(f"ğŸ“Š FIDåˆ†æ•°: {fid_score:.2f}")
    
    # è¯„ä¼°ç»“æœ
    if fid_score < 5.0:
        print("ğŸ‰ ä¼˜ç§€ï¼FID < 5.0")
    elif fid_score < 10.0:
        print("âœ… è‰¯å¥½ï¼FID < 10.0")
    elif fid_score < 20.0:
        print("âš ï¸ ä¸€èˆ¬ï¼ŒFID < 20.0ï¼Œå»ºè®®ç»§ç»­å¾®è°ƒ")
    else:
        print("âŒ è¾ƒå·®ï¼ŒFID > 20.0ï¼Œéœ€è¦æ£€æŸ¥è®­ç»ƒè¿‡ç¨‹")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è¯„ä¼°VA-VAEå¾®è°ƒæ•ˆæœ")
    parser.add_argument("--checkpoint", type=str, required=True, 
                       help="å¾®è°ƒåçš„æ¨¡å‹checkpointè·¯å¾„")
    parser.add_argument("--test_data", type=str, default="/kaggle/input/dataset",
                       help="æµ‹è¯•æ•°æ®ç›®å½•")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    if not Path(args.checkpoint).exists():
        print(f"âŒ Checkpointä¸å­˜åœ¨: {args.checkpoint}")
        return False
    
    if not Path(args.test_data).exists():
        print(f"âŒ æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨: {args.test_data}")
        return False
    
    # æ‰§è¡Œè¯„ä¼°
    success = evaluate_model(args.checkpoint, args.test_data)
    
    if success:
        print("\nâœ… è¯„ä¼°å®Œæˆ")
    else:
        print("\nâŒ è¯„ä¼°å¤±è´¥")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
