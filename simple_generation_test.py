#!/usr/bin/env python3
"""
ç®€å•ç”Ÿæˆæµ‹è¯•è„šæœ¬ - æ— ç­›é€‰ï¼Œç›´æ¥æ£€æŸ¥æ‰©æ•£æ¨¡å‹ç”Ÿæˆè´¨é‡
"""

import os
import torch
import argparse
from pathlib import Path
from PIL import Image
import yaml
import sys

# æ·»åŠ LightningDiTè·¯å¾„
sys.path.insert(0, './LightningDiT')
from lightningdit.inference import create_model_and_transport
from simplified_vavae import SimplifiedVAVAE

def load_models(args, device, rank=0):
    """åŠ è½½DiTå’ŒVAEæ¨¡å‹"""
    print(f"ğŸ”„ [GPU{rank}] åŠ è½½æ¨¡å‹...")
    
    # åŠ è½½é…ç½®
    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)
    
    # åˆ›å»ºDiTæ¨¡å‹å’Œtransport
    model, transport = create_model_and_transport(
        config_path=args.config,
        checkpoint_path=args.dit_checkpoint,
        device=device,
        use_compile=False
    )
    
    # åŠ è½½VAE
    print(f"ğŸ”„ [GPU{rank}] åŠ è½½VA-VAE...")
    vae = SimplifiedVAVAE.from_pretrained('./VA-VAE-checkpoint')
    vae = vae.to(device)
    vae.eval()
    
    return model, transport, vae

def generate_samples(model, vae, transport, user_id, num_samples, batch_size, device, rank=0):
    """ç›´æ¥ç”Ÿæˆæ ·æœ¬ï¼Œæ— ä»»ä½•ç­›é€‰"""
    print(f"ğŸ”„ [GPU{rank}] ä¸ºç”¨æˆ·{user_id}ç”Ÿæˆ{num_samples}ä¸ªæ ·æœ¬...")
    
    generated_images = []
    total_generated = 0
    
    while len(generated_images) < num_samples:
        current_batch_size = min(batch_size, num_samples - len(generated_images))
        
        # ç”Ÿæˆæ¡ä»¶å‘é‡
        y = torch.full((current_batch_size,), user_id, dtype=torch.long, device=device)
        
        # ç”Ÿæˆlatent
        latents = torch.randn(current_batch_size, 32, 16, 16, device=device)
        
        # DiTç”Ÿæˆ
        with torch.no_grad():
            samples = transport.sample_ode(
                model.forward_with_cfg,
                latents,
                model_kwargs={"y": y},
                cfg_scale=12.0,
                sample_steps=50
            )
        
        # VAEè§£ç 
        if vae is not None:
            try:
                # ç›´æ¥è§£ç ï¼Œä¸åšåå½’ä¸€åŒ–ï¼ˆåŸºäºä¹‹å‰çš„è¯Šæ–­ç»“æœï¼‰
                decoded_images = vae.decode_to_images(samples)
                images_pil = [Image.fromarray(img) for img in decoded_images]
                generated_images.extend(images_pil)
                
                total_generated += current_batch_size
                print(f"âœ… [GPU{rank}] ç”¨æˆ·{user_id}: å·²ç”Ÿæˆ {len(generated_images)}/{num_samples}")
                
            except Exception as e:
                print(f"âŒ [GPU{rank}] VAEè§£ç é”™è¯¯: {e}")
                break
        else:
            print(f"âŒ [GPU{rank}] VAEæœªåŠ è½½")
            break
    
    return generated_images[:num_samples], total_generated

def save_samples(images, user_id, output_dir, rank=0):
    """ä¿å­˜ç”Ÿæˆçš„æ ·æœ¬"""
    user_dir = Path(output_dir) / f"User_{user_id:02d}"
    user_dir.mkdir(parents=True, exist_ok=True)
    
    saved_count = 0
    for i, img in enumerate(images):
        try:
            img_path = user_dir / f"sample_{rank}_{i:04d}.png"
            img.save(img_path)
            saved_count += 1
        except Exception as e:
            print(f"âŒ [GPU{rank}] ä¿å­˜å›¾åƒå¤±è´¥: {e}")
    
    print(f"âœ… [GPU{rank}] ç”¨æˆ·{user_id}: ä¿å­˜äº† {saved_count} å¼ å›¾åƒåˆ° {user_dir}")
    return saved_count

def main():
    parser = argparse.ArgumentParser(description='ç®€å•ç”Ÿæˆæµ‹è¯• - æ— ç­›é€‰')
    parser.add_argument('--dit_checkpoint', type=str, required=True,
                       help='DiT checkpoint path')
    parser.add_argument('--config', type=str, 
                       default='configs/dit_s_microdoppler.yaml',
                       help='Config file path')
    parser.add_argument('--output_dir', type=str, 
                       default='./raw_samples_test',
                       help='Output directory')
    parser.add_argument('--num_samples', type=int, default=50,
                       help='Number of samples to generate per user')
    parser.add_argument('--batch_size', type=int, default=20,
                       help='Batch size for generation')
    parser.add_argument('--start_user', type=int, default=0,
                       help='Starting user ID')
    parser.add_argument('--end_user', type=int, default=5,
                       help='Ending user ID (exclusive)')
    
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    rank = int(os.environ.get('LOCAL_RANK', 0))
    
    print(f"ğŸš€ å¼€å§‹ç®€å•ç”Ÿæˆæµ‹è¯•")
    print(f"ğŸ“Š ç›®æ ‡: æ¯ç”¨æˆ· {args.num_samples} å¼ æ ·æœ¬")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ‘¥ ç”¨æˆ·èŒƒå›´: {args.start_user} - {args.end_user-1}")
    
    # åŠ è½½æ¨¡å‹
    model, transport, vae = load_models(args, device, rank)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆæ ·æœ¬
    total_stats = {'generated': 0, 'saved': 0}
    
    for user_id in range(args.start_user, args.end_user):
        print(f"\nğŸ¯ [GPU{rank}] å¤„ç†ç”¨æˆ· {user_id}...")
        
        # ç”Ÿæˆæ ·æœ¬
        images, generated_count = generate_samples(
            model, vae, transport, user_id, 
            args.num_samples, args.batch_size, device, rank
        )
        
        # ä¿å­˜æ ·æœ¬
        saved_count = save_samples(images, user_id, args.output_dir, rank)
        
        total_stats['generated'] += generated_count
        total_stats['saved'] += saved_count
        
        print(f"âœ… [GPU{rank}] ç”¨æˆ·{user_id}å®Œæˆ: ç”Ÿæˆ{generated_count}, ä¿å­˜{saved_count}")
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ‰ ç”Ÿæˆæµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š æ€»è®¡ç”Ÿæˆ: {total_stats['generated']} å¼ ")
    print(f"ğŸ’¾ æ€»è®¡ä¿å­˜: {total_stats['saved']} å¼ ")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"\nğŸ’¡ è¯·æ‰‹å·¥æ£€æŸ¥ç”Ÿæˆæ ·æœ¬çš„è´¨é‡:")
    print(f"   1. å›¾åƒæ˜¯å¦æ¸…æ™°å¯è¾¨è®¤?")
    print(f"   2. æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„ç”Ÿæˆä¼ªå½±?")
    print(f"   3. ä¸åŒç”¨æˆ·çš„æ ·æœ¬æ˜¯å¦æœ‰åŒºåˆ«?")
    print(f"   4. æ˜¯å¦ç¬¦åˆå¾®å¤šæ™®å‹’æ•°æ®çš„é¢„æœŸç‰¹å¾?")

if __name__ == "__main__":
    main()
