#!/usr/bin/env python3
"""
ç®€å•ç”Ÿæˆæµ‹è¯•è„šæœ¬ - æ— ç­›é€‰ï¼Œç›´æ¥æ£€æŸ¥æ‰©æ•£æ¨¡å‹ç”Ÿæˆè´¨é‡
"""

import os
import torch
import argparse
from pathlib import Path
from PIL import Image
import yaml
import sys

# æ·»åŠ LightningDiTè·¯å¾„
sys.path.append('LightningDiT')
from models.lightningdit import LightningDiT_models
from transport import create_transport, Sampler
from simplified_vavae import SimplifiedVAVAE

def load_models(args, device, rank=0):
    """åŠ è½½DiTå’ŒVAEæ¨¡å‹"""
    print(f"ğŸ”„ [GPU{rank}] åŠ è½½æ¨¡å‹...")
    
    # åŠ è½½é…ç½®
    with open(args.config, 'r', encoding='utf-8') as f:
        config = yaml.load(f, Loader=yaml.FullLoader)
    
    # åˆ›å»ºDiTæ¨¡å‹
    latent_size = config['data']['image_size'] // config['vae']['downsample_ratio']
    model = LightningDiT_models[config['model']['model_type']](
        input_size=latent_size,
        num_classes=config['data']['num_classes'],
        class_dropout_prob=config['model'].get('class_dropout_prob', 0.1),
        use_qknorm=config['model']['use_qknorm'],
        use_swiglu=config['model'].get('use_swiglu', False),
        use_rope=config['model'].get('use_rope', False),
        use_rmsnorm=config['model'].get('use_rmsnorm', False),
        wo_shift=config['model'].get('wo_shift', False),
        in_channels=config['model'].get('in_chans', 4),
        use_checkpoint=config['model'].get('use_checkpoint', False),
    ).to(device)
    
    # åŠ è½½æƒé‡
    if os.path.exists(args.dit_checkpoint):
        print(f"ğŸ“¦ [GPU{rank}] ä»checkpointåŠ è½½æƒé‡: {args.dit_checkpoint}")
        checkpoint = torch.load(args.dit_checkpoint, map_location=lambda storage, loc: storage)
        
        # å¤„ç†æƒé‡é”®å
        if 'ema' in checkpoint:
            checkpoint_weights = {'model': checkpoint['ema']}
            print(f"ğŸ“¦ [GPU{rank}] ä½¿ç”¨EMAæƒé‡è¿›è¡Œæ¨ç†")
        elif 'model' in checkpoint:
            checkpoint_weights = checkpoint
        else:
            checkpoint_weights = {'model': checkpoint}
        
        # åŠ è½½æƒé‡
        model_state_dict = model.state_dict()
        for name, param in checkpoint_weights['model'].items():
            if name in model_state_dict:
                if param.shape == model_state_dict[name].shape:
                    model_state_dict[name].copy_(param)
                elif name == 'x_embedder.proj.weight':
                    # ç‰¹æ®Šå¤„ç†x_embedder.proj.weight
                    weight = torch.zeros_like(model_state_dict[name])
                    weight[:, :16] = param[:, :16]
                    model_state_dict[name] = weight
                else:
                    if rank == 0:
                        print(f"è·³è¿‡å‚æ•° '{name}'ï¼Œå½¢çŠ¶ä¸åŒ¹é…: "
                            f"checkpoint {param.shape}, model {model_state_dict[name].shape}")
        model.load_state_dict(model_state_dict, strict=False)
    
    # åˆ›å»ºtransport
    transport = create_transport(
        config['sample'].get('sampling_method', 'dopri5'),
        config['sample'].get('num_sampling_steps', 250),
        config['transport'].get('snr_type', 'uniform'),
        config['sample'].get('top_p', 0.0),
        config['sample'].get('top_k', 0.0),
    )
    
    # åŠ è½½VAE
    print(f"ğŸ”„ [GPU{rank}] åŠ è½½VA-VAE...")
    vae = SimplifiedVAVAE.from_pretrained('./VA-VAE-checkpoint')
    vae = vae.to(device)
    vae.eval()
    
    return model, transport, vae

def generate_samples(model, vae, transport, user_id, num_samples, batch_size, device, rank=0):
    """ç›´æ¥ç”Ÿæˆæ ·æœ¬ï¼Œæ— ä»»ä½•ç­›é€‰"""
    print(f"ğŸ”„ [GPU{rank}] ä¸ºç”¨æˆ·{user_id}ç”Ÿæˆ{num_samples}ä¸ªæ ·æœ¬...")
    
    generated_images = []
    total_generated = 0
    
    while len(generated_images) < num_samples:
        current_batch_size = min(batch_size, num_samples - len(generated_images))
        
        # ç”Ÿæˆæ¡ä»¶å‘é‡
        y = torch.full((current_batch_size,), user_id, dtype=torch.long, device=device)
        
        # ç”Ÿæˆlatent
        latents = torch.randn(current_batch_size, 32, 16, 16, device=device)
        
        # DiTç”Ÿæˆ
        with torch.no_grad():
            samples = transport.sample_ode(
                model.forward_with_cfg,
                latents,
                model_kwargs={"y": y},
                cfg_scale=12.0,
                sample_steps=50
            )
        
        # VAEè§£ç 
        if vae is not None:
            try:
                # ç›´æ¥è§£ç ï¼Œä¸åšåå½’ä¸€åŒ–ï¼ˆåŸºäºä¹‹å‰çš„è¯Šæ–­ç»“æœï¼‰
                decoded_images = vae.decode_to_images(samples)
                images_pil = [Image.fromarray(img) for img in decoded_images]
                generated_images.extend(images_pil)
                
                total_generated += current_batch_size
                print(f"âœ… [GPU{rank}] ç”¨æˆ·{user_id}: å·²ç”Ÿæˆ {len(generated_images)}/{num_samples}")
                
            except Exception as e:
                print(f"âŒ [GPU{rank}] VAEè§£ç é”™è¯¯: {e}")
                break
        else:
            print(f"âŒ [GPU{rank}] VAEæœªåŠ è½½")
            break
    
    return generated_images[:num_samples], total_generated

def save_samples(images, user_id, output_dir, rank=0):
    """ä¿å­˜ç”Ÿæˆçš„æ ·æœ¬"""
    user_dir = Path(output_dir) / f"User_{user_id:02d}"
    user_dir.mkdir(parents=True, exist_ok=True)
    
    saved_count = 0
    for i, img in enumerate(images):
        try:
            img_path = user_dir / f"sample_{rank}_{i:04d}.png"
            img.save(img_path)
            saved_count += 1
        except Exception as e:
            print(f"âŒ [GPU{rank}] ä¿å­˜å›¾åƒå¤±è´¥: {e}")
    
    print(f"âœ… [GPU{rank}] ç”¨æˆ·{user_id}: ä¿å­˜äº† {saved_count} å¼ å›¾åƒåˆ° {user_dir}")
    return saved_count

def main():
    parser = argparse.ArgumentParser(description='ç®€å•ç”Ÿæˆæµ‹è¯• - æ— ç­›é€‰')
    parser.add_argument('--dit_checkpoint', type=str, required=True,
                       help='DiT checkpoint path')
    parser.add_argument('--config', type=str, 
                       default='configs/dit_s_microdoppler.yaml',
                       help='Config file path')
    parser.add_argument('--output_dir', type=str, 
                       default='./raw_samples_test',
                       help='Output directory')
    parser.add_argument('--num_samples', type=int, default=50,
                       help='Number of samples to generate per user')
    parser.add_argument('--batch_size', type=int, default=20,
                       help='Batch size for generation')
    parser.add_argument('--start_user', type=int, default=0,
                       help='Starting user ID')
    parser.add_argument('--end_user', type=int, default=5,
                       help='Ending user ID (exclusive)')
    
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    rank = int(os.environ.get('LOCAL_RANK', 0))
    
    print(f"ğŸš€ å¼€å§‹ç®€å•ç”Ÿæˆæµ‹è¯•")
    print(f"ğŸ“Š ç›®æ ‡: æ¯ç”¨æˆ· {args.num_samples} å¼ æ ·æœ¬")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ‘¥ ç”¨æˆ·èŒƒå›´: {args.start_user} - {args.end_user-1}")
    
    # åŠ è½½æ¨¡å‹
    model, transport, vae = load_models(args, device, rank)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆæ ·æœ¬
    total_stats = {'generated': 0, 'saved': 0}
    
    for user_id in range(args.start_user, args.end_user):
        print(f"\nğŸ¯ [GPU{rank}] å¤„ç†ç”¨æˆ· {user_id}...")
        
        # ç”Ÿæˆæ ·æœ¬
        images, generated_count = generate_samples(
            model, vae, transport, user_id, 
            args.num_samples, args.batch_size, device, rank
        )
        
        # ä¿å­˜æ ·æœ¬
        saved_count = save_samples(images, user_id, args.output_dir, rank)
        
        total_stats['generated'] += generated_count
        total_stats['saved'] += saved_count
        
        print(f"âœ… [GPU{rank}] ç”¨æˆ·{user_id}å®Œæˆ: ç”Ÿæˆ{generated_count}, ä¿å­˜{saved_count}")
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ‰ ç”Ÿæˆæµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š æ€»è®¡ç”Ÿæˆ: {total_stats['generated']} å¼ ")
    print(f"ğŸ’¾ æ€»è®¡ä¿å­˜: {total_stats['saved']} å¼ ")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"\nğŸ’¡ è¯·æ‰‹å·¥æ£€æŸ¥ç”Ÿæˆæ ·æœ¬çš„è´¨é‡:")
    print(f"   1. å›¾åƒæ˜¯å¦æ¸…æ™°å¯è¾¨è®¤?")
    print(f"   2. æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„ç”Ÿæˆä¼ªå½±?")
    print(f"   3. ä¸åŒç”¨æˆ·çš„æ ·æœ¬æ˜¯å¦æœ‰åŒºåˆ«?")
    print(f"   4. æ˜¯å¦ç¬¦åˆå¾®å¤šæ™®å‹’æ•°æ®çš„é¢„æœŸç‰¹å¾?")

if __name__ == "__main__":
    main()
