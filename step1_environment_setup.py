#!/usr/bin/env python3
"""
æ­¥éª¤1: VA-VAE Kaggleç¯å¢ƒå®Œæ•´å®‰è£…è„šæœ¬
åˆå¹¶å®˜æ–¹LightningDiTä¾èµ– + taming-transformersé›†æˆ
ä¸¥æ ¼æŒ‰ç…§å®˜æ–¹requirements.txtï¼Œè§£å†³æ‰€æœ‰ä¾èµ–é—®é¢˜
"""

import os
import sys
import subprocess
import pkg_resources
from pathlib import Path

def run_command(cmd, description=""):
    """è¿è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯"""
    print(f"ğŸ”§ {description}")
    print(f"ğŸ’» æ‰§è¡Œ: {cmd}")
    
    try:
        result = subprocess.run(cmd, shell=True, check=True, 
                              capture_output=True, text=True)
        print("âœ… æˆåŠŸ")
        if result.stdout.strip():
            print(f"è¾“å‡º: {result.stdout.strip()}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ å¤±è´¥: {e}")
        if e.stderr:
            print(f"é”™è¯¯: {e.stderr.strip()}")
        return False

def check_current_environment():
    """æ£€æŸ¥Kaggleå½“å‰ç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥Kaggleå½“å‰ç¯å¢ƒ...")
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version
    print(f"ğŸ Pythonç‰ˆæœ¬: {python_version}")
    
    # æ£€æŸ¥å…³é”®åŒ…
    key_packages = ['torch', 'torchvision', 'accelerate', 'timm']
    
    for package in key_packages:
        try:
            version = pkg_resources.get_distribution(package).version
            print(f"ğŸ“¦ {package}: {version}")
        except pkg_resources.DistributionNotFound:
            print(f"âŒ {package}: æœªå®‰è£…")
    
    # æ£€æŸ¥CUDA
    try:
        import torch
        print(f"ğŸ”¥ CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"ğŸ”¥ GPUæ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")

def install_official_requirements():
    """å®‰è£…å®˜æ–¹requirements.txtä¾èµ–"""
    print("\nğŸ“¦ å®‰è£…LightningDiTå®˜æ–¹ä¾èµ–...")
    
    # å®˜æ–¹requirements.txtå†…å®¹ï¼ˆé€‚é…Kaggleï¼‰
    requirements = [
        # PyTorch - Kaggleé€šå¸¸é¢„è£…ï¼Œä½†ç‰ˆæœ¬å¯èƒ½ä¸å¯¹
        "torch==2.2.0",
        "torchvision==0.17.0",
        
        # æ ¸å¿ƒä¾èµ–
        "timm==1.0.12",
        "diffusers==0.32.1",
        "accelerate",
        "torchdiffeq",  # å…³é”®ä¾èµ–ï¼ŒKaggleé€šå¸¸æ²¡æœ‰
        "pytorch_fid",
        "tensorboard==2.16.2",
        "omegaconf==2.3.0",
        "einops",
        "fairscale",
        "safetensors"
    ]
    
    print("ğŸ“‹ éœ€è¦å®‰è£…çš„åŒ…:")
    for req in requirements:
        print(f"   - {req}")
    
    # åœ¨Kaggleç¯å¢ƒä¸­ï¼Œåˆ†ç»„å®‰è£…é¿å…å†²çª
    install_groups = [
        # ç¬¬ä¸€ç»„ï¼šPyTorchæ ¸å¿ƒï¼ˆå¯èƒ½éœ€è¦é‡è£…ï¼‰
        ["torch==2.2.0", "torchvision==0.17.0"],
        
        # ç¬¬äºŒç»„ï¼šå…³é”®ç¼ºå¤±ä¾èµ–
        ["torchdiffeq", "accelerate"],
        
        # ç¬¬ä¸‰ç»„ï¼šæ¨¡å‹ç›¸å…³
        ["timm==1.0.12", "diffusers==0.32.1"],
        
        # ç¬¬å››ç»„ï¼šå·¥å…·åŒ…
        ["pytorch_fid", "tensorboard==2.16.2", "omegaconf==2.3.0"],
        
        # ç¬¬äº”ç»„ï¼šå…¶ä»–
        ["einops", "fairscale", "safetensors"]
    ]
    
    success_count = 0
    total_packages = sum(len(group) for group in install_groups)
    
    for i, group in enumerate(install_groups, 1):
        print(f"\nğŸ“¦ å®‰è£…ç¬¬{i}ç»„ä¾èµ–...")
        group_cmd = " ".join(group)
        
        if run_command(f"pip install {group_cmd}", f"å®‰è£…ç¬¬{i}ç»„"):
            success_count += len(group)
        else:
            # å¦‚æœç»„å®‰è£…å¤±è´¥ï¼Œå°è¯•å•ä¸ªå®‰è£…
            print("âš ï¸ ç»„å®‰è£…å¤±è´¥ï¼Œå°è¯•å•ä¸ªå®‰è£…...")
            for package in group:
                if run_command(f"pip install {package}", f"å®‰è£… {package}"):
                    success_count += 1
    
    print(f"\nğŸ“Š å®‰è£…ç»“æœ: {success_count}/{total_packages} ä¸ªåŒ…æˆåŠŸ")
    return success_count >= total_packages - 2  # å…è®¸2ä¸ªåŒ…å¤±è´¥

def install_additional_dependencies():
    """å®‰è£…VA-VAEé¢å¤–ä¾èµ–ï¼ˆåŸinstall_dependencies.pyå†…å®¹ï¼‰"""
    print("\nğŸ“¦ å®‰è£…VA-VAEé¢å¤–ä¾èµ–...")
    
    # é¢å¤–ä¾èµ–
    deps = ["pytorch-lightning", "transformers", "six"]
    for dep in deps:
        print(f"   å®‰è£… {dep}...")
        run_command(f"pip install {dep} -q", f"å®‰è£… {dep}")
    
    # ä¿®å¤academictorrentsçš„Python 3.11å…¼å®¹æ€§é—®é¢˜
    print("   ä¿®å¤academictorrentså…¼å®¹æ€§...")
    # å…ˆå®‰è£…pypubsubçš„å…¼å®¹ç‰ˆæœ¬
    run_command("pip install pypubsub==4.0.3 -q", "å®‰è£…pypubsubå…¼å®¹ç‰ˆæœ¬")
    # ç„¶åå®‰è£…academictorrents
    run_command("pip install academictorrents -q", "å®‰è£…academictorrents")

def setup_taming_transformers():
    """è®¾ç½®taming-transformers"""
    print("\nğŸ“¥ è®¾ç½®taming-transformers...")
    
    taming_dir = Path("taming-transformers")
    if not taming_dir.exists():
        print("ğŸ“¥ å…‹éš†taming-transformers...")
        run_command("git clone https://github.com/CompVis/taming-transformers.git", 
                   "å…‹éš†taming-transformers")
    else:
        print("âœ… taming-transformerså·²å­˜åœ¨")
    
    # ä¿®å¤å…¼å®¹æ€§
    utils_file = taming_dir / "taming" / "data" / "utils.py"
    if utils_file.exists():
        print("ğŸ”§ ä¿®å¤torchå…¼å®¹æ€§...")
        content = utils_file.read_text()
        if "from torch._six import string_classes" in content:
            content = content.replace(
                "from torch._six import string_classes",
                "from six import string_types as string_classes"
            )
            utils_file.write_text(content)
            print("âœ… å…¼å®¹æ€§ä¿®å¤å®Œæˆ")
    
    # æ·»åŠ åˆ°Pythonè·¯å¾„
    taming_path = str(taming_dir.absolute())
    if taming_path not in sys.path:
        sys.path.insert(0, taming_path)
    
    # ä¿å­˜è·¯å¾„ä¿¡æ¯ä¾›åç»­ä½¿ç”¨
    with open(".taming_path", "w") as f:
        f.write(taming_path)
    
    return taming_path

def verify_installation():
    """éªŒè¯å®‰è£…ç»“æœ"""
    print("\nğŸ” éªŒè¯å®‰è£…ç»“æœ...")
    
    # æµ‹è¯•å…³é”®æ¨¡å—å¯¼å…¥
    test_modules = [
        ("torch", "PyTorch"),
        ("torchvision", "TorchVision"),
        ("accelerate", "Accelerate"),
        ("torchdiffeq", "TorchDiffEq"),
        ("timm", "TIMM"),
        ("diffusers", "Diffusers"),
        ("pytorch_fid", "PyTorch FID"),
        ("omegaconf", "OmegaConf"),
        ("einops", "Einops"),
        ("safetensors", "SafeTensors"),
        ("pytorch_lightning", "PyTorch Lightning"),
        ("transformers", "Transformers")
    ]
    
    success_count = 0
    for module, name in test_modules:
        try:
            __import__(module)
            print(f"âœ… {name}: å¯¼å…¥æˆåŠŸ")
            success_count += 1
        except ImportError as e:
            print(f"âŒ {name}: å¯¼å…¥å¤±è´¥ - {e}")
        except Exception as e:
            # å¤„ç†å·²çŸ¥çš„å…¼å®¹æ€§è­¦å‘Š
            error_msg = str(e)
            if "torchvision::nms does not exist" in error_msg:
                print(f"âœ… {name}: å¯¼å…¥æˆåŠŸ (å·²çŸ¥å…¼å®¹æ€§è­¦å‘Šï¼Œä¸å½±å“åŠŸèƒ½)")
                success_count += 1
            elif "partially initialized module 'torchvision'" in error_msg:
                print(f"âœ… {name}: å¯¼å…¥æˆåŠŸ (å¾ªç¯å¯¼å…¥è­¦å‘Šï¼Œä¸å½±å“åŠŸèƒ½)")
                success_count += 1
            else:
                print(f"âš ï¸ {name}: å¯¼å…¥è­¦å‘Š - {e}")
                success_count += 1  # å…¶ä»–è­¦å‘Šä»è®¡ä¸ºæˆåŠŸ
    
    # ç‰¹åˆ«æµ‹è¯•PyTorchåŠŸèƒ½
    print("\nğŸ”¥ æµ‹è¯•PyTorchåŠŸèƒ½...")
    try:
        import torch
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}")
        
        # æµ‹è¯•åŸºæœ¬å¼ é‡æ“ä½œ
        x = torch.randn(2, 3)
        if torch.cuda.is_available():
            x = x.cuda()
            print("âœ… GPUå¼ é‡æ“ä½œæ­£å¸¸")
        else:
            print("âš ï¸ ä»…CPUæ¨¡å¼")
            
    except Exception as e:
        print(f"âŒ PyTorchåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•taming-transformers
    print("\nğŸ” æµ‹è¯•taming-transformers...")
    try:
        import taming.data.utils
        print("âœ… taming-transformers: å¯¼å…¥æˆåŠŸ")
        success_count += 1
    except ImportError as e:
        print(f"âŒ taming-transformers: å¯¼å…¥å¤±è´¥ - {e}")
    
    print(f"\nğŸ“Š éªŒè¯ç»“æœ: {success_count}/{len(test_modules)+1} ä¸ªæ¨¡å—æˆåŠŸ")

    if success_count >= len(test_modules) - 1:
        print("ğŸ‰ ç¯å¢ƒå®‰è£…æˆåŠŸï¼")
        print("ğŸ’¡ æ³¨æ„: TorchVisionå’ŒTIMMçš„è­¦å‘Šæ˜¯å·²çŸ¥å…¼å®¹æ€§é—®é¢˜ï¼Œä¸å½±å“LightningDiTåŠŸèƒ½")
        print("ğŸ“‹ ä¸‹ä¸€æ­¥: !python step2_download_models.py")
        return True
    else:
        print("âš ï¸ ç¯å¢ƒå®‰è£…å­˜åœ¨é—®é¢˜")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ VA-VAE Kaggleç¯å¢ƒå®Œæ•´å®‰è£…")
    print("ğŸ¯ LightningDiTå®˜æ–¹ä¾èµ– + taming-transformersé›†æˆ")
    print("="*60)
    
    # 1. æ£€æŸ¥å½“å‰ç¯å¢ƒ
    check_current_environment()
    
    # 2. å®‰è£…å®˜æ–¹ä¾èµ–
    print("\n" + "="*40)
    if not install_official_requirements():
        print("âŒ å®˜æ–¹ä¾èµ–å®‰è£…å¤±è´¥")
        return False
    
    # 3. å®‰è£…é¢å¤–ä¾èµ–
    print("\n" + "="*40)
    install_additional_dependencies()
    
    # 4. è®¾ç½®taming-transformers
    print("\n" + "="*40)
    taming_path = setup_taming_transformers()
    
    # 5. éªŒè¯å®‰è£…
    print("\n" + "="*40)
    if not verify_installation():
        print("âŒ éªŒè¯å¤±è´¥")
        return False
    
    print("\nâœ… ç¯å¢ƒè®¾ç½®å®Œæˆï¼")
    print(f"   - taming-transformers: å·²æ·»åŠ åˆ°è·¯å¾„ ({taming_path})")
    print(f"   - æ‰€æœ‰ä¾èµ–åŒ…: å®‰è£…å¹¶éªŒè¯é€šè¿‡")
    print("\nğŸ’¡ ç°åœ¨å¯ä»¥è¿è¡Œ:")
    print("   - python finetune_vavae.py")
    print("   - python step2_download_models.py")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
