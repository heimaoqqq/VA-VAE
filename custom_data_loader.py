#!/usr/bin/env python3
"""
è‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨ï¼Œé€‚ç”¨äºåˆ†ç±»ç›®å½•ç»“æ„çš„æ•°æ®é›†
æ”¯æŒ /kaggle/input/dataset/ID_1/, ID_2/, ... ID_31/ ç»“æ„
"""

import os
import glob
from PIL import Image
import numpy as np
import albumentations
from torch.utils.data import Dataset
from omegaconf import OmegaConf


class CustomImageDataset(Dataset):
    """
    è‡ªå®šä¹‰å›¾åƒæ•°æ®é›†åŠ è½½å™¨
    é€‚ç”¨äºæŒ‰ç±»åˆ«ç»„ç»‡çš„ç›®å½•ç»“æ„: data_root/class1/, data_root/class2/, ...
    """
    
    def __init__(self, data_root, size=256, config=None):
        self.data_root = data_root
        self.size = size
        self.config = config or {}
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        self.image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        
        # å›¾åƒé¢„å¤„ç†
        self.preprocessor = albumentations.Compose([
            albumentations.Resize(size, size),
            albumentations.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        
        # åŠ è½½æ‰€æœ‰å›¾åƒè·¯å¾„
        self._load_image_paths()
        
        print(f"âœ… åŠ è½½äº† {len(self.image_paths)} å¼ å›¾åƒï¼Œæ¥è‡ª {len(self.class_names)} ä¸ªç±»åˆ«")
        
    def _load_image_paths(self):
        """åŠ è½½æ‰€æœ‰å›¾åƒè·¯å¾„å’Œæ ‡ç­¾"""
        self.image_paths = []
        self.labels = []
        self.class_names = []
        
        # æ‰«ææ‰€æœ‰å­ç›®å½•
        class_dirs = sorted([d for d in os.listdir(self.data_root) 
                           if os.path.isdir(os.path.join(self.data_root, d))])
        
        for class_idx, class_name in enumerate(class_dirs):
            class_path = os.path.join(self.data_root, class_name)
            self.class_names.append(class_name)
            
            # æ‰«æè¯¥ç±»åˆ«ä¸‹çš„æ‰€æœ‰å›¾åƒ
            class_images = []
            for ext in self.image_extensions:
                class_images.extend(glob.glob(os.path.join(class_path, ext)))
            
            # æ·»åŠ åˆ°æ€»åˆ—è¡¨
            for img_path in class_images:
                self.image_paths.append(img_path)
                self.labels.append(class_idx)
                
        print(f"ğŸ“ å‘ç°ç±»åˆ«: {self.class_names}")
        
    def __len__(self):
        return len(self.image_paths)
        
    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        img_path = self.image_paths[idx]
        image = Image.open(img_path)
        
        # ç¡®ä¿æ˜¯RGBæ ¼å¼
        if image.mode != 'RGB':
            image = image.convert('RGB')
            
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        image = np.array(image)
        
        # åº”ç”¨é¢„å¤„ç†
        processed = self.preprocessor(image=image)
        image = processed['image']
        
        # è¿”å›æ•°æ®å­—å…¸ï¼ˆå…¼å®¹LDMæ ¼å¼ï¼‰
        return {
            'image': image.astype(np.float32),
            'class_label': self.labels[idx],
            'class_name': self.class_names[self.labels[idx]],
            'file_path_': img_path
        }


class CustomImageTrain(CustomImageDataset):
    """è®­ç»ƒæ•°æ®é›†"""
    def __init__(self, data_root, config=None, **kwargs):
        super().__init__(data_root, config=config, **kwargs)


class CustomImageValidation(CustomImageDataset):
    """éªŒè¯æ•°æ®é›†"""
    def __init__(self, data_root, config=None, **kwargs):
        super().__init__(data_root, config=config, **kwargs)
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ éªŒè¯é›†ç‰¹å®šçš„é€»è¾‘ï¼Œæ¯”å¦‚åªä½¿ç”¨éƒ¨åˆ†æ•°æ®
