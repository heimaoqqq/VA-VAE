#!/usr/bin/env python3
"""
æ­¥éª¤4: LightningDiTæ¨ç† - æœ€ç»ˆç‰ˆæœ¬
é›†æˆäº†æ ‡å‡†æ¨ç†å’ŒDemoæ¨ç†ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹æ¡ˆ
"""

import os
import sys
import torch
import subprocess
from pathlib import Path
import yaml

def check_environment():
    """æ£€æŸ¥æ¨ç†ç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥æ¨ç†ç¯å¢ƒ...")
    
    # æ£€æŸ¥CUDA
    print(f"ğŸ”¥ CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"ğŸ”¥ GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
            memory_total = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i} å†…å­˜: {memory_total:.1f} GB")
    
    # æ£€æŸ¥å…³é”®æ¨¡å—
    required_modules = ['accelerate', 'torchdiffeq', 'timm', 'diffusers']
    for module in required_modules:
        try:
            __import__(module)
            print(f"âœ… {module}: å¯ç”¨")
        except ImportError:
            print(f"âŒ {module}: ä¸å¯ç”¨")
            return False
    
    return True

def check_files():
    """æ£€æŸ¥å¿…éœ€æ–‡ä»¶"""
    print("\nğŸ” æ£€æŸ¥å¿…éœ€æ–‡ä»¶...")
    
    # æ£€æŸ¥LightningDiTç›®å½•
    lightningdit_dir = Path("LightningDiT")
    if not lightningdit_dir.exists():
        print(f"âŒ LightningDiTç›®å½•ä¸å­˜åœ¨: {lightningdit_dir}")
        return False
    print(f"âœ… LightningDiTç›®å½•: {lightningdit_dir}")
    
    # æ£€æŸ¥æ¨ç†è„šæœ¬
    inference_script = lightningdit_dir / "inference.py"
    if not inference_script.exists():
        print(f"âŒ æ¨ç†è„šæœ¬ä¸å­˜åœ¨: {inference_script}")
        return False
    print(f"âœ… æ¨ç†è„šæœ¬: {inference_script}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    models_dir = Path("models")
    required_models = [
        "vavae-imagenet256-f16d32-dinov2.pt",
        "lightningdit-xl-imagenet256-800ep.pt",
        "latents_stats.pt"
    ]
    
    for model in required_models:
        model_path = models_dir / model
        if not model_path.exists():
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
        size_mb = model_path.stat().st_size / 1024 / 1024
        print(f"âœ… {model}: {size_mb:.1f} MB")
    
    return True

def create_demo_config():
    """åˆ›å»ºDemoé…ç½®æ–‡ä»¶"""
    print("âš™ï¸ åˆ›å»ºDemoé…ç½®æ–‡ä»¶...")
    
    demo_config = {
        'ckpt_path': str(Path("../models/lightningdit-xl-imagenet256-800ep.pt").absolute()),
        'data': {
            'data_path': str(Path("../models").absolute()),
            'image_size': 256,
            'num_classes': 1000,
            'num_workers': 2,
            'latent_norm': True,
            'latent_multiplier': 1.0
        },
        'vae': {
            'model_name': 'vavae_f16d32',
            'downsample_ratio': 16
        },
        'model': {
            'model_type': 'LightningDiT-XL/1',
            'use_qknorm': False,
            'use_swiglu': True,
            'use_rope': True,
            'use_rmsnorm': True,
            'wo_shift': False,
            'in_chans': 32
        },
        'train': {
            'max_steps': 80000,
            'global_batch_size': 256,
            'global_seed': 0,
            'output_dir': 'demo_output',
            'exp_name': 'lightningdit_demo',
            'ckpt': None,
            'log_every': 100,
            'ckpt_every': 20000
        },
        'optimizer': {'lr': 0.0002, 'beta2': 0.95},
        'transport': {
            'path_type': 'Linear',
            'prediction': 'velocity',
            'loss_weight': None,
            'sample_eps': None,
            'train_eps': None,
            'use_cosine_loss': True,
            'use_lognorm': True
        },
        'sample': {
            'mode': 'ODE',
            'sampling_method': 'euler',
            'atol': 0.000001,
            'rtol': 0.001,
            'reverse': False,
            'likelihood': False,
            'num_sampling_steps': 50,
            'cfg_scale': 9.0,
            'per_proc_batch_size': 1,
            'fid_num': 100,
            'cfg_interval_start': 0.0,
            'timestep_shift': 0.0
        }
    }
    
    config_path = Path("demo_config.yaml")
    with open(config_path, 'w') as f:
        yaml.dump(demo_config, f, default_flow_style=False, indent=2)
    
    print(f"âœ… Demoé…ç½®å·²åˆ›å»º: {config_path}")
    return str(config_path)

def run_inference():
    """è¿è¡Œæ¨ç† - æ™ºèƒ½é€‰æ‹©æ–¹æ¡ˆ"""
    print("\nğŸš€ å¼€å§‹LightningDiTæ¨ç†...")
    
    original_cwd = os.getcwd()
    lightningdit_dir = Path("LightningDiT")
    
    try:
        os.chdir(lightningdit_dir)
        current_dir = Path.cwd()
        print(f"ğŸ“ å½“å‰ç›®å½•: {current_dir}")
        
        # æ–¹æ¡ˆ1: å°è¯•å®˜æ–¹é…ç½®
        official_config = "configs/reproductions/lightningdit_xl_vavae_f16d32_800ep_cfg.yaml"
        if Path(official_config).exists():
            print(f"ğŸ¯ å°è¯•å®˜æ–¹é…ç½®: {official_config}")
            cmd = f"accelerate launch --mixed_precision bf16 inference.py --config {official_config} --demo"
            
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                print("âœ… å®˜æ–¹é…ç½®æ¨ç†æˆåŠŸï¼")
                return True
            else:
                print("âš ï¸ å®˜æ–¹é…ç½®å¤±è´¥ï¼Œå°è¯•Demoé…ç½®...")
        
        # æ–¹æ¡ˆ2: ä½¿ç”¨Demoé…ç½®
        demo_config = create_demo_config()
        print(f"ğŸ¯ ä½¿ç”¨Demoé…ç½®: {demo_config}")
        
        # å•GPUè¿è¡Œï¼Œé¿å…åˆ†å¸ƒå¼é—®é¢˜
        cmd = f"python inference.py --config {demo_config} --demo"
        print(f"ğŸ’» æ‰§è¡Œå‘½ä»¤: {cmd}")
        
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=1800)
        
        # è¾“å‡ºç»“æœ
        if result.stdout:
            print("ğŸ“¤ æ ‡å‡†è¾“å‡º:")
            print(result.stdout[-1000:])  # åªæ˜¾ç¤ºæœ€å1000å­—ç¬¦
        
        if result.stderr:
            print("ğŸ“¤ é”™è¯¯è¾“å‡º:")
            print(result.stderr[-1000:])  # åªæ˜¾ç¤ºæœ€å1000å­—ç¬¦
        
        if result.returncode == 0:
            print("âœ… Demoæ¨ç†æˆåŠŸå®Œæˆï¼")
            return True
        else:
            print(f"âŒ æ¨ç†å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return False
            
    except subprocess.TimeoutExpired:
        print("âŒ æ¨ç†è¶…æ—¶ï¼ˆ30åˆ†é’Ÿï¼‰")
        return False
    except Exception as e:
        print(f"âŒ æ¨ç†å¼‚å¸¸: {e}")
        return False
    finally:
        os.chdir(original_cwd)

def verify_results():
    """éªŒè¯æ¨ç†ç»“æœ"""
    print("\nğŸ” éªŒè¯æ¨ç†ç»“æœ...")
    
    output_dirs = [
        Path("LightningDiT/demo_output"),
        Path("LightningDiT/demo_images"),
        Path("LightningDiT/output")
    ]
    
    found_images = []
    
    for output_dir in output_dirs:
        if output_dir.exists():
            print(f"ğŸ“ å‘ç°è¾“å‡ºç›®å½•: {output_dir}")
            
            for ext in ['*.png', '*.jpg', '*.jpeg']:
                images = list(output_dir.glob(ext))
                found_images.extend(images)
                
                for img in images:
                    size_mb = img.stat().st_size / 1024 / 1024
                    print(f"   ğŸ“¸ {img.name}: {size_mb:.2f} MB")
    
    if found_images:
        print(f"âœ… æ‰¾åˆ° {len(found_images)} ä¸ªç”Ÿæˆå›¾åƒ")
        return True
    else:
        print("âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„å›¾åƒ")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ­¥éª¤4: LightningDiTæ¨ç† (æœ€ç»ˆç‰ˆæœ¬)")
    print("="*60)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return False
    
    # æ£€æŸ¥æ–‡ä»¶
    if not check_files():
        print("âŒ æ–‡ä»¶æ£€æŸ¥å¤±è´¥")
        return False
    
    # è¿è¡Œæ¨ç†
    if not run_inference():
        print("âŒ æ¨ç†å¤±è´¥")
        return False
    
    # éªŒè¯ç»“æœ
    if not verify_results():
        print("âŒ ç»“æœéªŒè¯å¤±è´¥")
        return False
    
    print("\nğŸ‰ LightningDiTæ¨ç†å®Œæˆï¼")
    print("ğŸ“Š æˆåŠŸå¤ç°äº†å®˜æ–¹æ•ˆæœ")
    print("ğŸ¯ ä¸‹ä¸€æ­¥: è€ƒè™‘é€‚é…æ‚¨çš„31ç”¨æˆ·å¾®å¤šæ™®å‹’æ•°æ®")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
