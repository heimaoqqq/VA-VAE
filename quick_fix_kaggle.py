#!/usr/bin/env python3
"""
Kaggleå¿«é€Ÿä¿®å¤è„šæœ¬
ç›´æ¥ä¿®å¤æ•°æ®åŠ è½½å’Œæ¨¡å‹åŠ è½½é—®é¢˜
"""

import os
import sys

def fix_data_loading():
    """ä¿®å¤æ•°æ®åŠ è½½é—®é¢˜"""
    print("ğŸ”§ ä¿®å¤æ•°æ®åŠ è½½é—®é¢˜...")
    
    # è¯»å–åŸå§‹æ–‡ä»¶
    dataset_file = "minimal_micro_doppler_dataset.py"
    if not os.path.exists(dataset_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {dataset_file}")
        return False
    
    with open(dataset_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ä¿®å¤__getitem__æ–¹æ³•ä¸­çš„ç»´åº¦è½¬æ¢
    old_code = '''        # è½¬æ¢ä¸ºtensor
        image_tensor = torch.from_numpy(spectrogram).float()
        
        return {
            'image': image_tensor,      # LightningDiTæœŸæœ›çš„é”®å
            'user_id': item['user_id']  # æ–°å¢çš„ç”¨æˆ·æ¡ä»¶
        }'''
    
    new_code = '''        # è½¬æ¢ä¸ºtensor
        image_tensor = torch.from_numpy(spectrogram).float()
        
        # ç¡®ä¿ç»´åº¦ä¸º (C, H, W)
        if image_tensor.dim() == 3:
            if image_tensor.shape[2] == 3:  # (H, W, C) -> (C, H, W)
                image_tensor = image_tensor.permute(2, 0, 1)
            elif image_tensor.shape[0] != 3:  # å…¶ä»–æƒ…å†µ
                # å¦‚æœä¸æ˜¯3é€šé“ï¼Œè½¬æ¢ä¸º3é€šé“
                if image_tensor.shape[0] == 1:
                    image_tensor = image_tensor.repeat(3, 1, 1)
                else:
                    # å–ç¬¬ä¸€ä¸ªé€šé“å¹¶å¤åˆ¶
                    image_tensor = image_tensor[0:1].repeat(3, 1, 1)
        elif image_tensor.dim() == 2:  # (H, W) -> (3, H, W)
            image_tensor = image_tensor.unsqueeze(0).repeat(3, 1, 1)
        
        # éªŒè¯æœ€ç»ˆç»´åº¦
        assert image_tensor.shape == (3, 256, 256), f"ç»´åº¦é”™è¯¯: {image_tensor.shape}"
        
        return {
            'image': image_tensor,      # LightningDiTæœŸæœ›çš„é”®å
            'user_id': item['user_id']  # æ–°å¢çš„ç”¨æˆ·æ¡ä»¶
        }'''
    
    if old_code in content:
        content = content.replace(old_code, new_code)
        with open(dataset_file, 'w', encoding='utf-8') as f:
            f.write(content)
        print("âœ… æ•°æ®åŠ è½½ä¿®å¤å®Œæˆ")
        return True
    else:
        print("âš ï¸ æœªæ‰¾åˆ°éœ€è¦ä¿®å¤çš„ä»£ç æ®µ")
        return False

def fix_model_loading():
    """ä¿®å¤æ¨¡å‹åŠ è½½é—®é¢˜"""
    print("ğŸ”§ ä¿®å¤æ¨¡å‹åŠ è½½é—®é¢˜...")
    
    # è¯»å–åŸå§‹æ–‡ä»¶
    training_file = "minimal_training_modification.py"
    if not os.path.exists(training_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {training_file}")
        return False
    
    with open(training_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ä¿®å¤å¯¼å…¥é—®é¢˜
    old_import = "from tokenizer.vavae import VAVAE"
    new_import = "from tokenizer.autoencoder import AutoencoderKL"
    
    if old_import in content:
        content = content.replace(old_import, new_import)
    
    # ä¿®å¤æ¨¡å‹åˆ›å»º
    old_model_code = '''            # åˆ›å»ºVA-VAEæ¨¡å‹å®ä¾‹
            original_vavae = VAVAE()
            
            # åŠ è½½æƒé‡
            if 'state_dict' in checkpoint:
                original_vavae.load_state_dict(checkpoint['state_dict'])
            else:
                original_vavae.load_state_dict(checkpoint)'''
    
    new_model_code = '''            # åˆ›å»ºVA-VAEæ¨¡å‹å®ä¾‹å¹¶ç›´æ¥åŠ è½½æƒé‡
            original_vavae = AutoencoderKL(
                embed_dim=32,  # f16d32é…ç½®
                ch_mult=(1, 1, 2, 2, 4),
                ckpt_path=args.original_vavae,  # ç›´æ¥ä½¿ç”¨ckpt_pathå‚æ•°
                model_type='vavae'
            )'''
    
    if old_model_code in content:
        content = content.replace(old_model_code, new_model_code)
    
    with open(training_file, 'w', encoding='utf-8') as f:
        f.write(content)
    print("âœ… æ¨¡å‹åŠ è½½ä¿®å¤å®Œæˆ")
    return True

def create_simple_test():
    """åˆ›å»ºç®€å•æµ‹è¯•è„šæœ¬"""
    print("ğŸ”§ åˆ›å»ºç®€å•æµ‹è¯•è„šæœ¬...")
    
    test_code = '''#!/usr/bin/env python3
"""ç®€å•çš„æ•°æ®å’Œæ¨¡å‹æµ‹è¯•"""

import torch
import sys
import os

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('LightningDiT')

def test_data():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("æµ‹è¯•æ•°æ®åŠ è½½...")
    from minimal_micro_doppler_dataset import MicroDopplerDataset
    
    dataset = MicroDopplerDataset("/kaggle/working/data_split/train", split='train')
    sample = dataset[0]
    image = sample['image']
    
    print(f"å›¾åƒç»´åº¦: {image.shape}")
    print(f"å›¾åƒç±»å‹: {image.dtype}")
    print(f"å›¾åƒèŒƒå›´: [{image.min():.3f}, {image.max():.3f}]")
    
    assert image.shape == (3, 256, 256), f"ç»´åº¦é”™è¯¯: {image.shape}"
    print("âœ… æ•°æ®æµ‹è¯•é€šè¿‡")

def test_model():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("æµ‹è¯•æ¨¡å‹åŠ è½½...")
    from tokenizer.autoencoder import AutoencoderKL
    
    model = AutoencoderKL(
        embed_dim=32,
        ch_mult=(1, 1, 2, 2, 4),
        ckpt_path="/kaggle/working/pretrained/vavae-imagenet256-f16d32-dinov2.pt",
        model_type='vavae'
    )
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    dummy_input = torch.randn(1, 3, 256, 256)
    with torch.no_grad():
        output = model.encode(dummy_input)
    
    print("âœ… æ¨¡å‹æµ‹è¯•é€šè¿‡")

if __name__ == "__main__":
    test_data()
    test_model()
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
'''
    
    with open("simple_test.py", 'w', encoding='utf-8') as f:
        f.write(test_code)
    
    print("âœ… æµ‹è¯•è„šæœ¬åˆ›å»ºå®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹Kaggleå¿«é€Ÿä¿®å¤...")
    print("=" * 50)
    
    # æ£€æŸ¥å½“å‰ç›®å½•
    print(f"å½“å‰ç›®å½•: {os.getcwd()}")
    files = [f for f in os.listdir('.') if f.endswith('.py')]
    print(f"Pythonæ–‡ä»¶: {files}")
    
    # æ‰§è¡Œä¿®å¤
    fix_data_loading()
    fix_model_loading()
    create_simple_test()
    
    print("=" * 50)
    print("ğŸ¯ ä¿®å¤å®Œæˆï¼")
    print("ä¸‹ä¸€æ­¥:")
    print("1. è¿è¡Œæµ‹è¯•: python simple_test.py")
    print("2. å¦‚æœæµ‹è¯•é€šè¿‡ï¼Œè¿è¡Œè®­ç»ƒ: python minimal_training_modification.py ...")

if __name__ == "__main__":
    main()
