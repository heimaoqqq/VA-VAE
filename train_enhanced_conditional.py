#!/usr/bin/env python3
"""
è®­ç»ƒå¢å¼ºæ¡ä»¶æ‰©æ•£æ¨¡å‹çš„å®Œæ•´è„šæœ¬
æ•´åˆSimplifiedVAVAE + Enhanced Conditional Diffusion + å¹³è¡¡æ•°æ®åŠ è½½
"""

import torch
import torch.nn as nn
from pathlib import Path
import json
import argparse
from datetime import datetime
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from torchvision.utils import make_grid, save_image
from microdoppler_data_loader import (
    MicroDopplerLatentDataset, 
    BalancedBatchSampler,
    prepare_latent_dataset,
    create_balanced_dataloader
)
from enhanced_conditional_diffusion import EnhancedConditionalDiffusion
from simplified_vavae import SimplifiedVAVAE

def compute_latent_statistics(dataloader, device, max_batches=50):
    """
    è®¡ç®—è®­ç»ƒæ•°æ®çš„latentåˆ†å¸ƒç»Ÿè®¡
    Args:
        dataloader: æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
        max_batches: æœ€å¤§æ‰¹æ¬¡æ•°ï¼ˆé¿å…è®¡ç®—è¿‡ä¹…ï¼‰
    Returns:
        dict: {'mean': float, 'std': float, 'min': float, 'max': float}
    """
    print(f"   ğŸ” åˆ†æå‰{max_batches}ä¸ªæ‰¹æ¬¡çš„latentåˆ†å¸ƒ...")
    
    all_latents = []
    batch_count = 0
    
    for batch_idx, (latents, user_ids) in enumerate(dataloader):
        if batch_count >= max_batches:
            break
            
        latents = latents.to(device)
        all_latents.append(latents.cpu().flatten())
        batch_count += 1
        
        if batch_count % 10 == 0:
            print(f"   ğŸ“Š å·²å¤„ç† {batch_count}/{max_batches} æ‰¹æ¬¡...")
    
    # åˆå¹¶æ‰€æœ‰latentæ•°æ®
    all_latents = torch.cat(all_latents, dim=0)
    
    # è®¡ç®—ç»Ÿè®¡é‡
    latent_mean = all_latents.mean().item()
    latent_std = all_latents.std().item()
    latent_min = all_latents.min().item()
    latent_max = all_latents.max().item()
    
    print(f"   âœ… ç»Ÿè®¡å®Œæˆï¼šåˆ†æäº† {len(all_latents):,} ä¸ªlatentå€¼")
    
    return {
        'mean': latent_mean,
        'std': latent_std, 
        'min': latent_min,
        'max': latent_max
    }

def train_enhanced_diffusion(args):
    """è®­ç»ƒå¢å¼ºæ¡ä»¶æ‰©æ•£æ¨¡å‹"""
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    checkpoint_dir = output_dir / 'checkpoints'
    checkpoint_dir.mkdir(exist_ok=True)
    
    sample_dir = output_dir / 'samples'
    sample_dir.mkdir(exist_ok=True)
    
    # åˆå§‹åŒ–VAE
    vae_path = args.vae_checkpoint if hasattr(args, 'vae_checkpoint') else "/kaggle/input/stage3/vavae-stage3-epoch26-val_rec_loss0.0000.ckpt"
    vae = SimplifiedVAVAE(vae_path)
    vae.eval()
    vae.freeze()
    vae = vae.to(device)
    print(f"âœ… VAEåŠ è½½å®Œæˆï¼Œç¼©æ”¾å› å­: {vae.scale_factor}")
    vae.eval()
    
    # æ­¥éª¤2: æ™ºèƒ½æ£€æŸ¥å¹¶å‡†å¤‡latentæ•°æ®é›†
    latent_dir = Path(args.latent_dir)
    
    # æ£€æŸ¥latentæ•°æ®é›†æ˜¯å¦å·²ç»å­˜åœ¨ä¸”å®Œæ•´
    def check_latent_dataset_complete(latent_dir, split_file):
        """æ£€æŸ¥latentæ•°æ®é›†æ˜¯å¦å®Œæ•´"""
        if not latent_dir.exists():
            return False, "ç›®å½•ä¸å­˜åœ¨"
        
        if not (latent_dir / "train").exists() or not (latent_dir / "val").exists():
            return False, "ç¼ºå°‘trainæˆ–valå­ç›®å½•"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰latentæ–‡ä»¶
        train_files = list((latent_dir / "train").glob("*.pt"))
        val_files = list((latent_dir / "val").glob("*.pt"))
        
        if len(train_files) == 0 or len(val_files) == 0:
            return False, f"latentæ–‡ä»¶ä¸è¶³: train={len(train_files)}, val={len(val_files)}"
        
        return True, f"æ•°æ®é›†å®Œæ•´: train={len(train_files)}, val={len(val_files)} files"
    
    is_complete, status_msg = check_latent_dataset_complete(latent_dir, args.split_file)
    
    if not is_complete or args.prepare_latents:
        if args.prepare_latents:
            print("\nğŸ”„ å¼ºåˆ¶é‡æ–°å‡†å¤‡latentæ•°æ®é›†...")
        else:
            print(f"\nğŸ”„ æ•°æ®é›†ä¸å®Œæ•´({status_msg})ï¼Œå¼€å§‹å‡†å¤‡latentæ•°æ®é›†...")
            
        latent_dir = prepare_latent_dataset(
            image_dir=args.image_dir,
            vae_model=vae,
            output_dir=args.latent_dir,
            split_file=args.split_file,
            device=device
        )
    else:
        print(f"\nâœ… å‘ç°å®Œæ•´çš„latentæ•°æ®é›†: {status_msg}")
        print(f"   è·¯å¾„: {latent_dir}")
        print("   è·³è¿‡æ•°æ®é›†å‡†å¤‡æ­¥éª¤")
    
    # æ­¥éª¤3: åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader = create_balanced_dataloader(
        latent_dir=latent_dir,
        batch_size=args.batch_size,
        num_users_per_batch=args.num_users_per_batch,
        split='train',
        num_workers=args.num_workers
    )
    
    val_loader = create_balanced_dataloader(
        latent_dir=latent_dir,
        batch_size=args.batch_size,
        num_users_per_batch=args.num_users_per_batch,
        split='val',
        shuffle=False,
        num_workers=args.num_workers
    )
    
    # æ­¥éª¤3.5: è®¡ç®—è®­ç»ƒæ•°æ®çš„å®é™…latentåˆ†å¸ƒç»Ÿè®¡
    print("\nğŸ“Š è®¡ç®—è®­ç»ƒæ•°æ®latentåˆ†å¸ƒç»Ÿè®¡...")
    latent_stats = compute_latent_statistics(train_loader, device, max_batches=50)
    train_mean = latent_stats['mean']
    train_std = latent_stats['std']
    latent_min = latent_stats['min']
    latent_max = latent_stats['max']
    
    print(f"ğŸ“ˆ å®é™…è®­ç»ƒlatentåˆ†å¸ƒ:")
    print(f"   Mean: {train_mean:.6f}")
    print(f"   Std:  {train_std:.6f}")
    print(f"   Range: [{latent_min:.2f}, {latent_max:.2f}]")
    print(f"   3Ïƒ Range: [{train_mean-3*train_std:.2f}, {train_mean+3*train_std:.2f}]")
    
    # æ­¥éª¤4: åˆ›å»ºå¢å¼ºæ‰©æ•£æ¨¡å‹
    print("\nğŸš€ åˆ›å»ºå¢å¼ºæ¡ä»¶æ‰©æ•£æ¨¡å‹...")
    model = EnhancedConditionalDiffusion(
        vae=vae,
        num_users=args.num_users,
        prototype_dim=args.prototype_dim,
        latent_mean=latent_stats['mean'],
        latent_std=latent_stats['std']
    )
    
    # å…³é”®ä¿®å¤ï¼šä¼ é€’VAEå®ä¾‹ä»¥è·å–æ­£ç¡®çš„scale_factor
    model.vae = vae
    print(f"âœ… å·²å°†VAEå®ä¾‹ä¼ é€’ç»™æ‰©æ•£æ¨¡å‹ (scale_factor={vae.scale_factor})")
    
    # ğŸ”§ ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„è®­ç»ƒåˆ†å¸ƒ
    model.set_training_stats(latent_stats['mean'], latent_stats['std'])
    
    print(f"ğŸ“Š VAEé…ç½®: scale_factor={vae.scale_factor}")
    print(f"ğŸ¯ æ‰©æ•£æ¨¡å‹: num_users={args.num_users}, prototype_dim={args.prototype_dim}")
    print(f"ğŸ”‘ æ ‡å‡†åŒ–æ–¹æ³•: ç¼©æ”¾å› å­={model.scale_factor:.4f} (ç±»ä¼¼Stable Diffusion)")
    
    # æ­¥éª¤5: è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(), 
        lr=args.learning_rate,
        weight_decay=args.weight_decay
    )
    
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, 
        T_max=args.num_epochs
    )
    
    # æ­¥éª¤6: è®­ç»ƒå¾ªç¯
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    best_val_loss = float('inf')
    
    for epoch in range(args.num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_losses = {
            'total': 0.0,
            'diffusion': 0.0, 
            'contrastive': 0.0
        }
        
        train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{args.num_epochs}')
        for batch_idx, (latents, user_ids) in enumerate(train_bar):
            latents = latents.to(device)
            user_ids = user_ids.to(device)
            
            # ç¬¬ä¸€ä¸ªepochçš„ç¬¬ä¸€ä¸ªbatchæ˜¾ç¤ºlatentåˆ†å¸ƒä¿¡æ¯
            if epoch == 0 and batch_idx == 0:
                print(f"\nğŸ“Š è®­ç»ƒæ•°æ®Latentåˆ†å¸ƒç»Ÿè®¡:")
                print(f"   Shape: {latents.shape}")
                print(f"   Mean: {latents.mean():.6f}, Std: {latents.std():.6f}")
                print(f"   Range: [{latents.min():.2f}, {latents.max():.2f}]")
            
            # å‰å‘ä¼ æ’­
            losses = model.training_step(
                latents, user_ids, 
                support_ratio=args.support_ratio
            )
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            losses['total_loss'].backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            
            # æ›´æ–°ç»Ÿè®¡
            for key in train_losses:
                loss_key = f'{key}_loss' if key != 'total' else 'total_loss'
                train_losses[key] += losses[loss_key].item()
            
            # æ›´æ–°è¿›åº¦æ¡
            train_bar.set_postfix({
                'loss': losses['total_loss'].item(),
                'diff': losses['diffusion_loss'].item(),
                'cont': losses['contrastive_loss'].item()
            })
            
            # ä½¿ç”¨å‡å€¼ä½œä¸ºç”¨æˆ·åŸå‹ - ä¿®å¤å™ªå£°åˆå§‹åŒ–æ›´æ–°ï¼ˆåœ¨epochç»“æŸæ—¶ç»Ÿä¸€æ›´æ–°æ›´é«˜æ•ˆï¼‰
            # if batch_idx % args.prototype_update_freq == 0:
            #     update_user_prototypes(model, train_loader, device)
        
        # è®¡ç®—å¹³å‡æŸå¤±
        num_batches = len(train_loader)
        for key in train_losses:
            train_losses[key] /= num_batches
        
        # åœ¨epochç»“æŸæ—¶æ›´æ–°ç”¨æˆ·åŸå‹ï¼ˆæ›´é«˜æ•ˆï¼‰
        if (epoch + 1) % 5 == 0:  # æ¯5ä¸ªepochæ›´æ–°ä¸€æ¬¡
            print("   ğŸ”„ æ›´æ–°ç”¨æˆ·åŸå‹...")
            update_user_prototypes(model, train_loader, device)
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_losses = {'total': 0.0, 'diffusion': 0.0, 'contrastive': 0.0}
        
        with torch.no_grad():
            for latents, user_ids in val_loader:
                latents = latents.to(device)
                user_ids = user_ids.to(device)
                
                losses = model.training_step(latents, user_ids)
                
                for key in val_losses:
                    loss_key = f'{key}_loss' if key != 'total' else 'total_loss'
                    loss_value = losses[loss_key]
                    # å¤„ç†å¯èƒ½å·²ç»æ˜¯floatçš„æƒ…å†µ
                    if hasattr(loss_value, 'item'):
                        val_losses[key] += loss_value.item()
                    else:
                        val_losses[key] += float(loss_value)
        
        for key in val_losses:
            val_losses[key] /= len(val_loader)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        
        # æ‰“å°epochæ€»ç»“
        print(f"\nğŸ“Š Epoch {epoch+1} Summary:")
        print(f"   Train Loss: {train_losses['total']:.4f} "
              f"(Diff: {train_losses['diffusion']:.4f}, "
              f"Cont: {train_losses['contrastive']:.4f})")
        print(f"   Val Loss: {val_losses['total']:.4f} "
              f"(Diff: {val_losses['diffusion']:.4f}, "
              f"Cont: {val_losses['contrastive']:.4f})")
        print(f"   LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_losses['total'] < best_val_loss:
            best_val_loss = val_losses['total']
            save_path = checkpoint_dir / 'best_model.pth'
            
            # åˆ é™¤æ—§çš„æœ€ä½³æ¨¡å‹
            if save_path.exists():
                save_path.unlink()
                print(f"   ğŸ—‘ï¸ åˆ é™¤æ—§çš„æœ€ä½³æ¨¡å‹")
            
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'train_losses': train_losses,
                'val_losses': val_losses,
                'user_prototypes': model.user_prototypes,
                'best_val_loss': best_val_loss
            }, save_path)
            print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: {save_path} (Val Loss: {best_val_loss:.4f})")
        
        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % args.save_freq == 0:
            save_path = checkpoint_dir / f'checkpoint_epoch_{epoch+1}.pth'
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'train_losses': train_losses,
                'val_losses': val_losses,
                'user_prototypes': model.user_prototypes
            }, save_path)
        
        # æ¯ä¸ªepochéƒ½ç”Ÿæˆ4x4æ ·æœ¬ç½‘æ ¼
        generate_samples(model, vae, epoch+1, sample_dir, device, args.num_users)
    
    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    return model


def update_user_prototypes(model, dataloader, device):
    """æ›´æ–°ç”¨æˆ·åŸå‹"""
    user_latents = {}
    
    with torch.no_grad():
        for latents, user_ids in dataloader:
            latents = latents.to(device)
            
            for i, user_id in enumerate(user_ids):
                user_id = user_id.item()
                if user_id not in user_latents:
                    user_latents[user_id] = []
                user_latents[user_id].append(latents[i:i+1])
    
    # åˆå¹¶æ¯ä¸ªç”¨æˆ·çš„latents
    for user_id in user_latents:
        user_latents[user_id] = torch.cat(user_latents[user_id], dim=0)
    
    # æ›´æ–°æ¨¡å‹ä¸­çš„åŸå‹
    model.update_user_prototypes(user_latents)


def generate_samples(model, vae, epoch, sample_dir, device, num_users):
    """ç”Ÿæˆå¹¶ä¿å­˜æ ·æœ¬"""
    print(f"\nğŸ¨ ç”Ÿæˆæ ·æœ¬ (Epoch {epoch+1})...")
    
    # é€‰æ‹©å‡ ä¸ªç”¨æˆ·ç”Ÿæˆ
    sample_users = list(range(min(4, num_users)))
    
    # ç”Ÿæˆlatents
    with torch.no_grad():
        latents = model.generate(
            user_ids=sample_users,
            num_samples_per_user=4,
            num_inference_steps=100,  # ä½¿ç”¨100æ­¥ç¡®ä¿ç”Ÿæˆè´¨é‡
            guidance_scale=4.0,       # ä½¿ç”¨æ ‡å‡†CFGå¼ºåº¦
            use_ddim=True
        )
        
        # å…³é”®åˆ†å¸ƒéªŒè¯ä¿¡æ¯
        print(f"ğŸ“Š ç”Ÿæˆlatentåˆ†å¸ƒ: mean={latents.mean():.4f}, std={latents.std():.4f}")
        print(f"   âœ… ä¿®å¤éªŒè¯: æœŸæœ›stdâ‰ˆ1.54 {'âœ…' if abs(latents.std() - 1.54) < 0.3 else 'âŒ'}")
        
        # è§£ç åˆ°å›¾åƒ
        print(f"ğŸ¨ è§£ç  {len(latents)} ä¸ªlatentåˆ°å›¾åƒ...")
        images = []
        for i in range(0, len(latents), 8):
            batch = latents[i:i+8]
            decoded = vae.decode(batch)
            images.append(decoded)
        
        images = torch.cat(images, dim=0)
    
    # æ£€æŸ¥å›¾åƒå€¼èŒƒå›´
    print(f"ğŸ” è§£ç å›¾åƒèŒƒå›´: min={images.min():.3f}, max={images.max():.3f}")
    print(f"ğŸ” å›¾åƒå½¢çŠ¶: {images.shape}")
    print(f"ğŸ” latentèŒƒå›´: min={latents.min():.3f}, max={latents.max():.3f}, std={latents.std():.3f}")
    
    # SimplifiedVAVAE.decode()å·²ç»è¾“å‡º[0,1]èŒƒå›´ï¼Œæ— éœ€å†å¤„ç†
    # åªéœ€ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
    if images.max() > 1.1 or images.min() < -0.1:
        print(f"âš ï¸ å›¾åƒå€¼è¶…å‡ºé¢„æœŸèŒƒå›´ï¼Œè¿›è¡Œè£å‰ª")
        images = torch.clamp(images, 0, 1)
    else:
        print("âœ… å›¾åƒå·²åœ¨[0,1]èŒƒå›´ï¼Œæ— éœ€å¤„ç†")
    
    # ä¿å­˜å›¾åƒç½‘æ ¼
    grid = make_grid(images, nrow=4, normalize=False, value_range=(0, 1))
    save_path = sample_dir / f'samples_epoch_{epoch:04d}.png'
    save_image(grid, save_path)
    
    print(f"   âœ… æ ·æœ¬å·²ä¿å­˜: {save_path}")


def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒå¢å¼ºæ¡ä»¶æ‰©æ•£æ¨¡å‹')
    
    # æ•°æ®ç›¸å…³
    parser.add_argument('--image_dir', type=str, default='/kaggle/input/microdoppler',
                      help='åŸå§‹å›¾åƒç›®å½•')
    parser.add_argument('--latent_dir', type=str, default='/kaggle/working/latents',
                      help='Latentæ•°æ®ç›®å½•')
    parser.add_argument('--split_file', type=str, default='/kaggle/working/dataset_split.json',
                      help='æ•°æ®åˆ’åˆ†æ–‡ä»¶')
    parser.add_argument('--prepare_latents', action='store_true', 
                       help='å‡†å¤‡latentæ•°æ®é›†ï¼ˆå¦‚æœéœ€è¦ï¼‰')
    # UNetæ–¹æ³•ï¼šä½¿ç”¨ç®€åŒ–çš„åŒ¹é…è®­ç»ƒåˆ†å¸ƒæ–¹æ¡ˆ
    
    parser.add_argument('--vae_checkpoint', type=str, 
                      default='/kaggle/input/stage3/vavae-stage3-epoch26-val_rec_loss0.0000.ckpt',
                      help='VA-VAEæ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--num_users', type=int, default=31,
                      help='ç”¨æˆ·æ•°é‡')
    parser.add_argument('--prototype_dim', type=int, default=768,
                      help='åŸå‹ç»´åº¦')
    
    # è®­ç»ƒç›¸å…³
    parser.add_argument('--num_epochs', type=int, default=100,
                      help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32,
                      help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_users_per_batch', type=int, default=4,
                      help='æ¯æ‰¹ç”¨æˆ·æ•°')
    parser.add_argument('--support_ratio', type=float, default=0.3,
                      help='Support setæ¯”ä¾‹')
    parser.add_argument('--learning_rate', type=float, default=1e-4,
                      help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-5,
                      help='æƒé‡è¡°å‡')
    parser.add_argument('--num_workers', type=int, default=2,
                      help='æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°')
    
    # å…¶ä»–
    parser.add_argument('--output_dir', type=str, 
                      default='/kaggle/working/enhanced_diffusion',
                      help='è¾“å‡ºç›®å½•')
    parser.add_argument('--save_freq', type=int, default=10,
                      help='ä¿å­˜æ£€æŸ¥ç‚¹é¢‘ç‡')
    parser.add_argument('--sample_freq', type=int, default=5,
                      help='ç”Ÿæˆæ ·æœ¬é¢‘ç‡')
    parser.add_argument('--prototype_update_freq', type=int, default=50,
                      help='åŸå‹æ›´æ–°é¢‘ç‡ï¼ˆæ‰¹æ¬¡ï¼‰')
    parser.add_argument('--seed', type=int, default=42,
                      help='éšæœºç§å­')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # è®­ç»ƒæ¨¡å‹
    model = train_enhanced_diffusion(args)
    
    print("\nâœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
