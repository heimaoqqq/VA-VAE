#!/usr/bin/env python3
"""
è®­ç»ƒå¢å¼ºæ¡ä»¶æ‰©æ•£æ¨¡å‹çš„å®Œæ•´è„šæœ¬
æ•´åˆSimplifiedVAVAE + Enhanced Conditional Diffusion + å¹³è¡¡æ•°æ®åŠ è½½
"""

import torch
import torch.nn as nn
from pathlib import Path
import json
import argparse
from datetime import datetime
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from torchvision.utils import save_image, make_grid

from simplified_vavae import SimplifiedVAVAE
from enhanced_conditional_diffusion import EnhancedConditionalDiffusion
from microdoppler_data_loader import (
    create_balanced_dataloader, 
    prepare_latent_dataset
)


def train_enhanced_diffusion(args):
    """è®­ç»ƒå¢å¼ºæ¡ä»¶æ‰©æ•£æ¨¡å‹"""
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”¥ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    checkpoint_dir = output_dir / 'checkpoints'
    checkpoint_dir.mkdir(exist_ok=True)
    
    sample_dir = output_dir / 'samples'
    sample_dir.mkdir(exist_ok=True)
    
    # æ­¥éª¤1: å‡†å¤‡VAEå’Œlatentæ•°æ®
    print("\nğŸ“¦ åŠ è½½VA-VAEæ¨¡å‹...")
    vae = SimplifiedVAVAE(args.vae_checkpoint)
    vae = vae.to(device)
    vae.eval()
    
    # æ­¥éª¤2: å‡†å¤‡latentæ•°æ®é›†ï¼ˆå¦‚æœéœ€è¦ï¼‰
    latent_dir = Path(args.latent_dir)
    if not latent_dir.exists() or args.prepare_latents:
        print("\nğŸ”„ å‡†å¤‡latentæ•°æ®é›†...")
        latent_dir = prepare_latent_dataset(
            image_dir=args.image_dir,
            vae_model=vae,
            output_dir=args.latent_dir,
            split_file=args.split_file,
            device=device
        )
    
    # æ­¥éª¤3: åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader = create_balanced_dataloader(
        latent_dir=latent_dir,
        batch_size=args.batch_size,
        num_users_per_batch=args.num_users_per_batch,
        split='train',
        num_workers=args.num_workers
    )
    
    val_loader = create_balanced_dataloader(
        latent_dir=latent_dir,
        batch_size=args.batch_size,
        num_users_per_batch=args.num_users_per_batch,
        split='val',
        shuffle=False,
        num_workers=args.num_workers
    )
    
    # æ­¥éª¤4: åˆ›å»ºå¢å¼ºæ‰©æ•£æ¨¡å‹
    print("\nğŸš€ åˆ›å»ºå¢å¼ºæ¡ä»¶æ‰©æ•£æ¨¡å‹...")
    model = EnhancedConditionalDiffusion(
        num_users=args.num_users,
        prototype_dim=args.prototype_dim
    )
    model = model.to(device)
    
    # æ­¥éª¤5: è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(), 
        lr=args.learning_rate,
        weight_decay=args.weight_decay
    )
    
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, 
        T_max=args.num_epochs
    )
    
    # æ­¥éª¤6: è®­ç»ƒå¾ªç¯
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    best_val_loss = float('inf')
    
    for epoch in range(args.num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_losses = {
            'total': 0.0,
            'diffusion': 0.0, 
            'contrastive': 0.0
        }
        
        train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{args.num_epochs}')
        for batch_idx, (latents, user_ids) in enumerate(train_bar):
            latents = latents.to(device)
            user_ids = user_ids.to(device)
            
            # å‰å‘ä¼ æ’­
            losses = model.training_step(
                latents, user_ids, 
                support_ratio=args.support_ratio
            )
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            losses['total_loss'].backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            
            # æ›´æ–°ç»Ÿè®¡
            for key in train_losses:
                loss_key = f'{key}_loss' if key != 'total' else 'total_loss'
                train_losses[key] += losses[loss_key].item()
            
            # æ›´æ–°è¿›åº¦æ¡
            train_bar.set_postfix({
                'loss': losses['total_loss'].item(),
                'diff': losses['diffusion_loss'].item(),
                'cont': losses['contrastive_loss'].item()
            })
            
            # å®šæœŸæ›´æ–°ç”¨æˆ·åŸå‹
            if batch_idx % args.prototype_update_freq == 0:
                update_user_prototypes(model, train_loader, device)
        
        # è®¡ç®—å¹³å‡æŸå¤±
        num_batches = len(train_loader)
        for key in train_losses:
            train_losses[key] /= num_batches
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_losses = {'total': 0.0, 'diffusion': 0.0, 'contrastive': 0.0}
        
        with torch.no_grad():
            for latents, user_ids in val_loader:
                latents = latents.to(device)
                user_ids = user_ids.to(device)
                
                losses = model.training_step(latents, user_ids)
                
                for key in val_losses:
                    loss_key = f'{key}_loss' if key != 'total' else 'total_loss'
                    val_losses[key] += losses[loss_key].item()
        
        for key in val_losses:
            val_losses[key] /= len(val_loader)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        
        # æ‰“å°epochæ€»ç»“
        print(f"\nğŸ“Š Epoch {epoch+1} Summary:")
        print(f"   Train Loss: {train_losses['total']:.4f} "
              f"(Diff: {train_losses['diffusion']:.4f}, "
              f"Cont: {train_losses['contrastive']:.4f})")
        print(f"   Val Loss: {val_losses['total']:.4f} "
              f"(Diff: {val_losses['diffusion']:.4f}, "
              f"Cont: {val_losses['contrastive']:.4f})")
        print(f"   LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_losses['total'] < best_val_loss:
            best_val_loss = val_losses['total']
            save_path = checkpoint_dir / 'best_model.pth'
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'train_losses': train_losses,
                'val_losses': val_losses,
                'user_prototypes': model.user_prototypes
            }, save_path)
            print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹: {save_path}")
        
        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % args.save_freq == 0:
            save_path = checkpoint_dir / f'checkpoint_epoch_{epoch+1}.pth'
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'train_losses': train_losses,
                'val_losses': val_losses,
                'user_prototypes': model.user_prototypes
            }, save_path)
        
        # ç”Ÿæˆæ ·æœ¬
        if (epoch + 1) % args.sample_freq == 0:
            generate_samples(model, vae, epoch+1, sample_dir, device, args.num_users)
    
    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    return model


def update_user_prototypes(model, dataloader, device):
    """æ›´æ–°ç”¨æˆ·åŸå‹"""
    user_latents = {}
    
    with torch.no_grad():
        for latents, user_ids in dataloader:
            latents = latents.to(device)
            
            for i, user_id in enumerate(user_ids):
                user_id = user_id.item()
                if user_id not in user_latents:
                    user_latents[user_id] = []
                user_latents[user_id].append(latents[i:i+1])
    
    # åˆå¹¶æ¯ä¸ªç”¨æˆ·çš„latents
    for user_id in user_latents:
        user_latents[user_id] = torch.cat(user_latents[user_id], dim=0)
    
    # æ›´æ–°æ¨¡å‹ä¸­çš„åŸå‹
    model.update_user_prototypes(user_latents)


def generate_samples(model, vae, epoch, sample_dir, device, num_users):
    """ç”Ÿæˆå¹¶ä¿å­˜æ ·æœ¬"""
    print(f"\nğŸ¨ ç”Ÿæˆæ ·æœ¬ (Epoch {epoch})...")
    
    # é€‰æ‹©å‡ ä¸ªç”¨æˆ·ç”Ÿæˆ
    sample_users = list(range(min(4, num_users)))
    
    # ç”Ÿæˆlatents
    with torch.no_grad():
        latents = model.generate(
            user_ids=sample_users,
            num_samples_per_user=4,
            num_inference_steps=100,
            guidance_scale=2.0,
            use_ddim=True
        )
        
        # è§£ç åˆ°å›¾åƒ
        images = []
        for i in range(0, len(latents), 8):
            batch = latents[i:i+8]
            decoded = vae.decode(batch)
            images.append(decoded)
        
        images = torch.cat(images, dim=0)
    
    # ä¿å­˜å›¾åƒç½‘æ ¼
    grid = make_grid(images, nrow=4, normalize=True, value_range=(0, 1))
    save_path = sample_dir / f'samples_epoch_{epoch:04d}.png'
    save_image(grid, save_path)
    
    print(f"   âœ… æ ·æœ¬å·²ä¿å­˜: {save_path}")


def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒå¢å¼ºæ¡ä»¶æ‰©æ•£æ¨¡å‹')
    
    # æ•°æ®ç›¸å…³
    parser.add_argument('--image_dir', type=str, default='/kaggle/input/microdoppler',
                      help='åŸå§‹å›¾åƒç›®å½•')
    parser.add_argument('--latent_dir', type=str, default='/kaggle/working/latents',
                      help='Latentæ•°æ®ç›®å½•')
    parser.add_argument('--split_file', type=str, default='/kaggle/working/data_split.json',
                      help='æ•°æ®åˆ’åˆ†æ–‡ä»¶')
    parser.add_argument('--prepare_latents', action='store_true',
                      help='æ˜¯å¦å‡†å¤‡latentæ•°æ®é›†')
    
    # æ¨¡å‹ç›¸å…³
    parser.add_argument('--vae_checkpoint', type=str, 
                      default='/kaggle/working/checkpoints/va_vae_final.ckpt',
                      help='VA-VAEæ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--num_users', type=int, default=31,
                      help='ç”¨æˆ·æ•°é‡')
    parser.add_argument('--prototype_dim', type=int, default=256,
                      help='åŸå‹ç»´åº¦')
    
    # è®­ç»ƒç›¸å…³
    parser.add_argument('--num_epochs', type=int, default=100,
                      help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32,
                      help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_users_per_batch', type=int, default=4,
                      help='æ¯æ‰¹ç”¨æˆ·æ•°')
    parser.add_argument('--support_ratio', type=float, default=0.3,
                      help='Support setæ¯”ä¾‹')
    parser.add_argument('--learning_rate', type=float, default=1e-4,
                      help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-5,
                      help='æƒé‡è¡°å‡')
    parser.add_argument('--num_workers', type=int, default=2,
                      help='æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°')
    
    # å…¶ä»–
    parser.add_argument('--output_dir', type=str, 
                      default='/kaggle/working/enhanced_diffusion',
                      help='è¾“å‡ºç›®å½•')
    parser.add_argument('--save_freq', type=int, default=10,
                      help='ä¿å­˜æ£€æŸ¥ç‚¹é¢‘ç‡')
    parser.add_argument('--sample_freq', type=int, default=5,
                      help='ç”Ÿæˆæ ·æœ¬é¢‘ç‡')
    parser.add_argument('--prototype_update_freq', type=int, default=50,
                      help='åŸå‹æ›´æ–°é¢‘ç‡ï¼ˆæ‰¹æ¬¡ï¼‰')
    parser.add_argument('--seed', type=int, default=42,
                      help='éšæœºç§å­')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    
    # è®­ç»ƒæ¨¡å‹
    model = train_enhanced_diffusion(args)
    
    print("\nâœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
