"""
æœ€å°åŒ–å¾®å¤šæ™®å‹’æ•°æ®é›† - ç›´æ¥é€‚é…LightningDiT
ä»…åšå¿…è¦çš„æ•°æ®åŠ è½½ï¼Œä¸åšä»»ä½•æ•°æ®å¢å¼º
"""

import os
import numpy as np
import torch
from torch.utils.data import Dataset
from pathlib import Path
from PIL import Image


class MicroDopplerDataset(Dataset):
    """
    æœ€ç®€å•çš„å¾®å¤šæ™®å‹’æ•°æ®é›†ç±»
    ç›´æ¥é€‚é…LightningDiTçš„æ•°æ®æ ¼å¼è¦æ±‚
    æ”¯æŒæ•°æ®é›†åˆ’åˆ†
    """

    def __init__(self, data_dir, img_size=256, split='train', original_structure=False):
        """
        åˆå§‹åŒ–æ•°æ®é›†

        Args:
            data_dir: æ•°æ®ç›®å½•ï¼Œå¯ä»¥æ˜¯åŸå§‹ç›®å½•æˆ–åˆ’åˆ†åçš„ç›®å½•
            img_size: å›¾åƒå°ºå¯¸ (LightningDiTé»˜è®¤256)
            split: æ•°æ®é›†åˆ’åˆ† ('train', 'val', 'test', 'all')
            original_structure: æ˜¯å¦æ˜¯åŸå§‹çš„ID_1, ID_2...ç»“æ„
        """
        self.data_dir = Path(data_dir)
        self.img_size = img_size
        self.split = split
        self.original_structure = original_structure

        # æ ¹æ®splitç¡®å®šæ•°æ®ç›®å½•
        if split in ['train', 'val', 'test'] and not original_structure:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åˆ’åˆ†åçš„ç›®å½•
            split_dir = self.data_dir / split
            if split_dir.exists():
                scan_dir = split_dir
                print(f"ä½¿ç”¨åˆ’åˆ†åçš„æ•°æ®: {scan_dir}")
            else:
                scan_dir = self.data_dir
                print(f"æœªæ‰¾åˆ°åˆ’åˆ†ç›®å½•ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {scan_dir}")
        else:
            scan_dir = self.data_dir

        # æ‰«ææ•°æ®æ–‡ä»¶
        self.data_files = []

        if original_structure:
            # åŸå§‹ç»“æ„: ID_1/, ID_2/, ..., ID_31/
            self._scan_original_structure(scan_dir)
        else:
            # åˆ’åˆ†åç»“æ„: train/, val/, test/ åŒ…å«é‡å‘½åçš„æ–‡ä»¶
            self._scan_split_structure(scan_dir)

        print(f"åŠ è½½äº† {len(self.data_files)} ä¸ªå¾®å¤šæ™®å‹’æ ·æœ¬ (split: {split})")
        
        # ç»Ÿè®¡ç”¨æˆ·ä¿¡æ¯
        self.user_ids = sorted(list(set(item['user_id'] for item in self.data_files)))
        self.num_users = len(self.user_ids)
        print(f"ç”¨æˆ·æ•°é‡: {self.num_users}, ç”¨æˆ·ID: {self.user_ids}")

    def _scan_original_structure(self, scan_dir):
        """æ‰«æåŸå§‹ID_1, ID_2...ç»“æ„"""
        image_extensions = ['png', 'jpg', 'jpeg', 'bmp', 'tiff']

        for user_dir in scan_dir.iterdir():
            if user_dir.is_dir() and user_dir.name.startswith('ID_'):
                try:
                    # è§£æç”¨æˆ·ID: ID_1 -> 1, ID_2 -> 2, ...
                    user_id = int(user_dir.name.split('_')[1])

                    # æ‰«æè¯¥ç”¨æˆ·ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾åƒæ–‡ä»¶
                    sample_id = 1
                    for ext in image_extensions:
                        for file_path in sorted(user_dir.glob(f"*.{ext}")):
                            self.data_files.append({
                                'file_path': str(file_path),
                                'user_id': user_id,
                                'sample_id': sample_id
                            })
                            sample_id += 1

                except (ValueError, IndexError):
                    print(f"è­¦å‘Š: æ— æ³•è§£æç›®å½•å {user_dir.name}")

    def _scan_split_structure(self, scan_dir):
        """æ‰«æåˆ’åˆ†åçš„ç»“æ„"""
        # æ‰«ææ‰€æœ‰å›¾åƒæ–‡ä»¶ï¼ˆå‡è®¾å·²ç»é‡å‘½åä¸ºuser_XX_sample_XXXæ ¼å¼ï¼‰
        image_extensions = ['png', 'jpg', 'jpeg', 'bmp', 'tiff', 'npy']

        for ext in image_extensions:
            for file_path in scan_dir.glob(f"*.{ext}"):
                # è§£ææ–‡ä»¶å: user_XX_sample_XXX.ext
                parts = file_path.stem.split('_')
                if len(parts) >= 4 and parts[0] == 'user':
                    try:
                        user_id = int(parts[1])
                        sample_id = int(parts[3])
                        self.data_files.append({
                            'file_path': str(file_path),
                            'user_id': user_id,
                            'sample_id': sample_id
                        })
                    except ValueError:
                        print(f"è­¦å‘Š: æ— æ³•è§£ææ–‡ä»¶å {file_path.name}")
    
    def __len__(self):
        return len(self.data_files)
    
    def __getitem__(self, idx):
        """
        è·å–æ•°æ®é¡¹ - ä¿æŒLightningDiTçš„æ•°æ®æ ¼å¼
        
        Returns:
            dict: {
                'image': torch.Tensor,  # (3, H, W) - LightningDiTæœŸæœ›çš„æ ¼å¼
                'user_id': int         # ç”¨æˆ·ID - æ–°å¢çš„æ¡ä»¶ä¿¡æ¯
            }
        """
        item = self.data_files[idx]

        # åŠ è½½æ—¶é¢‘å›¾æ•°æ®
        file_path = Path(item['file_path'])

        if file_path.suffix.lower() == '.npy':
            # NumPyæ–‡ä»¶
            spectrogram = np.load(file_path)
        else:
            # å›¾åƒæ–‡ä»¶
            from PIL import Image
            pil_img = Image.open(file_path)
            spectrogram = np.array(pil_img)
        
        # é¢„å¤„ç†: è°ƒæ•´å°ºå¯¸åˆ°ç›®æ ‡å¤§å°
        if spectrogram.shape != (self.img_size, self.img_size):
            # ä½¿ç”¨PILè¿›è¡Œå°ºå¯¸è°ƒæ•´
            if spectrogram.ndim == 2:
                # è½¬æ¢ä¸ºPILå›¾åƒ
                # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´
                spec_norm = ((spectrogram - spectrogram.min()) / 
                           (spectrogram.max() - spectrogram.min()) * 255).astype(np.uint8)
                pil_img = Image.fromarray(spec_norm, mode='L')
                pil_img = pil_img.resize((self.img_size, self.img_size), Image.LANCZOS)
                spectrogram = np.array(pil_img).astype(np.float32) / 255.0
        
        # è°ƒè¯•ä¿¡æ¯ï¼šåªåœ¨ç¬¬ä¸€æ¬¡åŠ è½½æ—¶æ˜¾ç¤º
        if not hasattr(self, '_debug_printed'):
            print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯ - å›¾åƒå°ºå¯¸: {spectrogram.shape}, æ•°æ®ç±»å‹: {spectrogram.dtype}")
            self._debug_printed = True

        # è½¬æ¢ä¸º3é€šé“ (LightningDiTæœŸæœ›RGBæ ¼å¼)
        if spectrogram.ndim == 2:
            # ç°åº¦ -> RGB: å¤åˆ¶3æ¬¡ï¼Œæ ¼å¼ä¸º (3, H, W)
            spectrogram = np.stack([spectrogram, spectrogram, spectrogram], axis=0)
        elif spectrogram.ndim == 3:
            if spectrogram.shape[2] == 3:
                # (H, W, 3) -> (3, H, W) - RGBå›¾åƒ
                spectrogram = np.transpose(spectrogram, (2, 0, 1))
            elif spectrogram.shape[2] == 1:
                # (H, W, 1) -> (3, H, W) - å•é€šé“å›¾åƒ
                spectrogram = spectrogram.squeeze(2)
                spectrogram = np.stack([spectrogram, spectrogram, spectrogram], axis=0)
            elif spectrogram.shape[0] == 1:
                # (1, H, W) -> (3, H, W)
                spectrogram = np.repeat(spectrogram, 3, axis=0)
            elif spectrogram.shape[0] == 3:
                # å·²ç»æ˜¯ (3, H, W) æ ¼å¼ï¼Œæ— éœ€è½¬æ¢
                pass
            else:
                # å…¶ä»–æƒ…å†µï¼Œå¼ºåˆ¶è½¬æ¢ä¸º (3, H, W)
                if spectrogram.shape[0] != 3:
                    # å–ç¬¬ä¸€ä¸ªé€šé“å¹¶å¤åˆ¶3æ¬¡
                    if len(spectrogram.shape) == 3:
                        spectrogram = spectrogram[0]  # å–ç¬¬ä¸€ä¸ªé€šé“
                    spectrogram = np.stack([spectrogram, spectrogram, spectrogram], axis=0)

        # ç¡®ä¿æ•°æ®èŒƒå›´åœ¨[0, 1]
        if spectrogram.max() > 1.0:
            spectrogram = spectrogram / 255.0

        # è½¬æ¢ä¸ºtensorï¼Œç¡®ä¿ç»´åº¦ä¸º (C, H, W)
        image_tensor = torch.from_numpy(spectrogram).float()

        # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿å¼ é‡ç»´åº¦æ­£ç¡®
        if image_tensor.dim() == 3 and image_tensor.shape[0] != 3:
            # å¦‚æœç¬¬ä¸€ä¸ªç»´åº¦ä¸æ˜¯3ï¼Œè¿›è¡Œè½¬æ¢
            if image_tensor.shape[2] == 3:
                image_tensor = image_tensor.permute(2, 0, 1)  # (H, W, C) -> (C, H, W)

        # éªŒè¯æœ€ç»ˆç»´åº¦
        try:
            assert image_tensor.dim() == 3, f"æœŸæœ›3ç»´å¼ é‡ï¼Œå¾—åˆ°{image_tensor.dim()}ç»´"
            assert image_tensor.shape[0] == 3, f"æœŸæœ›3ä¸ªé€šé“ï¼Œå¾—åˆ°{image_tensor.shape[0]}ä¸ªé€šé“"
            assert image_tensor.shape[1] == self.img_size, f"æœŸæœ›é«˜åº¦{self.img_size}ï¼Œå¾—åˆ°{image_tensor.shape[1]}"
            assert image_tensor.shape[2] == self.img_size, f"æœŸæœ›å®½åº¦{self.img_size}ï¼Œå¾—åˆ°{image_tensor.shape[2]}"
        except AssertionError as e:
            print(f"âŒ ç»´åº¦éªŒè¯å¤±è´¥: {e}")
            print(f"âŒ å®é™…å¼ é‡å½¢çŠ¶: {image_tensor.shape}")
            raise

        # æœ€ç»ˆéªŒè¯ä¿¡æ¯ï¼ˆåªæ˜¾ç¤ºä¸€æ¬¡ï¼‰
        if not hasattr(self, '_final_debug_printed'):
            print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ - è¾“å‡ºç»´åº¦: {image_tensor.shape}, æ•°å€¼èŒƒå›´: [{image_tensor.min():.3f}, {image_tensor.max():.3f}]")
            self._final_debug_printed = True

        return {
            'image': image_tensor,      # LightningDiTæœŸæœ›çš„é”®å
            'user_id': item['user_id']  # æ–°å¢çš„ç”¨æˆ·æ¡ä»¶
        }


def create_micro_doppler_dataloader(data_dir, batch_size=32, shuffle=True, num_workers=4, split='train', original_structure=False):
    """
    åˆ›å»ºå¾®å¤šæ™®å‹’æ•°æ®åŠ è½½å™¨ - ç›´æ¥æ›¿æ¢LightningDiTçš„æ•°æ®åŠ è½½å™¨

    Args:
        data_dir: æ•°æ®ç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°
        shuffle: æ˜¯å¦æ‰“ä¹±
        num_workers: å·¥ä½œè¿›ç¨‹æ•°
        split: æ•°æ®é›†åˆ’åˆ†
        original_structure: æ˜¯å¦æ˜¯åŸå§‹çš„ID_1, ID_2...ç»“æ„

    Returns:
        DataLoader: å¯ç›´æ¥ç”¨äºLightningDiTè®­ç»ƒçš„æ•°æ®åŠ è½½å™¨
        num_users: ç”¨æˆ·æ•°é‡
    """
    dataset = MicroDopplerDataset(data_dir, split=split, original_structure=original_structure)

    dataloader = torch.utils.data.DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True  # LightningDiTé€šå¸¸éœ€è¦å›ºå®šæ‰¹æ¬¡å¤§å°
    )

    return dataloader, dataset.num_users


def create_split_dataloaders(data_dir, batch_size=32, num_workers=4):
    """
    åˆ›å»ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•æ•°æ®åŠ è½½å™¨

    Args:
        data_dir: æ•°æ®ç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: å·¥ä½œè¿›ç¨‹æ•°

    Returns:
        train_loader, val_loader, test_loader, num_users
    """
    train_loader, num_users = create_micro_doppler_dataloader(
        data_dir, batch_size, shuffle=True, num_workers=num_workers, split='train'
    )
    val_loader, _ = create_micro_doppler_dataloader(
        data_dir, batch_size, shuffle=False, num_workers=num_workers, split='val'
    )
    test_loader, _ = create_micro_doppler_dataloader(
        data_dir, batch_size, shuffle=False, num_workers=num_workers, split='test'
    )

    return train_loader, val_loader, test_loader, num_users


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®é›†
    data_dir = "data/processed"  # æ‚¨çš„æ•°æ®ç›®å½•
    
    if os.path.exists(data_dir):
        dataset = MicroDopplerDataset(data_dir)
        
        print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
        print(f"ç”¨æˆ·æ•°é‡: {dataset.num_users}")
        
        # æµ‹è¯•åŠ è½½ä¸€ä¸ªæ ·æœ¬
        sample = dataset[0]
        print(f"å›¾åƒå½¢çŠ¶: {sample['image'].shape}")
        print(f"ç”¨æˆ·ID: {sample['user_id']}")
        print(f"æ•°å€¼èŒƒå›´: [{sample['image'].min():.3f}, {sample['image'].max():.3f}]")
        
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataloader, num_users = create_micro_doppler_dataloader(data_dir, batch_size=4)
        batch = next(iter(dataloader))
        print(f"æ‰¹æ¬¡å›¾åƒå½¢çŠ¶: {batch['image'].shape}")
        print(f"æ‰¹æ¬¡ç”¨æˆ·ID: {batch['user_id']}")
    else:
        print(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("è¯·å°†æ‚¨çš„å¾®å¤šæ™®å‹’æ•°æ®æ”¾åœ¨è¯¥ç›®å½•ä¸‹ï¼Œæ–‡ä»¶åæ ¼å¼: user_XX_sample_XXX.npy")
