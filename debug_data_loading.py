#!/usr/bin/env python3
"""
è°ƒè¯•æ•°æ®åŠ è½½é—®é¢˜çš„è„šæœ¬
"""

import torch
import numpy as np
from pathlib import Path
import sys
import os

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½å’Œç»´åº¦è½¬æ¢"""
    print("ğŸ” æµ‹è¯•æ•°æ®åŠ è½½å’Œç»´åº¦è½¬æ¢...")
    
    # æ·»åŠ é¡¹ç›®è·¯å¾„
    sys.path.append('.')
    
    try:
        from minimal_micro_doppler_dataset import MicroDopplerDataset
        print("âœ… æˆåŠŸå¯¼å…¥MicroDopplerDataset")
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ•°æ®é›†
    data_dir = "/kaggle/working/data_split/train"
    if not os.path.exists(data_dir):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False
    
    print(f"ğŸ“ æµ‹è¯•æ•°æ®ç›®å½•: {data_dir}")
    
    # åˆ›å»ºæ•°æ®é›†
    try:
        dataset = MicroDopplerDataset(data_dir, split='train')
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œæ ·æœ¬æ•°é‡: {len(dataset)}")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•å•ä¸ªæ ·æœ¬
    try:
        sample = dataset[0]
        image = sample['image']
        user_id = sample['user_id']
        
        print(f"ğŸ“Š æ ·æœ¬ä¿¡æ¯:")
        print(f"  - å›¾åƒç»´åº¦: {image.shape}")
        print(f"  - å›¾åƒç±»å‹: {image.dtype}")
        print(f"  - å›¾åƒèŒƒå›´: [{image.min():.3f}, {image.max():.3f}]")
        print(f"  - ç”¨æˆ·ID: {user_id}")
        
        # éªŒè¯ç»´åº¦
        if image.dim() == 3 and image.shape[0] == 3:
            print("âœ… å›¾åƒç»´åº¦æ­£ç¡®: (C, H, W)")
            return True
        else:
            print(f"âŒ å›¾åƒç»´åº¦é”™è¯¯: æœŸæœ›(3, 256, 256)ï¼Œå¾—åˆ°{image.shape}")
            return False
            
    except Exception as e:
        print(f"âŒ æ ·æœ¬æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("\nğŸ” æµ‹è¯•æ¨¡å‹åŠ è½½...")
    
    # æ·»åŠ LightningDiTè·¯å¾„
    sys.path.append('LightningDiT')
    
    try:
        from tokenizer.autoencoder import AutoencoderKL
        print("âœ… æˆåŠŸå¯¼å…¥AutoencoderKL")
    except Exception as e:
        print(f"âŒ å¯¼å…¥AutoencoderKLå¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ¨¡å‹åˆ›å»º
    try:
        model = AutoencoderKL(
            embed_dim=32,
            ch_mult=(1, 1, 2, 2, 4),
            ckpt_path=None,
            model_type='vavae'
        )
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        dummy_input = torch.randn(1, 3, 256, 256)
        with torch.no_grad():
            output = model.encode(dummy_input)
            print(f"âœ… ç¼–ç æµ‹è¯•æˆåŠŸï¼Œè¾“å‡ºç±»å‹: {type(output)}")
            
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_pretrained_loading():
    """æµ‹è¯•é¢„è®­ç»ƒæ¨¡å‹åŠ è½½"""
    print("\nğŸ” æµ‹è¯•é¢„è®­ç»ƒæ¨¡å‹åŠ è½½...")
    
    pretrained_path = "/kaggle/working/pretrained/vavae-imagenet256-f16d32-dinov2.pt"
    if not os.path.exists(pretrained_path):
        print(f"âŒ é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {pretrained_path}")
        return False
    
    print(f"ğŸ“ é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„: {pretrained_path}")
    
    # æ·»åŠ LightningDiTè·¯å¾„
    sys.path.append('LightningDiT')
    
    try:
        from tokenizer.autoencoder import AutoencoderKL
        
        # ä½¿ç”¨ckpt_pathå‚æ•°åŠ è½½
        model = AutoencoderKL(
            embed_dim=32,
            ch_mult=(1, 1, 2, 2, 4),
            ckpt_path=pretrained_path,
            model_type='vavae'
        )
        print("âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        dummy_input = torch.randn(1, 3, 256, 256)
        with torch.no_grad():
            output = model.encode(dummy_input)
            print(f"âœ… é¢„è®­ç»ƒæ¨¡å‹ç¼–ç æµ‹è¯•æˆåŠŸ")
            
        return True
        
    except Exception as e:
        print(f"âŒ é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è°ƒè¯•æµ‹è¯•...")
    print("=" * 50)
    
    # æ£€æŸ¥å·¥ä½œç›®å½•
    print(f"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ“ Pythonè·¯å¾„: {sys.path[:3]}...")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    data_ok = test_data_loading()
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    model_ok = test_model_loading()
    
    # æµ‹è¯•é¢„è®­ç»ƒæ¨¡å‹åŠ è½½
    pretrained_ok = test_pretrained_loading()
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ¯ æµ‹è¯•æ€»ç»“:")
    print(f"  - æ•°æ®åŠ è½½: {'âœ… é€šè¿‡' if data_ok else 'âŒ å¤±è´¥'}")
    print(f"  - æ¨¡å‹åˆ›å»º: {'âœ… é€šè¿‡' if model_ok else 'âŒ å¤±è´¥'}")
    print(f"  - é¢„è®­ç»ƒåŠ è½½: {'âœ… é€šè¿‡' if pretrained_ok else 'âŒ å¤±è´¥'}")
    
    if data_ok and model_ok and pretrained_ok:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒ")
    else:
        print("âš ï¸ å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦ä¿®å¤")

if __name__ == "__main__":
    main()
