#!/usr/bin/env python3
"""
æµ‹è¯•é¢œè‰²ä¿®å¤
"""

import sys
import os
import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# æ·»åŠ è·¯å¾„
sys.path.insert(0, 'LightningDiT')

def test_vavae_decode():
    """æµ‹è¯•VA-VAEè§£ç è¿‡ç¨‹"""
    print("ğŸ§ª æµ‹è¯•VA-VAEè§£ç è¿‡ç¨‹...")
    
    try:
        from tokenizer.vavae import VA_VAE
        
        # åŠ è½½VA-VAE
        vavae = VA_VAE('vavae_config.yaml')
        print("âœ… VA-VAEåŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ½œåœ¨ç‰¹å¾
        batch_size = 2
        latent_dim = 32  # æ ¹æ®é…ç½®è°ƒæ•´
        height, width = 16, 16  # æ ¹æ®é…ç½®è°ƒæ•´
        
        # æµ‹è¯•ä¸åŒèŒƒå›´çš„æ½œåœ¨ç‰¹å¾
        test_ranges = [
            ("æ ‡å‡†æ­£æ€åˆ†å¸ƒ", torch.randn(batch_size, latent_dim, height, width)),
            ("[-1, 1]èŒƒå›´", torch.rand(batch_size, latent_dim, height, width) * 2 - 1),
            ("[0, 1]èŒƒå›´", torch.rand(batch_size, latent_dim, height, width)),
            ("è¾ƒå°èŒƒå›´[-0.5, 0.5]", torch.rand(batch_size, latent_dim, height, width) - 0.5),
        ]
        
        for name, z in test_ranges:
            print(f"\nğŸ” æµ‹è¯• {name}:")
            print(f"  æ½œåœ¨ç‰¹å¾èŒƒå›´: [{z.min():.3f}, {z.max():.3f}]")
            
            # è§£ç 
            with torch.no_grad():
                images = vavae.decode_to_images(z)
            
            print(f"  è§£ç å›¾åƒå½¢çŠ¶: {images.shape}")
            print(f"  è§£ç å›¾åƒèŒƒå›´: [{images.min()}, {images.max()}]")
            print(f"  è§£ç å›¾åƒç±»å‹: {images.dtype}")
            
            # ä¿å­˜ç¬¬ä¸€å¼ å›¾åƒ
            if len(images) > 0:
                img = images[0]
                if img.shape[-1] == 1:
                    img = np.repeat(img, 3, axis=-1)
                
                pil_img = Image.fromarray(img)
                filename = f"test_decode_{name.replace(' ', '_').replace('[', '').replace(']', '').replace(',', '_').replace('.', 'p')}.png"
                pil_img.save(filename)
                print(f"  ä¿å­˜å›¾åƒ: {filename}")
        
        return True
        
    except Exception as e:
        print(f"âŒ VA-VAEæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_data_range_conversion():
    """æµ‹è¯•æ•°æ®èŒƒå›´è½¬æ¢"""
    print("\nğŸ§ª æµ‹è¯•æ•°æ®èŒƒå›´è½¬æ¢...")
    
    # æ¨¡æ‹Ÿä¸åŒèŒƒå›´çš„æ•°æ®
    test_data = torch.randn(1, 3, 64, 64)
    
    print(f"åŸå§‹æ•°æ®èŒƒå›´: [{test_data.min():.3f}, {test_data.max():.3f}]")
    
    # æµ‹è¯•ä¸åŒçš„å½’ä¸€åŒ–æ–¹æ³•
    methods = [
        ("tanh", torch.tanh(test_data)),
        ("clamp+tanh", torch.tanh(torch.clamp(test_data, -3, 3))),
        ("sigmoid*2-1", torch.sigmoid(test_data) * 2 - 1),
        ("ç›´æ¥clamp", torch.clamp(test_data, -1, 1)),
    ]
    
    for name, normalized in methods:
        print(f"{name}: [{normalized.min():.3f}, {normalized.max():.3f}]")
        
        # æ¨¡æ‹ŸVA-VAEè§£ç å…¬å¼
        decoded = torch.clamp(127.5 * normalized + 128.0, 0, 255)
        print(f"  è§£ç å: [{decoded.min():.1f}, {decoded.max():.1f}]")

def test_color_mapping():
    """æµ‹è¯•é¢œè‰²æ˜ å°„"""
    print("\nğŸ§ª æµ‹è¯•é¢œè‰²æ˜ å°„...")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    height, width = 64, 64
    
    # åˆ›å»ºæ¸å˜å›¾åƒ
    gradient = np.linspace(0, 255, width, dtype=np.uint8)
    test_image = np.tile(gradient, (height, 1))
    test_image = np.stack([test_image, test_image, test_image], axis=-1)
    
    # ä¿å­˜åŸå§‹å›¾åƒ
    Image.fromarray(test_image).save("test_gradient_original.png")
    print("âœ… ä¿å­˜åŸå§‹æ¸å˜å›¾åƒ: test_gradient_original.png")
    
    # æµ‹è¯•ä¸åŒçš„é¢œè‰²ç©ºé—´è½¬æ¢
    import cv2
    
    # RGB to HSV
    hsv = cv2.cvtColor(test_image, cv2.COLOR_RGB2HSV)
    Image.fromarray(cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)).save("test_gradient_hsv.png")
    
    # RGB to LAB
    lab = cv2.cvtColor(test_image, cv2.COLOR_RGB2LAB)
    Image.fromarray(cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)).save("test_gradient_lab.png")
    
    print("âœ… ä¿å­˜é¢œè‰²ç©ºé—´æµ‹è¯•å›¾åƒ")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ é¢œè‰²ä¿®å¤æµ‹è¯•")
    print("=" * 40)
    
    success = True
    
    # æµ‹è¯•1: VA-VAEè§£ç 
    if not test_vavae_decode():
        success = False
    
    # æµ‹è¯•2: æ•°æ®èŒƒå›´è½¬æ¢
    test_data_range_conversion()
    
    # æµ‹è¯•3: é¢œè‰²æ˜ å°„
    test_color_mapping()
    
    if success:
        print("\nâœ… é¢œè‰²æµ‹è¯•å®Œæˆ!")
        print("ç°åœ¨å¯ä»¥è¿è¡Œä¿®å¤åçš„æ¨ç†:")
        print("python stage3_inference.py \\")
        print("    --dit_checkpoint /kaggle/working/trained_models/best_model \\")
        print("    --vavae_config vavae_config.yaml \\")
        print("    --output_dir /kaggle/working/generated_images \\")
        print("    --user_ids 1 2 3 4 5 \\")
        print("    --num_samples_per_user 2 \\")
        print("    --seed 42")
    else:
        print("\nâŒ é¢œè‰²æµ‹è¯•å¤±è´¥")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
