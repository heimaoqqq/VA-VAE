#!/usr/bin/env python3
"""
æµ‹è¯•VA-VAEçš„é‡å»ºè´¨é‡
éªŒè¯ç¼–ç -è§£ç è¿‡ç¨‹æ˜¯å¦æ­£ç¡®
"""

import sys
import os
import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# æ·»åŠ è·¯å¾„
sys.path.insert(0, 'LightningDiT')

def test_vavae_reconstruction():
    """æµ‹è¯•VA-VAEé‡å»º"""
    print("ğŸ§ª æµ‹è¯•VA-VAEé‡å»ºè´¨é‡...")
    
    try:
        from tokenizer.vavae import VA_VAE
        
        # åŠ è½½VA-VAE
        vavae = VA_VAE('vavae_config.yaml')
        print("âœ… VA-VAEåŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ (æ¨¡æ‹Ÿå¾®å¤šæ™®å‹’æ—¶é¢‘å›¾)
        batch_size = 2
        height, width = 256, 256
        
        # åˆ›å»ºå…·æœ‰æ—¶é¢‘å›¾ç‰¹å¾çš„æµ‹è¯•å›¾åƒ
        test_images = []
        for i in range(batch_size):
            # åˆ›å»ºé¢‘ç‡-æ—¶é—´ç½‘æ ¼
            freq = np.linspace(-1, 1, height)
            time = np.linspace(-1, 1, width)
            F, T = np.meshgrid(freq, time, indexing='ij')
            
            # æ¨¡æ‹Ÿå¤šæ™®å‹’é¢‘ç§»æ¨¡å¼
            doppler_pattern = np.sin(2 * np.pi * F * 3) * np.exp(-T**2 / 0.5)
            doppler_pattern += 0.5 * np.sin(2 * np.pi * F * 5 + T * np.pi)
            
            # å½’ä¸€åŒ–åˆ°[0, 1]
            doppler_pattern = (doppler_pattern - doppler_pattern.min()) / (doppler_pattern.max() - doppler_pattern.min())
            
            # è½¬æ¢ä¸ºRGB (é‡å¤3ä¸ªé€šé“)
            rgb_image = np.stack([doppler_pattern] * 3, axis=-1)
            rgb_image = (rgb_image * 255).astype(np.uint8)
            
            test_images.append(rgb_image)
        
        # è½¬æ¢ä¸ºtensor
        test_tensor = torch.stack([
            torch.from_numpy(img).permute(2, 0, 1).float() / 255.0 * 2.0 - 1.0
            for img in test_images
        ])
        
        print(f"æµ‹è¯•å›¾åƒå½¢çŠ¶: {test_tensor.shape}")
        print(f"æµ‹è¯•å›¾åƒèŒƒå›´: [{test_tensor.min():.3f}, {test_tensor.max():.3f}]")
        
        # ç¼–ç 
        with torch.no_grad():
            latents = vavae.encode_images(test_tensor)
            print(f"æ½œåœ¨ç‰¹å¾å½¢çŠ¶: {latents.shape}")
            print(f"æ½œåœ¨ç‰¹å¾èŒƒå›´: [{latents.min():.3f}, {latents.max():.3f}]")
            
            # è§£ç 
            reconstructed = vavae.decode_to_images(latents)
            print(f"é‡å»ºå›¾åƒå½¢çŠ¶: {reconstructed.shape}")
            print(f"é‡å»ºå›¾åƒèŒƒå›´: [{reconstructed.min()}, {reconstructed.max()}]")
        
        # ä¿å­˜ç»“æœ
        for i in range(batch_size):
            # åŸå§‹å›¾åƒ
            orig_img = Image.fromarray(test_images[i])
            orig_img.save(f"test_original_{i}.png")
            
            # é‡å»ºå›¾åƒ
            recon_img = Image.fromarray(reconstructed[i])
            recon_img.save(f"test_reconstructed_{i}.png")
            
            print(f"âœ… ä¿å­˜å›¾åƒå¯¹ {i}: test_original_{i}.png, test_reconstructed_{i}.png")
        
        # è®¡ç®—é‡å»ºè¯¯å·®
        mse_errors = []
        for i in range(batch_size):
            orig = test_images[i].astype(np.float32)
            recon = reconstructed[i].astype(np.float32)
            mse = np.mean((orig - recon) ** 2)
            mse_errors.append(mse)
            print(f"å›¾åƒ {i} MSE: {mse:.2f}")
        
        avg_mse = np.mean(mse_errors)
        print(f"å¹³å‡MSE: {avg_mse:.2f}")
        
        if avg_mse < 1000:  # åˆç†çš„é˜ˆå€¼
            print("âœ… VA-VAEé‡å»ºè´¨é‡è‰¯å¥½")
            return True
        else:
            print("âš ï¸  VA-VAEé‡å»ºè´¨é‡è¾ƒå·®")
            return False
        
    except Exception as e:
        print(f"âŒ VA-VAEé‡å»ºæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_latent_distribution():
    """æµ‹è¯•æ½œåœ¨ç‰¹å¾åˆ†å¸ƒ"""
    print("\nğŸ§ª æµ‹è¯•æ½œåœ¨ç‰¹å¾åˆ†å¸ƒ...")
    
    try:
        from tokenizer.vavae import VA_VAE
        
        vavae = VA_VAE('vavae_config.yaml')
        
        # æµ‹è¯•ä¸åŒèŒƒå›´çš„æ½œåœ¨ç‰¹å¾
        test_ranges = [
            ("æ ‡å‡†æ­£æ€", torch.randn(2, 32, 16, 16)),
            ("å°èŒƒå›´", torch.randn(2, 32, 16, 16) * 0.5),
            ("å¤§èŒƒå›´", torch.randn(2, 32, 16, 16) * 2.0),
            ("å½’ä¸€åŒ–", torch.randn(2, 32, 16, 16) / 0.18215),
        ]
        
        for name, latents in test_ranges:
            print(f"\næµ‹è¯• {name}:")
            print(f"  æ½œåœ¨ç‰¹å¾èŒƒå›´: [{latents.min():.3f}, {latents.max():.3f}]")
            
            with torch.no_grad():
                images = vavae.decode_to_images(latents)
                
            print(f"  è§£ç å›¾åƒèŒƒå›´: [{images.min()}, {images.max()}]")
            
            # ä¿å­˜ç¬¬ä¸€å¼ å›¾åƒ
            if len(images) > 0:
                img = Image.fromarray(images[0])
                filename = f"test_latent_{name.replace(' ', '_')}.png"
                img.save(filename)
                print(f"  ä¿å­˜: {filename}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ½œåœ¨ç‰¹å¾åˆ†å¸ƒæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ VA-VAEé‡å»ºæµ‹è¯•")
    print("=" * 40)
    
    success = True
    
    # æµ‹è¯•1: é‡å»ºè´¨é‡
    if not test_vavae_reconstruction():
        success = False
    
    # æµ‹è¯•2: æ½œåœ¨ç‰¹å¾åˆ†å¸ƒ
    if not test_latent_distribution():
        success = False
    
    if success:
        print("\nâœ… VA-VAEæµ‹è¯•å®Œæˆ!")
        print("æ£€æŸ¥ç”Ÿæˆçš„å›¾åƒæ–‡ä»¶ï¼Œå¯¹æ¯”åŸå§‹å’Œé‡å»ºè´¨é‡")
    else:
        print("\nâŒ VA-VAEæµ‹è¯•å¤±è´¥")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
