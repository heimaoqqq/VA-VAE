"""
å°†é¢„ç¼–ç çš„latentæ•°æ®è½¬æ¢ä¸ºLightningDiTå®˜æ–¹çš„safetensorsæ ¼å¼
ä¿æŒä¸å®˜æ–¹æ•°æ®æ ¼å¼å®Œå…¨ä¸€è‡´
"""

import torch
import numpy as np
from pathlib import Path
from safetensors.torch import save_file
from tqdm import tqdm
import argparse

def convert_to_safetensors(input_path, output_dir, split='train'):
    """
    è½¬æ¢latentæ•°æ®åˆ°safetensorsæ ¼å¼
    
    å®˜æ–¹æ ¼å¼:
    - latents: [N, C, H, W] çš„latentå‘é‡
    - latents_flip: æ°´å¹³ç¿»è½¬çš„latentï¼ˆæ•°æ®å¢å¼ºï¼‰
    - labels: ç±»åˆ«æ ‡ç­¾ï¼ˆæ— æ¡ä»¶ç”Ÿæˆæ—¶ä¸º0ï¼‰
    """
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½é¢„ç¼–ç çš„latents
    print(f"ğŸ“‚ åŠ è½½ {split} latents...")
    latent_file = Path(input_path) / f"{split}_latents.pt"
    
    if not latent_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {latent_file}")
        return
    
    data = torch.load(latent_file, map_location='cpu', weights_only=False)
    
    # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®æ ¼å¼
    print(f"ğŸ“Š æ•°æ®ç±»å‹: {type(data)}")
    if isinstance(data, dict):
        print(f"   å­—å…¸é”®: {list(data.keys())}")
        latents = data['latents']
        user_ids = data.get('user_ids', None)
    elif isinstance(data, (list, tuple)):
        print(f"   åˆ—è¡¨é•¿åº¦: {len(data)}")
        # æ£€æŸ¥åˆ—è¡¨ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ çš„ç±»å‹
        if len(data) > 0:
            first_item = data[0]
            print(f"   åˆ—è¡¨å…ƒç´ ç±»å‹: {type(first_item)}")
            if isinstance(first_item, dict):
                print(f"   å­—å…¸é”®: {list(first_item.keys())}")
                # æå–æ¯ä¸ªå­—å…¸ä¸­çš„latent tensorï¼Œå°è¯•å¤šç§å¯èƒ½çš„é”®å
                latents = []
                user_ids = []
                for item in data:
                    # å°è¯•å¤šç§å¯èƒ½çš„é”®å
                    if 'latent' in item:
                        latents.append(item['latent'])
                    elif 'tensor' in item:
                        latents.append(item['tensor'])
                    elif 'latents' in item:
                        latents.append(item['latents'])
                    else:
                        # å¦‚æœæ‰¾ä¸åˆ°é¢„æœŸçš„é”®ï¼Œæ‰“å°æ‰€æœ‰é”®å¹¶ä½¿ç”¨ç¬¬ä¸€ä¸ªå¼ é‡
                        tensor_keys = [k for k, v in item.items() if isinstance(v, torch.Tensor)]
                        if tensor_keys:
                            print(f"   ä½¿ç”¨é”® '{tensor_keys[0]}' ä½œä¸ºlatentå¼ é‡")
                            latents.append(item[tensor_keys[0]])
                        else:
                            print(f"   è­¦å‘Šï¼šåœ¨å­—å…¸ä¸­æ‰¾ä¸åˆ°å¼ é‡ï¼Œè·³è¿‡æ­¤é¡¹")
                            continue
                    
                    # æå–ç”¨æˆ·IDï¼ˆå¦‚æœæœ‰ï¼‰
                    user_ids.append(item.get('user_id', 0))
                
                user_ids = user_ids if len(user_ids) > 0 else None
            else:
                latents = data  # ç›´æ¥ä½¿ç”¨åˆ—è¡¨
                user_ids = None
        else:
            latents = []
            user_ids = None
    else:
        print(f"   å•ä¸ªtensorå½¢çŠ¶: {data.shape}")
        latents = [data] if data.dim() == 3 else data
        user_ids = None
    
    # è½¬æ¢ä¸ºtensoråˆ—è¡¨
    if not isinstance(latents, torch.Tensor):
        latents = torch.stack(latents) if isinstance(latents[0], torch.Tensor) else torch.tensor(latents)
    
    print(f"âœ… åŠ è½½äº† {len(latents)} ä¸ªlatents")
    print(f"   Shape: {latents.shape}")
    
    if user_ids is not None:
        print(f"   ç”¨æˆ·æ ‡ç­¾: {len(user_ids)} ä¸ªï¼ŒèŒƒå›´ {user_ids.min()}-{user_ids.max()}")
    else:
        print("   âš ï¸ æœªæ‰¾åˆ°ç”¨æˆ·æ ‡ç­¾ï¼Œå°†ä½¿ç”¨0ä½œä¸ºé»˜è®¤æ ‡ç­¾")
    
    # è®¡ç®—channel-wiseç»Ÿè®¡ï¼ˆä¸å®˜æ–¹ä¸€è‡´ï¼‰
    print("ğŸ“Š è®¡ç®—channel-wiseç»Ÿè®¡...")
    mean = latents.mean(dim=[0, 2, 3], keepdim=True)  # [1, 32, 1, 1]
    std = latents.std(dim=[0, 2, 3], keepdim=True)
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯ï¼ˆå®˜æ–¹æ ¼å¼ï¼‰
    stats = {
        'mean': mean.squeeze(0),  # [32, 1, 1]
        'std': std.squeeze(0)      # [32, 1, 1]
    }
    stats_file = output_dir / 'latents_stats.pt'
    torch.save(stats, stats_file)
    print(f"âœ… ä¿å­˜ç»Ÿè®¡ä¿¡æ¯åˆ° {stats_file}")
    
    # åˆ†æ‰¹ä¿å­˜ä¸ºsafetensorsï¼ˆå®˜æ–¹æ¯ä¸ªæ–‡ä»¶1000ä¸ªæ ·æœ¬ï¼‰
    batch_size = 1000
    num_batches = (len(latents) + batch_size - 1) // batch_size
    
    print(f"ğŸ“¦ è½¬æ¢ä¸ºsafetensorsæ ¼å¼...")
    for batch_idx in tqdm(range(num_batches), desc="æ‰¹æ¬¡"):
        start_idx = batch_idx * batch_size
        end_idx = min((batch_idx + 1) * batch_size, len(latents))
        
        batch_latents = latents[start_idx:end_idx]
        
        # æ— æ•°æ®å¢å¼º - ä½¿ç”¨ç›¸åŒçš„latents
        batch_latents_flip = batch_latents  # ä¸åšç¿»è½¬
        
        # æ— æ¡ä»¶ç”Ÿæˆï¼Œlabelså…¨ä¸º0
        batch_labels = torch.zeros(len(batch_latents), dtype=torch.long)
        
        # ä¿å­˜ä¸ºsafetensors
        safetensors_data = {
            'latents': batch_latents,
            'latents_flip': batch_latents_flip,
            'labels': batch_labels
        }
        
        output_file = output_dir / f'latents_rank00_shard{batch_idx:03d}.safetensors'
        save_file(safetensors_data, output_file)
    
    print(f"âœ… å®Œæˆï¼ä¿å­˜äº† {num_batches} ä¸ªsafetensorsæ–‡ä»¶åˆ° {output_dir}")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input_dir', type=str, default='./latents',
                        help='åŒ…å«train_latents.ptå’Œval_latents.ptçš„ç›®å½•')
    parser.add_argument('--output_dir', type=str, default='./latents_safetensors',
                        help='è¾“å‡ºsafetensorsæ ¼å¼çš„ç›®å½•')
    args = parser.parse_args()
    
    # è½¬æ¢è®­ç»ƒé›†
    print("\n=== è½¬æ¢è®­ç»ƒé›† ===")
    train_output = Path(args.output_dir) / 'train'
    convert_to_safetensors(args.input_dir, train_output, 'train')
    
    # è½¬æ¢éªŒè¯é›†
    print("\n=== è½¬æ¢éªŒè¯é›† ===")
    val_output = Path(args.output_dir) / 'val'
    convert_to_safetensors(args.input_dir, val_output, 'val')
    
    print("\nâœ… å…¨éƒ¨å®Œæˆï¼")
    print(f"è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„data_pathä¸º: {train_output}")
    print(f"è¯·æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„valid_pathä¸º: {val_output}")

if __name__ == "__main__":
    main()
