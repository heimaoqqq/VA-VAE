#!/usr/bin/env python3
"""
å¾®å¤šæ™®å‹’æ•°æ®é›† - å®Œå…¨åŒ¹é…VA-VAEçš„é¢„å¤„ç†æ ¼å¼
ç”¨äºæ‰©æ•£æ¨¡å‹è®­ç»ƒ
"""

import os
import json
import numpy as np
from PIL import Image
from pathlib import Path
import torch
from torch.utils.data import Dataset


class MicrodopplerDataset(Dataset):
    """
    å¾®å¤šæ™®å‹’æ•°æ®é›† - å®Œå…¨åŒ¹é…step4_train_vavae.pyçš„é¢„å¤„ç†æ–¹å¼
    """
    
    def __init__(self, root_dir, split_file, split='train', transform=None, 
                 return_user_id=False, image_size=256):
        self.data_root = Path(root_dir)
        self.image_size = image_size
        self.split = split
        self.return_user_id = return_user_id
        self.transform = transform  # ä¿ç•™å…¼å®¹æ€§ï¼Œä½†ä¸ä½¿ç”¨
        
        # åŠ è½½æ•°æ®åˆ’åˆ†
        with open(split_file, 'r') as f:
            split_data = json.load(f)
        
        # è·å–å¯¹åº”splitçš„æ ·æœ¬
        if split not in split_data:
            raise ValueError(f"Split '{split}' not found in {split_file}")
            
        self.samples = []
        for sample in split_data[split]:
            # è°ƒè¯•ï¼šæ£€æŸ¥sampleçš„å®é™…æ ¼å¼
            print(f"ğŸ” Debug sample type: {type(sample)}, content: {sample}")
            
            # å¤„ç†ä¸åŒçš„JSONæ ¼å¼
            if isinstance(sample, dict):
                # æ ‡å‡†æ ¼å¼ï¼š{'path': '...', 'user_id': '...'}
                sample_path = self.data_root / sample['path']
                user_id = sample.get('user_id', 'unknown')
            elif isinstance(sample, str):
                # å­—ç¬¦ä¸²æ ¼å¼ï¼šç›´æ¥æ˜¯è·¯å¾„
                sample_path = self.data_root / sample
                # ä»è·¯å¾„æ¨æ–­ç”¨æˆ·IDï¼ˆå‡è®¾æ ¼å¼ä¸º ID_X/xxx.jpgï¼‰
                path_parts = Path(sample).parts
                user_id = path_parts[0] if path_parts else 'unknown'
            else:
                print(f"âŒ æœªçŸ¥sampleæ ¼å¼: {type(sample)} - {sample}")
                continue
                
            if sample_path.exists():
                self.samples.append({
                    'path': sample_path,
                    'user_id': user_id
                })
            else:
                print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {sample_path}")
        
        print(f"âœ… åŠ è½½{split}é›†: {len(self.samples)}ä¸ªæ ·æœ¬")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # åŠ è½½å›¾åƒ - å®Œå…¨åŒ¹é…step4_train_vavae.pyçš„æ–¹å¼
        img = Image.open(sample['path']).convert('RGB')
        img = img.resize((self.image_size, self.image_size), Image.LANCZOS)
        
        # **å…³é”®**ï¼šå®Œå…¨åŒ¹é…VA-VAEçš„é¢„å¤„ç†æ–¹å¼
        # ä»step4_train_vavae.pyç¬¬118-122è¡Œï¼š
        img_array = np.array(img).astype(np.float32)  # HWCæ ¼å¼ [256,256,3]
        img_array = img_array / 127.5 - 1.0  # å½’ä¸€åŒ–åˆ°[-1,1]
        
        # è½¬ä¸ºtensorï¼Œä¿æŒHWCæ ¼å¼ï¼ˆè¿™å¾ˆé‡è¦ï¼ï¼‰
        img_tensor = torch.from_numpy(img_array)  # [256,256,3]
        
        if self.return_user_id:
            return img_tensor, sample['user_id']
        else:
            return img_tensor, 0  # è¿”å›dummy labelï¼Œä¿æŒDataLoaderå…¼å®¹æ€§
