# DiT-S configuration for micro-Doppler dataset
# Based on official LightningDiT config with minimal modifications

# Data configuration
data:
  data_path: '/kaggle/working/VA-VAE/latents_safetensors/train'  # 训练集latent路径
  valid_path: '/kaggle/working/VA-VAE/latents_safetensors/val'   # 验证集latent路径
  image_size: 256             # 原始图像大小
  num_classes: 32             # 31个用户 + 1个null类用于CFG
  num_workers: 4               # 适配Kaggle环境的系统建议值，避免过度创建进程
  
  # Channel-wise normalization (与官方LightningDiT一致)
  latent_norm: true      # 使用channel-wise归一化
  latent_multiplier: 1.0 # 归一化后不需要额外缩放

# VAE configuration (我们的VA-VAE)
vae:
  model_name: 'vavae_f16d32'
  downsample_ratio: 16   # 256x256 -> 16x16 latent

# Model configuration - DiT-S (最小模型，手动添加)
model:
  model_type: 'LightningDiT-S/2'  # S模型，patch_size=2正确配置
  use_qknorm: false               # 官方推荐设置
  use_swiglu: true                # 使用SwiGLU激活
  use_rope: true                  # 使用RoPE位置编码
  use_rmsnorm: true               # 使用RMSNorm
  wo_shift: false                 # 不使用shift
  in_chans: 32                    # VA-VAE的32个通道
  use_checkpoint: false           # 小模型不需要梯度检查点
  class_dropout_prob: 0.05        # 小dropout让模型学习无条件生成，支持CFG

# Training configuration
train:
  max_steps: 4000                # 约10个epochs（6200样本 / 16 batch_size * 10 = 3875步）
  global_batch_size: 16           # 双GPU，每GPU 8个batch
  global_seed: 0
  output_dir: '/kaggle/working/finetuned_models'
  exp_name: 'dit_s_microdoppler_finetune'  # 微调实验
  ckpt: '/kaggle/input/50000-pt/0050000.pt'  # 加载预训练权重
  log_every: 100                  # 更频繁的日志
  ckpt_every: 500                # 每500步保存
  resume: false                   # 不从检查点恢复，使用预训练权重
  early_stopping_patience: 8      # 稍微延长耐心
  ema_decay: 0.999               # 小数据集优化的EMA衰减率

# Optimizer configuration (微调配置)
optimizer:
  lr: 0.00001                     # 微调使用更小的学习率
  beta2: 0.99                     # 提高beta2适应更noisy的梯度
  max_grad_norm: 1.0              # 标准梯度裁剪
  weight_decay: 0.01              # 增加权重衰减以防过拟合

# Transport configuration (Rectified Flow官方优化)
transport:
  path_type: Linear
  prediction: velocity
  loss_weight: null
  sample_eps: null
  train_eps: null
  use_lognorm: true               # 启用logit_normal采样(官方固定mu=0,sigma=1)
  use_cosine_loss: true           # 使用余弦损失提升训练稳定性
  # 官方高级优化参数
  partitial_train: null           # 部分时间步训练（高级技术）
  partial_ratio: 1.0              # 部分训练比例
  shift_lg: false                 # 不使用shifted logit-normal

# Sampling configuration (微多普勒优化版)
sample:
  mode: ODE
  sampling_method: 'dopri5'       # 高精度自适应求解器，更适合时频图像细节
  atol: 0.000001
  rtol: 0.001
  reverse: false
  likelihood: false
  num_sampling_steps: 300         # 增加采样步数以提高质量
  cfg_scale: 10.0                 # 提高CFG增强条件引导（经验证的做法）
  per_proc_batch_size: 4
  cfg_interval_start: 0.11
  timestep_shift: 0.1             # 保留更多早期去噪过程
