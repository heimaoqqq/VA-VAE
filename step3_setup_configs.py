#!/usr/bin/env python3
"""
æ­¥éª¤3: è®¾ç½®LightningDiTæ¨ç†é…ç½®
åŸºäºå®˜æ–¹reproductioné…ç½®ï¼Œé€‚é…Kaggleç¯å¢ƒ
"""

import yaml
import sys
from pathlib import Path

def check_prerequisites():
    """æ£€æŸ¥å‰ç½®æ¡ä»¶"""
    print("ğŸ” æ£€æŸ¥å‰ç½®æ¡ä»¶...")
    
    # æ£€æŸ¥LightningDiTç›®å½•
    lightningdit_dir = Path("LightningDiT")
    if not lightningdit_dir.exists():
        print("âŒ LightningDiTç›®å½•ä¸å­˜åœ¨")
        return False
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    models_dir = Path("models")
    required_models = [
        "vavae-imagenet256-f16d32-dinov2.pt",
        "lightningdit-xl-imagenet256-800ep.pt",
        "latents_stats.pt"
    ]
    
    for model in required_models:
        model_path = models_dir / model
        if not model_path.exists():
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
        else:
            size_mb = model_path.stat().st_size / 1024 / 1024
            print(f"âœ… {model}: {size_mb:.1f} MB")
    
    print("âœ… å‰ç½®æ¡ä»¶æ£€æŸ¥é€šè¿‡")
    return True

def setup_inference_config():
    """è®¾ç½®æ¨ç†é…ç½®"""
    print("\nâš™ï¸ è®¾ç½®æ¨ç†é…ç½®...")
    
    # ä½¿ç”¨å®˜æ–¹reproductioné…ç½®ä½œä¸ºåŸºç¡€
    lightningdit_dir = Path("LightningDiT")
    original_config_path = lightningdit_dir / "configs" / "reproductions" / "lightningdit_xl_vavae_f16d32_800ep_cfg.yaml"
    
    if not original_config_path.exists():
        print(f"âŒ å®˜æ–¹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {original_config_path}")
        return False
    
    print(f"ğŸ“‹ è¯»å–å®˜æ–¹é…ç½®: {original_config_path}")
    
    # è¯»å–å®˜æ–¹é…ç½®
    with open(original_config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    print("ğŸ“ å®˜æ–¹é…ç½®å†…å®¹:")
    print(yaml.dump(config, default_flow_style=False, indent=2))
    
    # é€‚é…Kaggleç¯å¢ƒ
    models_dir = Path("models").absolute()
    
    # æ›´æ–°æ¨¡å‹è·¯å¾„
    config['ckpt_path'] = str(models_dir / "lightningdit-xl-imagenet256-800ep.pt")
    config['data']['data_path'] = str(models_dir / "latents_stats.pt")
    
    # Kaggleç¯å¢ƒä¼˜åŒ–
    config['sample']['per_proc_batch_size'] = 2  # é™ä½æ‰¹æ¬¡å¤§å°é€‚åº”Kaggle GPU
    config['sample']['num_sampling_steps'] = 50  # é™ä½é‡‡æ ·æ­¥æ•°åŠ å¿«æ¨ç†
    
    # åˆ›å»ºKaggleé€‚é…çš„é…ç½®æ–‡ä»¶
    kaggle_config_path = Path("kaggle_inference_config.yaml")
    
    with open(kaggle_config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, indent=2)
    
    print(f"âœ… Kaggleé…ç½®å·²åˆ›å»º: {kaggle_config_path}")
    return True

def setup_vavae_config():
    """è®¾ç½®VA-VAEé…ç½®"""
    print("\nâš™ï¸ è®¾ç½®VA-VAEé…ç½®...")
    
    lightningdit_dir = Path("LightningDiT")
    vavae_config_path = lightningdit_dir / "tokenizer" / "configs" / "vavae_f16d32.yaml"
    
    if not vavae_config_path.exists():
        print(f"âŒ VA-VAEé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {vavae_config_path}")
        return False
    
    # è¯»å–é…ç½®
    with open(vavae_config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # æ›´æ–°æ¨¡å‹è·¯å¾„
    models_dir = Path("models").absolute()
    config['ckpt_path'] = str(models_dir / "vavae-imagenet256-f16d32-dinov2.pt")
    
    # å†™å›é…ç½®
    with open(vavae_config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, indent=2)
    
    print(f"âœ… VA-VAEé…ç½®å·²æ›´æ–°: {vavae_config_path}")
    
    # æ˜¾ç¤ºé…ç½®å†…å®¹
    print("ğŸ“ VA-VAEé…ç½®å†…å®¹:")
    print(yaml.dump(config, default_flow_style=False, indent=2))
    
    return True

def create_kaggle_inference_script():
    """åˆ›å»ºKaggleæ¨ç†è„šæœ¬"""
    print("\nğŸ“ åˆ›å»ºKaggleæ¨ç†è„šæœ¬...")
    
    script_content = '''#!/usr/bin/env python3
"""
Kaggleç¯å¢ƒLightningDiTæ¨ç†è„šæœ¬
åŸºäºå®˜æ–¹inference.pyï¼Œé€‚é…Kaggleç¯å¢ƒ
"""

import os
import sys
import torch

# è®¾ç½®ç¯å¢ƒ
os.chdir("LightningDiT")
sys.path.append(".")

# è¿è¡Œæ¨ç†
if __name__ == "__main__":
    # è®¾ç½®é…ç½®æ–‡ä»¶è·¯å¾„
    config_path = "../kaggle_inference_config.yaml"
    
    print("ğŸš€ å¼€å§‹LightningDiTæ¨ç†...")
    print(f"ğŸ“‹ é…ç½®æ–‡ä»¶: {config_path}")
    print(f"ğŸ”¥ CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    # å¯¼å…¥å¹¶è¿è¡Œæ¨ç†
    try:
        from inference import main
        
        # è®¾ç½®å‘½ä»¤è¡Œå‚æ•°
        sys.argv = ["inference.py", "--config", config_path]
        
        # è¿è¡Œæ¨ç†
        main()
        
        print("âœ… æ¨ç†å®Œæˆï¼")
        print("ğŸ“ è¾“å‡ºå›¾åƒ: demo_images/demo_samples.png")
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
'''
    
    script_path = Path("step4_run_inference.py")
    with open(script_path, 'w') as f:
        f.write(script_content)
    
    print(f"âœ… æ¨ç†è„šæœ¬å·²åˆ›å»º: {script_path}")
    return True

def verify_configuration():
    """éªŒè¯é…ç½®"""
    print("\nğŸ” éªŒè¯é…ç½®...")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_files = [
        "kaggle_inference_config.yaml",
        "LightningDiT/tokenizer/configs/vavae_f16d32.yaml"
    ]
    
    for config_file in config_files:
        config_path = Path(config_file)
        if config_path.exists():
            print(f"âœ… {config_file}: å­˜åœ¨")
            
            # éªŒè¯YAMLæ ¼å¼
            try:
                with open(config_path, 'r') as f:
                    yaml.safe_load(f)
                print(f"âœ… {config_file}: YAMLæ ¼å¼æ­£ç¡®")
            except yaml.YAMLError as e:
                print(f"âŒ {config_file}: YAMLæ ¼å¼é”™è¯¯ - {e}")
                return False
        else:
            print(f"âŒ {config_file}: ä¸å­˜åœ¨")
            return False
    
    # æ£€æŸ¥æ¨ç†è„šæœ¬
    inference_script = Path("step4_run_inference.py")
    if inference_script.exists():
        print(f"âœ… æ¨ç†è„šæœ¬: å­˜åœ¨")
    else:
        print(f"âŒ æ¨ç†è„šæœ¬: ä¸å­˜åœ¨")
        return False
    
    print("âœ… é…ç½®éªŒè¯é€šè¿‡")
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ­¥éª¤3: è®¾ç½®LightningDiTæ¨ç†é…ç½®")
    print("="*60)
    
    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    if not check_prerequisites():
        print("âŒ å‰ç½®æ¡ä»¶æ£€æŸ¥å¤±è´¥")
        return False
    
    # è®¾ç½®æ¨ç†é…ç½®
    if not setup_inference_config():
        print("âŒ æ¨ç†é…ç½®è®¾ç½®å¤±è´¥")
        return False
    
    # è®¾ç½®VA-VAEé…ç½®
    if not setup_vavae_config():
        print("âŒ VA-VAEé…ç½®è®¾ç½®å¤±è´¥")
        return False
    
    # åˆ›å»ºæ¨ç†è„šæœ¬
    if not create_kaggle_inference_script():
        print("âŒ æ¨ç†è„šæœ¬åˆ›å»ºå¤±è´¥")
        return False
    
    # éªŒè¯é…ç½®
    if not verify_configuration():
        print("âŒ é…ç½®éªŒè¯å¤±è´¥")
        return False
    
    print("\nâœ… æ­¥éª¤3å®Œæˆï¼é…ç½®è®¾ç½®å®Œæˆ")
    print("ğŸ“‹ ä¸‹ä¸€æ­¥: !python step4_run_inference.py")
    print("ğŸ“ é…ç½®æ–‡ä»¶:")
    print("   - kaggle_inference_config.yaml (ä¸»é…ç½®)")
    print("   - LightningDiT/tokenizer/configs/vavae_f16d32.yaml (VA-VAEé…ç½®)")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
