"""
æ”¹è¿›çš„åˆ†ç±»å™¨è®­ç»ƒæ–¹æ¡ˆ
åŸºäºå°æ•°æ®é›†åˆ†ç±»çš„æœ€ä½³å®è·µï¼ŒåŒ…å«å¯¹æ¯”å­¦ä¹ å’Œæ­£åˆ™åŒ–æŠ€æœ¯
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import timm
import numpy as np
from PIL import Image
from pathlib import Path
import argparse
import json
from tqdm import tqdm
import matplotlib.pyplot as plt
from collections import defaultdict
import random


class InterUserContrastiveLoss(nn.Module):
    """ç”¨æˆ·é—´å¯¹æ¯”æŸå¤±å‡½æ•° - ä¸“é—¨å¤„ç†ç”¨æˆ·é—´å·®å¼‚å°çš„é—®é¢˜"""
    
    def __init__(self, temperature=0.07, margin=0.5):
        super().__init__()
        self.temperature = temperature
        self.margin = margin  # ç”¨äºhard negative mining
    
    def forward(self, features, labels):
        """
        features: [batch_size, feature_dim]
        labels: [batch_size] ç”¨æˆ·ID
        """
        batch_size = features.size(0)
        features = F.normalize(features, dim=1)
        
        # è®¡ç®—æ‰€æœ‰æ ·æœ¬é—´çš„ç›¸ä¼¼åº¦
        similarity_matrix = torch.matmul(features, features.T) / self.temperature
        
        # åˆ›å»ºæ­£è´Ÿæ ·æœ¬mask
        labels = labels.contiguous().view(-1, 1)
        positive_mask = torch.eq(labels, labels.T).float().to(features.device)
        negative_mask = 1 - positive_mask
        
        # ç§»é™¤å¯¹è§’çº¿ï¼ˆè‡ªå·±å’Œè‡ªå·±ï¼‰
        eye_mask = torch.eye(batch_size).to(features.device)
        positive_mask = positive_mask - eye_mask
        negative_mask = negative_mask - eye_mask
        
        # è®¡ç®—æ­£æ ·æœ¬æŸå¤±ï¼ˆåŒç”¨æˆ·æ ·æœ¬åº”è¯¥ç›¸ä¼¼ï¼‰
        pos_sim = similarity_matrix * positive_mask
        pos_loss = -pos_sim.sum() / positive_mask.sum().clamp(min=1)
        
        # è®¡ç®—è´Ÿæ ·æœ¬æŸå¤±ï¼ˆä¸åŒç”¨æˆ·æ ·æœ¬åº”è¯¥ä¸ç›¸ä¼¼ï¼‰
        # ä½¿ç”¨hard negative mining - åªå…³æ³¨éš¾åŒºåˆ†çš„è´Ÿæ ·æœ¬
        neg_sim = similarity_matrix * negative_mask
        hard_negatives = (neg_sim > self.margin) * negative_mask
        
        if hard_negatives.sum() > 0:
            neg_loss = neg_sim[hard_negatives > 0].mean()
        else:
            neg_loss = neg_sim[negative_mask > 0].mean()
        
        # æ€»æŸå¤± = å‡å°‘æ­£æ ·æœ¬è·ç¦» + å¢åŠ è´Ÿæ ·æœ¬è·ç¦»
        total_loss = pos_loss + neg_loss
        
        return total_loss
    

class SupConLoss(nn.Module):
    """ç›‘ç£å¯¹æ¯”æŸå¤± - æ›´é€‚åˆå¤šç±»åˆ†ç±»çš„å¯¹æ¯”å­¦ä¹ """
    
    def __init__(self, temperature=0.07, contrast_mode='all'):
        super().__init__()
        self.temperature = temperature
        self.contrast_mode = contrast_mode
    
    def forward(self, features, labels):
        """
        features: [batch_size, feature_dim]
        labels: [batch_size]
        """
        device = features.device
        batch_size = features.shape[0]
        
        labels = labels.contiguous().view(-1, 1)
        mask = torch.eq(labels, labels.T).float().to(device)
        
        # å½’ä¸€åŒ–ç‰¹å¾
        features = F.normalize(features, dim=1)
        
        # è®¡ç®—anchorå’Œæ‰€æœ‰æ ·æœ¬çš„ç›¸ä¼¼åº¦
        anchor_dot_contrast = torch.div(
            torch.matmul(features, features.T),
            self.temperature
        )
        
        # ä¸ºæ•°å€¼ç¨³å®šæ€§å‡å»æœ€å¤§å€¼
        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)
        logits = anchor_dot_contrast - logits_max.detach()
        
        # ç§»é™¤å¯¹è§’çº¿
        logits_mask = torch.scatter(
            torch.ones_like(mask),
            1,
            torch.arange(batch_size).view(-1, 1).to(device),
            0
        )
        mask = mask * logits_mask
        
        # è®¡ç®—logæ¦‚ç‡
        exp_logits = torch.exp(logits) * logits_mask
        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))
        
        # è®¡ç®—æ­£æ ·æœ¬çš„å¹³å‡logæ¦‚ç‡
        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)
        
        loss = -mean_log_prob_pos.mean()
        
        return loss


class ImprovedMicroDopplerDataset(Dataset):
    """æ”¹è¿›çš„å¾®å¤šæ™®å‹’æ•°æ®é›†ï¼ŒåŒ…å«å¼ºæ•°æ®å¢å¼º"""
    
    def __init__(self, data_dir, split='train', transform=None, contrastive_pairs=False):
        self.data_dir = Path(data_dir)
        self.split = split
        self.contrastive_pairs = contrastive_pairs
        self.samples = []
        
        # æ”¶é›†æ‰€æœ‰æ ·æœ¬
        user_samples = defaultdict(list)
        for user_dir in sorted(self.data_dir.glob("ID_*")):
            if user_dir.is_dir():
                user_id = int(user_dir.name.split('_')[1]) - 1
                for ext in ['*.png', '*.jpg', '*.jpeg']:
                    for img_path in user_dir.glob(ext):
                        user_samples[user_id].append(str(img_path))
        
        # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
        for user_id, paths in user_samples.items():
            random.shuffle(paths)
            split_idx = int(len(paths) * 0.8)
            
            if split == 'train':
                selected_paths = paths[:split_idx]
            else:  # validation
                selected_paths = paths[split_idx:]
            
            for path in selected_paths:
                self.samples.append((path, user_id))
        
        print(f"{split.capitalize()} set: {len(self.samples)} samples")
        
        # å¾®å¤šæ™®å‹’å›¾åƒä¸“ç”¨å˜æ¢ï¼ˆæœ€å°å¢å¼ºï¼Œä¿æŒé¢‘è°±ç»“æ„ï¼‰
        if split == 'train':
            self.transform = transforms.Compose([
                transforms.Resize((224, 224)),
                # åªä½¿ç”¨æè½»å¾®çš„å™ªå£°å¢å¼ºï¼Œä¸ç ´åé¢‘è°±ç»“æ„
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                # å¯é€‰ï¼šæå°çš„é«˜æ–¯å™ªå£°ï¼ˆæ¨¡æ‹Ÿæµ‹é‡å™ªå£°ï¼‰
                transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.01 if torch.rand(1) < 0.3 else x)
            ])
        else:
            self.transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        
        if transform:
            self.transform = transform
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        try:
            image = Image.open(img_path).convert('RGB')
            
            if self.contrastive_pairs and self.split == 'train':
                # ç”Ÿæˆå¯¹æ¯”æ ·æœ¬å¯¹
                image1 = self.transform(image)
                image2 = self.transform(image)  # åŒä¸€å›¾åƒçš„ä¸åŒå¢å¼º
                return (image1, image2), label
            else:
                image = self.transform(image)
                return image, label
                
        except Exception as e:
            print(f"Error loading {img_path}: {e}")
            # è¿”å›é›¶å¼ é‡
            if self.contrastive_pairs:
                return (torch.zeros(3, 224, 224), torch.zeros(3, 224, 224)), label
            else:
                return torch.zeros(3, 224, 224), label


class ImprovedClassifier(nn.Module):
    """æ”¹è¿›çš„åˆ†ç±»å™¨ï¼Œä¸“ä¸ºå¾®å¤šæ™®å‹’ä¿¡å·ä¼˜åŒ–"""
    
    def __init__(self, num_classes, backbone='resnet18', dropout_rate=0.3, freeze_layers=True):
        super().__init__()
        
        # ResNet18æ˜¯å¾®å¤šæ™®å‹’åˆ†ç±»çš„ç»å…¸é€‰æ‹©
        self.backbone = timm.create_model('resnet18', pretrained=True, num_classes=0, global_pool='avg')
        feature_dim = 512
        
        # çµæ´»çš„å±‚å†»ç»“ç­–ç•¥
        if freeze_layers == 'minimal':
            # æœ€å°å†»ç»“ï¼šåªå†»ç»“æœ€æ—©çš„å·ç§¯å±‚
            for name, param in self.backbone.named_parameters():
                if any(x in name for x in ['conv1', 'bn1']):
                    param.requires_grad = False
        elif freeze_layers == 'moderate':
            # ä¸­ç­‰å†»ç»“ï¼šå†»ç»“æ—©æœŸå±‚ï¼Œä¿ç•™é€‚åº”æ€§
            for name, param in self.backbone.named_parameters():
                if any(x in name for x in ['conv1', 'bn1', 'layer1']):
                    param.requires_grad = False
        elif freeze_layers == 'aggressive':
            # æ¿€è¿›å†»ç»“ï¼šå†»ç»“æ›´å¤šå±‚ï¼ˆå°æ•°æ®é›†ï¼‰
            for name, param in self.backbone.named_parameters():
                if any(x in name for x in ['conv1', 'bn1', 'layer1', 'layer2']):
                    param.requires_grad = False
        elif freeze_layers == 'none':
            # ä¸å†»ç»“ä»»ä½•å±‚ï¼ˆé£é™©æ›´é«˜ä½†å¯èƒ½æ•ˆæœæ›´å¥½ï¼‰
            pass
        
        # åˆ†ç±»å¤´
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(feature_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.5),
            nn.Linear(256, num_classes)
        )
        
        # å¯¹æ¯”å­¦ä¹ æŠ•å½±å¤´
        self.projection_head = nn.Sequential(
            nn.Linear(feature_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64)
        )
    
    def forward(self, x, return_features=False):
        features = self.backbone(x)
        
        if return_features:
            projected = self.projection_head(features)
            return features, projected
        
        logits = self.classifier(features)
        return logits


class FocalLoss(nn.Module):
    """Focal Loss - å¤„ç†ç±»åˆ«ä¸å¹³è¡¡"""
    
    def __init__(self, alpha=1, gamma=2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()


class LabelSmoothingLoss(nn.Module):
    """æ ‡ç­¾å¹³æ»‘æŸå¤±"""
    
    def __init__(self, num_classes, smoothing=0.1):
        super().__init__()
        self.num_classes = num_classes
        self.smoothing = smoothing
    
    def forward(self, pred, target):
        confidence = 1.0 - self.smoothing
        smooth_target = torch.full_like(pred, self.smoothing / (self.num_classes - 1))
        smooth_target.scatter_(1, target.unsqueeze(1), confidence)
        
        return F.kl_div(F.log_softmax(pred, dim=1), smooth_target, reduction='batchmean')


def train_with_contrastive_learning(model, train_loader, val_loader, device, args):
    """ä½¿ç”¨å¯¹æ¯”å­¦ä¹ è®­ç»ƒåˆ†ç±»å™¨"""
    
    # æŸå¤±å‡½æ•°
    if args.use_focal_loss:
        classification_criterion = FocalLoss()
    elif args.use_label_smoothing:
        classification_criterion = LabelSmoothingLoss(args.num_classes)
    else:
        classification_criterion = nn.CrossEntropyLoss()
    
    # é€‰æ‹©å¯¹æ¯”æŸå¤±ç±»å‹
    if args.contrastive_type == 'interuser':
        contrastive_criterion = InterUserContrastiveLoss(
            temperature=args.contrastive_temperature,
            margin=args.contrastive_margin
        )
    elif args.contrastive_type == 'supcon':
        contrastive_criterion = SupConLoss(temperature=args.contrastive_temperature)
    else:
        contrastive_criterion = SupConLoss(temperature=args.contrastive_temperature)  # é»˜è®¤ä½¿ç”¨SupCon
    
    # ä¼˜åŒ–å™¨ - ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡å’Œæ›´å¼ºçš„weight decay
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=args.lr, 
        weight_decay=args.weight_decay,
        betas=(0.9, 0.999)
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=10, T_mult=2, eta_min=1e-6
    )
    
    best_val_acc = 0
    patience_counter = 0
    
    history = {
        'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],
        'contrastive_loss': [], 'classification_loss': []
    }
    
    for epoch in range(args.epochs):
        # è®­ç»ƒ
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        contrastive_losses = []
        classification_losses = []
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}")
        for batch_idx, batch_data in enumerate(pbar):
            data, target = batch_data
            target = target.to(device)
            
            # è°ƒè¯•ä¿¡æ¯
            # print(f"Data type: {type(data)}, Target type: {type(target)}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯¹æ¯”å­¦ä¹ çš„tupleå¯¹
            if isinstance(data, (tuple, list)) and len(data) == 2:
                data1, data2 = data
                # ç¡®ä¿data1å’Œdata2æ˜¯tensor
                if isinstance(data1, torch.Tensor) and isinstance(data2, torch.Tensor):
                    data1, data2 = data1.to(device), data2.to(device)
                    
                    # å‰å‘ä¼ æ’­
                    features1, proj1 = model(data1, return_features=True)
                    features2, proj2 = model(data2, return_features=True)
                    
                    # åˆ†ç±»æŸå¤±
                    logits1 = model.classifier(features1)
                    logits2 = model.classifier(features2)
                    
                    cls_loss1 = classification_criterion(logits1, target)
                    cls_loss2 = classification_criterion(logits2, target)
                    classification_loss = (cls_loss1 + cls_loss2) / 2
                    
                    # å¯¹æ¯”æŸå¤±
                    combined_proj = torch.cat([proj1, proj2], dim=0)
                    combined_labels = torch.cat([target, target], dim=0)
                    contrastive_loss = contrastive_criterion(combined_proj, combined_labels)
                    
                    # æ€»æŸå¤±
                    total_loss = classification_loss + args.contrastive_weight * contrastive_loss
                    
                    # ç»Ÿè®¡
                    pred = logits1.argmax(dim=1)
                else:
                    raise ValueError(f"Expected tensors in contrastive pair, got {type(data1)}, {type(data2)}")
                
            elif isinstance(data, torch.Tensor):  # å¸¸è§„å¼ é‡æ•°æ®
                data = data.to(device)
                
                if args.use_contrastive:
                    # å³ä½¿æ˜¯å¸¸è§„æ•°æ®ï¼Œä¹Ÿå¯ä»¥ç”¨å¯¹æ¯”å­¦ä¹ 
                    features, proj = model(data, return_features=True)
                    logits = model.classifier(features)
                    
                    classification_loss = classification_criterion(logits, target)
                    contrastive_loss = contrastive_criterion(proj, target)
                    total_loss = classification_loss + args.contrastive_weight * contrastive_loss
                else:
                    logits = model(data)
                    classification_loss = classification_criterion(logits, target)
                    contrastive_loss = torch.tensor(0.0)
                    total_loss = classification_loss
                
                pred = logits.argmax(dim=1)
            
            else:
                raise ValueError(f"Unexpected data type: {type(data)}, content: {data}")
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            total_loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # ç»Ÿè®¡
            train_loss += total_loss.item()
            train_correct += pred.eq(target).sum().item()
            train_total += target.size(0)
            
            contrastive_losses.append(contrastive_loss.item())
            classification_losses.append(classification_loss.item())
            
            pbar.set_postfix({
                'Loss': f'{total_loss.item():.4f}',
                'Acc': f'{100.*train_correct/train_total:.1f}%'
            })
        
        # éªŒè¯
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(device), target.to(device)
                
                logits = model(data)
                loss = classification_criterion(logits, target)
                
                pred = logits.argmax(dim=1)
                val_loss += loss.item()
                val_correct += pred.eq(target).sum().item()
                val_total += target.size(0)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # ç»Ÿè®¡
        train_acc = 100. * train_correct / train_total
        val_acc = 100. * val_correct / val_total
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        
        history['train_loss'].append(avg_train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(avg_val_loss)
        history['val_acc'].append(val_acc)
        history['contrastive_loss'].append(np.mean(contrastive_losses))
        history['classification_loss'].append(np.mean(classification_losses))
        
        print(f"Epoch {epoch+1}/{args.epochs}")
        print(f"Train: Loss={avg_train_loss:.4f}, Acc={train_acc:.2f}%")
        print(f"Val: Loss={avg_val_loss:.4f}, Acc={val_acc:.2f}%")
        print(f"LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict().copy()
            patience_counter = 0
            print(f"ğŸ¯ New best validation accuracy: {best_val_acc:.2f}%")
        else:
            patience_counter += 1
        
        if patience_counter >= args.patience:
            print(f"ğŸ›‘ Early stopping at epoch {epoch+1}")
            break
    
    return model, best_model_state, best_val_acc, history


def main():
    parser = argparse.ArgumentParser(description='Improved classifier training')
    parser.add_argument('--data_dir', type=str, required=True, help='Dataset directory')
    parser.add_argument('--output_dir', type=str, default='./improved_classifier', help='Output directory')
    parser.add_argument('--num_classes', type=int, default=31, help='Number of classes')
    parser.add_argument('--epochs', type=int, default=200, help='Number of epochs')
    parser.add_argument('--batch_size', type=int, default=16, help='Batch size (smaller for small dataset)')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate (smaller)')
    parser.add_argument('--weight_decay', type=float, default=0.01, help='Weight decay (stronger)')
    parser.add_argument('--dropout_rate', type=float, default=0.5, help='Dropout rate')
    parser.add_argument('--patience', type=int, default=20, help='Early stopping patience')
    
    # å¯¹æ¯”å­¦ä¹ å‚æ•°
    parser.add_argument('--use_contrastive', action='store_true', help='Use contrastive learning')
    parser.add_argument('--contrastive_weight', type=float, default=0.5, help='Contrastive loss weight')
    parser.add_argument('--contrastive_temperature', type=float, default=0.07, help='Contrastive temperature')
    parser.add_argument('--contrastive_type', type=str, default='supcon', 
                       choices=['interuser', 'supcon'],
                       help='Contrastive loss type: interuser(hard negative mining), supcon(supervised contrastive)')
    parser.add_argument('--contrastive_margin', type=float, default=0.5, 
                       help='Margin for hard negative mining in interuser contrastive loss')
    
    # æŸå¤±å‡½æ•°é€‰æ‹©
    parser.add_argument('--use_focal_loss', action='store_true', help='Use focal loss')
    parser.add_argument('--use_label_smoothing', action='store_true', help='Use label smoothing')
    
    # æ¨¡å‹é€‰æ‹© - ResNet18ä¸“ä¸ºå¾®å¤šæ™®å‹’ä¼˜åŒ–
    parser.add_argument('--backbone', type=str, default='resnet18', help='Backbone architecture')
    parser.add_argument('--freeze_layers', type=str, default='moderate', 
                       choices=['none', 'minimal', 'moderate', 'aggressive'],
                       help='Layer freezing strategy: none(risk overfitting), minimal(conv1+bn1), moderate(+layer1), aggressive(+layer2)')
    
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    # æ•°æ®é›†
    train_dataset = ImprovedMicroDopplerDataset(
        args.data_dir, 
        split='train', 
        contrastive_pairs=args.use_contrastive
    )
    val_dataset = ImprovedMicroDopplerDataset(
        args.data_dir, 
        split='val'
    )
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=args.batch_size, 
        shuffle=True, 
        num_workers=4,
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=args.batch_size * 2, 
        shuffle=False, 
        num_workers=4,
        pin_memory=True
    )
    
    # æ¨¡å‹
    model = ImprovedClassifier(
        num_classes=args.num_classes,
        backbone=args.backbone,
        dropout_rate=args.dropout_rate,
        freeze_layers=args.freeze_layers
    ).to(device)
    
    print(f"Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    # è®­ç»ƒ
    model, best_state, best_acc, history = train_with_contrastive_learning(
        model, train_loader, val_loader, device, args
    )
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    model_path = output_dir / 'best_improved_classifier.pth'
    torch.save({
        'model_state_dict': best_state,
        'best_val_acc': best_acc,
        'num_classes': args.num_classes,
        'model_name': args.backbone,
        'args': vars(args)
    }, model_path)
    
    # ä¿å­˜è®­ç»ƒå†å²
    history_path = output_dir / 'training_history.json'
    with open(history_path, 'w') as f:
        json.dump(history, f, indent=2)
    
    print(f"\nâœ… Training completed!")
    print(f"Best validation accuracy: {best_acc:.2f}%")
    print(f"Model saved to: {model_path}")


if __name__ == "__main__":
    main()
