"""
æ”¹è¿›çš„åˆ†ç±»å™¨è®­ç»ƒæ–¹æ¡ˆ
åŸºäºå°æ•°æ®é›†åˆ†ç±»çš„æœ€ä½³å®è·µï¼ŒåŒ…å«å¯¹æ¯”å­¦ä¹ å’Œæ­£åˆ™åŒ–æŠ€æœ¯
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, DistributedSampler
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.nn.parallel import DistributedDataParallel as DDP
import torchvision.transforms as transforms
import timm
import numpy as np
from PIL import Image
from pathlib import Path
import argparse
import json
from tqdm import tqdm
import matplotlib.pyplot as plt
from collections import defaultdict
import random
import os


def setup_distributed():
    """åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ"""
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        rank = int(os.environ['RANK'])
        world_size = int(os.environ['WORLD_SIZE'])
        local_rank = int(os.environ['LOCAL_RANK'])
        
        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)
        torch.cuda.set_device(local_rank)
        
        return rank, world_size, local_rank
    else:
        return 0, 1, 0


def cleanup_distributed():
    """æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒ"""
    if dist.is_initialized():
        try:
            # æ·»åŠ è¶…æ—¶ä¿æŠ¤
            import time
            start_time = time.time()
            dist.destroy_process_group()
            print(f"âœ… åˆ†å¸ƒå¼æ¸…ç†å®Œæˆï¼Œè€—æ—¶ {time.time() - start_time:.2f}s")
        except Exception as e:
            print(f"âš ï¸ åˆ†å¸ƒå¼æ¸…ç†å¤±è´¥: {e}")


def is_main_process():
    """åˆ¤æ–­æ˜¯å¦ä¸ºä¸»è¿›ç¨‹"""
    return not dist.is_initialized() or dist.get_rank() == 0


class GlobalNegativeContrastiveLoss(nn.Module):
    """å…¨å±€è´Ÿæ ·æœ¬å¯¹æ¯”æŸå¤±å‡½æ•°"""
    
    def __init__(self, num_classes, temperature=0.07, margin=0.5, memory_size=200):
        super().__init__()
        self.num_classes = num_classes
        self.temperature = temperature
        self.margin = margin
        self.memory_size = memory_size
        
        # ä¸ºæ¯ä¸ªç±»åˆ«ç»´æŠ¤ç‰¹å¾memory bank
        self.register_buffer('memory_bank', torch.randn(num_classes, memory_size, 512))
        self.register_buffer('memory_ptr', torch.zeros(num_classes, dtype=torch.long))
        self.memory_bank = F.normalize(self.memory_bank, dim=2)
    
    @torch.no_grad()
    def update_memory_bank(self, features, labels):
        """æ›´æ–°memory bank"""
        features_normalized = F.normalize(features, dim=1)
        
        for i, label in enumerate(labels):
            label = label.item()
            ptr = self.memory_ptr[label].item()
            
            # ç›´æ¥æ›´æ–°ï¼Œå› ä¸ºå·²ç»åœ¨no_gradä¸Šä¸‹æ–‡ä¸­
            self.memory_bank[label, ptr] = features_normalized[i].detach()
            self.memory_ptr[label] = (ptr + 1) % self.memory_size
    
    def forward(self, features, labels):
        """
        features: [batch_size, feature_dim]
        labels: [batch_size] ç”¨æˆ·ID
        """
        batch_size = features.size(0)
        features = F.normalize(features, dim=1)
        
        # æ›´æ–°memory bank - ä½¿ç”¨detached featuresé¿å…æ¢¯åº¦é—®é¢˜
        with torch.no_grad():
            self.update_memory_bank(features.detach(), labels)
        
        total_loss = 0
        num_pairs = 0
        
        # å¯¹batchä¸­æ¯ä¸ªæ ·æœ¬è®¡ç®—ä¸å…¨å±€è´Ÿæ ·æœ¬çš„å¯¹æ¯”æŸå¤±
        for i, anchor_label in enumerate(labels):
            anchor_feature = features[i].unsqueeze(0)  # [1, feature_dim]
            
            # æ­£æ ·æœ¬ï¼šåŒç±»åˆ«çš„å…¶ä»–æ ·æœ¬ï¼ˆbatchå†… + memory bankï¼‰
            positive_features = []
            
            # batchå†…æ­£æ ·æœ¬
            batch_positives = features[labels == anchor_label]
            if len(batch_positives) > 1:  # é™¤äº†è‡ªå·±è¿˜æœ‰å…¶ä»–åŒç±»æ ·æœ¬
                mask = torch.arange(len(batch_positives)) != (labels == anchor_label).nonzero()[0]
                if mask.any():
                    positive_features.append(batch_positives[mask])
            
            # memory bankä¸­çš„æ­£æ ·æœ¬
            memory_positives = self.memory_bank[anchor_label]  # [memory_size, feature_dim]
            positive_features.append(memory_positives[:50])  # å–å‰50ä¸ªé¿å…è¿‡å¤š
            
            if positive_features:
                positive_features = torch.cat(positive_features, dim=0)
                pos_similarity = torch.matmul(anchor_feature, positive_features.T) / self.temperature
                pos_loss = -pos_similarity.mean()
            else:
                pos_loss = torch.tensor(0.0, device=features.device)
            
            # è´Ÿæ ·æœ¬ï¼šæ‰€æœ‰å…¶ä»–ç±»åˆ«çš„æ ·æœ¬ï¼ˆå…¨å±€ï¼‰
            negative_features = []
            for neg_label in range(self.num_classes):
                if neg_label != anchor_label:
                    # ä»memory bankä¸­é‡‡æ ·è´Ÿæ ·æœ¬
                    neg_samples = self.memory_bank[neg_label][:20]  # æ¯ä¸ªç±»åˆ«20ä¸ªæ ·æœ¬
                    negative_features.append(neg_samples)
            
            if negative_features:
                negative_features = torch.cat(negative_features, dim=0)  # [num_negatives, feature_dim]
                neg_similarity = torch.matmul(anchor_feature, negative_features.T) / self.temperature
                
                # Hard negative mining
                hard_mask = neg_similarity.squeeze() > self.margin
                if hard_mask.any():
                    neg_loss = neg_similarity.squeeze()[hard_mask].mean()
                else:
                    neg_loss = neg_similarity.mean()
            else:
                neg_loss = torch.tensor(0.0, device=features.device)
            
            # ç´¯ç§¯æŸå¤±
            total_loss += pos_loss + neg_loss
            num_pairs += 1
        
        return total_loss / num_pairs if num_pairs > 0 else torch.tensor(0.0, device=features.device)


class InterUserContrastiveLoss(nn.Module):
    """ç”¨æˆ·é—´å¯¹æ¯”æŸå¤±å‡½æ•° - ç®€åŒ–ç‰ˆæœ¬é¿å…æ¢¯åº¦é—®é¢˜"""
    
    def __init__(self, temperature=0.07, margin=0.5):
        super().__init__()
        self.temperature = temperature
        self.margin = margin
    
    def forward(self, features, labels):
        """
        features: [batch_size, feature_dim] 
        labels: [batch_size] ç”¨æˆ·ID
        """
        batch_size = features.size(0)
        if batch_size < 2:
            return torch.tensor(0.0, device=features.device, requires_grad=True)
        
        # å½’ä¸€åŒ–ç‰¹å¾
        features_norm = F.normalize(features, dim=1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        sim_matrix = torch.matmul(features_norm, features_norm.T) / self.temperature
        
        # åˆ›å»ºæ ‡ç­¾mask
        labels_expanded = labels.view(-1, 1)
        pos_mask = torch.eq(labels_expanded, labels_expanded.T).float()
        
        # ç§»é™¤å¯¹è§’çº¿ï¼ˆè‡ªå·±å’Œè‡ªå·±çš„ç›¸ä¼¼åº¦ï¼‰
        eye_mask = torch.eye(batch_size, device=features.device)
        pos_mask = pos_mask * (1.0 - eye_mask)
        neg_mask = (1.0 - torch.eq(labels_expanded, labels_expanded.T).float()) * (1.0 - eye_mask)
        
        # æ•°å€¼ç¨³å®šæ€§ï¼šå‡å»æœ€å¤§å€¼
        sim_max, _ = torch.max(sim_matrix, dim=1, keepdim=True)
        sim_matrix_stable = sim_matrix - sim_max.detach()
        
        # è®¡ç®—InfoNCEé£æ ¼çš„å¯¹æ¯”æŸå¤±
        exp_sim = torch.exp(sim_matrix_stable)
        
        # è®¡ç®—æ¯ä¸ªanchorçš„æŸå¤±
        pos_sum = torch.sum(exp_sim * pos_mask, dim=1, keepdim=True)
        neg_sum = torch.sum(exp_sim * neg_mask, dim=1, keepdim=True)
        
        # é¿å…é™¤é›¶
        pos_sum = torch.clamp(pos_sum, min=1e-8)
        total_sum = pos_sum + neg_sum + 1e-8
        
        # InfoNCEæŸå¤±ï¼š-log(pos_sum / total_sum)
        loss_per_sample = -torch.log(pos_sum / total_sum)
        
        # åªå¯¹æœ‰æ­£æ ·æœ¬çš„anchorè®¡ç®—æŸå¤±
        has_pos = (torch.sum(pos_mask, dim=1) > 0).float()
        valid_loss = loss_per_sample.squeeze() * has_pos
        
        if has_pos.sum() > 0:
            return valid_loss.sum() / has_pos.sum()
        else:
            return torch.tensor(0.0, device=features.device, requires_grad=True)
    

class SupConLoss(nn.Module):
    """ç›‘ç£å¯¹æ¯”æŸå¤± - é¿å…æ‰€æœ‰åŸåœ°æ“ä½œ"""
    
    def __init__(self, temperature=0.07):
        super().__init__()
        self.temperature = temperature
    
    def forward(self, features, labels):
        """
        features: [batch_size, feature_dim]
        labels: [batch_size]
        """
        device = features.device
        batch_size = features.shape[0]
        
        if batch_size < 2:
            return torch.tensor(0.0, device=device, requires_grad=True)
        
        # å½’ä¸€åŒ–ç‰¹å¾
        features_norm = F.normalize(features, dim=1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        sim_matrix = torch.matmul(features_norm, features_norm.T) / self.temperature
        
        # åˆ›å»ºæ­£æ ·æœ¬mask
        labels_expanded = labels.view(-1, 1)
        pos_mask = torch.eq(labels_expanded, labels_expanded.T).float()
        
        # ç§»é™¤å¯¹è§’çº¿ - é¿å…åŸåœ°æ“ä½œ
        eye_mask = torch.eye(batch_size, device=device)
        pos_mask = torch.sub(pos_mask, eye_mask)
        
        # è´Ÿæ ·æœ¬mask
        neg_mask = torch.ne(labels_expanded, labels_expanded.T).float()
        
        # æ•°å€¼ç¨³å®šæ€§
        sim_max, _ = torch.max(sim_matrix, dim=1, keepdim=True)
        sim_matrix = torch.sub(sim_matrix, sim_max.detach())
        
        # è®¡ç®—InfoNCEæŸå¤±
        exp_sim = torch.exp(sim_matrix)
        
        # åˆ†æ¯ï¼šæ‰€æœ‰è´Ÿæ ·æœ¬ + æ­£æ ·æœ¬
        denominator = torch.sum(exp_sim * neg_mask, dim=1, keepdim=True) + \
                     torch.sum(exp_sim * pos_mask, dim=1, keepdim=True)
        
        # åˆ†å­ï¼šæ­£æ ·æœ¬
        numerator = torch.sum(exp_sim * pos_mask, dim=1, keepdim=True)
        
        # é¿å…é™¤é›¶
        loss = torch.neg(torch.log(torch.div(numerator, denominator + 1e-8)))
        
        # åªè®¡ç®—æœ‰æ­£æ ·æœ¬çš„è¡Œ
        valid_mask = (pos_mask.sum(dim=1) > 0)
        if valid_mask.sum() > 0:
            return loss[valid_mask].mean()
        else:
            return torch.tensor(0.0, device=device, requires_grad=True)


class ImprovedMicroDopplerDataset(Dataset):
    """æ”¹è¿›çš„å¾®å¤šæ™®å‹’æ•°æ®é›†ï¼ŒåŒ…å«å¼ºæ•°æ®å¢å¼º"""
    
    def __init__(self, data_dir, split='train', transform=None, contrastive_pairs=False, 
                 generated_data_dirs=None, use_generated=False):
        self.data_dir = Path(data_dir)
        self.split = split
        self.contrastive_pairs = contrastive_pairs
        self.generated_data_dirs = generated_data_dirs or []
        self.use_generated = use_generated
        self.samples = []
        
        # åŠ è½½æ•°æ®
        self._load_data()
        
        # å¦‚æœæ˜¯è®­ç»ƒé›†ä¸”ä½¿ç”¨ç”Ÿæˆæ•°æ®ï¼Œåˆ™åŠ è½½åˆæˆæ•°æ®
        if self.split == 'train' and self.use_generated:
            self._load_generated_data()
        
        # æ•°æ®åˆ’åˆ†å¤„ç†
        self._split_data()
        
        # å¾®å¤šæ™®å‹’å›¾åƒä¸“ç”¨å˜æ¢ï¼ˆæœ€å°å¢å¼ºï¼Œä¿æŒé¢‘è°±ç»“æ„ï¼‰
        if split == 'train':
            self.transform = transforms.Compose([
                transforms.Resize((256, 256)),
                # åªä½¿ç”¨æè½»å¾®çš„å™ªå£°å¢å¼ºï¼Œä¸ç ´åé¢‘è°±ç»“æ„
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                # å¯é€‰ï¼šæå°çš„é«˜æ–¯å™ªå£°ï¼ˆæ¨¡æ‹Ÿæµ‹é‡å™ªå£°ï¼‰ - é¿å…åŸåœ°æ“ä½œ
                # transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.01 if torch.rand(1).item() < 0.3 else x)
            ])
        else:
            self.transform = transforms.Compose([
                transforms.Resize((256, 256)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
        
        if transform:
            self.transform = transform
    
    def _load_data(self):
        """åŠ è½½çœŸå®æ•°æ®é›†"""
        if not self.data_dir.exists():
            raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
        
        user_samples = defaultdict(list)
        self._load_data_from_dir(self.data_dir, user_samples, 'real')
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_samples = sum(len(samples) for samples in user_samples.values())
        print(f"çœŸå®æ•°æ®: {len(user_samples)} ä¸ªç”¨æˆ·çš„ {total_samples} å¼ å›¾åƒ")
    
    def _load_data_from_dir(self, data_dir, user_samples, data_type='real'):
        """ä»æŒ‡å®šç›®å½•åŠ è½½æ•°æ®"""
        data_dir = Path(data_dir)
        if not data_dir.exists():
            print(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
            return
            
        # æŸ¥æ‰¾ç”¨æˆ·ç›®å½•ï¼šæ”¯æŒID_*, User_*, user_*æ ¼å¼
        id_dirs = []
        for pattern in ["ID_*", "User_*", "user_*"]:
            id_dirs.extend(data_dir.glob(pattern))
        
        if len(id_dirs) == 0:
            print(f"Warning: åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ°ID_*ã€User_*æˆ–user_*æ ¼å¼çš„ç”¨æˆ·ç›®å½•")
            # å°è¯•æ•°å­—æ ¼å¼ç›®å½•
            id_dirs = [d for d in data_dir.iterdir() if d.is_dir() and d.name.isdigit()]
            id_dirs = sorted(id_dirs, key=lambda x: int(x.name))
        
        for user_dir in sorted(id_dirs):
            user_folder_name = user_dir.name
            
            # è§£æç”¨æˆ·ID
            if user_folder_name.startswith("ID_"):
                user_id = int(user_folder_name.split('_')[1]) - 1  # ID_1->0, ID_2->1, ..., ID_31->30
            elif user_folder_name.startswith(("User_", "user_")):
                user_id = int(user_folder_name.split('_')[1])  # User_00->0, User_01->1, ..., User_30->30
            else:
                # å°è¯•ç›´æ¥è§£ææ•°å­—
                try:
                    user_id = int(user_folder_name)
                except ValueError:
                    print(f"æ— æ³•è§£æç”¨æˆ·ID: {user_folder_name}")
                    continue
            
            # éªŒè¯æ˜ å°„æ­£ç¡®æ€§
            if data_type == 'generated' and user_folder_name.startswith("User_"):
                expected_real_id = f"ID_{user_id + 1}"  # User_00 -> ID_1
                if not dist.is_initialized() or dist.get_rank() == 0:
                    print(f"   æ˜ å°„: {user_folder_name} -> {expected_real_id} (user_id={user_id})")
            
            # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
            image_files = list(user_dir.glob("*.png")) + list(user_dir.glob("*.jpg"))
            
            current_data_samples = []
            for img_path in image_files:
                path_info = (str(img_path), data_type)
                current_data_samples.append(path_info)
                user_samples[user_id].append(path_info)
            
            # æ·»åŠ åˆ°ä¸»æ ·æœ¬åˆ—è¡¨
            for path_info in current_data_samples:
                path, dtype = path_info
                self.samples.append((path, user_id, dtype))
    
    def _load_generated_data(self):
        """åŠ è½½åˆæˆæ•°æ®"""
        if not self.generated_data_dirs:
            return
        
        total_generated = 0
        user_samples = defaultdict(list)
        
        for gen_dir in self.generated_data_dirs:
            gen_dir = Path(gen_dir)
            if gen_dir.exists():
                print(f"åŠ è½½åˆæˆæ•°æ®: {gen_dir}")
                self._load_data_from_dir(gen_dir, user_samples, 'generated')
                
        # ç»Ÿè®¡åˆæˆæ•°æ®
        for user_id, samples in user_samples.items():
            generated_count = sum(1 for _, dtype in samples if dtype == 'generated')
            total_generated += generated_count
            
        print(f" åˆæˆæ•°æ®: {len(user_samples)} ä¸ªç”¨æˆ·çš„ {total_generated} å¼ å›¾åƒ")
    
    def _split_data(self):
        """æ ¹æ®splitå‚æ•°åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†"""
        if not hasattr(self, '_all_samples_collected'):
            # æ”¶é›†æ‰€æœ‰å·²åŠ è½½çš„æ ·æœ¬ï¼ŒæŒ‰ç”¨æˆ·åˆ†ç»„
            user_samples = defaultdict(list)
            for sample in self.samples:
                if len(sample) == 3:
                    path, user_id, data_type = sample
                else:
                    path, user_id = sample
                    data_type = 'real'
                user_samples[user_id].append((path, data_type))
            
            # æ¸…ç©ºå½“å‰æ ·æœ¬åˆ—è¡¨ï¼Œå‡†å¤‡é‡æ–°åˆ†é…
            self.samples = []
            
            # æŒ‰ç”¨æˆ·åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆ7:3æ¯”ä¾‹ï¼‰
            random.seed(42)  # ç¡®ä¿å¯é‡å¤
            for user_id, samples in user_samples.items():
                # åˆ†ç¦»çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®
                real_samples = [(p, dt) for p, dt in samples if dt == 'real']
                generated_samples = [(p, dt) for p, dt in samples if dt == 'generated']
                
                # åªå¯¹çœŸå®æ•°æ®è¿›è¡Œè®­ç»ƒ/éªŒè¯åˆ’åˆ†
                if real_samples:
                    random.shuffle(real_samples)
                    split_idx = int(len(real_samples) * 0.7)
                    
                    if self.split == 'train':
                        # è®­ç»ƒé›†ï¼šçœŸå®è®­ç»ƒæ•°æ® + å…¨éƒ¨åˆæˆæ•°æ®
                        selected_samples = real_samples[:split_idx] + generated_samples
                    else:  # validation
                        # éªŒè¯é›†ï¼šåªç”¨çœŸå®éªŒè¯æ•°æ®
                        selected_samples = real_samples[split_idx:]
                    
                    for path, data_type in selected_samples:
                        self.samples.append((path, user_id, data_type))
            
            self._all_samples_collected = True
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        if len(self.samples[idx]) == 3:
            img_path, label, data_type = self.samples[idx]
        else:
            img_path, label = self.samples[idx]
            data_type = 'real'
        
        try:
            image = Image.open(img_path).convert('RGB')
            
            if self.contrastive_pairs and self.split == 'train':
                # ç”Ÿæˆå¯¹æ¯”æ ·æœ¬å¯¹
                image1 = self.transform(image)
                image2 = self.transform(image)  # åŒä¸€å›¾åƒçš„ä¸åŒå¢å¼º
                return (image1, image2), label
            else:
                image = self.transform(image)
                return image, label
                
        except Exception as e:
            print(f"Error loading {img_path}: {e}")
            # è¿”å›é›¶å¼ é‡ - å°ºå¯¸ä¸å®é™…å›¾åƒä¸€è‡´
            if self.contrastive_pairs:
                return (torch.zeros(3, 256, 256), torch.zeros(3, 256, 256)), label
            else:
                return torch.zeros(3, 256, 256), label


class ImprovedClassifier(nn.Module):
    """æ”¹è¿›çš„åˆ†ç±»å™¨ï¼Œä¸“ä¸ºå¾®å¤šæ™®å‹’ä¿¡å·ä¼˜åŒ– - å®Œå…¨é¿å…inplaceæ“ä½œ"""
    
    def __init__(self, num_classes, backbone='resnet18', dropout_rate=0.3, freeze_layers=True):
        super().__init__()
        
        # ä½¿ç”¨æ ‡å‡†ResNet18é¿å…TIMMçš„æ½œåœ¨inplaceé—®é¢˜
        import torchvision.models as models
        self.backbone = models.resnet18(pretrained=True)
        # ç§»é™¤æœ€åçš„åˆ†ç±»å±‚
        self.backbone.fc = nn.Identity()
        feature_dim = 512
        
        # é€’å½’ç¦ç”¨æ‰€æœ‰ReLUçš„inplaceæ“ä½œ
        self._disable_inplace_operations(self.backbone)
        
        # çµæ´»çš„å±‚å†»ç»“ç­–ç•¥
        if freeze_layers == 'minimal':
            # æœ€å°å†»ç»“ï¼šåªå†»ç»“æœ€æ—©çš„å·ç§¯å±‚
            for name, param in self.backbone.named_parameters():
                if any(x in name for x in ['conv1', 'bn1']):
                    param.requires_grad = False
        elif freeze_layers == 'moderate':
            # ä¸­ç­‰å†»ç»“ï¼šå†»ç»“æ—©æœŸå±‚ï¼Œä¿ç•™é€‚åº”æ€§
            for name, param in self.backbone.named_parameters():
                if any(x in name for x in ['conv1', 'bn1', 'layer1']):
                    param.requires_grad = False
        elif freeze_layers == 'aggressive':
            # æ¿€è¿›å†»ç»“ï¼šå†»ç»“æ›´å¤šå±‚ï¼ˆå°æ•°æ®é›†ï¼‰
            for name, param in self.backbone.named_parameters():
                if any(x in name for x in ['conv1', 'bn1', 'layer1', 'layer2']):
                    param.requires_grad = False
        elif freeze_layers == 'none':
            # ä¸å†»ç»“ä»»ä½•å±‚ï¼ˆé£é™©æ›´é«˜ä½†å¯èƒ½æ•ˆæœæ›´å¥½ï¼‰
            pass
        
        # åˆ†ç±»å¤´ - ç¡®ä¿æ‰€æœ‰æ¿€æ´»å‡½æ•°éƒ½ä¸æ˜¯inplace
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(feature_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=False),  # æ˜ç¡®ç¦ç”¨inplace
            nn.Dropout(dropout_rate * 0.5),
            nn.Linear(256, num_classes)
        )
        
        # å¯¹æ¯”å­¦ä¹ æŠ•å½±å¤´
        self.projection_head = nn.Sequential(
            nn.Linear(feature_dim, 128),
            nn.ReLU(inplace=False),  # æ˜ç¡®ç¦ç”¨inplace
            nn.Linear(128, 64)
        )
    
    def _disable_inplace_operations(self, module):
        """é€’å½’ç¦ç”¨æ¨¡å—ä¸­æ‰€æœ‰çš„inplaceæ“ä½œ"""
        for child_name, child in module.named_children():
            if isinstance(child, nn.ReLU):
                # æ›¿æ¢inplace=Trueçš„ReLU
                setattr(module, child_name, nn.ReLU(inplace=False))
            elif isinstance(child, nn.ReLU6):
                setattr(module, child_name, nn.ReLU6(inplace=False))
            elif isinstance(child, nn.LeakyReLU):
                setattr(module, child_name, nn.LeakyReLU(child.negative_slope, inplace=False))
            else:
                # é€’å½’å¤„ç†å­æ¨¡å—
                self._disable_inplace_operations(child)
    
    def forward(self, x, return_features=False):
        features = self.backbone(x)
        
        if return_features:
            projected = self.projection_head(features)
            return features, projected
        
        logits = self.classifier(features)
        return logits


def train_with_contrastive_learning(model, train_loader, val_loader, device, args, rank=0):
    """æ”¹è¿›çš„è®­ç»ƒå‡½æ•°ï¼Œé›†æˆå¯¹æ¯”å­¦ä¹ """
    
    # åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®
    def is_main_process():
        return rank == 0
    
    # éªŒè¯æ•°æ®é›†æ˜¯å¦ä¸ºç©º
    if len(train_loader.dataset) == 0:
        if is_main_process():
            print("è®­ç»ƒæ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•å¼€å§‹è®­ç»ƒ")
        return model, None, 0.0, {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'contrastive_loss': [], 'classification_loss': []}
    
    if len(val_loader.dataset) == 0:
        if is_main_process():
            print("éªŒè¯æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•å¼€å§‹è®­ç»ƒ")
        return model, None, 0.0, {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'contrastive_loss': [], 'classification_loss': []}
    
    if is_main_process():
        print(f"è®­ç»ƒé›†: {len(train_loader.dataset)} æ ·æœ¬, éªŒè¯é›†: {len(val_loader.dataset)} æ ·æœ¬")
    
    # æŸå¤±å‡½æ•°
    if args.use_focal_loss:
        classification_criterion = FocalLoss()
    elif args.use_label_smoothing:
        classification_criterion = LabelSmoothingLoss(args.num_classes)
    else:
        classification_criterion = nn.CrossEntropyLoss()
    
    # é‡æ–°å¯ç”¨å¯¹æ¯”å­¦ä¹  - æ ¹æ®ç±»å‹é€‰æ‹©æŸå¤±å‡½æ•°
    if args.use_contrastive:
        if args.contrastive_type == 'interuser':
            if is_main_process():
                print("å¯ç”¨InterUserContrastiveLosså¯¹æ¯”å­¦ä¹  - ä¼˜åŒ–ç”¨æˆ·é—´å·®å¼‚")
            contrastive_criterion = InterUserContrastiveLoss(
                temperature=args.contrastive_temperature,
                margin=args.contrastive_margin
            )
        elif args.contrastive_type == 'supcon':
            if is_main_process():
                print("å¯ç”¨SupConLosså¯¹æ¯”å­¦ä¹  - ç›‘ç£å¯¹æ¯”å­¦ä¹ ")
            contrastive_criterion = SupConLoss(temperature=args.contrastive_temperature)
        elif args.contrastive_type == 'global':
            if is_main_process():
                print("å¯ç”¨GlobalNegativeContrastiveLoss - å…¨å±€è´Ÿæ ·æœ¬å¯¹æ¯”")
            contrastive_criterion = GlobalNegativeContrastiveLoss(
                memory_size=64,
                temperature=args.contrastive_temperature
            )
        else:
            if is_main_process():
                print(f"æœªçŸ¥å¯¹æ¯”å­¦ä¹ ç±»å‹: {args.contrastive_type}ï¼Œä½¿ç”¨SupConLoss")
            contrastive_criterion = SupConLoss(temperature=args.contrastive_temperature)
    else:
        contrastive_criterion = None
    
    # ä¼˜åŒ–å™¨ - ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡å’Œæ›´å¼ºçš„weight decay
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=args.lr, 
        weight_decay=args.weight_decay,
        betas=(0.9, 0.999)
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=10, T_mult=2, eta_min=1e-6
    )
    
    best_val_acc = 0
    patience_counter = 0
    
    history = {
        'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],
        'contrastive_loss': [], 'classification_loss': []
    }
    
    # ç¦ç”¨å¼‚å¸¸æ£€æµ‹ï¼Œé¿å…é¢å¤–å¼€é”€
    torch.autograd.set_detect_anomaly(False)
    
    for epoch in range(args.epochs):
        # è®­ç»ƒ
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        contrastive_losses = []
        classification_losses = []
        
        # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
        if is_main_process():
            pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}")
        else:
            pbar = train_loader
        
        for batch_idx, batch_data in enumerate(pbar):
            data, target = batch_data
            target = target.to(device)
            
            # å¯¹æ¯”å­¦ä¹ è®­ç»ƒå¾ªç¯
            if isinstance(data, (tuple, list)) and len(data) == 2:
                # å¯¹æ¯”å­¦ä¹ æ•°æ®å¯¹
                data1, data2 = data[0].to(device), data[1].to(device)
                
                if args.use_contrastive and contrastive_criterion is not None:
                    # å®Œå…¨åˆå¹¶è¾“å…¥ï¼Œå•æ¬¡æ¨¡å‹å‰å‘ä¼ æ’­é¿å…ä»»ä½•å‚æ•°é‡å¤ä½¿ç”¨
                    combined_data = torch.cat([data1, data2], dim=0)
                    batch_size = data1.size(0)
                    combined_target = torch.cat([target, target], dim=0)
                    
                    # å•æ¬¡å®Œæ•´å‰å‘ä¼ æ’­è·å–ç‰¹å¾å’ŒæŠ•å½±
                    combined_features, combined_proj = model(combined_data, return_features=True)
                    
                    # å•æ¬¡åˆ†ç±»å™¨è°ƒç”¨
                    if hasattr(model, 'module'):
                        combined_logits = model.module.classifier(combined_features)
                    else:
                        combined_logits = model.classifier(combined_features)
                    
                    # åˆ†å‰²ç»“æœ
                    logits1 = combined_logits[:batch_size]
                    logits2 = combined_logits[batch_size:]
                    proj1 = combined_proj[:batch_size] 
                    proj2 = combined_proj[batch_size:]
                    
                    # åˆ†ç±»æŸå¤±
                    cls_loss1 = classification_criterion(logits1, target)
                    cls_loss2 = classification_criterion(logits2, target)
                    classification_loss = (cls_loss1 + cls_loss2) / 2
                    
                    # å¯¹æ¯”æŸå¤±ï¼šä½¿ç”¨æŠ•å½±ç‰¹å¾
                    contrastive_loss = contrastive_criterion(combined_proj, combined_target)
                    
                    # æ€»æŸå¤±
                    total_loss = classification_loss + args.contrastive_weight * contrastive_loss
                    pred = logits1.argmax(dim=1)
                else:
                    # åªä½¿ç”¨ç¬¬ä¸€å¼ å›¾è¿›è¡Œåˆ†ç±»
                    logits = model(data1)
                    total_loss = classification_criterion(logits, target)
                    classification_loss = total_loss
                    contrastive_loss = torch.tensor(0.0, device=device)
                    pred = logits.argmax(dim=1)
            else:
                # å•å¼ å›¾åƒè®­ç»ƒ
                if isinstance(data, (tuple, list)):
                    data = data[0]
                
                data = data.to(device)
                logits = model(data)
                total_loss = classification_criterion(logits, target)
                classification_loss = total_loss
                contrastive_loss = torch.tensor(0.0, device=device)
                pred = logits.argmax(dim=1)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            total_loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # ç»Ÿè®¡
            train_loss += total_loss.item()
            train_correct += pred.eq(target).sum().item()
            train_total += target.size(0)
            
            contrastive_losses.append(contrastive_loss.item() if isinstance(contrastive_loss, torch.Tensor) else 0.0)
            classification_losses.append(classification_loss.item())
            
            # åªåœ¨ä¸»è¿›ç¨‹æ›´æ–°è¿›åº¦æ¡
            if is_main_process() and isinstance(pbar, tqdm):
                pbar.set_postfix({
                    'Loss': f'{total_loss.item():.4f}',
                    'Acc': f'{100.*train_correct/train_total:.1f}%'
                })
        
        # éªŒè¯
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(device), target.to(device)
                
                logits = model(data)
                loss = classification_criterion(logits, target)
                
                pred = logits.argmax(dim=1)
                val_loss += loss.item()
                val_correct += pred.eq(target).sum().item()
                val_total += target.size(0)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # é˜²æ­¢é™¤é›¶é”™è¯¯
        if len(train_loader) == 0:
            print("è®­ç»ƒæ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ ¼å¼")
            return model, None, 0.0, {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'contrastive_loss': [], 'classification_loss': []}
        
        if len(val_loader) == 0:
            print("éªŒè¯æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ ¼å¼")
            return model, None, 0.0, {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'contrastive_loss': [], 'classification_loss': []}
        
        # ç»Ÿè®¡
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_acc = 100. * train_correct / train_total if train_total > 0 else 0.0
        val_acc = 100. * val_correct / val_total if val_total > 0 else 0.0
        
        history['train_loss'].append(avg_train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(avg_val_loss)
        history['val_acc'].append(val_acc)
        history['contrastive_loss'].append(np.mean(contrastive_losses))
        history['classification_loss'].append(np.mean(classification_losses))
        
        # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
        if is_main_process():
            print(f"Epoch {epoch+1}/{args.epochs}")
            print(f"Train: Loss={avg_train_loss:.4f}, Acc={train_acc:.2f}%")
            print(f"Val: Loss={avg_val_loss:.4f}, Acc={val_acc:.2f}%")
            print(f"LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # æ—©åœå’Œæœ€ä½³æ¨¡å‹ä¿å­˜ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
        if is_main_process():
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_model_state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()
                patience_counter = 0
                print(f"New best validation accuracy: {best_val_acc:.2f}%")
            else:
                patience_counter += 1
            
            if patience_counter >= args.patience:
                print(f"Early stopping at epoch {epoch+1}")
                break
    
    return model, best_model_state, best_val_acc, history


def main():
    parser = argparse.ArgumentParser(description='Improved classifier training with distributed support')
    parser.add_argument('--data_dir', type=str, required=True, help='Dataset directory')
    parser.add_argument('--output_dir', type=str, default='./improved_classifier', help='Output directory')
    parser.add_argument('--num_classes', type=int, default=31, help='Number of classes')
    parser.add_argument('--epochs', type=int, default=200, help='Number of epochs')
    parser.add_argument('--batch_size', type=int, default=16, help='Batch size per GPU')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate (smaller)')
    parser.add_argument('--weight_decay', type=float, default=0.01, help='Weight decay (stronger)')
    parser.add_argument('--dropout_rate', type=float, default=0.5, help='Dropout rate')
    parser.add_argument('--patience', type=int, default=10, help='Early stopping patience')
    
    # å¯¹æ¯”å­¦ä¹ å‚æ•°
    parser.add_argument('--use_contrastive', action='store_true', help='Use contrastive learning')
    parser.add_argument('--contrastive_weight', type=float, default=0.5, help='Contrastive loss weight')
    parser.add_argument('--contrastive_temperature', type=float, default=0.07, help='Contrastive temperature')
    parser.add_argument('--contrastive_type', type=str, default='supcon', 
                       choices=['global', 'interuser', 'supcon'],
                       help='Contrastive loss type: global(memory bank all users), interuser(hard negative mining), supcon(supervised contrastive)')
    parser.add_argument('--contrastive_margin', type=float, default=0.5, 
                       help='Margin for hard negative mining in interuser contrastive loss')
    
    # æŸå¤±å‡½æ•°é€‰æ‹©
    parser.add_argument('--use_focal_loss', action='store_true', help='Use focal loss')
    parser.add_argument('--use_label_smoothing', action='store_true', help='Use label smoothing')
    
    # æ¨¡å‹é€‰æ‹© - ResNet18ä¸“ä¸ºå¾®å¤šæ™®å‹’ä¼˜åŒ–
    parser.add_argument('--backbone', type=str, default='resnet18', help='Backbone architecture')
    parser.add_argument('--freeze_layers', type=str, default='moderate', 
                       choices=['none', 'minimal', 'moderate', 'aggressive'],
                       help='Layer freezing strategy: none(risk overfitting), minimal(conv1+bn1), moderate(+layer1), aggressive(+layer2)')
    
    parser.add_argument('--generated_data_dir', type=str, action='append', 
                       help='Generated dataset directory (can be specified multiple times)')
    parser.add_argument('--use_generated', action='store_true', 
                       help='Use generated data to augment training set')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ
    rank, world_size, local_rank = setup_distributed()
    
    # è®¾ç½®è®¾å¤‡
    if torch.cuda.is_available():
        device = torch.device(f'cuda:{local_rank}')
        torch.cuda.set_device(local_rank)
    else:
        device = torch.device('cpu')
    
    if is_main_process():
        print(f"Using distributed training with {world_size} GPUs")
        print(f"Current device: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
    if is_main_process():
        output_dir = Path(args.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)  # å›ºå®šç§å­ä¸º42
    np.random.seed(42)
    random.seed(42)
    
    # æ•°æ®é›†
    train_dataset = ImprovedMicroDopplerDataset(
        data_dir=args.data_dir, 
        split='train', 
        contrastive_pairs=args.use_contrastive,
        generated_data_dirs=args.generated_data_dir,
        use_generated=args.use_generated
    )
    val_dataset = ImprovedMicroDopplerDataset(
        args.data_dir, 
        split='val'
    )
    
    # åˆ†å¸ƒå¼é‡‡æ ·å™¨
    train_sampler = DistributedSampler(train_dataset) if world_size > 1 else None
    val_sampler = DistributedSampler(val_dataset, shuffle=False) if world_size > 1 else None
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=args.batch_size, 
        shuffle=(train_sampler is None), 
        sampler=train_sampler,
        num_workers=0,  # é¿å…å¤šè¿›ç¨‹å¡ä½
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=args.batch_size * 2, 
        shuffle=False,
        sampler=val_sampler,
        num_workers=0,  # é¿å…å¤šè¿›ç¨‹å¡ä½
        pin_memory=True
    )
    
    # æ¨¡å‹
    model = ImprovedClassifier(
        num_classes=args.num_classes,
        backbone=args.backbone,
        dropout_rate=args.dropout_rate,
        freeze_layers=args.freeze_layers
    ).to(device)
    
    # åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½® - ä½¿ç”¨static_graphè§£å†³å‚æ•°é‡å¤ä½¿ç”¨é—®é¢˜
    if dist.is_initialized():
        model = DDP(model, device_ids=[device], find_unused_parameters=True)
        # è®¾ç½®é™æ€å›¾æ¨¡å¼ï¼Œå…è®¸å‚æ•°åœ¨åŒä¸€æ¬¡åå‘ä¼ æ’­ä¸­å¤šæ¬¡ä½¿ç”¨
        model._set_static_graph()
    
    if is_main_process():
        total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"Model parameters: {total_params:,}")
    
    # è®­ç»ƒ
    model, best_state, best_acc, history = train_with_contrastive_learning(
        model, train_loader, val_loader, device, args, rank
    )
    
    # åªåœ¨ä¸»è¿›ç¨‹ä¿å­˜æ¨¡å‹
    if is_main_process():
        output_dir = Path(args.output_dir)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        model_path = output_dir / 'best_improved_classifier.pth'
        torch.save({
            'model_state_dict': best_state,
            'best_val_acc': best_acc,
            'num_classes': args.num_classes,
            'model_name': args.backbone,
            'args': vars(args)
        }, model_path)
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = output_dir / 'training_history.json'
        with open(history_path, 'w') as f:
            json.dump(history, f, indent=2)
        
        print(f"\nâœ… Training completed!")
        print(f"Best validation accuracy: {best_acc:.2f}%")
        print(f"Model saved to: {model_path}")
    
    # æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒ
    cleanup_distributed()
    
    # ç¡®ä¿ç¨‹åºæ­£å¸¸é€€å‡º
    if is_main_process():
        print("ğŸ‰ è®­ç»ƒæµç¨‹å®Œå…¨ç»“æŸï¼Œç¨‹åºå³å°†é€€å‡º")
    
    # æ˜¾å¼é€€å‡ºç¨‹åºé¿å…å¡ä½
    import sys
    sys.exit(0)


if __name__ == "__main__":
    main()
