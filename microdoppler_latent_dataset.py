"""
å¾®å¤šæ™®å‹’Latentæ•°æ®é›† - ç›´æ¥é€‚é…ç°æœ‰æ•°æ®æ ¼å¼
å®Œå…¨å…¼å®¹LightningDiTå®˜æ–¹è®­ç»ƒæµç¨‹
"""

import torch
import numpy as np
from pathlib import Path
from torch.utils.data import Dataset
from tqdm import tqdm

class MicroDopplerLatentDataset(Dataset):
    """
    å¾®å¤šæ™®å‹’Latentæ•°æ®é›†
    ç›´æ¥è¯»å–æˆ‘ä»¬çš„latentæ•°æ®æ ¼å¼ï¼š[{'latent': tensor, 'user_id': int, 'original_idx': int}, ...]
    """
    
    def __init__(self, data_dir, latent_norm=True, latent_multiplier=1.0):
        self.data_dir = Path(data_dir)
        self.latent_norm = latent_norm
        self.latent_multiplier = latent_multiplier
        
        # æŸ¥æ‰¾latentæ–‡ä»¶
        latent_files = list(self.data_dir.glob("*_latents.pt"))
        if not latent_files:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°latentæ–‡ä»¶åœ¨ {data_dir}")
        
        # åŠ è½½æ‰€æœ‰latentæ•°æ®
        print(f"ğŸ“‚ åŠ è½½latentæ•°æ®ä» {data_dir}")
        self.latents = []
        self.labels = []
        
        for latent_file in latent_files:
            print(f"   åŠ è½½ {latent_file.name}...")
            data = torch.load(latent_file, map_location='cpu', weights_only=False)
            
            if isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict):
                # æˆ‘ä»¬çš„æ ¼å¼ï¼š[{'latent': tensor, 'user_id': int, ...}, ...]
                for item in data:
                    latent = item['latent']
                    if isinstance(latent, np.ndarray):
                        latent = torch.from_numpy(latent)
                    self.latents.append(latent)
                    
                    # æ— æ¡ä»¶ç”Ÿæˆï¼Œæ‰€æœ‰æ ‡ç­¾ä¸º0
                    self.labels.append(0)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æ ¼å¼: {type(data)}")
        
        print(f"âœ… åŠ è½½å®Œæˆï¼š{len(self.latents)} ä¸ªlatents")
        print(f"   Shape: {self.latents[0].shape}")
        
        # è®¡ç®—å½’ä¸€åŒ–ç»Ÿè®¡
        if self.latent_norm:
            self._compute_latent_stats()
    
    def _compute_latent_stats(self):
        """è®¡ç®—channel-wiseå½’ä¸€åŒ–ç»Ÿè®¡"""
        print("ğŸ“Š è®¡ç®—channel-wiseç»Ÿè®¡...")
        
        # éšæœºé‡‡æ ·è®¡ç®—ç»Ÿè®¡ï¼ˆèŠ‚çœå†…å­˜ï¼‰
        num_samples = min(1000, len(self.latents))
        indices = np.random.choice(len(self.latents), num_samples, replace=False)
        
        sample_latents = torch.stack([self.latents[i] for i in indices])
        
        # Channel-wiseç»Ÿè®¡
        self._latent_mean = sample_latents.mean(dim=[0, 2, 3], keepdim=True)  # [1, 32, 1, 1]
        self._latent_std = sample_latents.std(dim=[0, 2, 3], keepdim=True)
        
        print(f"   Channel-wise meanèŒƒå›´: {self._latent_mean.min():.3f} ~ {self._latent_mean.max():.3f}")
        print(f"   Channel-wise stdèŒƒå›´: {self._latent_std.min():.3f} ~ {self._latent_std.max():.3f}")
    
    def __len__(self):
        return len(self.latents)
    
    def __getitem__(self, idx):
        latent = self.latents[idx].clone()
        label = self.labels[idx]
        
        # Channel-wiseå½’ä¸€åŒ–
        if self.latent_norm:
            latent = (latent - self._latent_mean) / self._latent_std
        
        # åº”ç”¨multiplier
        latent = latent * self.latent_multiplier
        
        return latent, label
