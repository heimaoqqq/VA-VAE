#!/usr/bin/env python3
"""
é˜¶æ®µ1: ç‰¹å¾æå–
ä½¿ç”¨é¢„è®­ç»ƒVA-VAEæå–å¾®å¤šæ™®å‹’å›¾åƒçš„æ½œåœ¨ç‰¹å¾
éµå¾ªLightningDiTåŸé¡¹ç›®çš„extract_features.pyå®ç°
"""

import torch
import torch.distributed as dist
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
import argparse
import os
import sys
from pathlib import Path
from safetensors.torch import save_file
from tqdm import tqdm
import numpy as np

# æ·»åŠ LightningDiTè·¯å¾„
sys.path.append('LightningDiT')
from tokenizer.autoencoder import AutoencoderKL

# å¯¼å…¥æˆ‘ä»¬çš„æ•°æ®é›†
from minimal_micro_doppler_dataset import MicroDopplerDataset

def setup_distributed():
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ"""
    try:
        dist.init_process_group("nccl")
        rank = dist.get_rank()
        device = rank % torch.cuda.device_count()
        world_size = dist.get_world_size()
        print(f"Rank {rank}/{world_size} initialized")
        return rank, device, world_size
    except:
        print("Failed to initialize DDP. Running in local mode.")
        return 0, 0, 1

def extract_latent_features(args):
    """
    æå–æ½œåœ¨ç‰¹å¾çš„ä¸»å‡½æ•°
    """
    print("ğŸ”„ å¼€å§‹æå–å¾®å¤šæ™®å‹’å›¾åƒçš„æ½œåœ¨ç‰¹å¾...")
    
    # è®¾ç½®åˆ†å¸ƒå¼
    rank, device, world_size = setup_distributed()
    torch.cuda.set_device(device)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_path)
    if rank == 0:
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # åŠ è½½é¢„è®­ç»ƒVA-VAE
    print(f"ğŸ“¥ åŠ è½½é¢„è®­ç»ƒVA-VAE: {args.vavae_path}")
    vavae = AutoencoderKL(
        embed_dim=32,  # f16d32é…ç½®
        ch_mult=(1, 1, 2, 2, 4),
        ckpt_path=args.vavae_path,
        model_type='vavae'
    )
    vavae.eval()
    vavae.cuda(device)
    
    # å¤„ç†æ¯ä¸ªæ•°æ®åˆ†å‰²
    for split in ['train', 'val']:
        print(f"\nğŸ“Š å¤„ç† {split} æ•°æ®...")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = MicroDopplerDataset(
            data_dir=os.path.join(args.data_dir, split),
            split=split
        )
        
        # åˆ†å¸ƒå¼é‡‡æ ·å™¨
        if world_size > 1:
            sampler = DistributedSampler(
                dataset, 
                num_replicas=world_size, 
                rank=rank,
                shuffle=False
            )
        else:
            sampler = None
        
        # æ•°æ®åŠ è½½å™¨
        dataloader = DataLoader(
            dataset,
            batch_size=args.batch_size,
            sampler=sampler,
            num_workers=4,
            pin_memory=True
        )
        
        # å­˜å‚¨ç‰¹å¾
        all_latents = []
        all_user_ids = []
        all_indices = []
        
        print(f"å¼€å§‹æå– {len(dataset)} ä¸ªæ ·æœ¬çš„ç‰¹å¾...")
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(tqdm(dataloader, desc=f"Rank {rank}")):
                images = batch['image'].cuda(device)  # (B, 3, 256, 256)
                user_ids = batch['user_id']  # (B,)
                
                # æå–æ½œåœ¨ç‰¹å¾
                posterior = vavae.encode(images)
                latents = posterior.sample()  # (B, 32, 16, 16)
                
                # æ”¶é›†æ•°æ®
                all_latents.append(latents.cpu())
                all_user_ids.append(user_ids)
                all_indices.extend([
                    batch_idx * args.batch_size + i 
                    for i in range(len(user_ids))
                ])
                
                # å®šæœŸæ¸…ç†GPUå†…å­˜
                if batch_idx % 100 == 0:
                    torch.cuda.empty_cache()
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        if all_latents:
            latents_tensor = torch.cat(all_latents, dim=0)  # (N, 32, 16, 16)
            user_ids_tensor = torch.cat(all_user_ids, dim=0)  # (N,)
            indices_tensor = torch.tensor(all_indices)  # (N,)
            
            print(f"Rank {rank}: æå–äº† {len(latents_tensor)} ä¸ªç‰¹å¾")
            print(f"ç‰¹å¾å½¢çŠ¶: {latents_tensor.shape}")
            print(f"ç”¨æˆ·IDèŒƒå›´: [{user_ids_tensor.min()}, {user_ids_tensor.max()}]")
            
            # ä¿å­˜ç‰¹å¾ (ä½¿ç”¨safetensorsæ ¼å¼ï¼Œéµå¾ªåŸé¡¹ç›®)
            output_file = output_dir / f"{split}_rank{rank}.safetensors"
            
            save_data = {
                'latents': latents_tensor,
                'user_ids': user_ids_tensor,
                'indices': indices_tensor,
                'metadata': {
                    'num_samples': len(latents_tensor),
                    'latent_shape': list(latents_tensor.shape[1:]),
                    'num_users': len(torch.unique(user_ids_tensor)),
                    'rank': rank,
                    'world_size': world_size
                }
            }
            
            # è½¬æ¢ä¸ºsafetensorsæ ¼å¼
            save_dict = {}
            for key, value in save_data.items():
                if key != 'metadata':
                    save_dict[key] = value
                else:
                    # å°†metadataè½¬æ¢ä¸ºtensor
                    for meta_key, meta_value in value.items():
                        if isinstance(meta_value, (int, float)):
                            save_dict[f'meta_{meta_key}'] = torch.tensor([meta_value])
                        elif isinstance(meta_value, list):
                            save_dict[f'meta_{meta_key}'] = torch.tensor(meta_value)
            
            save_file(save_dict, output_file)
            print(f"âœ… ç‰¹å¾å·²ä¿å­˜åˆ°: {output_file}")
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    if world_size > 1:
        dist.barrier()
    
    # ä¸»è¿›ç¨‹åˆå¹¶æ‰€æœ‰rankçš„ç»“æœ
    if rank == 0:
        print("\nğŸ”„ åˆå¹¶æ‰€æœ‰rankçš„ç‰¹å¾...")
        merge_features(output_dir, world_size)
    
    print("âœ… ç‰¹å¾æå–å®Œæˆ!")

def merge_features(output_dir, world_size):
    """åˆå¹¶æ‰€æœ‰rankçš„ç‰¹å¾æ–‡ä»¶"""
    from safetensors import safe_open
    
    for split in ['train', 'val']:
        print(f"åˆå¹¶ {split} ç‰¹å¾...")
        
        all_latents = []
        all_user_ids = []
        all_indices = []
        
        # è¯»å–æ‰€æœ‰rankçš„æ–‡ä»¶
        for rank in range(world_size):
            rank_file = output_dir / f"{split}_rank{rank}.safetensors"
            if rank_file.exists():
                with safe_open(rank_file, framework="pt", device="cpu") as f:
                    latents = f.get_tensor('latents')
                    user_ids = f.get_tensor('user_ids')
                    indices = f.get_tensor('indices')
                    
                    all_latents.append(latents)
                    all_user_ids.append(user_ids)
                    all_indices.append(indices)
                
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                rank_file.unlink()
        
        if all_latents:
            # åˆå¹¶æ•°æ®
            merged_latents = torch.cat(all_latents, dim=0)
            merged_user_ids = torch.cat(all_user_ids, dim=0)
            merged_indices = torch.cat(all_indices, dim=0)
            
            # æŒ‰ç´¢å¼•æ’åºï¼Œä¿æŒåŸå§‹é¡ºåº
            sort_idx = torch.argsort(merged_indices)
            merged_latents = merged_latents[sort_idx]
            merged_user_ids = merged_user_ids[sort_idx]
            
            print(f"åˆå¹¶åçš„ {split} ç‰¹å¾:")
            print(f"  æ ·æœ¬æ•°é‡: {len(merged_latents)}")
            print(f"  ç‰¹å¾å½¢çŠ¶: {merged_latents.shape}")
            print(f"  ç”¨æˆ·æ•°é‡: {len(torch.unique(merged_user_ids))}")
            
            # ä¿å­˜æœ€ç»ˆæ–‡ä»¶
            final_file = output_dir / f"{split}.safetensors"
            save_dict = {
                'latents': merged_latents,
                'user_ids': merged_user_ids,
                'num_samples': torch.tensor([len(merged_latents)]),
                'num_users': torch.tensor([len(torch.unique(merged_user_ids))]),
                'latent_shape_h': torch.tensor([merged_latents.shape[2]]),
                'latent_shape_w': torch.tensor([merged_latents.shape[3]]),
                'latent_channels': torch.tensor([merged_latents.shape[1]])
            }
            
            save_file(save_dict, final_file)
            print(f"âœ… æœ€ç»ˆç‰¹å¾ä¿å­˜åˆ°: {final_file}")

def main():
    parser = argparse.ArgumentParser(description='æå–å¾®å¤šæ™®å‹’å›¾åƒçš„æ½œåœ¨ç‰¹å¾')
    parser.add_argument('--data_dir', type=str, required=True, 
                       help='å¾®å¤šæ™®å‹’æ•°æ®ç›®å½• (åŒ…å«trainå’Œvalå­ç›®å½•)')
    parser.add_argument('--vavae_path', type=str, required=True,
                       help='é¢„è®­ç»ƒVA-VAEæ¨¡å‹è·¯å¾„')
    parser.add_argument('--output_path', type=str, required=True,
                       help='è¾“å‡ºç‰¹å¾çš„ç›®å½•')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    
    print("ğŸ¯ å¾®å¤šæ™®å‹’ç‰¹å¾æå– - é˜¶æ®µ1")
    print("=" * 50)
    print(f"æ•°æ®ç›®å½•: {args.data_dir}")
    print(f"VA-VAEæ¨¡å‹: {args.vavae_path}")
    print(f"è¾“å‡ºç›®å½•: {args.output_path}")
    print(f"æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    
    extract_latent_features(args)

if __name__ == "__main__":
    main()
