"""
åˆ†æçœŸå®å¾®å¤šæ™®å‹’æ•°æ®çš„ç­›é€‰æŒ‡æ ‡åˆ†å¸ƒ
ç”¨äºç¡®å®šåˆç†çš„ç­›é€‰é˜ˆå€¼ï¼Œé¿å…åˆæˆæ ·æœ¬è´¨é‡æ±¡æŸ“
"""

import torch
import torch.nn as nn
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
import argparse
from PIL import Image
import torchvision.transforms as transforms
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

class DomainAdaptiveClassifier(nn.Module):
    """ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„åˆ†ç±»å™¨ç»“æ„"""
    def __init__(self, num_classes=31, dropout_rate=0.3, feature_dim=512):
        super().__init__()
        import torchvision.models as models
        self.backbone = models.resnet18(pretrained=False)
        backbone_dim = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        
        self.feature_projector = nn.Sequential(
            nn.Linear(backbone_dim, feature_dim),
            nn.BatchNorm1d(feature_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate)
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(256, num_classes)
        )
        
        # ç”¨äºå­˜å‚¨ç”¨æˆ·åŸå‹
        self.register_buffer('feature_bank', torch.zeros(num_classes, feature_dim))
        self.register_buffer('feature_count', torch.zeros(num_classes))

    def forward(self, x):
        backbone_features = self.backbone(x)
        features = self.feature_projector(backbone_features)
        logits = self.classifier(features)
        return logits
    
    def extract_features(self, x):
        """æå–ç‰¹å¾ç”¨äºå¤šæ ·æ€§åˆ†æ"""
        backbone_features = self.backbone(x)
        features = self.feature_projector(backbone_features)
        return features

def load_classifier(checkpoint_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„åˆ†ç±»å™¨"""
    model = DomainAdaptiveClassifier(num_classes=31)
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()
    return model

def load_real_data(data_dir, max_samples_per_user=100):
    """åŠ è½½çœŸå®å¾®å¤šæ™®å‹’æ•°æ®"""
    data_dir = Path(data_dir)
    samples = []
    labels = []
    
    print(f"ğŸ” æ‰«æçœŸå®æ•°æ®ç›®å½•: {data_dir}")
    
    # åˆ›å»ºå’Œè®­ç»ƒæ—¶ä¸€è‡´çš„æ ‡ç­¾æ˜ å°„
    all_classes = []
    
    for user_id in range(1, 32):  # ID_1 åˆ° ID_31
        user_dir = data_dir / f"ID_{user_id}"
        if not user_dir.exists():
            continue
        all_classes.append(f"ID_{user_id}")
            
    # æ•°å€¼æ’åºï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰
    def sort_ids(class_list):
        def extract_number(class_name):
            if class_name.startswith('ID_'):
                try:
                    return int(class_name.split('_')[1])
                except (IndexError, ValueError):
                    return float('inf')
            return float('inf')
        return sorted(class_list, key=extract_number)
    
    sorted_classes = sort_ids(all_classes)
    class_to_idx = {cls: idx for idx, cls in enumerate(sorted_classes)}
    print(f"âœ… æ ‡ç­¾æ˜ å°„: {class_to_idx}")
    
    for user_id in range(1, 32):  # ID_1 åˆ° ID_31
        user_dir = data_dir / f"ID_{user_id}"
        if not user_dir.exists():
            continue
            
        user_samples = []
        # åŠ è½½æ‰€æœ‰jpgæ–‡ä»¶
        for img_path in user_dir.glob("*.jpg"):
            user_samples.append(str(img_path))
        
        # å¦‚æœæ–‡ä»¶æ•°è¶…è¿‡é™åˆ¶æ‰æˆªå–
        if len(user_samples) > max_samples_per_user:
            user_samples = user_samples[:max_samples_per_user]
        
        samples.extend(user_samples)
        class_name = f"ID_{user_id}"
        correct_label = class_to_idx[class_name]
        labels.extend([correct_label] * len(user_samples))
        print(f"ID_{user_id}: {len(user_samples)} samples -> label {correct_label} ({class_name})")
    
    print(f"ğŸ“Š æ€»è®¡åŠ è½½: {len(samples)} æ ·æœ¬")
    return samples, labels

def calculate_metrics_batch(classifier, images, labels, device):
    """æ‰¹é‡è®¡ç®—æ‰€æœ‰ç­›é€‰æŒ‡æ ‡"""
    classifier.eval()
    
    # ä¿®å¤ï¼šä½¿ç”¨å’Œè®­ç»ƒä¸€è‡´çš„é¢„å¤„ç†
    print("âœ… ä½¿ç”¨è®­ç»ƒæ—¶ä¸€è‡´çš„é¢„å¤„ç†: 256x256 + ImageNet normalization")
    transform = transforms.Compose([
        transforms.Resize((256, 256)),  # ä¿®å¤: ä¸è®­ç»ƒæ—¶ä¸€è‡´
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    batch_metrics = {
        'confidence': [],
        'margin': [],
        'user_specificity': [],
        'predicted_user': [],
        'true_user': [],
        'features': []
    }
    
    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    print(f"ğŸ“Š æ ‡ç­¾åˆ†å¸ƒ: {sorted(set(labels))}")
    print(f"ğŸ“Š æ ‡ç­¾èŒƒå›´: {min(labels)} - {max(labels)} (åº”è¯¥æ˜¯ 0-30)")
    print(f"ğŸ“Š æ€»ç±»åˆ«æ•°: {len(set(labels))} (åº”è¯¥æ˜¯ 31)")
    
    # æµ‹è¯•å‡ ä¸ªæ ·æœ¬çœ‹é¢„æµ‹ç»“æœ
    debug_predictions = []
    
    with torch.no_grad():
        for idx, (img_path, true_label) in enumerate(tqdm(zip(images, labels), total=len(images), desc="è®¡ç®—æŒ‡æ ‡")):
            try:
                # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
                img = Image.open(img_path).convert('RGB')
                img_tensor = transform(img).unsqueeze(0).to(device)
                
                # å‰å‘ä¼ æ’­
                logits = classifier(img_tensor)
                probs = torch.softmax(logits, dim=1)
                features = classifier.extract_features(img_tensor)
                
                # 1. ç½®ä¿¡åº¦ (æœ€å¤§æ¦‚ç‡)
                confidence = torch.max(probs).item()
                
                # 2. å†³ç­–è¾¹ç•Œ (æœ€å¤§æ¦‚ç‡ - æ¬¡å¤§æ¦‚ç‡)
                sorted_probs = torch.sort(probs, descending=True)[0]
                margin = (sorted_probs[0, 0] - sorted_probs[0, 1]).item()
                
                # 3. ç”¨æˆ·ç‰¹å¼‚æ€§ (é¢„æµ‹ç”¨æˆ·æ¦‚ç‡ - å…¶ä»–ç”¨æˆ·æœ€å¤§æ¦‚ç‡)
                predicted_user = torch.argmax(probs).item()
                user_prob = probs[0, predicted_user].item()
                other_max = torch.max(torch.cat([probs[0, :predicted_user], 
                                               probs[0, predicted_user+1:]])).item()
                user_specificity = user_prob - other_max
                
                # å­˜å‚¨ç»“æœ
                batch_metrics['confidence'].append(confidence)
                batch_metrics['margin'].append(margin)
                batch_metrics['user_specificity'].append(user_specificity)
                batch_metrics['predicted_user'].append(predicted_user)
                batch_metrics['true_user'].append(true_label)
                batch_metrics['features'].append(features.cpu().numpy().flatten())
                
                # è°ƒè¯•å‰10ä¸ªæ ·æœ¬
                if idx < 10:
                    debug_predictions.append({
                        'file': img_path.split('/')[-1],
                        'true_label': true_label,
                        'predicted': predicted_user,
                        'confidence': confidence,
                        'top3_probs': torch.topk(probs, 3)[0].cpu().numpy().flatten(),
                        'top3_users': torch.topk(probs, 3)[1].cpu().numpy().flatten()
                    })
                
            except Exception as e:
                print(f"âš ï¸ å¤„ç†å›¾åƒ {img_path} æ—¶å‡ºé”™: {e}")
                continue
    
    # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
    print("\nğŸ” å‰10ä¸ªæ ·æœ¬çš„é¢„æµ‹è°ƒè¯•ä¿¡æ¯:")
    for i, debug in enumerate(debug_predictions):
        print(f"æ ·æœ¬{i+1}: {debug['file']}")
        # æ ¹æ®æ ‡ç­¾æ˜ å°„æ‰¾åˆ°å¯¹åº”çš„ID
        true_id = [k for k, v in class_to_idx.items() if v == debug['true_label']][0] if debug['true_label'] in class_to_idx.values() else f"Unknown({debug['true_label']})"
        pred_id = [k for k, v in class_to_idx.items() if v == debug['predicted']][0] if debug['predicted'] in class_to_idx.values() else f"Unknown({debug['predicted']})"
        print(f"  çœŸå®æ ‡ç­¾: {debug['true_label']} ({true_id})")
        print(f"  é¢„æµ‹æ ‡ç­¾: {debug['predicted']} ({pred_id})")
        print(f"  ç½®ä¿¡åº¦: {debug['confidence']:.3f}")
        print(f"  Top3æ¦‚ç‡: {debug['top3_probs']}")
        top3_ids = []
        for user_idx in debug['top3_users']:
            if user_idx in class_to_idx.values():
                user_id = [k for k, v in class_to_idx.items() if v == user_idx][0]
                top3_ids.append(user_id)
            else:
                top3_ids.append(f"Unknown({user_idx})")
        print(f"  Top3ç”¨æˆ·: {debug['top3_users']} ({top3_ids})")
        print("")
    
    # æŠŠ class_to_idx ä¼ é€’ç»™å…¶ä»–å‡½æ•°ä½¿ç”¨
    batch_metrics['class_to_idx'] = class_to_idx
    return batch_metrics

def analyze_diversity(features):
    """åˆ†æç‰¹å¾å¤šæ ·æ€§"""
    if len(features) < 2:
        return []
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦çŸ©é˜µ
    similarity_matrix = cosine_similarity(features)
    
    # æå–ä¸Šä¸‰è§’çŸ©é˜µï¼ˆé¿å…é‡å¤å’Œå¯¹è§’çº¿ï¼‰
    triu_indices = np.triu_indices_from(similarity_matrix, k=1)
    similarities = similarity_matrix[triu_indices]
    
    return similarities

def analyze_user_differences(metrics):
    """åˆ†æç”¨æˆ·é—´å·®å¼‚"""
    df = pd.DataFrame(metrics)
    
    # æŒ‰ç”¨æˆ·åˆ†ç»„ç»Ÿè®¡
    user_stats = df.groupby('true_user').agg({
        'confidence': ['mean', 'std', 'min', 'max'],
        'margin': ['mean', 'std', 'min', 'max'],
        'user_specificity': ['mean', 'std', 'min', 'max']
    }).round(4)
    
    return user_stats

def plot_metric_distributions(metrics, output_dir):
    """ç»˜åˆ¶æŒ‡æ ‡åˆ†å¸ƒå›¾"""
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # 1. ç½®ä¿¡åº¦åˆ†å¸ƒ
    axes[0, 0].hist(metrics['confidence'], bins=50, alpha=0.7, edgecolor='black')
    axes[0, 0].axvline(np.mean(metrics['confidence']), color='red', linestyle='--', 
                       label=f'å‡å€¼: {np.mean(metrics["confidence"]):.3f}')
    axes[0, 0].set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ')
    axes[0, 0].set_xlabel('ç½®ä¿¡åº¦')
    axes[0, 0].legend()
    
    # 2. å†³ç­–è¾¹ç•Œåˆ†å¸ƒ
    axes[0, 1].hist(metrics['margin'], bins=50, alpha=0.7, edgecolor='black')
    axes[0, 1].axvline(np.mean(metrics['margin']), color='red', linestyle='--',
                       label=f'å‡å€¼: {np.mean(metrics["margin"]):.3f}')
    axes[0, 1].set_title('å†³ç­–è¾¹ç•Œåˆ†å¸ƒ')
    axes[0, 1].set_xlabel('å†³ç­–è¾¹ç•Œ')
    axes[0, 1].legend()
    
    # 3. ç”¨æˆ·ç‰¹å¼‚æ€§åˆ†å¸ƒ
    axes[0, 2].hist(metrics['user_specificity'], bins=50, alpha=0.7, edgecolor='black')
    axes[0, 2].axvline(np.mean(metrics['user_specificity']), color='red', linestyle='--',
                       label=f'å‡å€¼: {np.mean(metrics["user_specificity"]):.3f}')
    axes[0, 2].set_title('ç”¨æˆ·ç‰¹å¼‚æ€§åˆ†å¸ƒ')
    axes[0, 2].set_xlabel('ç”¨æˆ·ç‰¹å¼‚æ€§')
    axes[0, 2].legend()
    
    # 4. å‡†ç¡®ç‡åˆ†æ
    accuracy = np.mean(np.array(metrics['predicted_user']) == np.array(metrics['true_user']))
    axes[1, 0].bar(['æ­£ç¡®', 'é”™è¯¯'], [accuracy, 1-accuracy])
    axes[1, 0].set_title(f'åˆ†ç±»å‡†ç¡®ç‡: {accuracy:.3f}')
    axes[1, 0].set_ylabel('æ¯”ä¾‹')
    
    # 5. ç‰¹å¾å¤šæ ·æ€§
    if len(metrics['features']) > 1:
        similarities = analyze_diversity(metrics['features'])
        axes[1, 1].hist(similarities, bins=50, alpha=0.7, edgecolor='black')
        axes[1, 1].axvline(np.mean(similarities), color='red', linestyle='--',
                           label=f'å‡å€¼: {np.mean(similarities):.3f}')
        axes[1, 1].set_title('ç‰¹å¾ç›¸ä¼¼æ€§åˆ†å¸ƒ')
        axes[1, 1].set_xlabel('ä½™å¼¦ç›¸ä¼¼åº¦')
        axes[1, 1].legend()
    
    # 6. ç½®ä¿¡åº¦vså‡†ç¡®æ€§
    correct_mask = np.array(metrics['predicted_user']) == np.array(metrics['true_user'])
    correct_conf = np.array(metrics['confidence'])[correct_mask]
    wrong_conf = np.array(metrics['confidence'])[~correct_mask]
    
    axes[1, 2].hist([correct_conf, wrong_conf], bins=30, alpha=0.7, 
                    label=['æ­£ç¡®é¢„æµ‹', 'é”™è¯¯é¢„æµ‹'], edgecolor='black')
    axes[1, 2].set_title('ç½®ä¿¡åº¦vsé¢„æµ‹å‡†ç¡®æ€§')
    axes[1, 2].set_xlabel('ç½®ä¿¡åº¦')
    axes[1, 2].legend()
    
    plt.tight_layout()
    plt.savefig(output_dir / 'real_data_metrics_distribution.png', dpi=300, bbox_inches='tight')
    plt.show()

def recommend_thresholds(metrics):
    """åŸºäºçœŸå®æ•°æ®åˆ†å¸ƒæ¨èé˜ˆå€¼"""
    print("\n" + "="*60)
    print("ğŸ“Š åŸºäºçœŸå®æ•°æ®çš„é˜ˆå€¼æ¨è")
    print("="*60)
    
    # è®¡ç®—åˆ†ä½æ•°
    conf_percentiles = np.percentile(metrics['confidence'], [25, 50, 75, 90, 95])
    margin_percentiles = np.percentile(metrics['margin'], [25, 50, 75, 90, 95])
    spec_percentiles = np.percentile(metrics['user_specificity'], [25, 50, 75, 90, 95])
    
    if len(metrics['features']) > 1:
        similarities = analyze_diversity(metrics['features'])
        sim_percentiles = np.percentile(similarities, [5, 10, 25, 50, 75])
    
    print(f"ğŸ“ˆ ç½®ä¿¡åº¦åˆ†ä½æ•°: P25={conf_percentiles[0]:.3f}, P50={conf_percentiles[1]:.3f}, P75={conf_percentiles[2]:.3f}")
    print(f"ğŸ“ˆ å†³ç­–è¾¹ç•Œåˆ†ä½æ•°: P25={margin_percentiles[0]:.3f}, P50={margin_percentiles[1]:.3f}, P75={margin_percentiles[2]:.3f}")
    print(f"ğŸ“ˆ ç”¨æˆ·ç‰¹å¼‚æ€§åˆ†ä½æ•°: P25={spec_percentiles[0]:.3f}, P50={spec_percentiles[1]:.3f}, P75={spec_percentiles[2]:.3f}")
    
    if len(metrics['features']) > 1:
        print(f"ğŸ“ˆ ç›¸ä¼¼åº¦åˆ†ä½æ•°: P5={sim_percentiles[0]:.3f}, P25={sim_percentiles[2]:.3f}, P50={sim_percentiles[3]:.3f}")
    
    print("\nğŸ¯ æ¨èçš„ç­›é€‰é˜ˆå€¼ï¼ˆåŸºäºçœŸå®æ•°æ®ï¼‰:")
    
    # ä¿å®ˆç­–ç•¥ï¼šä¿ç•™75%çš„çœŸå®æ ·æœ¬è´¨é‡
    print("ã€ä¿å®ˆç­–ç•¥ - ä¿ç•™75%çœŸå®æ ·æœ¬è´¨é‡ã€‘")
    print(f"  - ç½®ä¿¡åº¦: {conf_percentiles[0]:.3f} (P25)")
    print(f"  - å†³ç­–è¾¹ç•Œ: {margin_percentiles[0]:.3f} (P25)")  
    print(f"  - ç”¨æˆ·ç‰¹å¼‚æ€§: {spec_percentiles[0]:.3f} (P25)")
    if len(metrics['features']) > 1:
        print(f"  - å¤šæ ·æ€§é˜ˆå€¼: {1-sim_percentiles[2]:.3f} (1-P25ç›¸ä¼¼åº¦)")
    
    # ä¸­ç­‰ç­–ç•¥ï¼šä¿ç•™50%çš„çœŸå®æ ·æœ¬è´¨é‡  
    print("\nã€ä¸­ç­‰ç­–ç•¥ - ä¿ç•™50%çœŸå®æ ·æœ¬è´¨é‡ã€‘")
    print(f"  - ç½®ä¿¡åº¦: {conf_percentiles[1]:.3f} (P50)")
    print(f"  - å†³ç­–è¾¹ç•Œ: {margin_percentiles[1]:.3f} (P50)")
    print(f"  - ç”¨æˆ·ç‰¹å¼‚æ€§: {spec_percentiles[1]:.3f} (P50)")
    if len(metrics['features']) > 1:
        print(f"  - å¤šæ ·æ€§é˜ˆå€¼: {1-sim_percentiles[3]:.3f} (1-P50ç›¸ä¼¼åº¦)")
    
    # ä¸¥æ ¼ç­–ç•¥ï¼šåªä¿ç•™25%æœ€å¥½çš„çœŸå®æ ·æœ¬è´¨é‡
    print("\nã€ä¸¥æ ¼ç­–ç•¥ - åªä¿ç•™25%æœ€é«˜è´¨é‡ã€‘")
    print(f"  - ç½®ä¿¡åº¦: {conf_percentiles[2]:.3f} (P75)")
    print(f"  - å†³ç­–è¾¹ç•Œ: {margin_percentiles[2]:.3f} (P75)")
    print(f"  - ç”¨æˆ·ç‰¹å¼‚æ€§: {spec_percentiles[2]:.3f} (P75)")
    if len(metrics['features']) > 1:
        print(f"  - å¤šæ ·æ€§é˜ˆå€¼: {1-sim_percentiles[1]:.3f} (1-P10ç›¸ä¼¼åº¦)")

def main():
    parser = argparse.ArgumentParser(description='åˆ†æçœŸå®å¾®å¤šæ™®å‹’æ•°æ®çš„ç­›é€‰æŒ‡æ ‡åˆ†å¸ƒ')
    parser.add_argument('--real_data_dir', type=str, required=True,
                       help='çœŸå®å¾®å¤šæ™®å‹’æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--classifier_checkpoint', type=str, required=True,
                       help='è®­ç»ƒå¥½çš„åˆ†ç±»å™¨checkpointè·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./real_data_analysis',
                       help='åˆ†æç»“æœè¾“å‡ºç›®å½•')
    parser.add_argument('--max_samples_per_user', type=int, default=100,
                       help='æ¯ä¸ªç”¨æˆ·æœ€å¤§æ ·æœ¬æ•°ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰')
    
    args = parser.parse_args()
    
    # è®¾å¤‡é…ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # åŠ è½½åˆ†ç±»å™¨
    print("ğŸ”„ åŠ è½½åˆ†ç±»å™¨...")
    classifier = load_classifier(args.classifier_checkpoint, device)
    
    # åŠ è½½çœŸå®æ•°æ®
    print("ğŸ”„ åŠ è½½çœŸå®æ•°æ®...")
    images, labels = load_real_data(args.real_data_dir, args.max_samples_per_user)
    
    if len(images) == 0:
        print("âŒ æœªæ‰¾åˆ°çœŸå®æ•°æ®ï¼è¯·æ£€æŸ¥æ•°æ®ç›®å½•è·¯å¾„")
        return
    
    # è®¡ç®—æŒ‡æ ‡
    print("ğŸ”„ è®¡ç®—ç­›é€‰æŒ‡æ ‡...")
    metrics = calculate_metrics_batch(classifier, images, labels, device)
    
    # åˆ†æç”¨æˆ·é—´å·®å¼‚
    print("ğŸ”„ åˆ†æç”¨æˆ·é—´å·®å¼‚...")
    user_stats = analyze_user_differences(metrics)
    print("\nç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯:")
    print(user_stats)
    
    # ç»˜åˆ¶åˆ†å¸ƒå›¾
    print("ğŸ”„ ç”Ÿæˆåˆ†æå›¾è¡¨...")
    plot_metric_distributions(metrics, output_dir)
    
    # æ¨èé˜ˆå€¼
    recommend_thresholds(metrics)
    
    # ä¿å­˜åˆ†æç»“æœ
    results = {
        'total_samples': len(images),
        'accuracy': np.mean(np.array(metrics['predicted_user']) == np.array(metrics['true_user'])),
        'mean_confidence': np.mean(metrics['confidence']),
        'mean_margin': np.mean(metrics['margin']),
        'mean_user_specificity': np.mean(metrics['user_specificity']),
        'user_statistics': user_stats.to_dict()
    }
    
    if len(metrics['features']) > 1:
        similarities = analyze_diversity(metrics['features'])
        results['mean_feature_similarity'] = np.mean(similarities)
    
    # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜ï¼‰
    import json
    # è½¬æ¢user_statisticsä¸­çš„tuple keysä¸ºstring
    if 'user_statistics' in results:
        results['user_statistics'] = {str(k): v for k, v in results['user_statistics'].items()}
    
    with open(output_dir / 'analysis_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åˆ°: {output_dir}")
    print(f"ğŸ“Š åˆ†æäº† {len(images)} ä¸ªçœŸå®æ ·æœ¬ï¼Œåˆ†ç±»å‡†ç¡®ç‡: {results['accuracy']:.3f}")
    
    # è¯¦ç»†åˆ†æç½®ä¿¡åº¦ä½çš„åŸå› 
    print("\n" + "="*60)
    print("ğŸ” ç½®ä¿¡åº¦åˆ†æ")
    print("="*60)
    
    correct_mask = np.array(metrics['predicted_user']) == np.array(metrics['true_user'])
    correct_conf = np.array(metrics['confidence'])[correct_mask]
    wrong_conf = np.array(metrics['confidence'])[~correct_mask]
    
    print(f"âœ… æ­£ç¡®é¢„æµ‹æ ·æœ¬ç½®ä¿¡åº¦: å‡å€¼={np.mean(correct_conf):.3f}, ä¸­ä½æ•°={np.median(correct_conf):.3f}")
    print(f"âŒ é”™è¯¯é¢„æµ‹æ ·æœ¬ç½®ä¿¡åº¦: å‡å€¼={np.mean(wrong_conf):.3f}, ä¸­ä½æ•°={np.median(wrong_conf):.3f}")
    print(f"ğŸ“Š é«˜ç½®ä¿¡åº¦(>0.8)æ ·æœ¬å æ¯”: {np.mean(np.array(metrics['confidence']) > 0.8)*100:.1f}%")
    print(f"ğŸ“Š ä¸­ç­‰ç½®ä¿¡åº¦(0.5-0.8)æ ·æœ¬å æ¯”: {np.mean((np.array(metrics['confidence']) > 0.5) & (np.array(metrics['confidence']) <= 0.8))*100:.1f}%")
    print(f"ğŸ“Š ä½ç½®ä¿¡åº¦(<0.5)æ ·æœ¬å æ¯”: {np.mean(np.array(metrics['confidence']) < 0.5)*100:.1f}%")
    
    # åˆ†ææ··æ·†æƒ…å†µ
    predicted = np.array(metrics['predicted_user'])
    true_labels = np.array(metrics['true_user'])
    
    # è®¡ç®—æœ€å®¹æ˜“æ··æ·†çš„ç”¨æˆ·å¯¹
    confusion_pairs = {}
    for i in range(len(predicted)):
        if predicted[i] != true_labels[i]:
            pair = tuple(sorted([true_labels[i], predicted[i]]))
            confusion_pairs[pair] = confusion_pairs.get(pair, 0) + 1
    
    if confusion_pairs:
        top_confusions = sorted(confusion_pairs.items(), key=lambda x: x[1], reverse=True)[:5]
        print(f"\nğŸ”„ æœ€å®¹æ˜“æ··æ·†çš„ç”¨æˆ·å¯¹ï¼ˆå‰5ï¼‰:")
        for (user1, user2), count in top_confusions:
            # æ ¹æ®æ ‡ç­¾æ˜ å°„æ‰¾åˆ°ID
            id1 = [k for k, v in class_to_idx.items() if v == user1][0] if user1 in class_to_idx.values() else f"Unknown({user1})"
            id2 = [k for k, v in class_to_idx.items() if v == user2][0] if user2 in class_to_idx.values() else f"Unknown({user2})"
            print(f"   {id1} â†” {id2}: {count} æ¬¡æ··æ·†")
    
    # ç½®ä¿¡åº¦ä½çš„å¯èƒ½åŸå› åˆ†æ
    print(f"\nğŸ’¡ ç½®ä¿¡åº¦ä½çš„å¯èƒ½åŸå› :")
    if results['accuracy'] < 0.6:
        print("   1. ğŸ¯ åˆ†ç±»å™¨æ€§èƒ½ä¸è¶³ - å‡†ç¡®ç‡è¿‡ä½å¯¼è‡´ä¸ç¡®å®šæ€§å¢åŠ ")
    if np.mean(np.array(metrics['confidence']) < 0.5) > 0.7:
        print("   2. ğŸ‘¥ ç”¨æˆ·é—´ç›¸ä¼¼æ€§è¿‡é«˜ - å¾®å¤šæ™®å‹’ç‰¹å¾å·®å¼‚å¾®å°")
    if len(confusion_pairs) > 10:
        print("   3. ğŸ”„ å¹¿æ³›çš„ç±»é—´æ··æ·† - å¤šä¸ªç”¨æˆ·ç‰¹å¾é‡å ")
    print("   4. ğŸ“ æ¨¡å‹æ ¡å‡†é—®é¢˜ - å¯èƒ½éœ€è¦æ¸©åº¦ç¼©æ”¾æˆ–é‡æ–°æ ¡å‡†")
    print("   5. ğŸ—ï¸ æ¶æ„é™åˆ¶ - ResNet18å¯èƒ½ä¸è¶³ä»¥æ•è·å¾®å¤šæ™®å‹’ç»†å¾®å·®å¼‚")

if __name__ == '__main__':
    main()
