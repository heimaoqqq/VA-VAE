"""
å¾®å¤šæ™®å‹’Latentæ•°æ®é›† - å®Œå…¨åŒ¹é…å®˜æ–¹ImgLatentDatasetæ ¼å¼
åŸºäºLightningDiT/datasets/img_latent_dataset.py
"""

import os
import numpy as np
from glob import glob
from tqdm import tqdm

import torch
from torch.utils.data import Dataset
from safetensors import safe_open


class MicroDopplerLatentDataset(Dataset):
    """
    å®Œå…¨åŒ¹é…å®˜æ–¹ImgLatentDatasetçš„æ•°æ®åŠ è½½æ–¹å¼
    """
    def __init__(self, data_dir, latent_norm=True, latent_multiplier=1.0):
        self.data_dir = data_dir
        self.latent_norm = latent_norm
        self.latent_multiplier = latent_multiplier

        # æŸ¥æ‰¾æ‰€æœ‰safetensorsæ–‡ä»¶
        self.files = sorted(glob(os.path.join(data_dir, "*.safetensors")))
        if not self.files:
            raise FileNotFoundError(f"No safetensors files found in {data_dir}")
        
        # å»ºç«‹å›¾åƒç´¢å¼•åˆ°æ–‡ä»¶çš„æ˜ å°„
        self.img_to_file_map = self.get_img_to_safefile_map()
        
        # åŠ è½½æˆ–è®¡ç®—å½’ä¸€åŒ–ç»Ÿè®¡
        if latent_norm:
            self._latent_mean, self._latent_std = self.get_latent_stats()

    def get_img_to_safefile_map(self):
        """å»ºç«‹å…¨å±€ç´¢å¼•åˆ°æ–‡ä»¶å†…ç´¢å¼•çš„æ˜ å°„"""
        img_to_file = {}
        for safe_file in self.files:
            with safe_open(safe_file, framework="pt", device="cpu") as f:
                labels = f.get_slice('labels')
                labels_shape = labels.get_shape()
                num_imgs = labels_shape[0]
                cur_len = len(img_to_file)
                for i in range(num_imgs):
                    img_to_file[cur_len+i] = {
                        'safe_file': safe_file,
                        'idx_in_file': i
                    }
        return img_to_file

    def get_latent_stats(self):
        """è·å–latentç»Ÿè®¡ä¿¡æ¯"""
        # å°è¯•åŠ è½½ç¼“å­˜çš„ç»Ÿè®¡æ–‡ä»¶
        latent_stats_cache_file = os.path.join(self.data_dir, "latent_stats.pt")
        if os.path.exists(latent_stats_cache_file):
            print(f"ğŸ“Š åŠ è½½ç¼“å­˜çš„latentç»Ÿè®¡: {latent_stats_cache_file}")
            latent_stats = torch.load(latent_stats_cache_file)
            return latent_stats['mean'], latent_stats['std']
        
        # å¦åˆ™è®¡ç®—ç»Ÿè®¡
        print(f"ğŸ“Š è®¡ç®—latentç»Ÿè®¡...")
        latent_stats = self.compute_latent_stats()
        # ä¿å­˜ç»Ÿè®¡
        torch.save(latent_stats, latent_stats_cache_file)
        return latent_stats['mean'], latent_stats['std']
    
    def compute_latent_stats(self):
        """è®¡ç®—channel-wiseç»Ÿè®¡"""
        num_samples = min(1000, len(self.img_to_file_map))
        random_indices = np.random.choice(len(self.img_to_file_map), num_samples, replace=False)
        latents = []
        
        for idx in tqdm(random_indices, desc="è®¡ç®—ç»Ÿè®¡"):
            img_info = self.img_to_file_map[idx]
            safe_file, img_idx = img_info['safe_file'], img_info['idx_in_file']
            with safe_open(safe_file, framework="pt", device="cpu") as f:
                features = f.get_slice('latents')
                feature = features[img_idx:img_idx+1]
                latents.append(feature)
        
        latents = torch.cat(latents, dim=0)
        mean = latents.mean(dim=[0, 2, 3], keepdim=True)
        std = latents.std(dim=[0, 2, 3], keepdim=True)
        latent_stats = {'mean': mean, 'std': std}
        
        print(f"   MeanèŒƒå›´: {mean.min().item():.3f} ~ {mean.max().item():.3f}")
        print(f"   StdèŒƒå›´: {std.min().item():.3f} ~ {std.max().item():.3f}")
        
        return latent_stats

    def __len__(self):
        return len(self.img_to_file_map.keys())

    def __getitem__(self, idx):
        img_info = self.img_to_file_map[idx]
        safe_file, img_idx = img_info['safe_file'], img_info['idx_in_file']
        
        with safe_open(safe_file, framework="pt", device="cpu") as f:
            # å®˜æ–¹ä½¿ç”¨éšæœºé€‰æ‹©åŸå§‹æˆ–ç¿»è½¬çš„latentï¼Œæˆ‘ä»¬æš‚æ—¶åªç”¨åŸå§‹çš„
            # tensor_key = "latents" if np.random.uniform(0, 1) > 0.5 else "latents_flip"
            tensor_key = "latents"  # æˆ‘ä»¬æ²¡æœ‰åšæ•°æ®å¢å¼ºï¼Œæ‰€ä»¥latentså’Œlatents_flipç›¸åŒ
            features = f.get_slice(tensor_key)
            labels = f.get_slice('labels')
            feature = features[img_idx:img_idx+1]
            label = labels[img_idx:img_idx+1]

        # Channel-wiseå½’ä¸€åŒ–
        if self.latent_norm:
            feature = (feature - self._latent_mean) / self._latent_std
        
        # åº”ç”¨multiplier
        feature = feature * self.latent_multiplier
        
        # ç§»é™¤batchç»´åº¦
        feature = feature.squeeze(0)
        label = label.squeeze(0)
        
        return feature, label
