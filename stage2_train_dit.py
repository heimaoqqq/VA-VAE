#!/usr/bin/env python3
"""
é˜¶æ®µ2: DiTè®­ç»ƒ
åŸºäºLightningDiTåŸé¡¹ç›®çš„train.py
ä½¿ç”¨Accelerateè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
"""

import torch
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
import torch.nn as nn
from torch.utils.data import DataLoader
import argparse
import os
from pathlib import Path
from tqdm import tqdm
import math
from datetime import datetime

from accelerate import Accelerator
from accelerate.utils import set_seed
from safetensors import safe_open

# å¯¼å…¥LightningDiTç»„ä»¶
import sys
import os

# ç¡®ä¿æ­£ç¡®çš„è·¯å¾„è®¾ç½®
current_dir = os.path.dirname(os.path.abspath(__file__))
lightningdit_path = os.path.join(current_dir, 'LightningDiT')
if lightningdit_path not in sys.path:
    sys.path.append(lightningdit_path)

from models.lightningdit import LightningDiT_models
from transport import create_transport
from datasets.img_latent_dataset import ImgLatentDataset

class MicroDopplerLatentDataset(torch.utils.data.Dataset):
    """å¾®å¤šæ™®å‹’æ½œåœ¨ç‰¹å¾æ•°æ®é›† (åŸºäºåŸé¡¹ç›®ImgLatentDataset)"""
    
    def __init__(self, latent_file, latent_norm=True, latent_multiplier=1.0):
        print(f"ğŸ“Š åŠ è½½æ½œåœ¨ç‰¹å¾: {latent_file}")
        
        # ä½¿ç”¨safetensorsåŠ è½½æ•°æ®
        with safe_open(latent_file, framework="pt", device="cpu") as f:
            self.latents = f.get_tensor('latents')  # (N, 32, 16, 16)
            self.user_ids = f.get_tensor('user_ids')  # (N,)
            self.num_samples = f.get_tensor('num_samples').item()
            self.num_users = f.get_tensor('num_users').item()
        
        self.latent_norm = latent_norm
        self.latent_multiplier = latent_multiplier
        
        print(f"  æ ·æœ¬æ•°é‡: {self.num_samples}")
        print(f"  ç‰¹å¾å½¢çŠ¶: {self.latents.shape}")
        print(f"  ç”¨æˆ·æ•°é‡: {self.num_users}")
        
        # åŠ è½½ç»Ÿè®¡ä¿¡æ¯ (å‚è€ƒåŸé¡¹ç›®)
        self._load_latent_stats(Path(latent_file).parent)
    
    def _load_latent_stats(self, data_dir):
        """åŠ è½½æ½œåœ¨ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯"""
        stats_file = data_dir / "latents_stats.pt"
        if stats_file.exists():
            print(f"ğŸ“Š åŠ è½½ç»Ÿè®¡ä¿¡æ¯: {stats_file}")
            stats = torch.load(stats_file)
            self.latent_mean = stats['mean']  # (1, 32, 1, 1)
            self.latent_std = stats['std']    # (1, 32, 1, 1)
            print(f"  å‡å€¼å½¢çŠ¶: {self.latent_mean.shape}")
            print(f"  æ ‡å‡†å·®å½¢çŠ¶: {self.latent_std.shape}")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°ç»Ÿè®¡ä¿¡æ¯ï¼Œä½¿ç”¨å…¨å±€ç»Ÿè®¡")
            self.latent_mean = self.latents.mean()
            self.latent_std = self.latents.std()
    
    def __len__(self):
        return len(self.latents)
    
    def __getitem__(self, idx):
        latent = self.latents[idx].clone()  # (32, 16, 16)
        user_id = self.user_ids[idx].item()
        
        # åº”ç”¨å½’ä¸€åŒ– (å‚è€ƒåŸé¡¹ç›®)
        if self.latent_norm:
            mean = self.latent_mean.squeeze(0)  # (32, 1, 1)
            std = self.latent_std.squeeze(0)    # (32, 1, 1)
            latent = (latent - mean) / std
        
        # åº”ç”¨ç¼©æ”¾å› å­
        latent = latent * self.latent_multiplier
        
        return {
            'latent': latent,
            'y': user_id - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
        }

def main():
    parser = argparse.ArgumentParser(description='åŸºäºAccelerateçš„DiTè®­ç»ƒ')
    parser.add_argument('--latent_dir', type=str, required=True, help='æ½œåœ¨ç‰¹å¾ç›®å½•')
    parser.add_argument('--output_dir', type=str, required=True, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--model_name', type=str, default='LightningDiT-XL/1', help='æ¨¡å‹åç§°')
    parser.add_argument('--batch_size', type=int, default=32, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--max_epochs', type=int, default=100, help='æœ€å¤§è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=1e-4, help='å­¦ä¹ ç‡')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--save_every', type=int, default=10, help='ä¿å­˜é—´éš”')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–Accelerator (å‚è€ƒåŸé¡¹ç›®é…ç½®)
    accelerator = Accelerator(
        mixed_precision='fp16',
        gradient_accumulation_steps=1,
        log_with="tensorboard",
        project_dir=args.output_dir
    )
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    
    if accelerator.is_main_process:
        print("ğŸ¯ åŸºäºAccelerateçš„ç”¨æˆ·æ¡ä»¶åŒ–DiTè®­ç»ƒ")
        print("=" * 60)
        print(f"ğŸ”§ Acceleratoré…ç½®:")
        print(f"  è¿›ç¨‹æ•°: {accelerator.num_processes}")
        print(f"  å½“å‰è¿›ç¨‹: {accelerator.process_index}")
        print(f"  è®¾å¤‡: {accelerator.device}")
        print(f"  æ··åˆç²¾åº¦: {accelerator.mixed_precision}")
        print(f"  åˆ†å¸ƒå¼ç±»å‹: {accelerator.distributed_type}")
    
    # åˆ›å»ºæ•°æ®é›† (å‚è€ƒåŸé¡¹ç›®)
    train_dataset = MicroDopplerLatentDataset(
        latent_file=os.path.join(args.latent_dir, 'train.safetensors'),
        latent_norm=True,
        latent_multiplier=1.0
    )
    
    val_dataset = MicroDopplerLatentDataset(
        latent_file=os.path.join(args.latent_dir, 'val.safetensors'),
        latent_norm=True,
        latent_multiplier=1.0
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=4,
        pin_memory=True
    )
    
    val_dataloader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    # åˆ›å»ºæ¨¡å‹ (å‚è€ƒåŸé¡¹ç›®)
    model = LightningDiT_models[args.model_name](
        input_size=16,  # 16x16 latent
        num_classes=train_dataset.num_users,  # ç”¨æˆ·æ•°é‡ä½œä¸ºç±»åˆ«æ•°
        in_channels=32,  # 32é€šé“
        use_qknorm=False,
        use_swiglu=True,
        use_rope=True,
        use_rmsnorm=True,
        wo_shift=False
    )
    
    if accelerator.is_main_process:
        print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
        print(f"  æ¨¡å‹: {args.model_name}")
        print(f"  è¾“å…¥å°ºå¯¸: 16x16")
        print(f"  è¾“å…¥é€šé“: 32")
        print(f"  ç±»åˆ«æ•°: {train_dataset.num_users}")
        print(f"  å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M")
    
    # åˆ›å»ºtransport (æ‰©æ•£è¿‡ç¨‹ï¼Œå‚è€ƒåŸé¡¹ç›®)
    transport = create_transport(
        path_type="Linear",
        prediction="velocity",
        loss_weight=None,
        train_eps=None,
        sample_eps=None
    )
    
    # åˆ›å»ºä¼˜åŒ–å™¨ (å‚è€ƒåŸé¡¹ç›®)
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=args.lr,
        betas=(0.9, 0.95),
        weight_decay=0.0
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨ (å‚è€ƒåŸé¡¹ç›®)
    num_training_steps = len(train_dataloader) * args.max_epochs
    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=num_training_steps
    )
    
    # ä½¿ç”¨Acceleratorå‡†å¤‡æ¨¡å‹ã€ä¼˜åŒ–å™¨å’Œæ•°æ®åŠ è½½å™¨
    model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(
        model, optimizer, train_dataloader, val_dataloader, lr_scheduler
    )
    
    if accelerator.is_main_process:
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        print(f"  è®­ç»ƒæ ·æœ¬: {len(train_dataset)}")
        print(f"  éªŒè¯æ ·æœ¬: {len(val_dataset)}")
        print(f"  æ‰¹æ¬¡å¤§å°: {args.batch_size}")
        print(f"  æ€»æ‰¹æ¬¡æ•°: {len(train_dataloader)}")
        print(f"  è®­ç»ƒè½®æ•°: {args.max_epochs}")
    
    # è®­ç»ƒå¾ªç¯ (å‚è€ƒåŸé¡¹ç›®)
    global_step = 0
    best_val_loss = float('inf')
    
    for epoch in range(args.max_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        total_loss = 0
        
        progress_bar = tqdm(
            train_dataloader, 
            desc=f"Epoch {epoch+1}/{args.max_epochs}",
            disable=not accelerator.is_local_main_process
        )
        
        for step, batch in enumerate(progress_bar):
            with accelerator.accumulate(model):
                latents = batch['latent']  # (B, 32, 16, 16)
                user_ids = batch['y']      # (B,) 0-basedç”¨æˆ·ID
                
                # æ‰©æ•£è®­ç»ƒ (å‚è€ƒåŸé¡¹ç›®)
                model_kwargs = dict(y=user_ids)
                loss_dict = transport.training_losses(model, latents, model_kwargs)
                loss = loss_dict["loss"].mean()
                
                # åå‘ä¼ æ’­
                accelerator.backward(loss)
                
                # æ¢¯åº¦è£å‰ª (å‚è€ƒåŸé¡¹ç›®)
                if accelerator.sync_gradients:
                    accelerator.clip_grad_norm_(model.parameters(), 1.0)
                
                optimizer.step()
                lr_scheduler.step()
                optimizer.zero_grad()
                
                total_loss += loss.item()
                global_step += 1
                
                # æ›´æ–°è¿›åº¦æ¡
                progress_bar.set_postfix({
                    'loss': f'{loss.item():.4f}',
                    'avg_loss': f'{total_loss/(step+1):.4f}',
                    'lr': f'{lr_scheduler.get_last_lr()[0]:.2e}'
                })
        
        # éªŒè¯é˜¶æ®µ
        if accelerator.is_main_process:
            model.eval()
            val_loss = 0
            with torch.no_grad():
                for batch in val_dataloader:
                    latents = batch['latent']
                    user_ids = batch['y']
                    
                    model_kwargs = dict(y=user_ids)
                    loss_dict = transport.training_losses(model, latents, model_kwargs)
                    val_loss += loss_dict["loss"].mean().item()
            
            val_loss /= len(val_dataloader)
            train_loss = total_loss / len(train_dataloader)
            
            print(f"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                accelerator.save_state(os.path.join(args.output_dir, "best_model"))
                print(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Loss: {val_loss:.4f})")
            
            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % args.save_every == 0:
                accelerator.save_state(os.path.join(args.output_dir, f"checkpoint_epoch_{epoch+1}"))
                print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: epoch_{epoch+1}")
    
    if accelerator.is_main_process:
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")

if __name__ == "__main__":
    main()
