"""
åŸºäºå®˜æ–¹LightningDiTçš„extract_features.pyä¿®æ”¹
ç”¨äºç¼–ç å¾®å¤šæ™®å‹’æ•°æ®é›†
"""

import torch
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
import torch.distributed as dist
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
from torchvision.datasets import ImageFolder
import argparse
import os
import sys
from safetensors.torch import save_file
from pathlib import Path
from PIL import Image
import json
from datetime import datetime

# æ·»åŠ LightningDiTè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'LightningDiT'))
from tokenizer.vavae import VA_VAE
import shutil

# å¾®å¤šæ™®å‹’æ•°æ®é›†ç±»ï¼ˆæ›¿ä»£ImageFolderï¼‰
class MicroDopplerDataset(torch.utils.data.Dataset):
    """å¾®å¤šæ™®å‹’æ•°æ®é›† - æ”¯æŒè®­ç»ƒ/éªŒè¯åˆ’åˆ†"""
    def __init__(self, data_root, split='all', split_file=None, transform=None):
        self.data_root = Path(data_root)
        self.transform = transform
        self.split = split
        
        # æ”¶é›†å›¾åƒ
        self.images = []
        self.labels = []
        
        if split == 'all' or split_file is None:
            # ä½¿ç”¨æ‰€æœ‰æ•°æ®ï¼ˆåŸå§‹è¡Œä¸ºï¼‰
            for user_id in range(1, 32):
                user_folder = self.data_root / f"ID_{user_id}"
                if user_folder.exists():
                    user_images = sorted(user_folder.glob("*.jpg"))
                    for img_path in user_images:
                        self.images.append(str(img_path))
                        self.labels.append(user_id - 1)  # 0-30
        else:
            # ä½¿ç”¨åˆ’åˆ†æ–‡ä»¶
            with open(split_file, 'r') as f:
                dataset_split = json.load(f)
            
            # æ”¶é›†æŒ‡å®šåˆ’åˆ†çš„æ‰€æœ‰å›¾åƒ
            for user_id in range(1, 32):
                user_key = f"ID_{user_id}"
                if user_key in dataset_split[split]:
                    user_images = dataset_split[split][user_key]
                    for img_path in user_images:
                        self.images.append(img_path)
                        self.labels.append(user_id - 1)  # 0-30       
                    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]
        
        img = Image.open(img_path)
        
        # å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾å¤„ç† - ä¿æŒå½©è‰²ä¿¡æ¯
        if img.mode == 'RGBA':
            img = img.convert('RGB')  # ç§»é™¤alphaé€šé“
        elif img.mode != 'RGB':
            img = img.convert('RGB')  # ç¡®ä¿æ˜¯RGBæ ¼å¼
        
        img_tensor = self.transform(img)
        return img_tensor, label

def encode_split(args, split='all'):
    """
    ç¼–ç æŒ‡å®šçš„æ•°æ®åˆ’åˆ†
    """
    assert torch.cuda.is_available(), "Extract features currently requires at least one GPU."

    # Setup DDP (ä¿æŒå®˜æ–¹ç»“æ„ï¼Œå³ä½¿å•GPUä¹Ÿç”¨DDP)
    try:
        dist.init_process_group("nccl")
        rank = dist.get_rank()
        device = rank % torch.cuda.device_count()
        world_size = dist.get_world_size()
        seed = args.seed + rank
        if rank == 0:
            print(f"Starting rank={rank}, seed={seed}, world_size={world_size}.")
    except:
        print("Failed to initialize DDP. Running in local mode.")
        rank = 0
        device = 0
        world_size = 1
        seed = args.seed
    torch.manual_seed(seed)
    torch.cuda.set_device(device)

    # Setup feature folders (ä¿æŒå®˜æ–¹ç»“æ„)
    data_split_name = f'{args.data_split}_{split}' if split != 'all' else args.data_split
    output_dir = os.path.join(args.output_path, os.path.splitext(os.path.basename(args.config))[0], f'{data_split_name}_{args.image_size}')
    if rank == 0:
        os.makedirs(output_dir, exist_ok=True)
        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_dir}")

    # Create model (å®Œå…¨æŒ‰å®˜æ–¹æ–¹å¼) - ç›´æ¥ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶
    tokenizer = VA_VAE(args.config)

    # Setup data (ä¿®æ”¹ä¸ºå¾®å¤šæ™®å‹’æ•°æ®é›†)
    datasets = [
        MicroDopplerDataset(args.data_path, split=split, split_file=args.split_file, 
                          transform=tokenizer.img_transform(p_hflip=0.0)),
        MicroDopplerDataset(args.data_path, split=split, split_file=args.split_file,
                          transform=tokenizer.img_transform(p_hflip=1.0))
    ]
    samplers = [
        DistributedSampler(
            dataset,
            num_replicas=world_size,
            rank=rank,
            shuffle=False,
            seed=args.seed
        ) for dataset in datasets
    ]
    loaders = [
        DataLoader(
            dataset,
            batch_size=args.batch_size,
            shuffle=False,
            sampler=sampler,
            num_workers=args.num_workers,
            pin_memory=True,
            drop_last=False
        ) for dataset, sampler in zip(datasets, samplers)
    ]
    total_data_in_loop = len(loaders[0].dataset)
    if rank == 0:
        print(f"Total data in one loop: {total_data_in_loop}")

    # å®˜æ–¹ç¼–ç å¾ªç¯
    run_images = 0
    saved_files = 0
    latents = []
    latents_flip = []
    labels = []
    for batch_idx, batch_data in enumerate(zip(*loaders)):
        run_images += batch_data[0][0].shape[0]
        if run_images % 100 == 0 and rank == 0:
            print(f'{datetime.now()} processing {run_images} of {total_data_in_loop} images')
        
        for loader_idx, data in enumerate(batch_data):
            x = data[0]
            y = data[1]  # (N,)
            
            # å®˜æ–¹ç¼–ç æ–¹å¼ï¼ˆç¬¬92è¡Œï¼‰
            z = tokenizer.encode_images(x).detach().cpu()  # (N, C, H, W)

            if batch_idx == 0 and rank == 0:
                print('latent shape', z.shape, 'dtype', z.dtype)
            
            if loader_idx == 0:
                latents.append(z)
                labels.append(y)
            else:
                latents_flip.append(z)

        # å®˜æ–¹ä¿å­˜é€»è¾‘ï¼ˆæ¯10000ä¸ªæ ·æœ¬ä¿å­˜ä¸€æ¬¡ï¼‰
        if len(latents) == 10000 // args.batch_size:
            latents = torch.cat(latents, dim=0)
            latents_flip = torch.cat(latents_flip, dim=0)
            labels = torch.cat(labels, dim=0)
            save_dict = {
                'latents': latents,
                'latents_flip': latents_flip,
                'labels': labels
            }
            for key in save_dict:
                if rank == 0:
                    print(key, save_dict[key].shape)
            save_filename = os.path.join(output_dir, f'latents_rank{rank:02d}_shard{saved_files:03d}.safetensors')
            save_file(
                save_dict,
                save_filename,
                metadata={'total_size': f'{latents.shape[0]}', 'dtype': f'{latents.dtype}', 'device': f'{latents.device}'}
            )
            if rank == 0:
                print(f'Saved {save_filename}')
            
            latents = []
            latents_flip = []
            labels = []
            saved_files += 1

    # ä¿å­˜å‰©ä½™çš„latentsï¼ˆå°‘äº10000ä¸ªï¼‰
    if len(latents) > 0:
        latents = torch.cat(latents, dim=0)
        latents_flip = torch.cat(latents_flip, dim=0)
        labels = torch.cat(labels, dim=0)
        save_dict = {
            'latents': latents,
            'latents_flip': latents_flip,
            'labels': labels
        }
        for key in save_dict:
            if rank == 0:
                print(key, save_dict[key].shape)
        save_filename = os.path.join(output_dir, f'latents_rank{rank:02d}_shard{saved_files:03d}.safetensors')
        save_file(
            save_dict,
            save_filename,
            metadata={'total_size': f'{latents.shape[0]}', 'dtype': f'{latents.dtype}', 'device': f'{latents.device}'}
        )
        if rank == 0:
            print(f'Saved {save_filename}')

    # å®Œæˆç¼–ç 
    if rank == 0:
        print(f"âœ… {split}é›†ç¼–ç å®Œæˆ")
    
    # æ¸…ç†åˆ†å¸ƒå¼
    if world_size > 1:
        dist.barrier()
    
    return output_dir


def main(args):
    """
    ä¸»å‡½æ•°ï¼šæ ¹æ®å‚æ•°å†³å®šç¼–ç æ¨¡å¼
    """
    if args.split_file and os.path.exists(args.split_file):
        # åˆ†åˆ«ç¼–ç è®­ç»ƒé›†å’ŒéªŒè¯é›†
        print("ğŸ“Š ä½¿ç”¨æ•°æ®åˆ’åˆ†æ–‡ä»¶ï¼Œåˆ†åˆ«ç¼–ç è®­ç»ƒé›†å’ŒéªŒè¯é›†")
        print(f"   åˆ’åˆ†æ–‡ä»¶: {args.split_file}")
        
        for split in ['train', 'val']:
            print(f"\n{'='*60}")
            print(f"ğŸ¯ ç¼–ç  {split} é›†")
            print(f"{'='*60}")
            output_dir = encode_split(args, split=split)
            print(f"âœ… {split}é›†å®Œæˆ: {output_dir}")
    else:
        # ç¼–ç æ‰€æœ‰æ•°æ®ï¼ˆåŸå§‹è¡Œä¸ºï¼‰
        print("ğŸ“Š ç¼–ç æ‰€æœ‰æ•°æ®ï¼ˆæœªä½¿ç”¨æ•°æ®åˆ’åˆ†ï¼‰")
        encode_split(args, split='all')
    
    # æœ€ç»ˆæ¸…ç†
    if dist.is_initialized():
        dist.destroy_process_group()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # ä¿®æ”¹ä¸ºæ­£ç¡®çš„Kaggleæ•°æ®è·¯å¾„
    parser.add_argument("--data_path", type=str, default='/kaggle/input/dataset')  # åŸå§‹æ•°æ®è·¯å¾„
    parser.add_argument("--data_split", type=str, default='microdoppler')
    parser.add_argument("--output_path", type=str, default="/kaggle/working/latents_official")
    parser.add_argument("--config", type=str, default="vavae_config_for_dit.yaml")  # YAMLé…ç½®æ–‡ä»¶ï¼ˆåŒ…å«ckpt_pathï¼‰
    parser.add_argument("--split_file", type=str, default="/kaggle/working/data_split/dataset_split.json",
                       help="æ•°æ®åˆ’åˆ†æ–‡ä»¶ï¼Œå¦‚æœæä¾›åˆ™åˆ†åˆ«ç¼–ç è®­ç»ƒ/éªŒè¯é›†")
    parser.add_argument("--image_size", type=int, default=256)
    parser.add_argument("--batch_size", type=int, default=20)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--num_workers", type=int, default=4)  # é™ä½åˆ°4ä»¥é¿å…è­¦å‘Š
    args = parser.parse_args()
    main(args)
