#!/usr/bin/env python3
"""
Stage 2 è®­ç»ƒå‰ç½®æ¡ä»¶éªŒè¯è„šæœ¬
ç¡®ä¿æ‰€æœ‰é…ç½®å’Œcheckpointæ­£ç¡®
"""

import os
import sys
from pathlib import Path
import torch
import json

def verify_stage2_readiness():
    """éªŒè¯Stage 2è®­ç»ƒå‡†å¤‡æƒ…å†µ"""
    
    print("="*60)
    print("ğŸ” VA-VAE Stage 2 è®­ç»ƒå‡†å¤‡çŠ¶æ€æ£€æŸ¥")
    print("="*60)
    
    issues = []
    warnings = []
    
    # 1. æ£€æŸ¥Stage 1 checkpoint
    print("\nğŸ“¦ Stage 1 Checkpointæ£€æŸ¥:")
    stage1_dir = Path('checkpoints/stage1')
    
    if not stage1_dir.exists():
        issues.append("âŒ Stage 1 checkpointç›®å½•ä¸å­˜åœ¨")
    else:
        ckpt_files = list(stage1_dir.glob('*.ckpt'))
        if not ckpt_files:
            issues.append("âŒ æœªæ‰¾åˆ°Stage 1 checkpointæ–‡ä»¶")
        else:
            # æ‰¾æœ€ä½³checkpoint
            best_ckpt = None
            best_loss = float('inf')
            
            for ckpt_file in ckpt_files:
                try:
                    filename = ckpt_file.stem
                    if 'val_rec_loss' in filename:
                        loss_str = filename.split('val_rec_loss=')[-1]
                        val_loss = float(loss_str)
                        if val_loss < best_loss:
                            best_loss = val_loss
                            best_ckpt = ckpt_file
                except:
                    continue
            
            if best_ckpt:
                print(f"   âœ… æ‰¾åˆ°æœ€ä½³checkpoint: {best_ckpt.name}")
                print(f"   éªŒè¯æŸå¤±: {best_loss:.6f}")
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                size_mb = best_ckpt.stat().st_size / (1024*1024)
                print(f"   æ–‡ä»¶å¤§å°: {size_mb:.1f} MB")
                
                if size_mb < 100:
                    warnings.append(f"âš ï¸ Checkpointæ–‡ä»¶è¾ƒå°({size_mb:.1f}MB)ï¼Œå¯èƒ½ä¸å®Œæ•´")
            else:
                issues.append("âŒ æ— æ³•è§£æStage 1 checkpointçš„éªŒè¯æŸå¤±")
    
    # 2. æ£€æŸ¥æ•°æ®é…ç½®
    print("\nğŸ“Š æ•°æ®é…ç½®æ£€æŸ¥:")
    split_file = Path('data/microdoppler_split.json')
    
    if not split_file.exists():
        issues.append("âŒ æ•°æ®åˆ’åˆ†æ–‡ä»¶ä¸å­˜åœ¨")
    else:
        with open(split_file, 'r') as f:
            split_data = json.load(f)
        
        train_count = sum(len(imgs) for imgs in split_data['train'].values())
        val_count = sum(len(imgs) for imgs in split_data['val'].values())
        
        print(f"   âœ… è®­ç»ƒé›†: {train_count} å¼ å›¾åƒ")
        print(f"   âœ… éªŒè¯é›†: {val_count} å¼ å›¾åƒ")
        
        if train_count < 100:
            warnings.append(f"âš ï¸ è®­ç»ƒé›†è¾ƒå°({train_count}å¼ )ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ")
    
    # 3. æ£€æŸ¥æŸå¤±è®¡ç®—ä¿®å¤
    print("\nğŸ”§ æŸå¤±è®¡ç®—ä¿®å¤æ£€æŸ¥:")
    loss_file = Path('../LightningDiT/vavae/ldm/modules/losses/contperceptual.py')
    
    if loss_file.exists():
        with open(loss_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        if 'torch.mean(weighted_nll_loss)' in content:
            print("   âœ… æŸå¤±è®¡ç®—å·²ä¿®å¤ä¸ºtorch.mean()")
        else:
            issues.append("âŒ æŸå¤±è®¡ç®—æœªä¿®å¤ï¼Œå°†å¯¼è‡´è®­ç»ƒæŸå¤±å¼‚å¸¸é«˜")
    else:
        warnings.append("âš ï¸ æ— æ³•éªŒè¯æŸå¤±è®¡ç®—ä¿®å¤çŠ¶æ€")
    
    # 4. æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹
    print("\nğŸ¯ é¢„è®­ç»ƒæ¨¡å‹æ£€æŸ¥:")
    pretrained_path = Path('../pretrained/vavae_ckpt.pt')
    
    if not pretrained_path.exists():
        issues.append("âŒ é¢„è®­ç»ƒæ¨¡å‹ä¸å­˜åœ¨")
    else:
        size_mb = pretrained_path.stat().st_size / (1024*1024)
        print(f"   âœ… é¢„è®­ç»ƒæ¨¡å‹å­˜åœ¨ ({size_mb:.1f} MB)")
    
    # 5. Stage 2é…ç½®éªŒè¯
    print("\nâš™ï¸ Stage 2 é…ç½®éªŒè¯:")
    print("   é¢„æœŸé…ç½®:")
    print("   - åˆ¤åˆ«å™¨å¯åŠ¨: epoch 1 (ç«‹å³å¯åŠ¨)")
    print("   - VFæƒé‡: 0.1 (é™ä½ä»¥ä¼˜åŒ–é‡å»º)")
    print("   - å­¦ä¹ ç‡: 5e-5 (é™ä½ä»¥ç¨³å®šè®­ç»ƒ)")
    print("   - æœ€å¤§è½®æ¬¡: 45")
    print("   - æ‰¹æ¬¡å¤§å°: å»ºè®®4 (GPUå†…å­˜é™åˆ¶)")
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“‹ æ£€æŸ¥æ€»ç»“:")
    
    if issues:
        print("\nâŒ å‘ç°ä¸¥é‡é—®é¢˜ (å¿…é¡»ä¿®å¤):")
        for issue in issues:
            print(f"   {issue}")
    
    if warnings:
        print("\nâš ï¸ è­¦å‘Š (å»ºè®®å…³æ³¨):")
        for warning in warnings:
            print(f"   {warning}")
    
    if not issues:
        print("\nâœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹Stage 2è®­ç»ƒ")
        print("\nå»ºè®®è¿è¡Œå‘½ä»¤:")
        print("python step4_train_vavae.py --stage 2 --batch_size 4")
    else:
        print("\nâŒ è¯·å…ˆè§£å†³ä»¥ä¸Šé—®é¢˜å†å¼€å§‹Stage 2è®­ç»ƒ")
    
    print("="*60)
    
    return len(issues) == 0

if __name__ == '__main__':
    success = verify_stage2_readiness()
    sys.exit(0 if success else 1)
