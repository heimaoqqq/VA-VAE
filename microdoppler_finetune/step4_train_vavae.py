#!/usr/bin/env python3
"""
VA-VAEè®­ç»ƒè„šæœ¬ - å¾®å¤šæ™®å‹’æ•°æ®å¾®è°ƒ
åŸºäºå®˜æ–¹LightningDiTé¡¹ç›®çš„ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥
"""

import os
import sys
import torch
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, Callback
from pytorch_lightning.loggers import TensorBoardLogger
from datetime import datetime
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'LightningDiT', 'vavae'))

from ldm.util import instantiate_from_config
from ldm.data.microdoppler import MicroDopplerDataset
from ldm.models.autoencoder import AutoencoderKL
from torch.utils.data import DataLoader, random_split

class MicroDopplerDataModule(pl.LightningDataModule):
    """PyTorch Lightningæ•°æ®æ¨¡å—"""
    def __init__(self, data_dir, batch_size=4, num_workers=2, val_split=0.1):
        super().__init__()
        self.data_dir = data_dir
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.val_split = val_split
        
    def setup(self, stage=None):
        if not hasattr(self, 'train_dataset'):
            dataset = MicroDopplerDataset(self.data_dir)
            
            # åˆ†å‰²è®­ç»ƒå’ŒéªŒè¯é›†
            total_size = len(dataset)
            val_size = int(total_size * self.val_split)
            train_size = total_size - val_size
            
            self.train_dataset, self.val_dataset = random_split(
                dataset, [train_size, val_size],
                generator=torch.Generator().manual_seed(42)
            )
            
            print(f"æ•°æ®é›†åˆ†å‰²: è®­ç»ƒ{train_size}, éªŒè¯{val_size}")
    
    def train_dataloader(self):
        return DataLoader(
            self.train_dataset,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=self.num_workers,
            persistent_workers=True if self.num_workers > 0 else False,
            pin_memory=True
        )
    
    def val_dataloader(self):
        return DataLoader(
            self.val_dataset,
            batch_size=self.batch_size,
            shuffle=False,
            num_workers=self.num_workers,
            persistent_workers=True if self.num_workers > 0 else False,
            pin_memory=True
        )

class TrainingMonitor(Callback):
    """è®­ç»ƒç›‘æ§å›è°ƒ"""
    def on_train_epoch_end(self, trainer, pl_module):
        print(f"Epoch {trainer.current_epoch}: è®­ç»ƒæŸå¤± = {trainer.callback_metrics.get('train/aeloss', 'N/A')}")
    
    def on_validation_epoch_end(self, trainer, pl_module):
        print(f"Epoch {trainer.current_epoch}: éªŒè¯æŸå¤± = {trainer.callback_metrics.get('val/aeloss', 'N/A')}")

def create_stage_config(stage, checkpoint_path=None):
    """åˆ›å»ºè®­ç»ƒé˜¶æ®µé…ç½®"""
    
    # ä¸‰é˜¶æ®µè®­ç»ƒé…ç½®
    stage_configs = {
        1: {  # Stage 1: è¯­ä¹‰å¯¹é½
            'max_epochs': 50,
            'learning_rate': 1e-4,
            'disc_start': 5001,
            'disc_weight': 0.5,
            'vf_weight': 0.5,
            'distmat_margin': 0.0,
            'cos_margin': 0.0
        },
        2: {  # Stage 2: é‡å»ºä¼˜åŒ–
            'max_epochs': 15,
            'learning_rate': 5e-5,
            'disc_start': 1,
            'disc_weight': 0.5,
            'vf_weight': 0.1,
            'distmat_margin': 0.0,
            'cos_margin': 0.0
        },
        3: {  # Stage 3: è¾¹ç•Œä¼˜åŒ–
            'max_epochs': 15,
            'learning_rate': 1e-5,
            'disc_start': 1,
            'disc_weight': 0.5,
            'vf_weight': 0.1,
            'distmat_margin': 0.25,
            'cos_margin': 0.5
        }
    }
    
    params = stage_configs[stage]
    
    config = {
        'base_learning_rate': params['learning_rate'],
        'target': 'ldm.models.autoencoder.AutoencoderKL',
        'params': {
            'embed_dim': 32,
            'monitor': 'val/rec_loss',
            'use_vf': 'dinov2',
            'ddconfig': {
                'double_z': True,
                'z_channels': 32,
                'resolution': 256,
                'in_channels': 3,
                'out_ch': 3,
                'ch': 128,
                'ch_mult': [1, 1, 2, 2, 4],
                'num_res_blocks': 2,
                'attn_resolutions': [16],
                'dropout': 0.0
            },
            'lossconfig': {
                'target': 'ldm.modules.losses.contperceptual.LPIPSWithDiscriminator',
                'params': {
                    'disc_start': params['disc_start'],
                    'disc_weight': params['disc_weight'],
                    'disc_num_layers': 3,
                    'kl_weight': 1e-6,
                    'pixelloss_weight': 1.0,
                    'perceptual_weight': 1.0,
                    'disc_in_channels': 3,
                    'disc_conditional': False,
                    'vf_weight': params['vf_weight'],
                    'adaptive_vf': True,  # åŸå§‹è®¾ç½®
                    'distmat_weight': 1.0,
                    'cos_weight': 1.0,
                    'distmat_margin': params['distmat_margin'],
                    'cos_margin': params['cos_margin'],
                    'use_actnorm': False,
                    'pp_style': False
                }
            },
            'ckpt_path': checkpoint_path,
            'ignore_keys': [],
            'image_key': 'image',
            'colorize_nlabels': None,
            'proj_fix': False
        }
    }
    
    return config, params

def main():
    # è§£æå‚æ•°
    parser = argparse.ArgumentParser()
    parser.add_argument('--stages', type=int, default=1, choices=[1, 2, 3])
    parser.add_argument('--batch_size', type=int, default=4)
    parser.add_argument('--data_root', type=str, required=True)
    parser.add_argument('--pretrained_path', type=str, required=True)
    parser.add_argument('--gradient_accumulation', type=int, default=1)
    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--kaggle', action='store_true')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ VA-VAE è®­ç»ƒ - Stage {args.stages}")
    print(f"{'='*60}")
    print(f"ğŸ“Š é…ç½®:")
    print(f"   æ•°æ®ç›®å½•: {args.data_root}")
    print(f"   é¢„è®­ç»ƒæ¨¡å‹: {args.pretrained_path}")
    print(f"   æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"   éšæœºç§å­: {args.seed}")
    print(f"{'='*60}\n")
    
    # ç¡®å®šæ£€æŸ¥ç‚¹è·¯å¾„
    checkpoint_path = None
    if args.stages == 1:
        checkpoint_path = args.pretrained_path
    elif args.stages > 1:
        # è‡ªåŠ¨æŸ¥æ‰¾å‰ä¸€é˜¶æ®µçš„æœ€ä½³æ£€æŸ¥ç‚¹
        prev_stage = args.stages - 1
        ckpt_dir = f'logs/stage{prev_stage}/checkpoints'
        if os.path.exists(ckpt_dir):
            checkpoints = [f for f in os.listdir(ckpt_dir) if f.endswith('.ckpt')]
            if checkpoints:
                checkpoint_path = os.path.join(ckpt_dir, sorted(checkpoints)[-1])
                print(f"âœ… è‡ªåŠ¨åŠ è½½Stage {prev_stage}æ£€æŸ¥ç‚¹: {checkpoint_path}")
    
    # åˆ›å»ºé…ç½®
    config, params = create_stage_config(args.stages, checkpoint_path)
    
    # åˆ›å»ºæ¨¡å‹
    model = instantiate_from_config(config)
    
    # åˆ›å»ºæ•°æ®æ¨¡å—
    data_module = MicroDopplerDataModule(
        data_dir=args.data_root,
        batch_size=args.batch_size,
        num_workers=2
    )
    
    # åˆ›å»ºå›è°ƒ
    checkpoint_callback = ModelCheckpoint(
        dirpath=f'logs/stage{args.stages}/checkpoints',
        filename='epoch{epoch:02d}-val_loss{val/rec_loss:.4f}',
        monitor='val/rec_loss',
        mode='min',
        save_top_k=3,
        save_last=True,
        every_n_epochs=1,
        verbose=True
    )
    
    monitor_callback = TrainingMonitor()
    
    # åˆ›å»ºlogger
    logger = TensorBoardLogger(
        save_dir='logs',
        name=f'stage{args.stages}',
        version=f'run_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = pl.Trainer(
        devices='auto',
        accelerator='gpu' if torch.cuda.is_available() else 'cpu',
        max_epochs=params['max_epochs'],
        precision=32,
        callbacks=[checkpoint_callback, monitor_callback],
        logger=logger,
        log_every_n_steps=10,
        enable_progress_bar=True
    )
    
    print(f"\nğŸ¯ å¼€å§‹Stage {args.stages}è®­ç»ƒ")
    print(f"   å­¦ä¹ ç‡: {config['base_learning_rate']:.2e}")
    print(f"   VFæƒé‡: {params['vf_weight']}")
    print(f"   åˆ¤åˆ«å™¨èµ·å§‹: {params['disc_start']}")
    print(f"   æœ€å¤§è½®æ•°: {params['max_epochs']}")
    print(f"{'='*60}\n")
    
    # å¼€å§‹è®­ç»ƒ
    trainer.fit(model, data_module)
    
    print(f"\nâœ… Stage {args.stages}è®­ç»ƒå®Œæˆ!")
    print(f"   æœ€ä½³æ£€æŸ¥ç‚¹ä¿å­˜åœ¨: logs/stage{args.stages}/checkpoints/")
    
    # å¦‚æœä¸æ˜¯æœ€åé˜¶æ®µï¼Œæç¤ºä¸‹ä¸€æ­¥
    if args.stages < 3:
        print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print(f"   è¿è¡ŒStage {args.stages + 1}: --stages {args.stages + 1}")

if __name__ == "__main__":
    main()
