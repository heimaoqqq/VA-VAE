"""
ç»Ÿä¸€çš„è¿­ä»£å¾®è°ƒè„šæœ¬ - æ•´åˆæ•°æ®å¢å¼ºå’Œæ¨¡å‹å¾®è°ƒ
åŸºäºLightningDiTæ¡†æ¶ï¼Œä½¿ç”¨é«˜è´¨é‡åˆæˆæ ·æœ¬å¢å¼ºæ•°æ®é›†ï¼Œå¾®è°ƒDiT-Sæ¨¡å‹

å·¥ä½œæµç¨‹ï¼š
1. æ•°æ®å¢å¼ºé˜¶æ®µï¼šé€‰æ‹©é«˜è´¨é‡åˆæˆæ ·æœ¬ï¼Œæ‰©å……åŸå§‹æ•°æ®é›†
2. æ¨¡å‹å¾®è°ƒé˜¶æ®µï¼šåœ¨å¢å¼ºæ•°æ®é›†ä¸Šå¾®è°ƒï¼Œå¯é€‰æ·»åŠ å¯¹æ¯”å­¦ä¹ 
3. è¯„ä¼°æ”¹è¿›ï¼šæµ‹è¯•æ–°æ¨¡å‹ç”Ÿæˆè´¨é‡

å¯¹æ¯”å­¦ä¹ è¯´æ˜ï¼š
- ä¸æ˜¯é¢„è®­ç»ƒæŠ€æœ¯ï¼Œè€Œæ˜¯åœ¨å¾®è°ƒæ—¶å¼•å…¥
- ç›®çš„ï¼šå¢å¼ºæ¨¡å‹å¯¹31ä¸ªç”¨æˆ·çš„åŒºåˆ†èƒ½åŠ›
- å®ç°ï¼šåœ¨å™ªå£°é¢„æµ‹æŸå¤±åŸºç¡€ä¸Šæ·»åŠ ç”¨æˆ·ç‰¹å¾å¯¹æ¯”æŸå¤±
- å…¬å¼ï¼šL_total = L_noise + Î» * L_contrastive
"""
import torch
import torch.nn as nn
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
import os
import sys
import yaml
import argparse
from pathlib import Path
import numpy as np
from tqdm import tqdm

# æ·»åŠ LightningDiTè·¯å¾„
sys.path.append('LightningDiT')
from models.lightningdit import LightningDiT_models
from transport import create_transport, Sampler
import shutil
import json
from collections import defaultdict


class IterativeTraining:
    """
    ç»Ÿä¸€çš„è¿­ä»£è®­ç»ƒç®¡ç†å™¨
    æ•´åˆæ•°æ®å¢å¼ºå’Œæ¨¡å‹å¾®è°ƒåŠŸèƒ½
    """
    
    def __init__(self, config_path, base_dataset_path=None, output_path='./iterative_training'):
        with open(config_path, 'r') as f:
            self.config = yaml.load(f, Loader=yaml.FullLoader)
        
        # DDPåˆå§‹åŒ–
        self.setup_distributed()
        
        # è·¯å¾„è®¾ç½®ï¼ˆé€‚é…Kaggleè¾“å…¥è·¯å¾„ï¼‰
        self.base_checkpoint = '/kaggle/input/50000-pt/0050000.pt'  # åŸºç¡€æ¨¡å‹
        # å…¼å®¹ä¸åŒçš„æ•°æ®é›†è·¯å¾„
        if base_dataset_path:
            self.base_dataset = Path(base_dataset_path)
        elif os.path.exists('/kaggle/input/dataset'):
            self.base_dataset = Path('/kaggle/input/dataset')  # æ‚¨ä½¿ç”¨çš„è·¯å¾„
        else:
            self.base_dataset = Path('/kaggle/input/microdoppler-dataset')
        self.output_path = Path(output_path)
        if self.rank == 0:  # åªæœ‰ä¸»è¿›ç¨‹åˆ›å»ºç›®å½•
            self.output_path.mkdir(parents=True, exist_ok=True)
        
        # è®­ç»ƒå‚æ•°
        self.iteration = 0
        self.iteration_log = []
        
    def setup_distributed(self):
        """åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ"""
        if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
            self.rank = int(os.environ['RANK'])
            self.world_size = int(os.environ['WORLD_SIZE'])
            self.local_rank = int(os.environ.get('LOCAL_RANK', 0))
            
            # åˆå§‹åŒ–è¿›ç¨‹ç»„
            if not dist.is_initialized():
                dist.init_process_group(backend='nccl')
            
            # è®¾ç½®è®¾å¤‡
            torch.cuda.set_device(self.local_rank)
            self.device = torch.device(f'cuda:{self.local_rank}')
            
            print(f"[Rank {self.rank}] åˆå§‹åŒ–DDP: device={self.device}, world_size={self.world_size}")
        else:
            # å•GPUæ¨¡å¼
            self.rank = 0
            self.world_size = 1
            self.local_rank = 0
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            print(f"å•GPUæ¨¡å¼: device={self.device}")
    
    def create_enhanced_dit_model(self):
        """
        åˆ›å»ºDiTæ¨¡å‹ - å®Œå…¨åŒ¹é…train_dit_s_official.pyçš„å‚æ•°
        """
        config = self.config
        latent_size = config['data']['image_size'] // config['vae']['downsample_ratio']
        
        # ä»train_dit_s_official.pyå¤åˆ¶çš„ç²¾ç¡®å‚æ•°
        model = LightningDiT_models[config['model']['model_type']](
            input_size=latent_size,
            num_classes=config['data']['num_classes'],
            class_dropout_prob=config['model'].get('class_dropout_prob', 0.1),
            use_qknorm=config['model']['use_qknorm'],
            use_swiglu=config['model'].get('use_swiglu', False),
            use_rope=config['model'].get('use_rope', False),
            use_rmsnorm=config['model'].get('use_rmsnorm', False),
            wo_shift=config['model'].get('wo_shift', False),
            in_channels=config['model'].get('in_chans', 4),  # VA-VAEæ˜¯32é€šé“ï¼Œä»é…ç½®è¯»å–
            use_checkpoint=config['model'].get('use_checkpoint', False),
        ).to(self.device)
        
        return model
    
    def load_checkpoint_for_finetuning(self, model, checkpoint_path):
        """
        åŠ è½½æ£€æŸ¥ç‚¹å‡†å¤‡å¾®è°ƒ
        å…³é”®ï¼šä¿ç•™å¤§éƒ¨åˆ†æƒé‡ï¼Œåªå¾®è°ƒå…³é”®å±‚
        """
        print(f"ğŸ“¦ åŠ è½½åŸºç¡€æ¨¡å‹: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        if 'ema' in checkpoint:
            state_dict = checkpoint['ema']
        elif 'model' in checkpoint:
            state_dict = checkpoint['model']
        else:
            state_dict = checkpoint
        
        # æ¸…ç†é”®å
        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        
        # åŠ è½½æƒé‡
        model.load_state_dict(state_dict, strict=False)
        
        # å†»ç»“éƒ¨åˆ†å±‚ï¼ˆå¯é€‰ï¼‰- é˜²æ­¢è¿‡æ‹Ÿåˆ
        # self.freeze_backbone_layers(model)
        
        return model
    
    def freeze_backbone_layers(self, model, freeze_ratio=0.7):
        """
        å†»ç»“éƒ¨åˆ†backboneå±‚ï¼Œåªå¾®è°ƒé¡¶å±‚
        è¿™å¯ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œç‰¹åˆ«æ˜¯æ•°æ®é‡å°çš„æ—¶å€™
        """
        total_params = 0
        frozen_params = 0
        
        # å†»ç»“å‰70%çš„transformer blocks
        if hasattr(model, 'blocks'):
            num_blocks = len(model.blocks)
            freeze_blocks = int(num_blocks * freeze_ratio)
            
            for i in range(freeze_blocks):
                for param in model.blocks[i].parameters():
                    param.requires_grad = False
                    frozen_params += param.numel()
                
                total_params += sum(p.numel() for p in model.blocks[i].parameters())
        
        # å§‹ç»ˆä¿æŒæ¡ä»¶ç¼–ç å™¨å¯è®­ç»ƒ
        if hasattr(model, 'y_embedder'):
            for param in model.y_embedder.parameters():
                param.requires_grad = True
        
        print(f"â„ï¸ å†»ç»“ {frozen_params}/{total_params} å‚æ•° ({frozen_params/total_params*100:.1f}%)")
        
    def analyze_synthetic_quality(self, filtered_samples_dir):
        """åˆ†æåˆæˆæ ·æœ¬è´¨é‡"""
        stats = defaultdict(lambda: {'count': 0, 'avg_conf': 0, 'avg_spec': 0})
        
        filtered_dir = Path(filtered_samples_dir)
        for user_dir in filtered_dir.glob("User_*"):
            user_id = int(user_dir.name.split('_')[1])
            samples = list(user_dir.glob("*.png"))
            
            if samples:
                confidences = []
                specificities = []
                
                for sample in samples:
                    parts = sample.stem.split('_')
                    for part in parts:
                        if part.startswith('conf'):
                            confidences.append(float(part[4:]))
                        elif part.startswith('spec'):
                            specificities.append(float(part[4:]))
                
                stats[user_id] = {
                    'count': len(samples),
                    'avg_conf': np.mean(confidences) if confidences else 0,
                    'avg_spec': np.mean(specificities) if specificities else 0
                }
        
        return stats
    
    def select_high_quality_samples(self, filtered_samples_dir, 
                                   samples_per_user=50,  # åŸºäºå®é™…ç­›é€‰ç»“æœï¼šæ¯ç”¨æˆ·50å¼ 
                                   min_confidence=0.0,  # è®¾ä¸º0ï¼Œä½¿ç”¨æ‰€æœ‰å·²ç­›é€‰æ ·æœ¬
                                   min_specificity=0.0):  # è®¾ä¸º0ï¼Œä½¿ç”¨æ‰€æœ‰å·²ç­›é€‰æ ·æœ¬
        """é€‰æ‹©é«˜è´¨é‡æ ·æœ¬ï¼ˆå·²ç­›é€‰çš„ç›´æ¥ä½¿ç”¨ï¼‰"""
        selected = defaultdict(list)
        filtered_dir = Path(filtered_samples_dir)
        
        for user_dir in filtered_dir.glob("User_*"):
            user_id = int(user_dir.name.split('_')[1])
            candidates = []
            
            for sample_path in user_dir.glob("*.png"):
                # ç›´æ¥æ·»åŠ æ‰€æœ‰æ ·æœ¬ï¼Œä¸å†ç­›é€‰
                candidates.append({
                    'path': sample_path,
                    'conf': 1.0,  # é»˜è®¤å€¼
                    'spec': 1.0,  # é»˜è®¤å€¼
                    'score': 1.0  # é»˜è®¤å€¼
                })
            
            candidates.sort(key=lambda x: x['score'], reverse=True)
            # å–æœ€å°å€¼ï¼šå®é™…å¯ç”¨æ ·æœ¬æ•° vs è¯·æ±‚çš„æ ·æœ¬æ•°
            actual_samples = min(len(candidates), samples_per_user)
            selected[user_id] = candidates[:actual_samples]
            
            if self.rank == 0:  # åªæœ‰ä¸»è¿›ç¨‹æ‰“å°
                if actual_samples < samples_per_user:
                    print(f"User_{user_id:02d}: é€‰æ‹© {actual_samples}/{len(candidates)} ä¸ªé«˜è´¨é‡æ ·æœ¬ (ä¸è¶³{samples_per_user}å¼ )")
                else:
                    print(f"User_{user_id:02d}: é€‰æ‹© {actual_samples}/{len(candidates)} ä¸ªé«˜è´¨é‡æ ·æœ¬")
        
        return selected
    
    def augment_dataset(self, selected_samples, iteration):
        """åˆ›å»ºå¢å¼ºæ•°æ®é›†"""
        augmented_dir = self.output_path / f"iteration_{iteration}_dataset"
        augmented_dir.mkdir(exist_ok=True)
        
        # å¤åˆ¶åŸå§‹æ•°æ®ï¼ˆID_1 åˆ° ID_31 æ˜ å°„åˆ° User_00 åˆ° User_30ï¼‰
        if self.rank == 0:  # åªæœ‰ä¸»è¿›ç¨‹å¤åˆ¶
            print(f"å¤åˆ¶åŸå§‹æ•°æ®é›†åˆ° {augmented_dir}")
            for user_id in range(31):
                # çœŸå®æ•°æ®é›†ï¼šID_1 åˆ° ID_31
                src_dir = self.base_dataset / f"ID_{user_id+1}"
                # ç›®æ ‡æ ¼å¼ï¼šUser_00 åˆ° User_30
                dst_dir = augmented_dir / f"User_{user_id:02d}"
                
                if src_dir.exists():
                    print(f"  å¤åˆ¶ {src_dir.name} -> {dst_dir.name}")
                    shutil.copytree(src_dir, dst_dir, dirs_exist_ok=True)
                else:
                    print(f"  è­¦å‘Šï¼šæ‰¾ä¸åˆ°åŸå§‹æ•°æ®ç›®å½• {src_dir}")
        
        # æ·»åŠ åˆæˆæ ·æœ¬
        if self.rank == 0:  # åªæœ‰ä¸»è¿›ç¨‹æ“ä½œ
            added_count = 0
            for user_id, samples in selected_samples.items():
                dst_dir = augmented_dir / f"User_{user_id:02d}"
                dst_dir.mkdir(parents=True, exist_ok=True)
                
                # ç»Ÿä¸€å¤„ç†jpgå’Œpngæ–‡ä»¶
                existing_files = list(dst_dir.glob("*.jpg")) + list(dst_dir.glob("*.png"))
                start_idx = len(existing_files)
                
                for idx, sample_info in enumerate(samples):
                    src_path = sample_info['path']
                    # ç»Ÿä¸€ä¸º.jpgæ ¼å¼
                    dst_path = dst_dir / f"synthetic_{start_idx + idx:04d}.jpg"
                    
                    # å¦‚æœæ˜¯PNGï¼Œè½¬æ¢ä¸ºJPG
                    if src_path.suffix.lower() == '.png':
                        from PIL import Image
                        img = Image.open(src_path)
                        # è½¬æ¢RGBAåˆ°RGB
                        if img.mode == 'RGBA':
                            rgb_img = Image.new('RGB', img.size, (0, 0, 0))
                            rgb_img.paste(img, mask=img.split()[3] if len(img.split()) > 3 else None)
                            rgb_img.save(dst_path, 'JPEG', quality=95)
                        else:
                            img.save(dst_path, 'JPEG', quality=95)
                    else:
                        # å·²ç»æ˜¯JPGï¼Œç›´æ¥å¤åˆ¶
                        shutil.copy2(src_path, dst_path)
                    added_count += 1
            
            print(f"âœ… æ·»åŠ äº† {added_count} ä¸ªåˆæˆæ ·æœ¬åˆ°å¢å¼ºæ•°æ®é›†")
        
        # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
        if dist.is_initialized():
            dist.barrier()
        return augmented_dir
    
    def prepare_augmented_dataset(self, original_data_path, synthetic_samples_path):
        """
        å‡†å¤‡å¢å¼ºæ•°æ®é›†
        æ··åˆåŸå§‹æ•°æ® + é«˜è´¨é‡åˆæˆæ ·æœ¬
        """
        from microdoppler_latent_dataset_simple import MicroDopplerLatentDataset
        
        # æ”¶é›†æ‰€æœ‰æ•°æ®è·¯å¾„
        all_image_paths = []
        all_labels = []
        
        # 1. åŸå§‹æ•°æ®
        original_path = Path(original_data_path)
        for user_id in range(31):
            user_dir = original_path / f"User_{user_id:02d}"
            if user_dir.exists():
                for img_path in user_dir.glob("*.png"):
                    all_image_paths.append(str(img_path))
                    all_labels.append(user_id)
        
        original_count = len(all_image_paths)
        
        # 2. é«˜è´¨é‡åˆæˆæ ·æœ¬
        synthetic_path = Path(synthetic_samples_path)
        synthetic_count = 0
        max_per_user = 30  # æ¯ç”¨æˆ·æœ€å¤šæ·»åŠ 30ä¸ªåˆæˆæ ·æœ¬
        
        for user_dir in synthetic_path.glob("User_*"):
            user_id = int(user_dir.name.split('_')[1])
            
            # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„æ ·æœ¬
            samples = []
            for img_path in user_dir.glob("*.png"):
                # ä»æ–‡ä»¶åæå–æŒ‡æ ‡
                parts = img_path.stem.split('_')
                conf = 0
                for part in parts:
                    if part.startswith('conf'):
                        try:
                            conf = float(part[4:])
                        except:
                            conf = 0
                        break
                
                if conf > 0.95:  # åªé€‰æ‹©é«˜ç½®ä¿¡åº¦æ ·æœ¬
                    samples.append((img_path, conf))
            
            # æ’åºå¹¶é€‰æ‹©top-k
            samples.sort(key=lambda x: x[1], reverse=True)
            for img_path, _ in samples[:max_per_user]:
                all_image_paths.append(str(img_path))
                all_labels.append(user_id)
                synthetic_count += 1
        
        print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  åŸå§‹æ ·æœ¬: {original_count}")
        print(f"  åˆæˆæ ·æœ¬: {synthetic_count}")
        print(f"  æ€»è®¡: {len(all_image_paths)}")
        print(f"  å¢é•¿ç‡: {synthetic_count/original_count*100:.1f}%")
        
        return all_image_paths, all_labels


    def create_contrastive_loss(self, features, labels, temperature=0.07):
        """
        å¯¹æ¯”å­¦ä¹ æŸå¤± - åœ¨å¾®è°ƒæ—¶å¼•å…¥ï¼Œä¸æ˜¯é¢„è®­ç»ƒ
        
        è¯´æ˜ï¼š
        1. è¿™æ˜¯åœ¨å¾®è°ƒé˜¶æ®µæ·»åŠ çš„é¢å¤–æŸå¤±é¡¹
        2. ä»DiTçš„ä¸­é—´å±‚æå–ç”¨æˆ·ç‰¹å¾è¡¨ç¤º
        3. æ‹‰è¿‘åŒç”¨æˆ·æ ·æœ¬ï¼Œæ¨è¿œä¸åŒç”¨æˆ·æ ·æœ¬
        4. ä¸å™ªå£°é¢„æµ‹æŸå¤±è”åˆä¼˜åŒ–ï¼šL_total = L_noise + Î»*L_contrastive
        """
        # å½’ä¸€åŒ–ç‰¹å¾
        features = F.normalize(features, dim=1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        sim_matrix = torch.matmul(features, features.T) / temperature
        
        # åˆ›å»ºæ ‡ç­¾mask
        batch_size = labels.shape[0]
        mask = labels.unsqueeze(0) == labels.unsqueeze(1)  # [B, B]
        mask = mask.float().to(features.device)
        
        # æ’é™¤å¯¹è§’çº¿
        mask.fill_diagonal_(0)
        
        # è®¡ç®—InfoNCEæŸå¤±
        exp_sim = torch.exp(sim_matrix)
        log_prob = sim_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True))
        
        # åªè®¡ç®—æ­£æ ·æœ¬å¯¹çš„æŸå¤±
        positive_pairs = mask.sum(dim=1)
        positive_pairs[positive_pairs == 0] = 1  # é¿å…é™¤0
        
        loss = -(mask * log_prob).sum(dim=1) / positive_pairs
        return loss.mean()
    
    def run_iteration(self, filtered_samples_dir, use_contrastive=False):
        """
        è¿è¡Œå®Œæ•´çš„è¿­ä»£æµç¨‹
        
        å‚æ•°:
            filtered_samples_dir: ç­›é€‰åçš„åˆæˆæ ·æœ¬ç›®å½•
            use_contrastive: æ˜¯å¦åœ¨å¾®è°ƒæ—¶ä½¿ç”¨å¯¹æ¯”å­¦ä¹ 
        """
        self.iteration += 1
        if self.rank == 0:  # åªæœ‰ä¸»è¿›ç¨‹æ‰“å°
            print(f"\n{'='*60}")
            print(f"ğŸ”„ ç¬¬ {self.iteration} è½®è¿­ä»£è®­ç»ƒ")
            print(f"{'='*60}")
        
        # 1. åˆ†æåˆæˆæ ·æœ¬è´¨é‡
        if self.rank == 0:
            print("\n1ï¸âƒ£ åˆ†æåˆæˆæ ·æœ¬è´¨é‡...")
        stats = self.analyze_synthetic_quality(filtered_samples_dir)
        
        # 2. é€‰æ‹©é«˜è´¨é‡æ ·æœ¬
        if self.rank == 0:
            print("\n2ï¸âƒ£ é€‰æ‹©é«˜è´¨é‡æ ·æœ¬...")
        
        # æ ¹æ®è¿­ä»£è½®æ¬¡è°ƒæ•´æ ·æœ¬æ•°é‡
        if self.iteration == 1:
            samples_per_user = 50  # ç¬¬1è½®ï¼šä½¿ç”¨50%çš„ç­›é€‰æ ·æœ¬
        elif self.iteration == 2:
            samples_per_user = 75  # ç¬¬2è½®ï¼šå¢åŠ åˆ°75%
        else:
            samples_per_user = 100  # ç¬¬3è½®ï¼šä½¿ç”¨å…¨éƒ¨ç­›é€‰æ ·æœ¬
        
        if self.rank == 0:
            print(f"  ğŸ“Š ç¬¬{self.iteration}è½®ï¼šæ¯ç”¨æˆ·{samples_per_user}å¼ ï¼Œæ€»å¢{samples_per_user*31}å¼ ")
        
        selected = self.select_high_quality_samples(
            filtered_samples_dir,
            samples_per_user=samples_per_user,
            min_confidence=0.0,  # ä½¿ç”¨æ‰€æœ‰å·²ç­›é€‰æ ·æœ¬
            min_specificity=0.0   # ä¸å†é¢å¤–ç­›é€‰
        )
        
        # 3. åˆ›å»ºå¢å¼ºæ•°æ®é›†
        if self.rank == 0:
            print("\n3ï¸âƒ£ åˆ›å»ºå¢å¼ºæ•°æ®é›†...")
        augmented_dir = self.augment_dataset(selected, self.iteration)
        
        # 4. é…ç½®å¾®è°ƒå‚æ•°
        if self.rank == 0:
            print("\n4ï¸âƒ£ é…ç½®å¾®è°ƒå‚æ•°...")
        
        finetune_config = {
            'iteration': self.iteration,
            'base_checkpoint': self.base_checkpoint,
            'augmented_dataset': str(augmented_dir),
            'use_contrastive': use_contrastive,
            'contrastive_weight': 0.1 if use_contrastive else 0,
            'learning_rate': 1e-5,  # å¾®è°ƒç”¨å°å­¦ä¹ ç‡
            'epochs': 10,  # åªéœ€10ä¸ªepoch
            'batch_size': 16,
            'gradient_accumulation': 4,
            'no_augmentation': True  # ä¸ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œå¯¹å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•ˆæœå·®
        }
        
        # 5. ä¿å­˜é…ç½®
        config_path = self.output_path / f"iteration_{self.iteration}_config.yaml"
        if self.rank == 0:  # åªæœ‰ä¸»è¿›ç¨‹ä¿å­˜
            with open(config_path, 'w') as f:
                yaml.dump(finetune_config, f)
        
        # 6. è®°å½•è¿­ä»£ä¿¡æ¯
        iteration_info = {
            'iteration': self.iteration,
            'stats': dict(stats),
            'selected_count': {k: len(v) for k, v in selected.items()},
            'config': finetune_config
        }
        self.iteration_log.append(iteration_info)
        
        # ä¿å­˜æ—¥å¿—
        log_path = self.output_path / 'iteration_log.json'
        if self.rank == 0:  # åªæœ‰ä¸»è¿›ç¨‹ä¿å­˜
            with open(log_path, 'w') as f:
                json.dump(self.iteration_log, f, indent=2, default=str)
            
            print(f"\nâœ… ç¬¬ {self.iteration} è½®å‡†å¤‡å®Œæˆ!")
            print(f"ğŸ“ å¢å¼ºæ•°æ®é›†: {augmented_dir}")
            print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {config_path}")
            
            if use_contrastive:
                print("\nğŸ“Œ å¯¹æ¯”å­¦ä¹ è¯´æ˜:")
                print("  - åœ¨å¾®è°ƒæ—¶å¼•å…¥ï¼Œä¸æ˜¯é¢„è®­ç»ƒ")
                print("  - å¢å¼º31ä¸ªç”¨æˆ·çš„åŒºåˆ†èƒ½åŠ›")
                print("  - æŸå¤±æƒé‡: 0.1")
        
        # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
        if dist.is_initialized():
            dist.barrier()
        
        return augmented_dir, config_path


def finetune_iteration(
    iteration: int,
    base_checkpoint: str,
    augmented_data_path: str,
    synthetic_samples_path: str,
    output_dir: str,
    config_path: str = 'configs/dit_s_microdoppler.yaml'
):
    """
    æ‰§è¡Œä¸€è½®å¾®è°ƒè¿­ä»£ï¼ˆæ”¯æŒDDPåŒGPUè®­ç»ƒï¼‰
    
    å¢å¼ºç­–ç•¥ï¼ˆåŸºäºå®é™…ç­›é€‰ç»“æœï¼‰ï¼š
    - ç¬¬1è½®ï¼šæ¯ç”¨æˆ·50å¼ ï¼ˆå·²ç­›é€‰100ä¸ªä¸­é€‰æœ€å¥½çš„50%ï¼‰
    - ç¬¬2è½®ï¼šæ¯ç”¨æˆ·75å¼ ï¼ˆä½¿ç”¨75%çš„ç­›é€‰æ ·æœ¬ï¼‰
    - ç¬¬3è½®ï¼šæ¯ç”¨æˆ·100å¼ ï¼ˆä½¿ç”¨å…¨éƒ¨ç­›é€‰æ ·æœ¬ï¼‰
    
    å‚æ•°:
        iteration: è¿­ä»£è½®æ¬¡
        base_checkpoint: åŸºç¡€æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆ50000.ptï¼‰
        augmented_data_path: åŸå§‹æ•°æ®è·¯å¾„
        synthetic_samples_path: ç­›é€‰åçš„åˆæˆæ ·æœ¬è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
    """
    
    # DDPåˆå§‹åŒ–
    if 'RANK' in os.environ:
        rank = int(os.environ['RANK'])
        local_rank = int(os.environ.get('LOCAL_RANK', 0))
        world_size = int(os.environ['WORLD_SIZE'])
        
        if not dist.is_initialized():
            dist.init_process_group(backend='nccl')
        
        torch.cuda.set_device(local_rank)
        device = torch.device(f'cuda:{local_rank}')
    else:
        rank = 0
        local_rank = 0
        world_size = 1
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    if rank == 0:
        print(f"\n{'='*60}")
        print(f"ğŸ”„ ç¬¬ {iteration} è½®è¿­ä»£å¾®è°ƒ")
        print(f"ğŸ’» ä½¿ç”¨ {world_size} ä¸ªGPUè¿›è¡ŒDDPè®­ç»ƒ")
        print(f"{'='*60}\n")
    
    # åŠ è½½é…ç½®
    with open(config_path, 'r') as f:
        config = yaml.load(f, Loader=yaml.FullLoader)
    
    # 1. åˆ›å»ºæ¨¡å‹
    if rank == 0:
        print("1ï¸âƒ£ åˆ›å»ºDiT-Sæ¨¡å‹...")
    
    # ç¦ç”¨torch.compileä»¥é¿å…OOM
    os.environ['TORCH_COMPILE_DISABLE'] = '1'
    os.environ['TORCHDYNAMO_DISABLE'] = '1'
    
    latent_size = config['data']['image_size'] // config['vae']['downsample_ratio']
    model = LightningDiT_models[config['model']['model_type']](
        input_size=latent_size,
        num_classes=config['data']['num_classes'],
        class_dropout_prob=config['model'].get('class_dropout_prob', 0.1),
        use_qknorm=config['model']['use_qknorm'],
        use_swiglu=config['model'].get('use_swiglu', False),
        use_rope=config['model'].get('use_rope', False),
        use_rmsnorm=config['model'].get('use_rmsnorm', False),
        wo_shift=config['model'].get('wo_shift', False),
        in_channels=config['model'].get('in_chans', 4),
        use_checkpoint=config['model'].get('use_checkpoint', False),
    ).to(device)
    
    # 2. åŠ è½½åŸºç¡€æƒé‡
    if rank == 0:
        print(f"2ï¸âƒ£ åŠ è½½åŸºç¡€æ¨¡å‹: {base_checkpoint}")
    
    checkpoint = torch.load(base_checkpoint, map_location='cpu')  # å…ˆåŠ è½½åˆ°CPU
    if 'ema' in checkpoint:
        state_dict = checkpoint['ema']
    elif 'model' in checkpoint:
        state_dict = checkpoint['model']
    else:
        state_dict = checkpoint
    
    state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
    model.load_state_dict(state_dict, strict=False)
    
    # 3. DDPåŒ…è£…æ¨¡å‹
    if world_size > 1:
        model = DDP(model, device_ids=[local_rank], output_device=local_rank)
        if rank == 0:
            print("âœ… æ¨¡å‹å·²åŒ…è£…ä¸ºDDP")
    
    # 4. å¾®è°ƒé…ç½®
    if rank == 0:
        print("4ï¸âƒ£ é…ç½®å¾®è°ƒå‚æ•°...")
        print("  âš ï¸ ä¸ä½¿ç”¨æ•°æ®å¢å¼ºï¼ˆå¯¹å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•ˆæœå·®ï¼‰")
        print(f"  ğŸ“Š æ•°æ®é›†å¤§å°: åŸå§‹4650 + åˆæˆ{50*31}(ç¬¬1è½®) = {4650+1550}å¼ ï¼ˆ33%å¢é•¿ï¼‰")
        print(f"  ğŸš€ æ‰¹å¤§å°: æ¯GPU {16//world_size}, æ€»æ‰¹å¤§å°: 16")
    
    # è°ƒæ•´å­¦ä¹ ç‡ï¼ˆçº¿æ€§ç¼©æ”¾ï¼‰
    base_lr = 1e-5
    lr = base_lr * world_size  # DDPçº¿æ€§ç¼©æ”¾å­¦ä¹ ç‡
    
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=lr,
        betas=(0.9, 0.999),
        weight_decay=0.01
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=10,  # åªè®­ç»ƒ10ä¸ªepoch
        eta_min=1e-6
    )
    
    # 5. å‡†å¤‡æ•°æ®
    if rank == 0:
        print("5ï¸âƒ£ å‡†å¤‡å¢å¼ºæ•°æ®é›†...")
    
    manager = IterativeTraining(config_path)
    image_paths, labels = manager.prepare_augmented_dataset(
        augmented_data_path,
        synthetic_samples_path
    )
    
    # åˆ›å»ºåˆ†å¸ƒå¼é‡‡æ ·å™¨
    if world_size > 1:
        # è¿™é‡Œéœ€è¦å®é™…çš„æ•°æ®é›†å¯¹è±¡ï¼Œç®€åŒ–ç¤ºä¾‹
        if rank == 0:
            print("  ğŸ“¦ ä½¿ç”¨DistributedSamplerè¿›è¡Œæ•°æ®å¹¶è¡Œ")
    
    # 6. å¾®è°ƒå¾ªç¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
    if rank == 0:
        print("6ï¸âƒ£ å¼€å§‹å¾®è°ƒ...")
        print(f"  - å­¦ä¹ ç‡: {lr:.2e} (åŸºç¡€{base_lr:.2e} Ã— {world_size}GPU)")
        print(f"  - Epochs: 10")
        print(f"  - ä¼˜åŒ–å™¨: AdamW")
    
    # ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹
    output_path = Path(output_dir) / f"iteration_{iteration}_checkpoint.pt"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # ç¤ºä¾‹ï¼šä¿å­˜é…ç½®
    finetune_config = {
        'iteration': iteration,
        'base_checkpoint': base_checkpoint,
        'dataset_size': len(image_paths),
        'learning_rate': 1e-5,
        'epochs': 10,
        'timestamp': str(Path(output_path).stat().st_mtime if output_path.exists() else 'new')
    }
    
    config_save_path = Path(output_dir) / f"iteration_{iteration}_config.yaml"
    
    if rank == 0:  # åªæœ‰ä¸»è¿›ç¨‹ä¿å­˜
        with open(config_save_path, 'w') as f:
            yaml.dump(finetune_config, f)
        
        print(f"\nâœ… å¾®è°ƒé…ç½®å·²ä¿å­˜åˆ°: {config_save_path}")
        print(f"ğŸ“ ä¸‹ä¸€æ­¥: åœ¨Kaggleä¸Šè¿è¡Œå®é™…çš„å¾®è°ƒè®­ç»ƒ")
    
    # æ¸…ç†DDP
    if world_size > 1:
        dist.destroy_process_group()
    
    return str(output_path)


def main():
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€çš„LightningDiTè¿­ä»£å¾®è°ƒè„šæœ¬')
    parser.add_argument('--mode', type=str, default='full', 
                       choices=['analyze', 'augment', 'finetune', 'full'],
                       help='è¿è¡Œæ¨¡å¼: analyze(åˆ†æ), augment(å¢å¼º), finetune(å¾®è°ƒ), full(å…¨æµç¨‹)')
    parser.add_argument('--synthetic_samples', type=str,
                       default='./filtered_samples_multi',
                       help='ç­›é€‰åçš„åˆæˆæ ·æœ¬è·¯å¾„')
    parser.add_argument('--base_dataset', type=str,
                       default='/kaggle/input/microdoppler-dataset',
                       help='åŸå§‹æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--output_dir', type=str,
                       default='./iterative_training',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--config', type=str,
                       default='configs/dit_s_microdoppler.yaml',
                       help='é…ç½®æ–‡ä»¶')
    parser.add_argument('--use_contrastive', action='store_true',
                       help='æ˜¯å¦åœ¨å¾®è°ƒæ—¶ä½¿ç”¨å¯¹æ¯”å­¦ä¹ ')
    parser.add_argument('--iteration', type=int, default=1, 
                       help='å½“å‰è¿­ä»£è½®æ¬¡')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç®¡ç†å™¨
    manager = IterativeTraining(
        config_path=args.config,
        base_dataset_path=args.base_dataset,
        output_path=args.output_dir
    )
    
    if args.mode == 'analyze':
        # ä»…åˆ†æ
        print("ğŸ” åˆ†æåˆæˆæ ·æœ¬è´¨é‡...")
        stats = manager.analyze_synthetic_quality(args.synthetic_samples)
        print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
        for user_id, stat in stats.items():
            print(f"User_{user_id:02d}: {stat['count']}ä¸ªæ ·æœ¬, å¹³å‡ç½®ä¿¡åº¦={stat['avg_conf']:.3f}, å¹³å‡ç‰¹å¼‚æ€§={stat['avg_spec']:.3f}")
    
    elif args.mode == 'augment':
        # ä»…æ•°æ®å¢å¼º
        print("ğŸ“¦ åˆ›å»ºå¢å¼ºæ•°æ®é›†...")
        selected = manager.select_high_quality_samples(args.synthetic_samples)
        augmented_dir = manager.augment_dataset(selected, args.iteration)
        print(f"âœ… å¢å¼ºæ•°æ®é›†å·²ä¿å­˜åˆ°: {augmented_dir}")
    
    elif args.mode == 'finetune':
        # ä»…é…ç½®å¾®è°ƒ
        print("âš™ï¸ é…ç½®å¾®è°ƒå‚æ•°...")
        finetune_iteration(
            iteration=args.iteration,
            base_checkpoint='/kaggle/input/50000-pt/0050000.pt',
            augmented_data_path=args.base_dataset,
            synthetic_samples_path=args.synthetic_samples,
            output_dir=args.output_dir
        )
    
    else:  # full
        # å®Œæ•´æµç¨‹
        if manager.rank == 0:
            print("ğŸˆ è¿è¡Œå®Œæ•´è¿­ä»£æµç¨‹...")
        
        augmented_dir, config_path = manager.run_iteration(
            args.synthetic_samples,
            use_contrastive=args.use_contrastive
        )
        
        if manager.rank == 0:
            print(f"\n{'='*60}")
            print("ğŸ“‹ è¿­ä»£å¾®è°ƒæ€»ç»“:")
            print(f"{'='*60}")
            print(f"âœ… æ•°æ®å¢å¼º: æ·»åŠ é«˜è´¨é‡åˆæˆæ ·æœ¬åˆ°è®­ç»ƒé›†")
            print(f"âœ… æ¨¡å‹å¾®è°ƒ: åŸºäº50000.ptç»§ç»­è®­ç»ƒï¼Œä¸æ˜¯ä»å¤´å¼€å§‹")
            contrastive_status = 'å·²å¯ç”¨ - å¢å¼ºç”¨æˆ·åŒºåˆ†' if args.use_contrastive else 'æœªå¯ç”¨'
            print(f"âœ… å¯¹æ¯”å­¦ä¹ : {contrastive_status}")
            print(f"âœ… è®­ç»ƒæ•ˆç‡: 10 epochs vs åŸå§‹50000æ­¥")
            print(f"âœ… é¢„æœŸæ•ˆæœ: æ¯è½®æå‡2-3å€ç”Ÿæˆè´¨é‡")
            print(f"{'='*60}\n")
            
            print("\nğŸ¯ æ•°æ®å‡†å¤‡å®Œæˆï¼è¯·è¿è¡Œå®é™…çš„å¾®è°ƒè®­ç»ƒè„šæœ¬ï¼š")
            print(f"python microdoppler_finetune/train_enhanced_dit.py --dataset {augmented_dir}")
        
        # æ¸…ç†DDP
        if dist.is_initialized():
            dist.destroy_process_group()


if __name__ == "__main__":
    main()
