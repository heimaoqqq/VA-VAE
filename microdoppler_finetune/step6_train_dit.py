"""
Step 6: è®­ç»ƒæ¡ä»¶LightningDiTæ¨¡å‹
ä½¿ç”¨å¾®è°ƒåçš„VA-VAEæ½œç©ºé—´è¿›è¡Œmicro-Dopplerå›¾åƒç”Ÿæˆ
é’ˆå¯¹Kaggle T4Ã—2 GPUç¯å¢ƒä¼˜åŒ–
"""

import os
import sys
import time
import json
import logging
import types
from pathlib import Path
from PIL import Image
import numpy as np
from tqdm import tqdm
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from omegaconf import OmegaConf
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ LightningDiTè·¯å¾„ï¼ˆå‚è€ƒstep4ï¼‰
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'LightningDiT' / 'vavae'))
sys.path.insert(0, str(project_root / 'LightningDiT'))
sys.path.insert(0, str(project_root))  # æ·»åŠ æ ¹ç›®å½•ä»¥å¯¼å…¥è‡ªå®šä¹‰æ•°æ®é›†

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Kaggle T4å†…å­˜ä¼˜åŒ–è®¾ç½®
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
os.environ['TORCH_COMPILE_DISABLE'] = '1'
os.environ['TORCHDYNAMO_DISABLE'] = '1'

# ç¦ç”¨torch.compile
import torch._dynamo
torch._dynamo.disable()

# DataParallelè¾…åŠ©å‡½æ•°
def is_main_process():
    """å§‹ç»ˆè¿”å›Trueï¼Œå› ä¸ºä¸ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ"""
    return True


# å¯¼å…¥LightningDiTæ¨¡å—
from transport import create_transport, Sampler
from models.lightningdit import LightningDiT_models, LightningDiT_B_1

# å¯¼å…¥VA-VAE
from tokenizer.vavae import VA_VAE

# ==================== æ•°æ®é›†å®šä¹‰ ====================
class MicroDopplerLatentDataset(Dataset):
    """å¾®è°ƒåçš„æ½œç©ºé—´æ•°æ®é›†ï¼ŒåŒ…å«ç”¨æˆ·æ¡ä»¶"""
    
    def __init__(self, data_dir, split='train', val_ratio=0.2, latent_norm=True):
        self.data_dir = Path(data_dir)
        self.split = split
        self.latent_norm = latent_norm
        
        # åŠ è½½æ•°æ®é›†åˆ’åˆ†ä¿¡æ¯
        split_file = Path("/kaggle/working/data_split/dataset_split.json")
        if not split_file.exists():
            # å¦‚æœæ²¡æœ‰åˆ’åˆ†æ–‡ä»¶ï¼Œå°è¯•å…¶ä»–ä½ç½®
            alt_split_file = Path("/kaggle/input/data_split/dataset_split.json")
            if alt_split_file.exists():
                split_file = alt_split_file
            else:
                logger.warning(f"æœªæ‰¾åˆ°æ•°æ®é›†åˆ’åˆ†æ–‡ä»¶: {split_file}")
                logger.warning("è¯·å…ˆè¿è¡Œ step3_prepare_dataset.py åˆ›å»ºæ•°æ®åˆ’åˆ†")
                split_info = None
        else:
            import json
            with open(split_file, 'r') as f:
                split_info = json.load(f)
            logger.info(f"åŠ è½½æ•°æ®åˆ’åˆ†: {split_file}")
        
        # åŠ è½½æ½œç©ºé—´æ•°æ®å’Œæ ‡ç­¾ - ä»å¯å†™ç›®å½•åŠ è½½
        latents_file = Path("/kaggle/working") / 'latents_microdoppler.npz'
        stats_file = Path("/kaggle/working") / 'latents_stats.pt'
        
        # åŠ è½½å¾®å¤šæ™®å‹’æ•°æ®é›†è‡ªå·±çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¸ä½¿ç”¨å®˜æ–¹ImageNetç»Ÿè®¡ï¼‰
        if stats_file.exists():
            stats = torch.load(stats_file)
            self.latent_mean = stats['mean'].float()
            self.latent_std = stats['std'].float()
            logger.info(f"åŠ è½½å¾®å¤šæ™®å‹’æ½œç©ºé—´ç»Ÿè®¡: mean={self.latent_mean.shape}, std={self.latent_std.shape}")
        else:
            self.latent_mean = None
            self.latent_std = None
            
        if latents_file.exists():
            data = np.load(latents_file)
            self.latents = torch.from_numpy(data['latents']).float()
            self.user_ids = torch.from_numpy(data['user_ids']).long()
            
            # å¦‚æœæ²¡æœ‰ç»Ÿè®¡ä¿¡æ¯ï¼Œä»æ•°æ®ä¸­è®¡ç®—
            if self.latent_mean is None:
                self.latent_mean = self.latents.mean(dim=[0, 2, 3], keepdim=True)
                self.latent_std = self.latents.std(dim=[0, 2, 3], keepdim=True)
                logger.info("ä»æ•°æ®è®¡ç®—æ½œç©ºé—´ç»Ÿè®¡ä¿¡æ¯")
            
            logger.info(f"Loaded {len(self.latents)} latent samples from {latents_file}")
            
            # è°ƒè¯•ä¿¡æ¯
            if len(self.latents) == 0:
                logger.error("æ½œç©ºé—´æ–‡ä»¶å­˜åœ¨ä½†ä¸ºç©ºï¼")
                raise ValueError("Empty latents file")
        else:
            # å¦‚æœé¢„è®¡ç®—çš„æ½œç©ºé—´ä¸å­˜åœ¨ï¼Œå®æ—¶ç¼–ç 
            logger.warning(f"Pre-computed latents not found at {latents_file}")
            self.latents = None
            self.load_images()
        
        # ä½¿ç”¨step3åˆ›å»ºçš„æ•°æ®åˆ’åˆ†
        if split_info is not None and split in split_info:
            # ä½¿ç”¨é¢„å®šä¹‰çš„åˆ’åˆ†
            self.file_list = []
            self.user_labels = []
            
            for user_key, image_paths in split_info[split].items():
                user_id = int(user_key.split('_')[1]) - 1  # ID_1 -> 0
                for img_path in image_paths:
                    self.file_list.append(img_path)
                    self.user_labels.append(user_id)
            
            logger.info(f"ä½¿ç”¨step3åˆ’åˆ†: {split} é›†åŒ…å« {len(self.file_list)} å¼ å›¾åƒ")
            self.indices = np.arange(len(self.file_list))
            n_samples = len(self.file_list)  # è®¾ç½®n_samplesç”¨äºåç»­æ—¥å¿—
        else:
            # å¦‚æœæ²¡æœ‰åˆ’åˆ†ä¿¡æ¯ï¼Œä½¿ç”¨åŸæ¥çš„éšæœºåˆ’åˆ†
            if self.latents is not None:
                n_samples = len(self.latents)
            elif hasattr(self, 'image_paths'):
                n_samples = len(self.image_paths)
            else:
                logger.error("æ²¡æœ‰æ•°æ®å¯ç”¨äºåˆ›å»ºæ•°æ®é›†")
                n_samples = 0
                
            if n_samples == 0:
                logger.error(f"æ•°æ®é›†ä¸ºç©ºï¼latents={self.latents is not None}, "
                            f"has_image_paths={hasattr(self, 'image_paths')}")
                self.indices = np.array([])
            else:
                indices = np.arange(n_samples)
                np.random.seed(42)
                np.random.shuffle(indices)
                
                n_val = int(n_samples * val_ratio)
                if split == 'train':
                    self.indices = indices[n_val:]
                else:
                    self.indices = indices[:n_val]
        
        logger.info(f"{split} dataset: {len(self.indices)} samples (total: {n_samples})")
    
    def load_images(self):
        """åŠ è½½åŸå§‹å›¾åƒè·¯å¾„"""
        self.image_paths = []
        self.user_ids = []
        
        # æ£€æŸ¥ä¸åŒçš„æ•°æ®è·¯å¾„æ ¼å¼
        # åŸå§‹æ•°æ®é›†: /kaggle/input/dataset/ID_*
        # å¤„ç†å: processed_microdoppler/ID_*
        data_path = self.data_dir
        if not (data_path / 'ID_1').exists():
            # å°è¯•processed_microdopplerå­ç›®å½•
            alt_path = data_path / 'processed_microdoppler'
            if alt_path.exists():
                data_path = alt_path
                logger.info(f"ä½¿ç”¨å¤„ç†åçš„æ•°æ®è·¯å¾„: {data_path}")
        
        for user_dir in sorted(data_path.glob('ID_*')):
            user_id = int(user_dir.name.split('_')[1]) - 1  # ID_1 -> 0
            
            # æ”¶é›†è¯¥ç”¨æˆ·çš„æ‰€æœ‰å›¾åƒï¼ˆä¿®æ­£ä¸º.jpgæ ¼å¼ï¼‰
            image_files = sorted(list(user_dir.glob('*.jpg')))
            
            if not image_files:
                logger.warning(f"ç”¨æˆ· {user_dir.name} æ²¡æœ‰æ‰¾åˆ°.jpgå›¾åƒæ–‡ä»¶")
                continue
                
            logger.info(f"ç¼–ç ç”¨æˆ· {user_dir.name}: {len(image_files)} å¼ å›¾åƒ")
            
            for img_path in image_files:
                self.image_paths.append(str(img_path))
                self.user_ids.append(user_id)
    
    def __len__(self):
        return len(self.indices)
    
    def __getitem__(self, idx):
        real_idx = self.indices[idx]
        
        if self.latents is not None:
            latent = self.latents[real_idx]
            user_id = self.user_ids[real_idx]
            
            # ç¡®ä¿æ˜¯tensoræ ¼å¼
            if isinstance(latent, np.ndarray):
                latent = torch.from_numpy(latent).float()
            else:
                latent = latent.float()
                
            if isinstance(user_id, np.ndarray):
                user_id = torch.from_numpy(user_id).long()
            else:
                user_id = user_id.long()
            
            # æ½œç©ºé—´å½’ä¸€åŒ–
            if self.latent_norm and self.latent_mean is not None:
                # ç¡®ä¿ç»´åº¦åŒ¹é…
                if latent.dim() == 3 and self.latent_mean.dim() == 4:
                    latent = latent.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
                latent = (latent - self.latent_mean) / self.latent_std
                if latent.dim() == 4 and latent.shape[0] == 1:
                    latent = latent.squeeze(0)  # ç§»é™¤ä¸´æ—¶batchç»´åº¦
        
        return latent, user_id


# ==================== è®­ç»ƒå‡½æ•° ====================
def train_dit():
    """ä¸»è®­ç»ƒå‡½æ•° - DataParallelæ¨¡å¼"""
    
    # è®¾å¤‡è®¾ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    logger.info(f"Using device: {device}")
    if torch.cuda.is_available():
        num_gpus = torch.cuda.device_count()
        logger.info(f"Available GPUs: {num_gpus}")
        for i in range(num_gpus):
            logger.info(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
            logger.info(f"  GPU Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB")
    
    # ===== 1. åˆå§‹åŒ–VA-VAEï¼ˆä»…ç”¨äºç¼–ç ï¼‰ =====
    logger.info("=== åˆå§‹åŒ–VA-VAEç¼–ç å™¨ ===")
    # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶ï¼Œè‡ªåŠ¨æ£€æµ‹VA-VAE checkpoint
    # ä½¿ç”¨æŒ‡å®šçš„VA-VAEæ¨¡å‹è·¯å¾„
    vae_checkpoint = "/kaggle/input/stage3/vavae-stage3-epoch26-val_rec_loss0.0000.ckpt"
    
    if Path(vae_checkpoint).exists():
        logger.info(f"âœ… æ‰¾åˆ°VA-VAEæ¨¡å‹: {vae_checkpoint}")
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        size_mb = Path(vae_checkpoint).stat().st_size / (1024 * 1024)
        logger.info(f"   æ¨¡å‹å¤§å°: {size_mb:.2f} MB")
    else:
        logger.error("âŒ æœªæ‰¾åˆ°VA-VAEæ¨¡å‹ï¼")
        logger.error(f"   è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨: {vae_checkpoint}")
        raise FileNotFoundError(f"VA-VAE checkpoint not found at {vae_checkpoint}")
    
    # åŠ è½½åŸå§‹é…ç½®å¹¶ä¿®æ”¹checkpointè·¯å¾„
    vae_config_path = project_root / 'LightningDiT' / 'tokenizer' / 'configs' / 'vavae_f16d32.yaml'
    vae_config = OmegaConf.load(str(vae_config_path))
    vae_config.ckpt_path = vae_checkpoint  # è®¾ç½®checkpointè·¯å¾„
    
    # ä¿å­˜ä¿®æ”¹åçš„é…ç½®åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_config_path = project_root / 'temp_vavae_config.yaml'
    OmegaConf.save(vae_config, str(temp_config_path))
    
    # ä½¿ç”¨ä¿®æ”¹åçš„é…ç½®åˆå§‹åŒ–VA-VAE
    vae = VA_VAE(
        config=str(temp_config_path),
        img_size=256,
        horizon_flip=0.0,  # è®­ç»ƒæ—¶ä¸éœ€è¦æ°´å¹³ç¿»è½¬ï¼ˆæ•°æ®å¢å¼ºå¯¹å¾®å¤šæ™®å‹’æ—¶é¢‘å›¾æ•ˆæœå¾ˆå·®ï¼‰
        fp16=True
    )
    
    # VA-VAEå·²ç»é€šè¿‡é…ç½®æ–‡ä»¶åŠ è½½äº†checkpoint
    if os.path.exists(vae_checkpoint):
        logger.info("âœ“ VA-VAE loaded successfully with checkpoint")
    else:
        logger.warning(f"âš ï¸ VA-VAE checkpoint not found at {vae_checkpoint}")
        logger.warning("Using randomly initialized weights")
    
    # VA-VAEçš„modelå·²ç»åœ¨åˆå§‹åŒ–æ—¶è°ƒç”¨äº†.cuda()ï¼Œä¸éœ€è¦.to(device)
    # vae.modelå·²ç»æ˜¯evalæ¨¡å¼
    
    # ===== 2. åˆå§‹åŒ–LightningDiT-Bæ¨¡å‹ =====
    logger.info("=== åˆå§‹åŒ–LightningDiT-B ===")
    latent_size = 16  # 256/16 = 16
    num_users = 31
    
    model = LightningDiT_models["LightningDiT-B/1"](
        input_size=latent_size,
        num_classes=num_users,
        use_qknorm=False,
        use_swiglu=True,
        use_rope=True,
        use_rmsnorm=True,
        wo_shift=False,
        in_channels=32  # VA-VAE f16d32
    )
    
    logger.info(f"Model: LightningDiT-B/1 (768-dim, 12 layers)")
    logger.info(f"Parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
    
    # ä½¿ç”¨æŒ‡å®šçš„LightningDiTæ¨¡å‹è·¯å¾„
    pretrained_xl = "/kaggle/working/VA-VAE/LightningDiT/models/lightningdit-xl-imagenet256-64ep.pt"
    pretrained_base = None
    
    # æ£€æŸ¥LightningDiTæ¨¡å‹æ˜¯å¦å­˜åœ¨
    if os.path.exists(pretrained_xl):
        logger.info(f"âœ… æ‰¾åˆ°LightningDiT-XLæ¨¡å‹: {pretrained_xl}")
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        size_gb = os.path.getsize(pretrained_xl) / (1024**3)
        logger.info(f"   æ¨¡å‹å¤§å°: {size_gb:.2f} GB")
        if size_gb < 5:
            logger.warning(f"   âš ï¸ æ¨¡å‹æ–‡ä»¶å¯èƒ½ä¸å®Œæ•´ï¼ˆé¢„æœŸçº¦10.8GBï¼‰")
    else:
        logger.error("âŒ æœªæ‰¾åˆ°LightningDiT-XLæ¨¡å‹ï¼")
        logger.error(f"   è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨: {pretrained_xl}")
        logger.error("   è¿è¡Œ python step2_download_models.py ä¸‹è½½æ¨¡å‹")
    
    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä¸‹è½½
    if pretrained_xl is None or not os.path.exists(pretrained_xl):
        logger.warning("æœªæ‰¾åˆ°LightningDiTæ¨¡å‹ï¼Œå°è¯•ä¸‹è½½...")
        import urllib.request
        # åˆ›å»ºæ¨¡å‹ç›®å½•
        os.makedirs('/kaggle/working/VA-VAE/LightningDiT/models', exist_ok=True)
        
        # ä¸‹è½½XLæ¨¡å‹
        xl_url = "https://huggingface.co/hustvl/lightningdit-xl-imagenet256-64ep/resolve/main/lightningdit-xl-imagenet256-64ep.pt"
        
        try:
            logger.info(f"ä» HuggingFace ä¸‹è½½LightningDiT-XLæ¨¡å‹...")
            logger.info(f"URL: {xl_url}")
            logger.info(f"ç›®æ ‡è·¯å¾„: {pretrained_xl}")
            urllib.request.urlretrieve(xl_url, pretrained_xl)
            logger.info(f"âœ… ä¸‹è½½å®Œæˆ")
            size_gb = os.path.getsize(pretrained_xl) / (1024**3)
            logger.info(f"   æ¨¡å‹å¤§å°: {size_gb:.2f} GB")
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            logger.error("è¯·æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æˆ–è¿è¡Œ step2_download_models.py")
    
    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    logger.info("\n" + "="*60)
    logger.info("ğŸ¯ åŠ è½½LightningDiTé¢„è®­ç»ƒæƒé‡")
    logger.info("="*60)
    
    if pretrained_xl and os.path.exists(pretrained_xl):
        logger.info(f"åŠ è½½XLæ¨¡å‹: {pretrained_xl}")
        checkpoint = torch.load(pretrained_xl, map_location='cpu')
        state_dict = checkpoint.get('model', checkpoint)
        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        
        # åªåŠ è½½å…¼å®¹çš„æƒé‡
        compatible = {}
        model_state = model.state_dict()
        for k, v in state_dict.items():
            if k in model_state and v.shape == model_state[k].shape:
                compatible[k] = v
        
        if compatible:
            model.load_state_dict(compatible, strict=False)
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(compatible)}/{len(state_dict)} ä¸ªæƒé‡")
            logger.info(f"   æ¨¡å‹æ€»å‚æ•°: {len(model_state)}")
            logger.info(f"   åŒ¹é…ç‡: {len(compatible)/len(model_state)*100:.1f}%")
        else:
            logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å…¼å®¹çš„æƒé‡ï¼")
    else:
        logger.error("\n" + "âŒ"*30)
        logger.error("âŒ ä¸¥é‡é”™è¯¯ï¼šæœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼")
        logger.error("âŒ æ¨¡å‹å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼Œè¿™ä¼šå¯¼è‡´ç”Ÿæˆçº¯å™ªå£°å›¾åƒã€‚")
        logger.error("âŒ"*30)
        logger.error("\nè¯·ç¡®ä¿ï¼š")
        logger.error(f"  1. LightningDiTæ¨¡å‹å­˜åœ¨äº: {pretrained_xl}")
        logger.error("  2. è¿è¡Œ step2_download_models.py ä¸‹è½½æ¨¡å‹")
        logger.error("  3. æˆ–ä» https://huggingface.co/hustvl/lightningdit-xl-imagenet256-64ep/ æ‰‹åŠ¨ä¸‹è½½")
        logger.error("\nè®­ç»ƒå°†ç«‹å³åœæ­¢ä»¥é¿å…æ—¶é—´æµªè´¹ï¼\n")
        raise ValueError("å¿…é¡»åŠ è½½é¢„è®­ç»ƒæƒé‡æ‰èƒ½æ­£å¸¸è®­ç»ƒï¼")
    
    model.to(device)
    
    # å¦‚æœæ˜¯å¤šGPUï¼Œä½¿ç”¨DataParallelåŒ…è£…
    num_gpus = torch.cuda.device_count()
    if num_gpus > 1:
        model = DataParallel(model)
        logger.info(f"Model wrapped with DataParallel using {num_gpus} GPUs")
    
    # åˆ›å»ºEMAæ¨¡å‹
    from copy import deepcopy
    ema_model = deepcopy(model.module if num_gpus > 1 else model).to(device)
    for p in ema_model.parameters():
        p.requires_grad = False
    
    # ===== 3. åˆ›å»ºTransportï¼ˆæ‰©æ•£è¿‡ç¨‹ï¼‰ =====
    transport = create_transport(
        path_type="Linear",
        prediction="velocity",
        loss_weight=None,
        train_eps=None,
        sample_eps=None,
        use_cosine_loss=True,  # å®˜æ–¹ä½¿ç”¨cosine loss
        use_lognorm=True  # å®˜æ–¹ä½¿ç”¨lognorm
    )
    
    # ===== 4. å‡†å¤‡æ•°æ®é›† =====
    if is_main_process():
        logger.info("=== å‡†å¤‡æ•°æ®é›† ===")
    
    # é¦–å…ˆå°è¯•ç”Ÿæˆæ½œç©ºé—´ï¼ˆå¦‚æœéœ€è¦ï¼‰
    # è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†è·¯å¾„
    possible_data_paths = [
        "/kaggle/input/dataset",  # æ ‡å‡†Kaggleè·¯å¾„
        "/kaggle/input/micro-doppler-data",  # æ›¿ä»£è·¯å¾„
        "./dataset",  # æœ¬åœ°è·¯å¾„
        "G:/micro-doppler-dataset"  # æœ¬åœ°æµ‹è¯•è·¯å¾„
    ]
    
    data_dir = None
    for path in possible_data_paths:
        if Path(path).exists():
            data_dir = Path(path)
            logger.info(f"æ‰¾åˆ°æ•°æ®é›†: {path}")
            break
    
    if data_dir is None:
        logger.error("æœªæ‰¾åˆ°æ•°æ®é›†ï¼è¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„:")
        for path in possible_data_paths:
            logger.error(f"  - {path}")
        raise FileNotFoundError("Dataset not found")
    latents_file = Path("/kaggle/working") / 'latents_microdoppler.npz'  # ä¿å­˜åˆ°å¯å†™ç›®å½•
    
    # åªåœ¨ä¸»è¿›ç¨‹ä¸­é¢„è®¡ç®—æ½œç©ºé—´ï¼Œé¿å…å¤šè¿›ç¨‹å†²çª
    if not latents_file.exists() and is_main_process():
        logger.info("é¢„è®¡ç®—æ½œç©ºé—´è¡¨ç¤º...")
        encode_dataset_to_latents(vae, data_dir, device)
        logger.info("æ½œç©ºé—´ç¼–ç å®Œæˆï¼Œç­‰å¾…æ–‡ä»¶å†™å…¥...")
        # ç¡®ä¿æ–‡ä»¶å·²å†™å…¥ç£ç›˜
        import time
        time.sleep(2)
    
    # DataParallelæ¨¡å¼ä¸éœ€è¦åŒæ­¥
    
    # åˆ›å»ºæ•°æ®é‡‡æ ·å™¨ï¼ˆåˆ†å¸ƒå¼ï¼‰
    train_dataset = MicroDopplerLatentDataset(data_dir, split='train')
    val_dataset = MicroDopplerLatentDataset(data_dir, split='val')
    
    # DataParallelæ¨¡å¼ä¸éœ€è¦ç‰¹æ®Šé‡‡æ ·å™¨
    train_sampler = None
    val_sampler = None
    
    # Kaggleç¯å¢ƒæ•°æ®åŠ è½½å™¨ä¼˜åŒ–
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],  # ä½¿ç”¨é…ç½®å€¼
        shuffle=(train_sampler is None),
        sampler=train_sampler,
        num_workers=1,  # Kaggleç¯å¢ƒå‡å°‘workeræ•°é‡
        pin_memory=True,
        persistent_workers=False,  # é¿å…Kaggleç¯å¢ƒä¸­çš„å†…å­˜é—®é¢˜
        prefetch_factor=1
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=4,
        shuffle=False,
        sampler=val_sampler,
        num_workers=1,  # ä¿æŒä¸€è‡´
        pin_memory=True,
        persistent_workers=False,
        prefetch_factor=1
    )
    
    # ===== 5. è®¾ç½®ä¼˜åŒ–å™¨ =====
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=5e-5,  # å¹³è¡¡ä¿æŠ¤å’Œå­¦ä¹ çš„å­¦ä¹ ç‡
        weight_decay=0.01,  # æ¢å¤é€‚åº¦æ­£åˆ™åŒ–
        betas=(0.9, 0.95)
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=35,  # å¯¹åº”æ–°çš„è½®æ•°
        eta_min=1e-7
    )
    
    # ===== 6. è®­ç»ƒå¾ªç¯ =====
    logger.info("=== å¼€å§‹è®­ç»ƒ ===")
    
    num_epochs = 35  # å…è®¸å……åˆ†å­¦ä¹ ï¼Œç”¨æ—©åœæ§åˆ¶
    best_val_loss = float('inf')
    patience = 8  # ç»™äºˆæ›´å¤šæ”¶æ•›æœºä¼š
    patience_counter = 0
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = torch.cuda.amp.GradScaler()
    
    for epoch in range(num_epochs):
        # DataParallelæ¨¡å¼ä¸éœ€è¦è®¾ç½®epoch
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        train_steps = 0
        
        # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]', disable=not is_main_process())
        for batch in pbar:
            latents = batch[0].to(device)
            user_ids = batch[1].to(device)
            
            # å‰å‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰
            with torch.cuda.amp.autocast():
                # Transportå†…éƒ¨è‡ªåŠ¨é‡‡æ ·æ—¶é—´
                model_kwargs = {"y": user_ids}
                # DataParallelæ—¶ä½¿ç”¨module
                dit_model = model.module if isinstance(model, DataParallel) else model
                loss_dict = transport.training_losses(dit_model, latents, model_kwargs)
                loss = loss_dict["loss"].mean()
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            scaler.scale(loss).backward()
            
            # æ¢¯åº¦è£å‰ª
            scaler.unscale_(optimizer)
            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip_norm'])
            
            scaler.step(optimizer)
            scaler.update()
            
            # å®šæœŸæ¸…ç†æ˜¾å­˜
            if batch_idx % 50 == 0:
                torch.cuda.empty_cache()
            
            # æ›´æ–°EMAï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
            if is_main_process():
                ema_decay = 0.9999
                model_params = model.module.parameters() if isinstance(model, DataParallel) else model.parameters()
                with torch.no_grad():
                    for ema_p, p in zip(ema_model.parameters(), model_params):
                        ema_p.data.mul_(ema_decay).add_(p.data, alpha=1-ema_decay)
            
            train_loss += loss.item()
            train_steps += 1
            
            if is_main_process():
                pbar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        avg_train_loss = train_loss / train_steps
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        val_steps = 0
        
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]', disable=not is_main_process())
            for batch in val_pbar:
                latents = batch[0].to(device)
                user_ids = batch[1].to(device)
                
                with torch.cuda.amp.autocast():
                    model_kwargs = {"y": user_ids}
                    dit_model = model.module if isinstance(model, DataParallel) else model
                    loss_dict = transport.training_losses(dit_model, latents, model_kwargs)
                    loss = loss_dict["loss"].mean()
                
                val_loss += loss.item()
                val_steps += 1
        
        avg_val_loss = val_loss / val_steps
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # åŒæ­¥æ‰€æœ‰è¿›ç¨‹çš„æŸå¤±ï¼ˆKaggleä¼˜åŒ–ï¼‰
        if world_size > 1:
            # ä½¿ç”¨æ›´å®‰å…¨çš„æŸå¤±åŒæ­¥æ–¹å¼
            train_loss_tensor = torch.tensor(avg_train_loss, device=device, dtype=torch.float32)
            val_loss_tensor = torch.tensor(avg_val_loss, device=device, dtype=torch.float32)
            
            try:
                dist.all_reduce(train_loss_tensor, op=dist.ReduceOp.AVG)
                dist.all_reduce(val_loss_tensor, op=dist.ReduceOp.AVG)
                avg_train_loss = train_loss_tensor.item()
                avg_val_loss = val_loss_tensor.item()
            except Exception as e:
                if is_main_process():
                    logger.warning(f"Loss synchronization failed: {e}, using local loss")
        
        # æ—¥å¿—è®°å½•ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
        if is_main_process():
            logger.info(f"Epoch {epoch+1}/{num_epochs}")
            logger.info(f"  Train Loss: {avg_train_loss:.4f}")
            logger.info(f"  Val Loss: {avg_val_loss:.4f}")
            logger.info(f"  LR: {scheduler.get_last_lr()[0]:.2e}")
        
        # æ—©åœæ£€æŸ¥ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
        should_stop = False
        if is_main_process():
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                patience_counter = 0
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                save_path = f"outputs/dit_best_epoch{epoch+1}_val{avg_val_loss:.4f}.pt"
                os.makedirs("outputs", exist_ok=True)
                model_state = model.module.state_dict() if isinstance(model, DataParallel) else model.state_dict()
                
                try:
                    torch.save({
                        'epoch': epoch,
                        'model_state_dict': model_state,
                        'ema_state_dict': ema_model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'scheduler_state_dict': scheduler.state_dict(),
                        'train_loss': avg_train_loss,
                        'val_loss': avg_val_loss,
                    }, save_path)
                    logger.info(f"  âœ“ Saved best model to {save_path}")
                except Exception as e:
                    logger.warning(f"Failed to save model: {e}")
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    logger.info(f"Early stopping triggered at epoch {epoch+1}")
                    should_stop = True
        
        # DataParallelæ¨¡å¼ä¸éœ€è¦åŒæ­¥æ—©åœå†³ç­–
        
        if should_stop:
            break
        
        # å®šæœŸç”Ÿæˆæ ·æœ¬ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
        if (epoch + 1) % 5 == 0 and is_main_process():
            logger.info("Generating samples...")
            generate_samples(ema_model, vae, transport, device, epoch+1)
        
        # å†…å­˜æ¸…ç†
        torch.cuda.empty_cache()
    
    if is_main_process():
        logger.info("=== è®­ç»ƒå®Œæˆ ===")
        logger.info(f"Best validation loss: {best_val_loss:.4f}")
    
    # DataParallelæ¨¡å¼ä¸éœ€è¦æ¸…ç†


def encode_dataset_to_latents(vae, data_dir, device, stats_path=None):
    """é¢„è®¡ç®—å¹¶ä¿å­˜æ•´ä¸ªæ•°æ®é›†çš„æ½œç©ºé—´è¡¨ç¤º"""
    logger.info("ç¼–ç æ•°æ®é›†åˆ°æ½œç©ºé—´...")
    
    latents_list = []
    user_ids_list = []
    
    # éå†æ‰€æœ‰ç”¨æˆ·æ–‡ä»¶å¤¹
    for user_dir in sorted(data_dir.glob('ID_*')):
        user_id = int(user_dir.name.split('_')[1]) - 1  # ID_1 -> 0
        
        # æ”¶é›†è¯¥ç”¨æˆ·çš„æ‰€æœ‰å›¾åƒï¼ˆä¿®æ­£ä¸º.jpgæ ¼å¼ï¼‰
        image_files = sorted(list(user_dir.glob('*.jpg')))
        
        if not image_files:
            logger.warning(f"ç”¨æˆ· {user_dir.name} æ²¡æœ‰æ‰¾åˆ°.jpgå›¾åƒæ–‡ä»¶")
            continue
            
        logger.info(f"ç¼–ç ç”¨æˆ· {user_dir.name}: {len(image_files)} å¼ å›¾åƒ")
        
        for img_path in image_files:
            # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
            image = Image.open(img_path).convert('RGB')
            image = torch.from_numpy(np.array(image)).float() / 127.5 - 1.0
            image = image.permute(2, 0, 1).unsqueeze(0).to(device)
            
            # ç¼–ç åˆ°æ½œç©ºé—´ - ä½¿ç”¨å®ä¾‹çš„encode_imagesæ–¹æ³•
            with torch.no_grad():
                latent = vae.encode_images(image)
            
            latents_list.append(latent.cpu().numpy())
            user_ids_list.append(user_id)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
    if not latents_list:
        logger.error("æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•æ½œç©ºé—´æ•°æ®ï¼")
        raise ValueError("No latent data collected")
    
    # ä¿å­˜æ½œç©ºé—´æ•°æ®
    latents = np.concatenate(latents_list, axis=0)
    user_ids = np.array(user_ids_list)
    
    logger.info(f"å‡†å¤‡ä¿å­˜ {len(latents)} ä¸ªæ½œç©ºé—´æ ·æœ¬")
    logger.info(f"æ½œç©ºé—´å½¢çŠ¶: {latents.shape}")
    logger.info(f"ç”¨æˆ·IDæ•°é‡: {len(user_ids)}, å”¯ä¸€ç”¨æˆ·: {len(np.unique(user_ids))}")
    
    # è®¡ç®—æ½œç©ºé—´ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
    mean = latents.mean(axis=(0, 2, 3), keepdims=True)  # [1, C, 1, 1]
    std = latents.std(axis=(0, 2, 3), keepdims=True)
    
    # ä¿å­˜åˆ°å¯å†™ç›®å½•
    save_path = Path("/kaggle/working") / 'latents_microdoppler.npz'
    stats_save_path = Path("/kaggle/working") / 'latents_stats.pt'
    
    np.savez(save_path, latents=latents, user_ids=user_ids, mean=mean, std=std)
    torch.save({'mean': torch.from_numpy(mean), 'std': torch.from_numpy(std)}, stats_save_path)
    
    logger.info(f"æˆåŠŸä¿å­˜æ½œç©ºé—´æ•°æ®åˆ° {save_path}")
    logger.info(f"æˆåŠŸä¿å­˜ç»Ÿè®¡ä¿¡æ¯åˆ° {stats_save_path}")
    logger.info(f"æ½œç©ºé—´å‡å€¼å½¢çŠ¶: {mean.shape}, æ ‡å‡†å·®å½¢çŠ¶: {std.shape}")
    
    # éªŒè¯ä¿å­˜
    test_data = np.load(save_path)
    logger.info(f"éªŒè¯: åŠ è½½äº† {len(test_data['latents'])} ä¸ªæ ·æœ¬")


def get_training_config():
    """è·å–å¾®è°ƒè®­ç»ƒé…ç½® - é’ˆå¯¹å¾®å¤šæ™®å‹’ç»†å¾®ç‰¹å¾å­¦ä¹ ä¼˜åŒ–"""
    return {
        'batch_size': 8,           # å¢å¤§batchæé«˜ç¨³å®šæ€§
        'gradient_accumulation_steps': 2,  # æ¨¡æ‹Ÿæ›´å¤§batch=16
        'num_epochs': 50,          # å»¶é•¿è®­ç»ƒä»¥å……åˆ†åˆ©ç”¨VA-VAEè¯­ä¹‰ç©ºé—´
        'learning_rate': 3e-5,      # å¹³è¡¡å­¦ä¹ é€Ÿåº¦ä¸ç¨³å®šæ€§
        'weight_decay': 0.005,      # é€‚åº¦æ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
        'num_workers': 1,          # Kaggleç¯å¢ƒä¼˜åŒ–
        'gradient_accumulation_steps': 4,  # æ¨¡æ‹Ÿæ›´å¤§batch
        'gradient_clip_norm': 2.0, # ç•¥æ”¾å®½ä»¥å…è®¸æ›´å¤§æ¢¯åº¦æ›´æ–°
        'warmup_steps': 1000,      # é‡‡æ ·é…ç½® - å¯¹é½å®˜æ–¹LightningDiTé…ç½®
        'gradient_checkpointing': True,  # æ˜¾å­˜ä¼˜åŒ–
        'cfg_dropout': 0.15,       # å¢å¼ºæ— æ¡ä»¶å­¦ä¹ 
        'cfg_scale': 7.0,         # é€‚åº¦CFGï¼Œä¿ç•™æ›´å¤šç»†èŠ‚
        'ema_decay': 0.9995,       # å¹³è¡¡ç¨³å®šæ€§ä¸å“åº”é€Ÿåº¦
        'sample_steps': 150,       # é‡‡æ ·æ­¥æ•°
        'patience': 10,            # æ—©åœè€å¿ƒå€¼
        'sampling_method': 'dopri5',  # 5é˜¶è‡ªé€‚åº”RKï¼Œæ›´ç²¾ç¡®
        'num_steps': 150,  # è¾ƒå°‘æ­¥æ•°å³å¯è¾¾åˆ°é«˜è´¨é‡
        'cfg_interval_start': 0.11,  # ä¿æŒå®˜æ–¹è®¾ç½®
        'timestep_shift': 0.15,  # å¹³è¡¡ç¨³å®šæ€§å’Œç»†èŠ‚ï¼šè·³è¿‡15%é«˜å™ªå£°ï¼Œä¿ç•™85%å»å™ªè¿‡ç¨‹
    }


def print_training_config(model, optimizer, scheduler, config, 
                         train_size, val_size, num_gpus, train_dataset=None):
    """è¾“å‡ºè¯¦ç»†çš„è®­ç»ƒé…ç½®ä¿¡æ¯"""
    
    # è®¡ç®—æ¨¡å‹å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    # è·å–æ¨¡å‹é…ç½®
    if hasattr(model, 'module'):  # DDP wrapped
        model_config = model.module
    else:
        model_config = model
    
    # åŠ¨æ€è·å–ç”¨æˆ·ç±»åˆ«æ•°
    num_classes = 31  # é»˜è®¤å€¼
    if train_dataset is not None:
        try:
            # å°è¯•ä»æ•°æ®é›†è·å–ç”¨æˆ·æ•°é‡
            if hasattr(train_dataset, 'user_ids'):
                num_classes = len(torch.unique(train_dataset.user_ids))
            elif hasattr(train_dataset, 'num_classes'):
                num_classes = train_dataset.num_classes
        except:
            pass  # ä½¿ç”¨é»˜è®¤å€¼
    
    print("\n" + "="*80)
    print("ğŸš€ DiTå¾®è°ƒè®­ç»ƒé…ç½®")
    print("="*80)
    
    print(f"ğŸ“Š æ•°æ®é…ç½®:")
    print(f"  è®­ç»ƒæ ·æœ¬æ•°: {train_size:,}")
    print(f"  éªŒè¯æ ·æœ¬æ•°: {val_size:,}")
    print(f"  æ¯GPUæ‰¹é‡å¤§å°: {config['batch_size']}")
    print(f"  æ€»æ‰¹é‡å¤§å°: {config['batch_size'] * num_gpus}")
    print(f"  ç”¨æˆ·ç±»åˆ«æ•°: {num_classes}")
    
    # åŠ¨æ€è·å–æ¨¡å‹ä¿¡æ¯
    model_type = getattr(model_config, '__class__', type(model_config)).__name__
    input_channels = getattr(model_config, 'in_channels', 'Unknown')
    input_size = getattr(model_config, 'input_size', 'Unknown')
    
    print(f"\nğŸ—ï¸  æ¨¡å‹é…ç½®:")
    print(f"  æ¨¡å‹ç±»å‹: {model_type}")
    if input_size != 'Unknown':
        print(f"  è¾“å…¥å°ºå¯¸: {input_size}Ã—{input_size} (æ½œç©ºé—´)")
    else:
        print(f"  è¾“å…¥å°ºå¯¸: æ¨æ–­ä¸º16Ã—16 (æ½œç©ºé—´)")
    print(f"  è¾“å…¥é€šé“: {input_channels}")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    if hasattr(model_config, 'depth'):
        print(f"  Transformerå±‚æ•°: {model_config.depth}")
    if hasattr(model_config, 'hidden_size'):
        print(f"  éšè—å±‚ç»´åº¦: {model_config.hidden_size}")
    if hasattr(model_config, 'num_heads'):
        print(f"  æ³¨æ„åŠ›å¤´æ•°: {model_config.num_heads}")
    
    print(f"\nâš™ï¸  è®­ç»ƒé…ç½®:")
    print(f"  è®­ç»ƒè½®æ•°: {config['num_epochs']}")
    print(f"  ä¼˜åŒ–å™¨: {optimizer.__class__.__name__}")
    print(f"  å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.2e}")
    print(f"  æƒé‡è¡°å‡: {optimizer.param_groups[0]['weight_decay']:.2e}")
    print(f"  æ¢¯åº¦è£å‰ª: {config['gradient_clip_norm']}")
    print(f"  æ•°æ®åŠ è½½å™¨workeræ•°: {config['num_workers']}")
    print(f"  è°ƒåº¦å™¨: {scheduler.__class__.__name__}")
    print(f"  æ··åˆç²¾åº¦: å¯ç”¨")
    
    print(f"\nğŸ”§ ç¡¬ä»¶é…ç½®:")
    print(f"  GPUæ•°é‡: {num_gpus}")
    print(f"  å¹¶è¡Œæ–¹å¼: {'DataParallel' if num_gpus > 1 else 'Single GPU'}")
    
    print(f"\nğŸ“ˆ è¯„ä¼°æŒ‡æ ‡:")
    print(f"  â€¢ è®­ç»ƒ/éªŒè¯æŸå¤±")
    print(f"  â€¢ æ¢¯åº¦èŒƒæ•°")
    print(f"  â€¢ å­¦ä¹ ç‡å˜åŒ–")
    print(f"  â€¢ æ¯ç§’å¤„ç†æ ·æœ¬æ•°")
    print(f"  â€¢ GPUå†…å­˜ä½¿ç”¨ç‡")
    
    print("="*80 + "\n")


def calculate_metrics(model, loss, optimizer):
    """è®¡ç®—è®­ç»ƒè´¨é‡è¯„ä¼°æŒ‡æ ‡"""
    metrics = {}
    
    # åŸºç¡€æŸå¤±
    metrics['loss'] = loss.item()
    
    # æ¢¯åº¦èŒƒæ•°
    total_norm = 0
    param_count = 0
    for p in model.parameters():
        if p.grad is not None:
            param_norm = p.grad.data.norm(2)
            total_norm += param_norm.item() ** 2
            param_count += 1
    
    if param_count > 0:
        metrics['grad_norm'] = total_norm ** (1. / 2)
    else:
        metrics['grad_norm'] = 0.0
    
    # å­¦ä¹ ç‡
    metrics['lr'] = optimizer.param_groups[0]['lr']
    
    return metrics


def train_dit_kaggle():
    """Kaggleç¯å¢ƒä¸‹çš„DiTå¾®è°ƒè®­ç»ƒ - ä½¿ç”¨DataParallel"""
    logger.info("å¼€å§‹Kaggle DiTå¾®è°ƒè®­ç»ƒ...")
    
    # æ£€æŸ¥GPUçŠ¶æ€
    if not torch.cuda.is_available():
        raise RuntimeError("éœ€è¦GPUè¿›è¡Œè®­ç»ƒ")
    
    # æ£€æµ‹GPUæ•°é‡
    n_gpus = torch.cuda.device_count()
    logger.info(f"æ£€æµ‹åˆ° {n_gpus} ä¸ªGPU")
    
    # è¯¦ç»†GPUä¿¡æ¯
    for i in range(n_gpus):
        props = torch.cuda.get_device_properties(i)
        logger.info(f"GPU {i}: {props.name}, æ˜¾å­˜: {props.total_memory / 1024**3:.1f}GB")
        torch.cuda.set_device(i)
        torch.cuda.empty_cache()
    
    # é¢„å¤„ç†ï¼šç¡®ä¿æ½œç©ºé—´æ•°æ®å‡†å¤‡å¥½
    latents_file = Path("/kaggle/working") / 'latents_microdoppler.npz'
    if not latents_file.exists():
        logger.info("é¢„è®¡ç®—æ½œç©ºé—´æ•°æ®...")
        prepare_latents_for_training()
        logger.info("æ½œç©ºé—´é¢„è®¡ç®—å®Œæˆ")
    
    # ç›´æ¥ä½¿ç”¨DataParallelè®­ç»ƒï¼Œé¿å…DDPçš„å¤æ‚æ€§
    train_with_dataparallel(n_gpus)


def train_with_dataparallel(n_gpus):
    """ä½¿ç”¨DataParallelè¿›è¡Œè®­ç»ƒ"""
    # è·å–è®­ç»ƒé…ç½®
    config = get_training_config()
    
    # è®¾ç½®ä¸»è®¾å¤‡
    device = torch.device('cuda:0')
    torch.cuda.set_device(0)
    
    # æ¸…ç†æ˜¾å­˜
    for i in range(n_gpus):
        torch.cuda.set_device(i)
        torch.cuda.empty_cache()
    torch.cuda.set_device(0)
    
    # åˆå§‹åŒ–VA-VAEç”¨äºæ ·æœ¬ç”Ÿæˆï¼ˆä»…åœ¨éœ€è¦æ—¶ä½¿ç”¨ï¼‰
    vae = None
    
    # åŠ è½½é…ç½®
    config_path = Path("../configs/microdoppler_finetune.yaml")
    model_config = OmegaConf.load(config_path).model
    
    # ä»é…ç½®æ–‡ä»¶è·å–æ½œç©ºé—´ä¿¡æ¯
    H_latent = model_config.params.latent_size
    W_latent = model_config.params.latent_size  
    C_latent = model_config.params.in_channels
    
    logger.info(f"æ½œç©ºé—´ç»´åº¦: {H_latent}x{W_latent}x{C_latent}")
    
    # è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†è·¯å¾„
    possible_data_paths = [
        "/kaggle/input/dataset",  # æ ‡å‡†Kaggleè·¯å¾„
        "/kaggle/input/micro-doppler-data",  # æ›¿ä»£è·¯å¾„
        "/kaggle/working/dataset",  # å·¥ä½œç›®å½•
        "./dataset",  # æœ¬åœ°è·¯å¾„
    ]
    
    data_dir = None
    for path in possible_data_paths:
        if Path(path).exists():
            data_dir = Path(path)
            logger.info(f"æ‰¾åˆ°æ•°æ®é›†: {path}")
            break
    
    if data_dir is None:
        logger.error("æœªæ‰¾åˆ°æ•°æ®é›†ï¼è¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„:")
        for path in possible_data_paths:
            logger.error(f"  - {path}")
        raise FileNotFoundError("Dataset not found")
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = MicroDopplerLatentDataset(
        data_dir=str(data_dir),
        split='train'
    )
    
    val_dataset = MicroDopplerLatentDataset(
        data_dir=str(data_dir), 
        split='val'
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'] * n_gpus,  # æ€»batch size
        shuffle=True,
        num_workers=config['num_workers'],
        pin_memory=True,
        drop_last=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'] * n_gpus,
        shuffle=False,
        num_workers=config['num_workers'],
        pin_memory=True
    )
    
    # ===== æ¨¡å‹åŠ è½½æ£€æŸ¥ =====
    logger.info("\n" + "="*60)
    logger.info("ğŸ” æ¨¡å‹åŠ è½½çŠ¶æ€æ£€æŸ¥")
    logger.info("="*60)
    
    # æ£€æŸ¥LightningDiTæ¨¡å‹
    pretrained_xl = "/kaggle/working/VA-VAE/LightningDiT/models/lightningdit-xl-imagenet256-64ep.pt"
    if os.path.exists(pretrained_xl):
        logger.info(f"âœ… æ‰¾åˆ°LightningDiT-XLæ¨¡å‹: {pretrained_xl}")
        size_gb = os.path.getsize(pretrained_xl) / (1024**3)
        logger.info(f"   æ¨¡å‹å¤§å°: {size_gb:.2f} GB")
        if size_gb < 5:
            logger.warning(f"   âš ï¸ æ¨¡å‹æ–‡ä»¶å¯èƒ½ä¸å®Œæ•´ï¼ˆé¢„æœŸçº¦10.8GBï¼‰")
    else:
        logger.error("âŒ æœªæ‰¾åˆ°LightningDiT-XLæ¨¡å‹ï¼")
        logger.error(f"   è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨: {pretrained_xl}")
        logger.error("   è¿è¡Œ python step2_download_models.py ä¸‹è½½æ¨¡å‹")
        
    # æ£€æŸ¥VA-VAEæ¨¡å‹
    vae_checkpoint = "/kaggle/input/stage3/vavae-stage3-epoch26-val_rec_loss0.0000.ckpt"
    if os.path.exists(vae_checkpoint):
        logger.info(f"âœ… æ‰¾åˆ°VA-VAEæ¨¡å‹: {vae_checkpoint}")
        size_mb = os.path.getsize(vae_checkpoint) / (1024 * 1024)
        logger.info(f"   æ¨¡å‹å¤§å°: {size_mb:.2f} MB")
    else:
        logger.error("âŒ æœªæ‰¾åˆ°VA-VAEæ¨¡å‹ï¼")
        logger.error(f"   è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨: {vae_checkpoint}")
    
    # åˆ›å»ºæ¨¡å‹ - ä½¿ç”¨Bæ¨¡å‹ä»¥é€‚é…T4æ˜¾å­˜
    logger.info("\nğŸ—ï¸ åˆ›å»ºLightningDiT-Bæ¨¡å‹...")
    model = LightningDiT_B_1(
        input_size=H_latent,
        in_channels=C_latent,
        num_classes=31,  # 31ä¸ªç”¨æˆ·ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨æ·»åŠ CFG token
        use_qknorm=False,
        use_swiglu=True,  
        use_rope=True,
        use_rmsnorm=True
    ).to(device)
    
    logger.info(f"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ")
    logger.info(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
    
    # DataParallelåŒ…è£…
    if n_gpus > 1:
        logger.info(f"ğŸ”— ä½¿ç”¨ DataParallel åœ¨ {n_gpus} ä¸ªGPUä¸Šè®­ç»ƒ")
        model = nn.DataParallel(model, device_ids=list(range(n_gpus)))
    
    # åˆ›å»ºEMAæ¨¡å‹ - ç”¨äºç¨³å®šç”Ÿæˆè´¨é‡
    from copy import deepcopy
    ema_model = deepcopy(model).eval()
    for param in ema_model.parameters():
        param.requires_grad = False
    logger.info("EMAæ¨¡å‹å·²åˆ›å»ºï¼ˆè¡°å‡ç‡=0.9999ï¼‰")
    
    # åˆ›å»ºtransport
    transport = create_transport(
        'Linear',
        'velocity',
        None,
        None,
        None,
    )
    
    # ä¼˜åŒ–å™¨ - æŒ‰å®˜æ–¹æ¨èé…ç½®
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config['learning_rate'],
        weight_decay=config['weight_decay'],
        betas=(0.9, 0.95),  # å®˜æ–¹é…ç½®ï¼šbeta2=0.95
        eps=1e-8
    )
    
    # ä½¿ç”¨ä½™å¼¦é€€ç«+é¢„çƒ­ï¼Œé¿å…æ—©æœŸå­¦ä¹ ç‡è¿‡é«˜
    from torch.optim.lr_scheduler import LambdaLR
    
    def lr_lambda(current_step):
        warmup_steps = config.get('warmup_steps', 500)  # é€‚åº¦é¢„çƒ­æœŸ
        if current_step < warmup_steps:
            # çº¿æ€§é¢„çƒ­
            return float(current_step) / float(max(1, warmup_steps))
        # ä½™å¼¦é€€ç«ï¼Œæœ€ä½ä¿ç•™å­¦ä¹ ç‡
        total_steps = config['num_epochs'] * len(train_loader)
        progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))
        return max(0.01, 0.5 * (1.0 + torch.cos(torch.tensor(progress * 3.14159))))  # æœ€ä½1%
    
    scheduler = LambdaLR(optimizer, lr_lambda)
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = torch.cuda.amp.GradScaler(init_scale=65536.0, growth_interval=2000)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print_training_config(model, optimizer, scheduler, config, 
                         len(train_dataset), len(val_dataset), n_gpus, train_dataset)
    
    # è®­ç»ƒå¾ªç¯
    best_val_loss = float('inf')
    train_metrics_history = []
    val_metrics_history = []
    
    for epoch in range(config['num_epochs']):
        epoch_start_time = time.time()
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        train_steps = 0
        train_grad_norm = 0
        train_samples = 0
        
        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config["num_epochs"]} [Train]')
        
        for batch_idx, batch in enumerate(pbar):
            batch_start_time = time.time()
            latents = batch[0].to(device)
            user_ids = batch[1].to(device)
            
            # å‰å‘ä¼ æ’­ - æ·»åŠ CFGè®­ç»ƒ(10%æ— æ¡ä»¶)
            with torch.cuda.amp.autocast():
                # CFGè®­ç»ƒï¼š15%æ¦‚ç‡ä¸¢å¼ƒæ¡ä»¶ï¼ˆå¢å¼ºæ— æ¡ä»¶å­¦ä¹ ï¼‰
                # æ³¨æ„ï¼šä¸éœ€è¦æ‰‹åŠ¨è®¾ç½®null tokenï¼ŒLabelEmbedderä¼šè‡ªåŠ¨å¤„ç†
                # å½“dropoutæ—¶ï¼Œæ¨¡å‹å†…éƒ¨ä¼šä½¿ç”¨num_classes(31)ä½œä¸ºnull token
                model_kwargs = {"y": user_ids}
                
                # ä½¿ç”¨é‡è¦æ€§é‡‡æ ·
                t = torch.rand(latents.shape[0], device=device)
                
                loss_dict = transport.training_losses(model, latents, model_kwargs)
                loss = loss_dict["loss"].mean()
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            
            # æ¢¯åº¦è£å‰ª
            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip_norm'])
            
            scaler.step(optimizer)
            scaler.update()
            
            # å®šæœŸæ¸…ç†æ˜¾å­˜
            if batch_idx % 50 == 0:
                torch.cuda.empty_cache()
            
            # ç»Ÿè®¡
            train_loss += loss.item()
            train_grad_norm += grad_norm.item() if hasattr(grad_norm, 'item') else grad_norm
            train_steps += 1
            train_samples += latents.size(0)
            
            # æ›´æ–°è¿›åº¦æ¡
            current_lr = optimizer.param_groups[0]['lr']
            samples_per_sec = latents.size(0) / (time.time() - batch_start_time)
            current_memory = torch.cuda.max_memory_allocated(0) / 1024**3
            
            pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'lr': f'{current_lr:.2e}',
                'grad': f'{grad_norm:.2f}',
                'sps': f'{samples_per_sec:.1f}',
                'mem': f'{current_memory:.1f}GB'
            })
            
            scheduler.step()
        
        # è®­ç»ƒé˜¶æ®µç»Ÿè®¡
        avg_train_loss = train_loss / train_steps
        avg_train_grad_norm = train_grad_norm / train_steps
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        val_steps = 0
        
        with tqdm(val_loader, desc=f"Epoch {epoch+1}/{config['num_epochs']} [Val]") as pbar:
            for batch in pbar:
                latents = batch[0].to(device)
                user_ids = batch[1].to(device)
                
                with torch.no_grad():
                    # ä¼ é€’æ¡ä»¶ä¿¡æ¯
                    model_kwargs = {"y": user_ids}
                    loss_dict = transport.training_losses(model, latents, model_kwargs)
                    loss = loss_dict["loss"].mean()
                
                val_loss += loss.item()
                val_steps += 1
                
                pbar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        avg_val_loss = val_loss / val_steps
        
        # ç¡®ä¿è¿›åº¦æ¡å®Œå…¨ç»“æŸåå†è¾“å‡ºæ—¥å¿—
        print()  # æ·»åŠ ç©ºè¡Œç¡®ä¿tqdmè¿›åº¦æ¡ç»“æŸ
        
        # è®°å½•æŒ‡æ ‡
        train_metrics_history.append({
            'epoch': epoch + 1,
            'loss': avg_train_loss,
            'grad_norm': avg_train_grad_norm,
            'lr': current_lr
        })
        
        val_metrics_history.append({
            'epoch': epoch + 1,
            'loss': avg_val_loss
        })
        
        # è¯¦ç»†è®­ç»ƒæŠ¥å‘Š - ä½¿ç”¨printç¡®ä¿è¾“å‡º
        print("\n" + "="*80)
        print(f"ğŸ“Š Epoch {epoch+1}/{config['num_epochs']} è®­ç»ƒæŠ¥å‘Š")
        print("="*80)
        
        # è®­ç»ƒç»Ÿè®¡
        print("\nğŸ“ˆ è®­ç»ƒé˜¶æ®µç»Ÿè®¡:")
        print(f"  â€¢ å¹³å‡æŸå¤±: {avg_train_loss:.6f}")
        print(f"  â€¢ æ¢¯åº¦èŒƒæ•°: {avg_train_grad_norm:.4f}")
        print(f"  â€¢ å­¦ä¹ ç‡: {current_lr:.2e}")
        print(f"  â€¢ è®­ç»ƒæ ·æœ¬æ•°: {train_samples}")
        print(f"  â€¢ æ¯ç§’æ ·æœ¬æ•°: {train_samples / (time.time() - epoch_start_time):.1f}")
        
        # éªŒè¯ç»Ÿè®¡
        print("\nğŸ“‰ éªŒè¯é˜¶æ®µç»Ÿè®¡:")
        print(f"  â€¢ å¹³å‡æŸå¤±: {avg_val_loss:.6f}")
        print(f"  â€¢ ç›¸å¯¹æ”¹å–„: {((best_val_loss - avg_val_loss) / best_val_loss * 100):.2f}%" if best_val_loss != float('inf') else "N/A")
        
        # GPUä½¿ç”¨æƒ…å†µ
        print("\nğŸ–¥ï¸ GPUèµ„æºä½¿ç”¨:")
        for i in range(n_gpus):
            mem_allocated = torch.cuda.memory_allocated(i) / 1024**3
            mem_reserved = torch.cuda.memory_reserved(i) / 1024**3
            print(f"  GPU {i}:")
            print(f"    â€¢ å·²åˆ†é…å†…å­˜: {mem_allocated:.2f}GB")
            print(f"    â€¢ å·²é¢„ç•™å†…å­˜: {mem_reserved:.2f}GB")
            print(f"    â€¢ åˆ©ç”¨ç‡: {(mem_allocated/mem_reserved*100):.1f}%" if mem_reserved > 0 else "N/A")
        
        # æ¡ä»¶ä¿¡æ¯éªŒè¯
        print("\nâœ… æ¡ä»¶æ³¨å…¥éªŒè¯:")
        print(f"  â€¢ ç”¨æˆ·ç±»åˆ«æ•°: {31}")
        # LabelEmbedderä½¿ç”¨embedding_tableè€Œéembedding_dim
        actual_model = model.module if hasattr(model, 'module') else model
        if hasattr(actual_model, 'y_embedder') and hasattr(actual_model.y_embedder, 'embedding_table'):
            embed_dim = actual_model.y_embedder.embedding_table.embedding_dim
            num_classes = actual_model.y_embedder.embedding_table.num_embeddings
            print(f"  â€¢ æ¡ä»¶åµŒå…¥ç»´åº¦: {embed_dim}")
            print(f"  â€¢ æ”¯æŒçš„ç±»åˆ«æ•°: {num_classes}")
        print(f"  â€¢ æ¡ä»¶ä¿¡æ¯å·²æ­£ç¡®ä¼ é€’åˆ°æ¨¡å‹")
        
        print("="*80)
        
        # æ¯ä¸ªepochè¾“å‡ºè¯¦ç»†è®­ç»ƒè´¨é‡æŠ¥å‘Š
        print("\n" + "="*80)
        print("ğŸ” è®­ç»ƒè´¨é‡åˆ†æ")
        print("="*80)
        
        # æŸå¤±è¶‹åŠ¿åˆ†æ
        if epoch > 0:
            train_loss_change = avg_train_loss - train_metrics_history[-2]['loss'] if len(train_metrics_history) > 1 else 0
            val_loss_change = avg_val_loss - val_metrics_history[-2]['loss'] if len(val_metrics_history) > 1 else 0
            
            print("\nğŸ“‰ æŸå¤±è¶‹åŠ¿:")
            if len(train_metrics_history) > 1:
                print(f"  â€¢ è®­ç»ƒæŸå¤±å˜åŒ–: {train_loss_change:+.6f} ({(train_loss_change/train_metrics_history[-2]['loss']*100):+.2f}%)")
            else:
                print("  â€¢ è®­ç»ƒæŸå¤±å˜åŒ–: N/A")
            if len(val_metrics_history) > 1:
                print(f"  â€¢ éªŒè¯æŸå¤±å˜åŒ–: {val_loss_change:+.6f} ({(val_loss_change/val_metrics_history[-2]['loss']*100):+.2f}%)")
            else:
                print("  â€¢ éªŒè¯æŸå¤±å˜åŒ–: N/A")
            
            # è¿‡æ‹Ÿåˆæ£€æµ‹
            overfit_gap = avg_val_loss - avg_train_loss
            print("\nâš ï¸ è¿‡æ‹Ÿåˆæ£€æµ‹:")
            print(f"  â€¢ éªŒè¯-è®­ç»ƒæŸå¤±å·®: {overfit_gap:.6f}")
            if overfit_gap > 0.1:
                print("  â€¢ è­¦å‘Š: å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆï¼ŒéªŒè¯æŸå¤±æ˜¾è‘—é«˜äºè®­ç»ƒæŸå¤±")
            elif overfit_gap < -0.05:
                print("  â€¢ æ³¨æ„: éªŒè¯æŸå¤±ä½äºè®­ç»ƒæŸå¤±ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®æ³„éœ²æˆ–è¯„ä¼°é—®é¢˜")
            else:
                print("  â€¢ çŠ¶æ€: æ­£å¸¸ï¼Œæ— æ˜æ˜¾è¿‡æ‹Ÿåˆ")
        
        # è®­ç»ƒç¨³å®šæ€§åˆ†æ
        print("\nâš¡ è®­ç»ƒç¨³å®šæ€§:")
        if avg_train_grad_norm > 10:
            print(f"  â€¢ è­¦å‘Š: æ¢¯åº¦èŒƒæ•°è¿‡å¤§ ({avg_train_grad_norm:.2f})ï¼Œå¯èƒ½éœ€è¦é™ä½å­¦ä¹ ç‡")
        elif avg_train_grad_norm < 0.01:
            print(f"  â€¢ è­¦å‘Š: æ¢¯åº¦èŒƒæ•°è¿‡å° ({avg_train_grad_norm:.4f})ï¼Œå¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜")
        else:
            print(f"  â€¢ æ¢¯åº¦èŒƒæ•°æ­£å¸¸: {avg_train_grad_norm:.4f}")
        
        # æ”¶æ•›çŠ¶æ€åˆ¤æ–­
        print("\nğŸ¯ æ”¶æ•›çŠ¶æ€:")
        if epoch >= 4:  # è‡³å°‘5ä¸ªepochååˆ¤æ–­
            recent_val_losses = [m['loss'] for m in val_metrics_history[-5:]]
            val_std = np.std(recent_val_losses)
            print(f"  â€¢ æœ€è¿‘5è½®éªŒè¯æŸå¤±æ ‡å‡†å·®: {val_std:.6f}")
            if val_std < 0.001:
                print("  â€¢ æ¨¡å‹å¯èƒ½å·²æ”¶æ•›")
            elif val_std < 0.01:
                print("  â€¢ æ¨¡å‹æ¥è¿‘æ”¶æ•›")
            else:
                print("  â€¢ æ¨¡å‹ä»åœ¨ä¼˜åŒ–ä¸­")
        
        if avg_val_loss < 0.4:
            print("  ğŸ“ˆ æ¨¡å‹è¡¨ç°ï¼šä¼˜ç§€ï¼ˆæŸå¤± < 0.4ï¼‰")
        elif avg_val_loss < 0.6:
            print("  ğŸ“Š æ¨¡å‹è¡¨ç°ï¼šè‰¯å¥½ï¼ˆæŸå¤± < 0.6ï¼‰")
        elif avg_val_loss < 0.8:
            print("  âš ï¸ æ¨¡å‹è¡¨ç°ï¼šä¸€èˆ¬ï¼ˆæŸå¤± < 0.8ï¼‰")
        else:
            print("  âŒ æ¨¡å‹è¡¨ç°ï¼šè¾ƒå·®ï¼ˆæŸå¤± >= 0.8ï¼Œéœ€è¦ç»§ç»­è®­ç»ƒï¼‰")
        
        print("="*80)
        
        # æ¯ä¸ªepochç”Ÿæˆæ¡ä»¶æ‰©æ•£æ ·æœ¬
        if True:  # æ¯ä¸ªepochéƒ½ç”Ÿæˆå¯è§†åŒ–å›¾åƒ
            print("\n" + "="*80)
            print(f"ğŸ¨ Epoch {epoch + 1}: ç”Ÿæˆæ¡ä»¶æ‰©æ•£æ ·æœ¬ï¼ˆä½¿ç”¨å¾®è°ƒåçš„VA-VAEï¼‰...")
            print("="*80)
            
            try:
                # å»¶è¿Ÿåˆå§‹åŒ–VAEä»¥èŠ‚çœå†…å­˜
                if vae is None:
                    print("  â€¢ åˆå§‹åŒ–VA-VAEç”¨äºæ ·æœ¬è§£ç ...")
                    from tokenizer.vavae import VA_VAE
                    # ä½¿ç”¨å¾®è°ƒå¥½çš„VA-VAEæ¨¡å‹
                    vae_config_path = Path("/kaggle/working/VA-VAE/LightningDiT/tokenizer/configs/vavae_f16d32.yaml")
                    vae_config = OmegaConf.load(str(vae_config_path))
                    # ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹åˆ°çš„VA-VAEæ¨¡å‹
                    vae_config.ckpt_path = vae_checkpoint
                    temp_config_path = Path("/kaggle/working/temp_vae_config.yaml")
                    OmegaConf.save(vae_config, str(temp_config_path))
                    vae = VA_VAE(str(temp_config_path), img_size=256, horizon_flip=False, fp16=True)
                    print("  â€¢ VA-VAEåˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨Stage 3å¾®è°ƒæ¨¡å‹ï¼‰")
                
                # ä½¿ç”¨EMAæ¨¡å‹ç”Ÿæˆæ ·æœ¬ï¼ˆè´¨é‡æ›´å¥½ï¼‰
                generate_conditional_samples(ema_model, vae, transport, device, epoch+1, n_gpus, config)
                print("  â€¢ æ¡ä»¶æ ·æœ¬ç”Ÿæˆå®Œæˆ\n")
            except Exception as e:
                print(f"  âš ï¸ æ¡ä»¶æ ·æœ¬ç”Ÿæˆå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            
            # åˆ é™¤æ—§çš„æœ€ä½³æ¨¡å‹ä»¥èŠ‚çº¦ç©ºé—´
            old_best_models = list(Path("/kaggle/working").glob("best_dit_epoch_*.pt"))
            for old_model in old_best_models:
                try:
                    old_model.unlink()
                    logger.info(f"  â€¢ åˆ é™¤æ—§æ¨¡å‹: {old_model.name}")
                except Exception as e:
                    logger.warning(f"  â€¢ æ— æ³•åˆ é™¤æ—§æ¨¡å‹ {old_model.name}: {e}")
            
            # ä¿å­˜æ–°çš„æœ€ä½³æ¨¡å‹
            best_model_path = Path("/kaggle/working") / f"best_dit_epoch_{epoch+1}.pt"
            model_state = model.module.state_dict() if n_gpus > 1 else model.state_dict()
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model_state,
                'ema_state_dict': ema_model.state_dict() if 'ema_model' in locals() else None,
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'val_loss': avg_val_loss,
                'config': config
            }, best_model_path)
            logger.info(f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹åˆ° {best_model_path} (val_loss: {avg_val_loss:.6f})")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = Path("/kaggle/working") / "final_dit_model.pt"
    model_state = model.module.state_dict() if n_gpus > 1 else model.state_dict()
    torch.save({
        'model_state_dict': model_state,
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict(),
        'config': config,
        'training_history': {
            'train_metrics': train_metrics_history,
            'val_metrics': val_metrics_history
        }
    }, final_model_path)
    
    logger.info(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    logger.info(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
    logger.info(f"æœ€ç»ˆæ¨¡å‹ä¿å­˜åˆ°: {final_model_path}")


def prepare_latents_for_training():
    """é¢„å¤„ç†ï¼šåªåœ¨ä¸»è¿›ç¨‹ä¸­å‡†å¤‡æ½œç©ºé—´æ•°æ®"""
    # æ£€æŸ¥GPUçŠ¶æ€å’Œæ˜¾å­˜
    device = torch.device('cuda:0')
    torch.cuda.set_device(0)
    torch.cuda.empty_cache()
    
    logger.info("=== å‡†å¤‡æ½œç©ºé—´æ•°æ® ===")
    initial_memory = torch.cuda.memory_allocated(device) / 1024**3
    logger.info(f"åˆå§‹æ˜¾å­˜ä½¿ç”¨: {initial_memory:.2f}GB")
    
    # ä½¿ç”¨æŒ‡å®šçš„VA-VAEæ¨¡å‹è·¯å¾„
    vae_checkpoint = "/kaggle/input/stage3/vavae-stage3-epoch26-val_rec_loss0.0000.ckpt"
    
    if Path(vae_checkpoint).exists():
        logger.info(f"âœ… æ‰¾åˆ°VA-VAEæ¨¡å‹: {vae_checkpoint}")
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        size_mb = Path(vae_checkpoint).stat().st_size / (1024 * 1024)
        logger.info(f"   æ¨¡å‹å¤§å°: {size_mb:.2f} MB")
    else:
        logger.error("âŒ æœªæ‰¾åˆ°VA-VAEæ¨¡å‹ï¼")
        logger.error(f"   è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨: {vae_checkpoint}")
        raise FileNotFoundError(f"VA-VAE checkpoint not found at {vae_checkpoint}")
    
    # è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†è·¯å¾„
    possible_data_paths = [
        "/kaggle/input/dataset",  # æ ‡å‡†Kaggleè·¯å¾„
        "/kaggle/input/micro-doppler-data",  # æ›¿ä»£è·¯å¾„
        "./dataset",  # æœ¬åœ°è·¯å¾„
        "G:/micro-doppler-dataset"  # æœ¬åœ°æµ‹è¯•è·¯å¾„
    ]
    
    data_dir = None
    for path in possible_data_paths:
        if Path(path).exists():
            data_dir = Path(path)
            logger.info(f"æ‰¾åˆ°æ•°æ®é›†: {path}")
            break
    
    if data_dir is None:
        logger.error("æœªæ‰¾åˆ°æ•°æ®é›†ï¼è¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„:")
        for path in possible_data_paths:
            logger.error(f"  - {path}")
        raise FileNotFoundError("Dataset not found")
    
    # ä¿®æ­£é…ç½®ä¸­çš„checkpointè·¯å¾„ä¸ºå¾®è°ƒæ¨¡å‹
    logger.info("å‡†å¤‡VA-VAEé…ç½®...")
    vae_config_path = Path("/kaggle/working/VA-VAE/LightningDiT/tokenizer/configs/vavae_f16d32.yaml")
    
    with open(vae_config_path, 'r') as f:
        config_content = f.read()
    
    # ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹åˆ°çš„å¾®è°ƒæ¨¡å‹  
    finetuned_checkpoint = vae_checkpoint
    if finetuned_checkpoint not in config_content:
        config_content = config_content.replace(
            'ckpt_path: /path/to/checkpoint.pt',
            f'ckpt_path: {finetuned_checkpoint}'
        )
        with open(vae_config_path, 'w') as f:
            f.write(config_content)
        logger.info(f"å·²æ›´æ–°VA-VAE checkpointè·¯å¾„: {finetuned_checkpoint}")
    
    # åˆå§‹åŒ–VA-VAEè¿›è¡Œæ½œç©ºé—´ç¼–ç 
    from tokenizer.vavae import VA_VAE
    logger.info("åŠ è½½VA-VAEæ¨¡å‹...")
    vae = VA_VAE(str(vae_config_path), img_size=256, horizon_flip=False, fp16=True)
    vae_memory = torch.cuda.memory_allocated(device) / 1024**3
    logger.info(f"VA-VAEåŠ è½½å®Œæˆï¼Œæ˜¾å­˜: {vae_memory:.2f}GB")
    
    # é¢„è®¡ç®—æ½œç©ºé—´ï¼ˆä½¿ç”¨å·²æ£€æµ‹çš„æ•°æ®è·¯å¾„ï¼‰
    latents_file = Path("/kaggle/working") / 'latents_microdoppler.npz'
    if not latents_file.exists():
        logger.info("å¼€å§‹ç¼–ç æ•°æ®é›†åˆ°æ½œç©ºé—´...")
        encode_dataset_to_latents(vae, data_dir, device)
        logger.info("æ½œç©ºé—´ç¼–ç å®Œæˆ")
    else:
        logger.info("æ½œç©ºé—´æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ç¼–ç ")
    
    # é‡Šæ”¾VA-VAEæ˜¾å­˜
    del vae
    torch.cuda.empty_cache()
    final_memory = torch.cuda.memory_allocated(device) / 1024**3
    logger.info(f"VA-VAEé‡Šæ”¾åæ˜¾å­˜: {final_memory:.2f}GB")


# DDPè®­ç»ƒå‡½æ•°å·²åˆ é™¤ï¼Œæ”¹ç”¨DataParallel


def generate_conditional_samples(model, vae, transport, device, epoch, n_gpus, config=None):
    """ç”Ÿæˆæ¡ä»¶æ‰©æ•£æ ·æœ¬ç”¨äºéªŒè¯æ¡ä»¶æ§åˆ¶èƒ½åŠ›
    
    é‡‡æ ·æŠ€æœ¯è¯´æ˜ï¼š
    - dopri5: 5é˜¶è‡ªé€‚åº”Runge-Kuttaæ–¹æ³•ï¼Œç²¾åº¦æœ€é«˜
    - 150æ­¥: å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦ï¼ˆå®˜æ–¹æ¨è250æ­¥ï¼‰
    - CFG: æœªå¯ç”¨ï¼ˆéœ€è¦ä¿®æ”¹æ¨¡å‹forwardæ¥å£ï¼‰
    """
    model.eval()
    
    with torch.no_grad():
        print(f"\n  ğŸ“Š å¼€å§‹ç”Ÿæˆæ¡ä»¶æ ·æœ¬ (Epoch {epoch}, euleræ±‚è§£å™¨, 250æ­¥)...")
        
        # ç”Ÿæˆå¤šä¸ªç”¨æˆ·çš„æ ·æœ¬
        num_users_to_sample = min(8, 31)  # é‡‡æ ·8ä¸ªä¸åŒç”¨æˆ·
        samples_per_user = 2  # æ¯ä¸ªç”¨æˆ·ç”Ÿæˆ2ä¸ªæ ·æœ¬
        
        # é€‰æ‹©è¦é‡‡æ ·çš„ç”¨æˆ·
        selected_users = torch.linspace(0, 30, num_users_to_sample, dtype=torch.long, device=device)
        print(f"  â€¢ é€‰æ‹©çš„ç”¨æˆ·ID: {selected_users.tolist()}")
        print(f"  â€¢ æ¯ä¸ªç”¨æˆ·ç”Ÿæˆ {samples_per_user} ä¸ªæ ·æœ¬")
        
        all_samples = []
        all_user_ids = []
        
        for idx, user_id in enumerate(selected_users):
            # ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆå¤šä¸ªæ ·æœ¬
            user_batch = user_id.repeat(samples_per_user)
            
            # éšæœºåˆå§‹åŒ–å™ªå£°
            z = torch.randn(samples_per_user, 32, 16, 16, device=device)
            
            # ç”Ÿæˆæ ·æœ¬ - ä½¿ç”¨CFGå¢å¼ºæ¡ä»¶æ§åˆ¶
            actual_model = model.module if n_gpus > 1 else model
            
            # CFGé‡‡æ ·ï¼šåŒæ—¶è®¡ç®—æ¡ä»¶å’Œæ— æ¡ä»¶
            cfg_scale = config.get('cfg_scale', 10.0)  # å®˜æ–¹æ¨èCFG=10.0
            
            # å‡†å¤‡æ¡ä»¶å’Œæ— æ¡ä»¶è¾“å…¥
            y_null = torch.full_like(user_batch, 31)  # null token (ç¬¬32ä¸ªç±»åˆ«)
            y_combined = torch.cat([user_batch, y_null], dim=0)
            
            # å®šä¹‰CFGåŒ…è£…å‡½æ•°ï¼ˆæ”¯æŒcfg_intervalï¼‰
            def model_fn(x, t):
                # åº”ç”¨cfg_intervalï¼šä»…åœ¨ä½å™ªå£°æ—¶ä½¿ç”¨CFG
                cfg_interval_start = config.get('cfg_interval_start', 0.11)
                # æ³¨æ„ï¼štæ˜¯å½’ä¸€åŒ–çš„æ—¶é—´æ­¥ï¼ˆ0åˆ°1ï¼‰ï¼Œt=0æ˜¯çº¯å™ªå£°ï¼Œt=1æ˜¯å¹²å‡€æ•°æ®
                # åªæœ‰å½“t > cfg_interval_startæ—¶æ‰ä½¿ç”¨CFG
                if t.min() > cfg_interval_start:
                    # xå·²ç»æ˜¯å•æ‰¹æ¬¡ï¼Œéœ€è¦å¤åˆ¶ä¸ºæ¡ä»¶å’Œæ— æ¡ä»¶
                    x_combined = torch.cat([x, x], dim=0)
                    # æ—¶é—´æ­¥tä¹Ÿéœ€è¦å¤åˆ¶ä»¥åŒ¹é…æ‰¹é‡å¤§å°
                    t_combined = torch.cat([t, t], dim=0)
                    out = actual_model(x_combined, t_combined, y=y_combined)
                    out_cond, out_uncond = out.chunk(2, dim=0)
                    # CFG: æ— æ¡ä»¶è¾“å‡º + scale * (æ¡ä»¶ - æ— æ¡ä»¶)
                    return out_uncond + cfg_scale * (out_cond - out_uncond)
                else:
                    # é«˜å™ªå£°é˜¶æ®µä¸ä½¿ç”¨CFGï¼Œåªä½¿ç”¨æ¡ä»¶ç”Ÿæˆ
                    return actual_model(x, t, y=user_batch)
            
            # ä½¿ç”¨Samplerè¿›è¡Œé‡‡æ · - å®˜æ–¹æ¨èé…ç½®
            sampler = Sampler(transport)
            sample_fn = sampler.sample_ode(
                sampling_method=config['sampling_method'],
                num_steps=config['num_steps'],
                atol=1e-6,
                rtol=1e-3,
                timestep_shift=config.get('timestep_shift', 0.3)
            )
            samples = sample_fn(z, model_fn)[-1]
            
            all_samples.append(samples)
            all_user_ids.append(user_batch)
            
            if (idx + 1) % 4 == 0:
                print(f"    â€¢ å·²ç”Ÿæˆ {idx + 1}/{num_users_to_sample} ä¸ªç”¨æˆ·çš„æ ·æœ¬")
        
        # åˆå¹¶æ‰€æœ‰æ ·æœ¬
        all_samples = torch.cat(all_samples, dim=0)
        all_user_ids = torch.cat(all_user_ids, dim=0)
        
        print(f"  â€¢ æˆåŠŸç”Ÿæˆ {len(all_samples)} ä¸ªæ¡ä»¶æ ·æœ¬")
        print(f"  â€¢ æ ·æœ¬å½¢çŠ¶: {all_samples.shape}")
        
        # ä½¿ç”¨VA-VAEè§£ç 
        print("\n  ğŸ¨ å¼€å§‹è§£ç æ½œç©ºé—´æ ·æœ¬åˆ°å›¾åƒ...")
        try:
            # å°†æ½œç©ºé—´æ ·æœ¬ç§»åˆ°cuda:0ï¼ˆVA-VAEæ‰€åœ¨çš„è®¾å¤‡ï¼‰
            samples_cuda0 = all_samples.to('cuda:0')
            print(f"    â€¢ æ ·æœ¬å·²ç§»åˆ° cuda:0")
            
            # åæ ‡å‡†åŒ–ï¼ˆå¦‚æœæœ‰ç»Ÿè®¡ä¿¡æ¯ï¼‰
            if hasattr(vae, 'latent_mean') and vae.latent_mean is not None:
                samples_cuda0 = samples_cuda0 * vae.latent_std + vae.latent_mean
                print(f"    â€¢ å·²åº”ç”¨åæ ‡å‡†åŒ–")
            
            # è§£ç 
            print(f"    â€¢ å¼€å§‹VA-VAEè§£ç ...")
            # VA_VAEä½¿ç”¨decode_to_imagesæ–¹æ³•ï¼Œè¿”å›[0,255]çš„uint8å›¾åƒ
            images_np = vae.decode_to_images(samples_cuda0)
            # è½¬æ¢ä¸ºtorch tensorå¹¶æ­£ç¡®å½’ä¸€åŒ–åˆ°[-1, 1]
            images = torch.from_numpy(images_np).float() / 255.0 * 2.0 - 1.0  # [0,255] -> [-1,1]
            images = images.permute(0, 3, 1, 2)  # NHWC -> NCHW
            print(f"    â€¢ è§£ç å®Œæˆï¼Œå›¾åƒå½¢çŠ¶: {images.shape}")
            
            # ä¿å­˜å›¾åƒ
            save_dir = Path("/kaggle/working") / f"samples_epoch_{epoch}"
            save_dir.mkdir(exist_ok=True, parents=True)
            
            from torchvision.utils import save_image
            
            # åˆ›å»ºç½‘æ ¼å›¾
            grid_path = save_dir / "grid.png"
            num_show = min(16, len(images))
            save_image(images[:num_show], grid_path, nrow=4, normalize=True, value_range=(-1, 1))
            print(f"  âœ… ç½‘æ ¼å›¾å·²ä¿å­˜: {grid_path}")
            
            # ä¿å­˜å‰å‡ å¼ å•ç‹¬çš„å›¾åƒ
            num_save = min(8, len(images))
            for i in range(num_save):
                uid = all_user_ids[i].item()
                img_path = save_dir / f"user_{uid}_sample_{i}.png"
                save_image(images[i], img_path, normalize=True, value_range=(-1, 1))
            print(f"  âœ… ä¿å­˜äº† {num_save} å¼ å•ç‹¬å›¾åƒåˆ°: {save_dir}")
            
            # åˆ›å»ºç”¨æˆ·åˆ†ç»„çš„ç½‘æ ¼å›¾
            users_path = save_dir / "users_grid.png"
            save_image(images, users_path, nrow=samples_per_user, normalize=True, value_range=(-1, 1))
            print(f"  âœ… ç”¨æˆ·åˆ†ç»„ç½‘æ ¼å›¾: {users_path}")
            
        except Exception as e:
            print(f"\n  âš ï¸ è§£ç å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            print("  â€¢ æ­£åœ¨ä¿å­˜æ½œç©ºé—´æ ·æœ¬è€Œéå›¾åƒ...")
            
            # ä¿å­˜æ½œç©ºé—´è¡¨ç¤º
            latent_path = Path("/kaggle/working") / f"latents_epoch_{epoch}.pt"
            torch.save({
                'latents': all_samples.cpu(),
                'user_ids': all_user_ids.cpu(),
                'epoch': epoch
            }, latent_path)
            print(f"  âœ… æ½œç©ºé—´æ ·æœ¬å·²ä¿å­˜åˆ°: {latent_path}")


def main():
    """ä¸»å‡½æ•° - Kaggle T4x2ä¼˜åŒ–ç‰ˆæœ¬"""
    # Kaggleç¯å¢ƒGPUæ£€æŸ¥
    if not torch.cuda.is_available():
        logger.error("CUDA not available! Please enable GPU accelerator in Kaggle.")
        return
    
    num_gpus = torch.cuda.device_count()
    logger.info(f"Detected {num_gpus} GPU(s)")
    
    # Kaggle T4x2ä½¿ç”¨DataParallelï¼Œä¸ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ
    train_dit_kaggle()

if __name__ == "__main__":
    main()
