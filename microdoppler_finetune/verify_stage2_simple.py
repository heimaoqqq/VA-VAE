#!/usr/bin/env python3
"""
Stage 2 è®­ç»ƒå‰ç½®æ¡ä»¶éªŒè¯è„šæœ¬ï¼ˆç®€åŒ–ç‰ˆï¼‰
"""

import os
import sys
from pathlib import Path
import json

def verify_stage2_readiness():
    """éªŒè¯Stage 2è®­ç»ƒå‡†å¤‡æƒ…å†µ"""
    
    print("="*60)
    print("ğŸ” VA-VAE Stage 2 è®­ç»ƒå‡†å¤‡çŠ¶æ€æ£€æŸ¥")
    print("="*60)
    
    issues = []
    warnings = []
    
    # 1. æ£€æŸ¥Stage 1 checkpoint (Kaggleè®­ç»ƒå¥½çš„æ¨¡å‹)
    print("\nğŸ“¦ Stage 1 Checkpointæ£€æŸ¥:")
    kaggle_stage1_path = Path("/kaggle/input/stage1/vavae-stage1-epoch43-val_rec_loss0.0000.ckpt")
    
    if kaggle_stage1_path.exists():
        size_mb = kaggle_stage1_path.stat().st_size / (1024*1024)
        print(f"   âœ… Kaggle Stage 1æ¨¡å‹å­˜åœ¨")
        print(f"   æ–‡ä»¶: {kaggle_stage1_path.name}")
        print(f"   éªŒè¯æŸå¤±: 0.0000 (epoch 43)")
        print(f"   æ–‡ä»¶å¤§å°: {size_mb:.1f} MB")
        
        if size_mb < 100:
            warnings.append(f"âš ï¸ Checkpointæ–‡ä»¶è¾ƒå°({size_mb:.1f}MB)ï¼Œå¯èƒ½ä¸å®Œæ•´")
    else:
        # å›é€€æ£€æŸ¥æœ¬åœ°checkpoint
        print(f"   âŒ Kaggleæ¨¡å‹æœªæ‰¾åˆ°: {kaggle_stage1_path}")
        print("   å°è¯•æ£€æŸ¥æœ¬åœ°checkpoint...")
        
        stage1_dir = Path('checkpoints/stage1')
        if stage1_dir.exists():
            ckpt_files = list(stage1_dir.glob('*.ckpt'))
            if ckpt_files:
                print("   ğŸ“‚ æœ¬åœ°checkpointæ–‡ä»¶:")
                for ckpt in ckpt_files:
                    size_mb = ckpt.stat().st_size / (1024*1024)
                    print(f"   - {ckpt.name} ({size_mb:.1f} MB)")
            else:
                issues.append("âŒ æœ¬åœ°ä¹Ÿæœªæ‰¾åˆ°Stage 1 checkpointæ–‡ä»¶")
        else:
            issues.append("âŒ Kaggleå’Œæœ¬åœ°éƒ½æœªæ‰¾åˆ°Stage 1 checkpoint")
    
    # 2. æ£€æŸ¥æ•°æ®é…ç½®
    print("\nğŸ“Š æ•°æ®é…ç½®æ£€æŸ¥:")
    # æ£€æŸ¥Kaggleæ•°æ®è·¯å¾„
    kaggle_split_file = Path("/kaggle/working/data_split/dataset_split.json")
    local_split_file = Path('data/microdoppler_split.json')
    
    split_file = kaggle_split_file if kaggle_split_file.exists() else local_split_file
    
    if split_file.exists():
        with open(split_file, 'r') as f:
            split_data = json.load(f)
        
        train_count = sum(len(imgs) for imgs in split_data['train'].values())
        val_count = sum(len(imgs) for imgs in split_data['val'].values())
        
        print(f"   âœ… æ•°æ®åˆ’åˆ†æ–‡ä»¶: {split_file}")
        print(f"   âœ… è®­ç»ƒé›†: {train_count} å¼ å›¾åƒ")
        print(f"   âœ… éªŒè¯é›†: {val_count} å¼ å›¾åƒ")
        
        if train_count < 100:
            warnings.append(f"âš ï¸ è®­ç»ƒé›†è¾ƒå°({train_count}å¼ )ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ")
    else:
        issues.append("âŒ æ•°æ®åˆ’åˆ†æ–‡ä»¶ä¸å­˜åœ¨ (æ£€æŸ¥äº†Kaggleå’Œæœ¬åœ°è·¯å¾„)")
    
    # 3. æ£€æŸ¥æŸå¤±è®¡ç®—çŠ¶æ€
    print("\nğŸ”§ æŸå¤±è®¡ç®—çŠ¶æ€æ£€æŸ¥:")
    loss_file = Path('../LightningDiT/vavae/ldm/modules/losses/contperceptual.py')
    
    if loss_file.exists():
        with open(loss_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        if 'torch.sum(weighted_nll_loss) / weighted_nll_loss.shape[0]' in content:
            print("   â„¹ï¸ å®˜æ–¹æŸå¤±è®¡ç®—ä½¿ç”¨sum/batch_size (ä¼šå¯¼è‡´é«˜æŸå¤±æ˜¾ç¤º)")
            print("   âœ… è®­ç»ƒè„šæœ¬ä¸­å·²å®ç°æŸå¤±åç¼©æ”¾æ˜¾ç¤ºåŠŸèƒ½")
        else:
            warnings.append("âš ï¸ æ— æ³•ç¡®è®¤æŸå¤±è®¡ç®—æ–¹å¼")
    else:
        warnings.append("âš ï¸ æ— æ³•éªŒè¯æŸå¤±è®¡ç®—çŠ¶æ€")
    
    # 4. æ£€æŸ¥è®­ç»ƒè„šæœ¬ä¸­çš„å…³é”®é…ç½®
    print("\nâš™ï¸ è®­ç»ƒè„šæœ¬é…ç½®æ£€æŸ¥:")
    train_script = Path('step4_train_vavae.py')
    
    if train_script.exists():
        with open(train_script, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æŸ¥å…³é”®é…ç½®
        checks = {
            "perceptual_weight': 1.0": "æ„ŸçŸ¥æŸå¤±æƒé‡",
            "adaptive_vf': False": "ç¦ç”¨è‡ªé€‚åº”VF",
            "best_loss = float('inf')": "æœ€ä½³checkpointé€‰æ‹©é€»è¾‘",
            "corrected_train_loss = train_ae_loss / pixel_count": "æŸå¤±åç¼©æ”¾æ˜¾ç¤ºåŠŸèƒ½"
        }
        
        for pattern, desc in checks.items():
            if pattern in content:
                print(f"   âœ… {desc}: å·²æ­£ç¡®é…ç½®")
            else:
                issues.append(f"âŒ {desc}: é…ç½®é”™è¯¯æˆ–ç¼ºå¤±")
    
    # 5. æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹ (ä»…Stage 1éœ€è¦)
    print("\nğŸ¯ é¢„è®­ç»ƒæ¨¡å‹æ£€æŸ¥:")
    print("   â„¹ï¸ Stage 2ä¸éœ€è¦é¢„è®­ç»ƒæ¨¡å‹ï¼Œç›´æ¥ç»§æ‰¿Stage 1æƒé‡")
    print("   âœ… Stage 1æ¨¡å‹å·²è®­ç»ƒå®Œæˆï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦æƒé‡")
    
    # 6. Stage 2é…ç½®éªŒè¯
    print("\nğŸ“‹ Stage 2 é¢„æœŸé…ç½®:")
    print("   âœ… åˆ¤åˆ«å™¨å¯åŠ¨: epoch 1 (ç«‹å³å¯åŠ¨)")
    print("   âœ… VFæƒé‡: 0.1 (ä»0.5é™ä½ä»¥ä¼˜åŒ–é‡å»º)")
    print("   âœ… å­¦ä¹ ç‡: 5e-5 (ä»1e-4é™ä½ä»¥ç¨³å®šè®­ç»ƒ)")
    print("   âœ… æœ€å¤§è½®æ¬¡: 15 (å®˜æ–¹æ ‡å‡†ï¼Œå¿«é€Ÿé‡å»ºå¾®è°ƒ)")
    print("   âœ… æ‰¹æ¬¡å¤§å°: 4 (GPUå†…å­˜é™åˆ¶)")
    print("   âœ… CheckpointåŠ è½½: Kaggle Stage 1æ¨¡å‹")
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š æ£€æŸ¥æ€»ç»“:")
    
    if issues:
        print("\nâŒ å‘ç°ä¸¥é‡é—®é¢˜ (å¿…é¡»ä¿®å¤):")
        for issue in issues:
            print(f"   {issue}")
    
    if warnings:
        print("\nâš ï¸ è­¦å‘Š (å»ºè®®å…³æ³¨):")
        for warning in warnings:
            print(f"   {warning}")
    
    if not issues:
        print("\nâœ… æ‰€æœ‰å…³é”®æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹Stage 2è®­ç»ƒ")
        print("\nğŸš€ å»ºè®®è¿è¡Œå‘½ä»¤:")
        print("   python step4_train_vavae.py --stage 2 --batch_size 4")
        print("\nğŸ“Œ Stage 2è®­ç»ƒè¦ç‚¹:")
        print("   1. ç»§æ‰¿Stage 1çš„æœ€ä½³æ¨¡å‹æƒé‡")
        print("   2. åˆ¤åˆ«å™¨ä»ç¬¬1ä¸ªepochå¼€å§‹å‚ä¸è®­ç»ƒ")
        print("   3. VFæƒé‡é™ä½åˆ°0.1ï¼Œä¸“æ³¨é‡å»ºè´¨é‡")
        print("   4. å­¦ä¹ ç‡é™ä½åˆ°5e-5ï¼Œç¡®ä¿ç¨³å®šæ”¶æ•›")
    else:
        print("\nâŒ è¯·å…ˆè§£å†³ä»¥ä¸Šé—®é¢˜å†å¼€å§‹Stage 2è®­ç»ƒ")
    
    print("="*60)
    
    return len(issues) == 0

if __name__ == '__main__':
    success = verify_stage2_readiness()
    sys.exit(0 if success else 1)
