#!/usr/bin/env python3
"""
Latenté¢„ç¼–ç å’Œæ•°æ®é›†å¤„ç†
é›†æˆé¢„ç¼–ç ç”Ÿæˆå’Œæ•°æ®é›†åŠ è½½åŠŸèƒ½
"""

import os
import json
import torch
import numpy as np
from pathlib import Path
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader

from simplified_vavae import SimplifiedVAVAE
from microdoppler_dataset_diffusion import MicrodopplerDataset


class PreEncodedLatentDataset(Dataset):
    """
    é¢„ç¼–ç latentæ•°æ®é›† - ç›´æ¥åŠ è½½latentè€Œéå›¾åƒ
    æ˜¾è‘—åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹
    """
    
    def __init__(self, latent_file, return_user_id=False):
        """
        Args:
            latent_file: é¢„ç¼–ç latentæ–‡ä»¶è·¯å¾„ (.ptæ ¼å¼)
            return_user_id: æ˜¯å¦è¿”å›ç”¨æˆ·ID
        """
        self.latent_file = Path(latent_file)
        self.return_user_id = return_user_id
        
        # åŠ è½½é¢„ç¼–ç æ•°æ®
        print(f"ğŸ“Š åŠ è½½é¢„ç¼–ç latent: {latent_file}")
        self.data = torch.load(latent_file, map_location='cpu', weights_only=False)
        
        print(f"âœ… åŠ è½½å®Œæˆ: {len(self.data)}ä¸ªlatentæ ·æœ¬")
        if len(self.data) > 0:
            sample_shape = self.data[0]['latent'].shape
            print(f"   Latentå½¢çŠ¶: {sample_shape}")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        item = self.data[idx]
        
        # è½¬æ¢ä¸ºtensor
        latent = torch.from_numpy(item['latent']).float()
        
        if self.return_user_id:
            return latent, item['user_id']
        else:
            return (latent,)  # ä¿æŒå…ƒç»„æ ¼å¼å…¼å®¹
            

class MixedLatentDataset(Dataset):
    """
    æ··åˆæ•°æ®é›†ï¼šä¼˜å…ˆä½¿ç”¨é¢„ç¼–ç latentï¼Œfallbackåˆ°å›¾åƒç¼–ç 
    """
    
    def __init__(self, latent_file=None, image_dataset=None, return_user_id=False):
        self.return_user_id = return_user_id
        
        # å°è¯•åŠ è½½é¢„ç¼–ç æ•°æ®
        if latent_file and Path(latent_file).exists():
            print(f"ğŸš€ ä½¿ç”¨é¢„ç¼–ç latentæ•°æ®é›†")
            self.use_preencoded = True
            self.latent_dataset = PreEncodedLatentDataset(
                latent_file, return_user_id=return_user_id
            )
        else:
            print(f"ğŸ“Š ä½¿ç”¨å›¾åƒæ•°æ®é›†ï¼ˆå®æ—¶ç¼–ç ï¼‰")
            self.use_preencoded = False
            self.image_dataset = image_dataset
            
    def __len__(self):
        if self.use_preencoded:
            return len(self.latent_dataset)
        else:
            return len(self.image_dataset)
    
    def __getitem__(self, idx):
        if self.use_preencoded:
            return self.latent_dataset[idx]
        else:
            return self.image_dataset[idx]


def precompute_latents(args):
    """é¢„ç¼–ç æ‰€æœ‰å›¾åƒåˆ°latentç©ºé—´"""
    
    # åˆå§‹åŒ–VAE
    print("ğŸ”§ åŠ è½½VA-VAE...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    vae = SimplifiedVAVAE(args.vae_checkpoint)
    vae.to(device)
    vae.eval()
    
    # è¾“å‡ºç›®å½•
    latent_dir = Path(args.output_dir)
    latent_dir.mkdir(exist_ok=True)
    
    splits = ['train', 'val', 'test']
    
    for split in splits:
        print(f"\nğŸ“Š å¤„ç†{split}é›†...")
        
        # åŠ è½½æ•°æ®é›†
        try:
            dataset = MicrodopplerDataset(
                root_dir=args.image_dir,
                split_file=args.split_file,
                split=split,
                return_user_id=True,  # éœ€è¦ç”¨æˆ·ID
                image_size=256
            )
        except ValueError as e:
            print(f"âš ï¸ {split}é›†ä¸å­˜åœ¨ï¼Œè·³è¿‡: {e}")
            continue
        
        if len(dataset) == 0:
            print(f"âš ï¸ {split}é›†ä¸ºç©ºï¼Œè·³è¿‡")
            continue
            
        dataloader = DataLoader(
            dataset, 
            batch_size=args.batch_size,
            shuffle=False,  # ä¿æŒé¡ºåº
            num_workers=4
        )
        
        latent_data = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(tqdm(dataloader, desc=f"ç¼–ç {split}")):
                images, user_ids = batch
                images = images.to(device)
                
                # æ ¼å¼è½¬æ¢ï¼šBHWC -> BCHW
                if images.dim() == 4 and images.shape[-1] == 3:
                    images = images.permute(0, 3, 1, 2)
                
                # VAEç¼–ç 
                latents = vae.encode(images)
                
                # ä¿å­˜æ¯ä¸ªæ ·æœ¬çš„latentå’Œå…ƒæ•°æ®
                for i in range(latents.shape[0]):
                    latent_item = {
                        'latent': latents[i].cpu().numpy(),  # [32, 16, 16]
                        'user_id': user_ids[i],
                        'original_idx': batch_idx * args.batch_size + i
                    }
                    latent_data.append(latent_item)
        
        # ä¿å­˜latentæ•°æ®
        split_file = latent_dir / f"{split}_latents.pt"
        torch.save(latent_data, split_file)
        
        print(f"âœ… {split}é›†å·²ä¿å­˜: {len(latent_data)}ä¸ªlatent -> {split_file}")
        print(f"   Latentå½¢çŠ¶: {latent_data[0]['latent'].shape}")
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        all_latents = np.stack([item['latent'] for item in latent_data])
        mean_val = np.mean(all_latents)
        std_val = np.std(all_latents)
        
        print(f"   ç»Ÿè®¡ä¿¡æ¯: Mean={mean_val:.6f}, Std={std_val:.6f}")
    
    print(f"\nğŸ‰ æ‰€æœ‰latentå·²ä¿å­˜åˆ°: {latent_dir}")


def main():
    """å‘½ä»¤è¡Œå…¥å£ - é¢„ç¼–ç latent"""
    import argparse
    
    parser = argparse.ArgumentParser(description="é¢„ç¼–ç å›¾åƒåˆ°latentç©ºé—´")
    parser.add_argument('--image_dir', type=str, required=True,
                       help='å›¾åƒæ•°æ®ç›®å½•')
    parser.add_argument('--split_file', type=str, required=True,
                       help='æ•°æ®åˆ’åˆ†JSONæ–‡ä»¶')
    parser.add_argument('--vae_checkpoint', type=str, required=True,
                       help='VA-VAE checkpointè·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./latents',
                       help='latentè¾“å‡ºç›®å½•')
    parser.add_argument('--batch_size', type=int, default=16,
                       help='æ‰¹å¤„ç†å¤§å°')
    
    args = parser.parse_args()
    precompute_latents(args)


if __name__ == '__main__':
    main()
