# å¾®å¤šæ™®å‹’ç”¨æˆ·æ¡ä»¶åŒ–ç”Ÿæˆ - æ­£ç¡®æ–¹æ³•

åŸºäºLightningDiTåŸé¡¹ç›®çš„æ­£ç¡®å®ç°æ–¹æ³•

## ğŸ¯ é¡¹ç›®ç†è§£

### æ ¸å¿ƒæ¦‚å¿µ
- **VA-VAE**: è§†è§‰åŸºç¡€æ¨¡å‹å¯¹é½çš„å˜åˆ†è‡ªç¼–ç å™¨ï¼Œè´Ÿè´£å›¾åƒâ†”æ½œåœ¨ç©ºé—´è½¬æ¢
- **DiT**: æ‰©æ•£Transformerï¼Œåœ¨æ½œåœ¨ç©ºé—´è¿›è¡Œæ‰©æ•£å»å™ª
- **ç”¨æˆ·æ¡ä»¶åŒ–**: åœ¨DiTä¸­æ·»åŠ ç”¨æˆ·IDä½œä¸ºç±»åˆ«æ¡ä»¶

### ä¸åŸæ–¹æ³•çš„åŒºåˆ«

| æ–¹é¢ | âŒ é”™è¯¯æ–¹æ³• (ä¹‹å‰) | âœ… æ­£ç¡®æ–¹æ³• (ç°åœ¨) |
|------|------------------|------------------|
| **VAEä½¿ç”¨** | å®æ—¶ç¼–ç è§£ç ï¼Œå‚ä¸è®­ç»ƒ | é¢„æå–ç‰¹å¾ï¼Œä¸å‚ä¸è®­ç»ƒ |
| **è®­ç»ƒç›®æ ‡** | VAEé‡å»ºæŸå¤± | æ‰©æ•£å»å™ªæŸå¤± |
| **æ•°æ®æ ¼å¼** | åŸå§‹å›¾åƒ (3, 256, 256) | æ½œåœ¨ç‰¹å¾ (32, 16, 16) |
| **ç”¨æˆ·æ¡ä»¶** | åœ¨VAEç¼–ç å™¨ä¸­æ·»åŠ  | åœ¨DiTä¸­ä½œä¸ºç±»åˆ«æ¡ä»¶ |
| **å†…å­˜æ•ˆç‡** | ä½ (éœ€è¦å­˜å‚¨å¤§å›¾åƒ) | é«˜ (åªéœ€å­˜å‚¨å°ç‰¹å¾) |
| **è®­ç»ƒç¨³å®šæ€§** | ä¸ç¨³å®š (KLæ•£åº¦çˆ†ç‚¸) | ç¨³å®š (æˆç†Ÿçš„æ‰©æ•£è®­ç»ƒ) |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡
```bash
# ç¡®ä¿å·²å®‰è£…ä¾èµ–
pip install torch torchvision pytorch-lightning
pip install safetensors transformers accelerate
pip install matplotlib pillow tqdm
```

### ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹
```bash
python run_complete_pipeline.py \
    --data_dir /kaggle/working/data_split \
    --vavae_path /kaggle/working/pretrained/vavae-imagenet256-f16d32-dinov2.pt \
    --output_dir /kaggle/working/correct_outputs \
    --batch_size 32 \
    --max_epochs 50 \
    --devices 2 \
    --generate_user_ids 1 2 3 4 5 \
    --num_samples_per_user 4
```

## ğŸ“‹ åˆ†é˜¶æ®µæ‰§è¡Œ

### é˜¶æ®µ1: ç‰¹å¾æå–
```bash
python stage1_extract_features.py \
    --data_dir /kaggle/working/data_split \
    --vavae_path /kaggle/working/pretrained/vavae-imagenet256-f16d32-dinov2.pt \
    --output_path /kaggle/working/latent_features \
    --batch_size 32
```

**è¾“å‡º**: 
- `train.safetensors`: è®­ç»ƒé›†æ½œåœ¨ç‰¹å¾ (N, 32, 16, 16)
- `val.safetensors`: éªŒè¯é›†æ½œåœ¨ç‰¹å¾ (M, 32, 16, 16)

### é˜¶æ®µ2: DiTè®­ç»ƒ
```bash
python stage2_train_dit.py \
    --latent_dir /kaggle/working/latent_features \
    --output_dir /kaggle/working/trained_models \
    --batch_size 32 \
    --max_epochs 100 \
    --lr 1e-4 \
    --devices 2 \
    --precision 16-mixed
```

**è¾“å‡º**:
- `checkpoints/`: æ¨¡å‹æ£€æŸ¥ç‚¹
- `lightning_logs/`: è®­ç»ƒæ—¥å¿—

### é˜¶æ®µ3: å›¾åƒç”Ÿæˆ
```bash
python stage3_inference.py \
    --dit_checkpoint /kaggle/working/trained_models/checkpoints/best.ckpt \
    --vavae_path /kaggle/working/pretrained/vavae-imagenet256-f16d32-dinov2.pt \
    --output_dir /kaggle/working/generated_images \
    --user_ids 1 2 3 4 5 \
    --num_samples_per_user 4 \
    --guidance_scale 4.0 \
    --num_steps 250
```

**è¾“å‡º**:
- å•ç‹¬çš„ç”Ÿæˆå›¾åƒ: `micro_doppler_user01_001.png`
- ç½‘æ ¼å›¾åƒ: `micro_doppler_grid.png`

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### æ•°æ®æµç¨‹
```
åŸå§‹å›¾åƒ (3, 256, 256)
    â†“ VA-VAE.encode()
æ½œåœ¨ç‰¹å¾ (32, 16, 16)
    â†“ DiT + æ‰©æ•£è®­ç»ƒ
è®­ç»ƒå¥½çš„DiTæ¨¡å‹
    â†“ DiT.sample() + ç”¨æˆ·æ¡ä»¶
æ–°çš„æ½œåœ¨ç‰¹å¾ (32, 16, 16)
    â†“ VA-VAE.decode()
ç”Ÿæˆå›¾åƒ (3, 256, 256)
```

### æ¨¡å‹æ¶æ„
```python
UserConditionedDiT:
â”œâ”€â”€ DiT Backbone (LightningDiT)
â”‚   â”œâ”€â”€ Patch Embedding: (32, 16, 16) â†’ patches
â”‚   â”œâ”€â”€ Transformer Blocks: 28å±‚
â”‚   â”œâ”€â”€ User Condition: åµŒå…¥ç”¨æˆ·ID
â”‚   â””â”€â”€ Output: é¢„æµ‹å™ªå£°/é€Ÿåº¦
â””â”€â”€ Transport: æ‰©æ•£é‡‡æ ·å™¨
```

### å…³é”®å‚æ•°
- **æ½œåœ¨ç©ºé—´**: 32é€šé“, 16Ã—16åˆ†è¾¨ç‡ (f16d32)
- **ä¸‹é‡‡æ ·æ¯”ä¾‹**: 16å€ (256â†’16)
- **ç”¨æˆ·æ¡ä»¶**: ç±»åˆ«æ¡ä»¶ï¼Œæ”¯æŒclassifier-free guidance
- **æ‰©æ•£é¢„æµ‹**: é€Ÿåº¦é¢„æµ‹ (velocity prediction)
- **é‡‡æ ·å™¨**: Linear transport

## ğŸ“Š é¢„æœŸç»“æœ

### è®­ç»ƒæŒ‡æ ‡
- **è®­ç»ƒæŸå¤±**: åº”è¯¥ç¨³å®šä¸‹é™ï¼Œæ”¶æ•›åˆ°0.01-0.1
- **éªŒè¯æŸå¤±**: ä¸è®­ç»ƒæŸå¤±æ¥è¿‘ï¼Œæ— æ˜æ˜¾è¿‡æ‹Ÿåˆ
- **è®­ç»ƒæ—¶é—´**: çº¦2-3å°æ—¶/epoch (åŒGPU)

### ç”Ÿæˆè´¨é‡
- **ç”¨æˆ·ç‰¹å¼‚æ€§**: ä¸åŒç”¨æˆ·ç”Ÿæˆçš„å›¾åƒåº”æœ‰æ˜æ˜¾å·®å¼‚
- **å›¾åƒè´¨é‡**: æ¸…æ™°çš„æ—¶é¢‘ç»“æ„ï¼Œæ— æ˜æ˜¾ä¼ªå½±
- **å¤šæ ·æ€§**: åŒä¸€ç”¨æˆ·çš„å¤šä¸ªæ ·æœ¬åº”æœ‰åˆç†å˜åŒ–

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘æ‰¹æ¬¡å¤§å°
   --batch_size 16
   
   # ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
   # åœ¨DiTæ¨¡å‹ä¸­å¯ç”¨checkpointing
   ```

2. **è®­ç»ƒæŸå¤±ä¸æ”¶æ•›**
   ```bash
   # è°ƒæ•´å­¦ä¹ ç‡
   --lr 5e-5
   
   # å¢åŠ è®­ç»ƒè½®æ•°
   --max_epochs 200
   ```

3. **ç”Ÿæˆå›¾åƒè´¨é‡å·®**
   ```bash
   # å¢åŠ é‡‡æ ·æ­¥æ•°
   --num_steps 500
   
   # è°ƒæ•´å¼•å¯¼å¼ºåº¦
   --guidance_scale 6.0
   ```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### è®­ç»ƒä¼˜åŒ–
- ä½¿ç”¨æ··åˆç²¾åº¦: `--precision 16-mixed`
- å¤šGPUè®­ç»ƒ: `--devices 2`
- æ•°æ®å¹¶è¡Œ: è‡ªåŠ¨å¯ç”¨DDP

### æ¨ç†ä¼˜åŒ–
- æ‰¹é‡ç”Ÿæˆ: ä¸€æ¬¡ç”Ÿæˆå¤šä¸ªæ ·æœ¬
- ç¼“å­˜æ¨¡å‹: é¿å…é‡å¤åŠ è½½
- GPUæ¨ç†: ä½¿ç”¨CUDAåŠ é€Ÿ

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **è¯„ä¼°ç”Ÿæˆè´¨é‡**: è®¡ç®—FIDã€ISç­‰æŒ‡æ ‡
2. **ç”¨æˆ·ç ”ç©¶**: é‚€è¯·ç”¨æˆ·è¯„ä¼°ç”Ÿæˆçš„å¾®å¤šæ™®å‹’å›¾åƒ
3. **æ¨¡å‹ä¼˜åŒ–**: å°è¯•ä¸åŒçš„DiTæ¶æ„å’Œè¶…å‚æ•°
4. **åº”ç”¨æ‰©å±•**: é›†æˆåˆ°å®é™…çš„é›·è¾¾ç³»ç»Ÿä¸­

## ğŸ“š å‚è€ƒèµ„æ–™

- [LightningDiTåŸé¡¹ç›®](https://github.com/hustvl/LightningDiT)
- [DiTè®ºæ–‡](https://arxiv.org/abs/2212.09748)
- [VA-VAEç›¸å…³å·¥ä½œ](https://arxiv.org/abs/2112.10752)
- [æ‰©æ•£æ¨¡å‹ç»¼è¿°](https://arxiv.org/abs/2006.11239)
