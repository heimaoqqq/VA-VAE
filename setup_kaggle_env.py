#!/usr/bin/env python3
"""
KaggleÁéØÂ¢ÉÂÆâË£ÖÂíåÊ£ÄÊµãËÑöÊú¨
‰∏ìÈó®‰∏∫ÂæÆÂ§öÊôÆÂãíVA-VAEÈ°πÁõÆËÆæËÆ°ÔºåÈÄÇÈÖçKaggleÁéØÂ¢É
"""

import subprocess
import sys
import os
import importlib
import pkg_resources
from packaging import version
import warnings
warnings.filterwarnings('ignore')

def print_header(text):
    """ÊâìÂç∞Ê†áÈ¢ò"""
    print("\n" + "="*60)
    print(f" {text}")
    print("="*60)

def print_step(step, text):
    """ÊâìÂç∞Ê≠•È™§"""
    print(f"\nüîß Step {step}: {text}")
    print("-" * 40)

def run_command(cmd, description=""):
    """ËøêË°åÂëΩ‰ª§Âπ∂Â§ÑÁêÜÈîôËØØ"""
    print(f"ÊâßË°å: {cmd}")
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=300)
        if result.returncode == 0:
            print(f"‚úÖ ÊàêÂäü: {description}")
            return True, result.stdout
        else:
            print(f"‚ùå Â§±Ë¥•: {description}")
            print(f"ÈîôËØØ‰ø°ÊÅØ: {result.stderr}")
            return False, result.stderr
    except subprocess.TimeoutExpired:
        print(f"‚è∞ Ë∂ÖÊó∂: {description}")
        return False, "Command timeout"
    except Exception as e:
        print(f"‚ùå ÂºÇÂ∏∏: {str(e)}")
        return False, str(e)

def check_python_version():
    """Ê£ÄÊü•PythonÁâàÊú¨"""
    print_step(1, "Ê£ÄÊü•PythonÁâàÊú¨")
    python_version = sys.version_info
    print(f"PythonÁâàÊú¨: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    if python_version.major == 3 and python_version.minor >= 8:
        print("‚úÖ PythonÁâàÊú¨Á¨¶ÂêàË¶ÅÊ±Ç (>=3.8)")
        return True
    else:
        print("‚ùå PythonÁâàÊú¨Ëøá‰ΩéÔºåÈúÄË¶ÅPython 3.8+")
        return False

def check_gpu():
    """Ê£ÄÊü•GPUÁéØÂ¢É"""
    print_step(2, "Ê£ÄÊü•GPUÁéØÂ¢É")
    
    # Ê£ÄÊü•nvidia-smi
    success, output = run_command("nvidia-smi", "Ê£ÄÊü•GPU")
    if success:
        print("‚úÖ GPUÂèØÁî®")
        print("GPU‰ø°ÊÅØ:")
        lines = output.split('\n')
        for line in lines:
            if 'Tesla' in line or 'RTX' in line or 'GTX' in line or 'P100' in line or 'T4' in line:
                print(f"  {line.strip()}")
        return True
    else:
        print("‚ö†Ô∏è  GPU‰∏çÂèØÁî®ÔºåÂ∞Ü‰ΩøÁî®CPUËÆ≠ÁªÉ")
        return False

def install_pytorch():
    """ÂÆâË£ÖPyTorch - ‰øÆÂ§çtorch._CÊ®°ÂùóÈóÆÈ¢ò"""
    print_step(3, "ÂÆâË£Ö/Ê£ÄÊü•PyTorch")

    # Ê£ÄÊü•ÂΩìÂâçPyTorchÁâàÊú¨
    try:
        import torch
        # ÊµãËØïÂÖ≥ÈîÆÊ®°Âùó
        import torch._C
        current_version = torch.__version__
        print(f"ÂΩìÂâçPyTorchÁâàÊú¨: {current_version}")

        # Ê£ÄÊü•CUDAÊîØÊåÅ
        cuda_available = torch.cuda.is_available()
        print(f"CUDAÂèØÁî®: {cuda_available}")
        if cuda_available:
            print(f"CUDAÁâàÊú¨: {torch.version.cuda}")
            print(f"GPUÊï∞Èáè: {torch.cuda.device_count()}")

        # Ê£ÄÊü•ÁâàÊú¨ÊòØÂê¶Êª°Ë∂≥Ë¶ÅÊ±Ç
        if version.parse(current_version) >= version.parse("2.0.0"):
            print("‚úÖ PyTorchÁâàÊú¨Á¨¶ÂêàË¶ÅÊ±Ç‰∏îÊ®°ÂùóÂÆåÊï¥")
            return True
        else:
            print("‚ö†Ô∏è  PyTorchÁâàÊú¨Ëøá‰ΩéÔºåÂ∞ùËØïÈáçÊñ∞ÂÆâË£Ö...")
    except ImportError as e:
        print(f"PyTorchÊ®°ÂùóÁº∫Â§±: {e}")
        print("üîÑ ÈáçÊñ∞ÂÆâË£ÖPyTorch...")
    except Exception as e:
        print(f"PyTorchÊ£ÄÊü•Â§±Ë¥•: {e}")
        print("üîÑ ÈáçÊñ∞ÂÆâË£ÖPyTorch...")

    # ÂÖàÂç∏ËΩΩÂèØËÉΩÊçüÂùèÁöÑPyTorch
    print("üóëÔ∏è  Ê∏ÖÁêÜÁé∞ÊúâPyTorchÂÆâË£Ö...")
    run_command("pip uninstall torch torchvision torchaudio -y", "Âç∏ËΩΩPyTorch")

    # ÂÆâË£ÖPyTorch - ‰ΩøÁî®KaggleÊé®ËçêÁöÑÁâàÊú¨
    print("üì¶ ÂÆâË£ÖÊñ∞ÁöÑPyTorch...")
    cuda_available, _ = run_command("nvidia-smi", "Ê£ÄÊü•CUDA")
    if cuda_available:
        # ‰ΩøÁî®‰∏éKaggleÂÖºÂÆπÁöÑCUDAÁâàÊú¨
        cmd = "pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 --index-url https://download.pytorch.org/whl/cu121"
    else:
        cmd = "pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cpu"

    success, _ = run_command(cmd, "ÂÆâË£ÖPyTorch")

    # È™åËØÅÂÆâË£Ö
    if success:
        try:
            import torch
            import torch._C  # È™åËØÅC++Êâ©Â±ï
            print(f"‚úÖ PyTorch {torch.__version__} ÂÆâË£ÖÊàêÂäüÔºåÊ®°ÂùóÂÆåÊï¥")
            return True
        except ImportError as e:
            print(f"‚ùå PyTorchÂÆâË£ÖÂêé‰ªçÊúâÈóÆÈ¢ò: {e}")
            return False

    return success

def install_pytorch_lightning():
    """ÂÆâË£ÖPyTorch Lightning"""
    print_step(4, "ÂÆâË£Ö/Ê£ÄÊü•PyTorch Lightning")
    
    try:
        import pytorch_lightning as pl
        current_version = pl.__version__
        print(f"ÂΩìÂâçPyTorch LightningÁâàÊú¨: {current_version}")
        
        if version.parse(current_version) >= version.parse("2.0.0"):
            print("‚úÖ PyTorch LightningÁâàÊú¨Á¨¶ÂêàË¶ÅÊ±Ç")
            return True
        else:
            print("‚ö†Ô∏è  PyTorch LightningÁâàÊú¨Ëøá‰ΩéÔºåÂ∞ùËØïÂçáÁ∫ß...")
    except ImportError:
        print("PyTorch LightningÊú™ÂÆâË£ÖÔºåÂºÄÂßãÂÆâË£Ö...")
    
    success, _ = run_command("pip install pytorch-lightning>=2.0.0", "ÂÆâË£ÖPyTorch Lightning")
    return success

def install_core_packages():
    """ÂÆâË£ÖÊ†∏ÂøÉ‰æùËµñÂåÖ"""
    print_step(5, "ÂÆâË£ÖÊ†∏ÂøÉ‰æùËµñÂåÖ")

    # Âü∫Á°Ä‰æùËµñ
    basic_packages = [
        "pillow>=9.0.0",
        "numpy>=1.21.0",
        "tqdm>=4.64.0",
        "tensorboard>=2.8.0",
        "matplotlib>=3.5.0",
        "scikit-learn>=1.1.0",
        "safetensors>=0.3.0",  # Áî®‰∫éÂÆâÂÖ®ÁöÑÂº†ÈáèÂ≠òÂÇ®
        "accelerate>=0.20.0",  # Áî®‰∫éÊ®°ÂûãÂä†ÈÄü
        "transformers>=4.30.0"  # ÂèØËÉΩÈúÄË¶ÅÁöÑtransformerÁªÑ‰ª∂
    ]

    success_count = 0
    for package in basic_packages:
        success, _ = run_command(f"pip install {package}", f"ÂÆâË£Ö {package}")
        if success:
            success_count += 1

    print(f"‚úÖ ÊàêÂäüÂÆâË£Ö {success_count}/{len(basic_packages)} ‰∏™Âü∫Á°ÄÂåÖ")
    return success_count == len(basic_packages)

def install_lightningdit_packages():
    """ÂÆâË£ÖLightningDiTÁâπÂÆö‰æùËµñ"""
    print_step(6, "ÂÆâË£ÖLightningDiTÁâπÂÆö‰æùËµñ")

    # LightningDiTÁâπÂÆö‰æùËµñ
    lightningdit_packages = [
        "fairscale>=0.4.13",     # ÂàÜÂ∏ÉÂºèËÆ≠ÁªÉÊîØÊåÅ
        "einops>=0.6.0",         # Âº†ÈáèÊìç‰Ωú
        "timm>=0.9.0",           # ÂõæÂÉèÊ®°ÂûãÂ∫ì
        "torchdiffeq>=0.2.3",    # ODEÊ±ÇËß£Âô® (transportÈúÄË¶Å)
        "omegaconf>=2.3.0",      # ÈÖçÁΩÆÁÆ°ÁêÜ
        "diffusers>=0.20.0",     # Êâ©Êï£Ê®°ÂûãÂ∫ì
        "pytorch-fid>=0.3.0",    # FIDËØÑ‰º∞
        "scipy>=1.9.0",          # ÁßëÂ≠¶ËÆ°ÁÆó (transportÈúÄË¶Å)
        "flash-attn>=2.0.0",     # È´òÊïàÊ≥®ÊÑèÂäõÊú∫Âà∂ (ÂèØÈÄâ)
        "triton>=2.0.0",         # GPUÂÜÖÊ†∏‰ºòÂåñ (ÂèØÈÄâ)
        "xformers>=0.0.20"       # ÂÜÖÂ≠òÈ´òÊïàÁöÑtransformer (ÂèØÈÄâ)
    ]

    # ÂàÜÁ¶ªÂøÖÈúÄÂíåÂèØÈÄâÂåÖ
    required_packages = [
        "fairscale>=0.4.13",
        "einops>=0.6.0",
        "timm>=0.9.0",
        "torchdiffeq>=0.2.3",
        "omegaconf>=2.3.0",
        "diffusers>=0.20.0",
        "pytorch-fid>=0.3.0",
        "scipy>=1.9.0"
    ]

    optional_packages = [
        "flash-attn>=2.0.0",
        "triton>=2.0.0",
        "xformers>=0.0.20"
    ]

    # ÂÆâË£ÖÂøÖÈúÄÂåÖ
    print("ÂÆâË£ÖÂøÖÈúÄÁöÑLightningDiT‰æùËµñ:")
    required_success = 0
    for package in required_packages:
        print(f"\nüì¶ ÂÆâË£Ö: {package}")
        success, _ = run_command(f"pip install {package}", f"ÂÆâË£Ö {package}")
        if success:
            required_success += 1
        else:
            print(f"‚ùå ÂøÖÈúÄÂåÖ {package} ÂÆâË£ÖÂ§±Ë¥•")

    # ÂÆâË£ÖÂèØÈÄâÂåÖ
    print("\nÂÆâË£ÖÂèØÈÄâÁöÑÊÄßËÉΩ‰ºòÂåñÂåÖ:")
    optional_success = 0
    for package in optional_packages:
        print(f"\nüîß Â∞ùËØïÂÆâË£Ö: {package}")

        if "flash-attn" in package:
            success, _ = run_command(f"pip install {package} --no-build-isolation", f"ÂÆâË£Ö {package}")
        else:
            success, _ = run_command(f"pip install {package}", f"ÂÆâË£Ö {package}")

        if success:
            optional_success += 1
            print(f"‚úÖ ÂèØÈÄâÂåÖ {package} ÂÆâË£ÖÊàêÂäü")
        else:
            print(f"‚ö†Ô∏è  ÂèØÈÄâÂåÖ {package} ÂÆâË£ÖÂ§±Ë¥•ÔºåË∑≥Ëøá")

    print(f"\nüìä ÂÆâË£ÖÁªìÊûú:")
    print(f"  ÂøÖÈúÄÂåÖ: {required_success}/{len(required_packages)}")
    print(f"  ÂèØÈÄâÂåÖ: {optional_success}/{len(optional_packages)}")

    # ÂøÖÈúÄÂåÖÂøÖÈ°ªÂÖ®ÈÉ®ÂÆâË£ÖÊàêÂäü
    return required_success == len(required_packages)

def test_lightningdit_imports():
    """ÊµãËØïLightningDiTÁõ∏ÂÖ≥ÁöÑÂØºÂÖ•"""
    print_step(8, "ÊµãËØïLightningDiTÂØºÂÖ•")

    # ÊµãËØïÂÖ≥ÈîÆÂØºÂÖ•
    test_imports = [
        ("safetensors", "from safetensors import safe_open"),
        ("fairscale", "import fairscale"),
        ("einops", "import einops"),
        ("timm", "import timm"),
        ("accelerate", "import accelerate"),
        ("transformers", "import transformers"),
        ("torchdiffeq", "from torchdiffeq import odeint"),
        ("omegaconf", "from omegaconf import OmegaConf"),
        ("diffusers", "import diffusers"),
        ("pytorch_fid", "import pytorch_fid"),
        ("scipy", "import scipy")
    ]

    success_count = 0
    for name, import_statement in test_imports:
        try:
            exec(import_statement)
            print(f"‚úÖ {name}: ÂØºÂÖ•ÊàêÂäü")
            success_count += 1
        except ImportError as e:
            print(f"‚ö†Ô∏è  {name}: ÂØºÂÖ•Â§±Ë¥• - {str(e)}")
        except Exception as e:
            print(f"‚ùå {name}: ÊµãËØïÂ§±Ë¥• - {str(e)}")

    # ÊµãËØïÂèØÈÄâÁöÑÈ´òÊÄßËÉΩÂåÖ
    optional_imports = [
        ("flash_attn", "import flash_attn"),
        ("triton", "import triton"),
        ("xformers", "import xformers")
    ]

    optional_success = 0
    for name, import_statement in optional_imports:
        try:
            exec(import_statement)
            print(f"‚úÖ {name}: ÂØºÂÖ•ÊàêÂäü (ÊÄßËÉΩ‰ºòÂåñ)")
            optional_success += 1
        except ImportError:
            print(f"‚ö†Ô∏è  {name}: Êú™ÂÆâË£Ö (ÂèØÈÄâÊÄßËÉΩ‰ºòÂåñ)")
        except Exception as e:
            print(f"‚ö†Ô∏è  {name}: ÊµãËØïÂ§±Ë¥• - {str(e)}")

    print(f"\nÊ†∏ÂøÉÂØºÂÖ•: {success_count}/{len(test_imports)}")
    print(f"ÊÄßËÉΩ‰ºòÂåñ: {optional_success}/{len(optional_imports)}")

    return success_count >= 4  # Ëá≥Â∞ë4‰∏™Ê†∏ÂøÉÂåÖÂØºÂÖ•ÊàêÂäü

def check_package_versions():
    """Ê£ÄÊü•ÂåÖÁâàÊú¨ÂÖºÂÆπÊÄß"""
    print_step(7, "Ê£ÄÊü•ÂåÖÁâàÊú¨ÂÖºÂÆπÊÄß")

    required_packages = {
        'torch': '2.0.0',
        'pytorch_lightning': '2.0.0',
        'PIL': '9.0.0',  # Pillow
        'numpy': '1.21.0',
        'tqdm': '4.64.0',
        'tensorboard': '2.8.0',
        'safetensors': '0.3.0',
        'accelerate': '0.20.0',
        'transformers': '4.30.0'
    }

    optional_packages = {
        'fairscale': '0.4.13',
        'einops': '0.6.0',
        'timm': '0.9.0',
        'flash_attn': '2.0.0',
        'triton': '2.0.0',
        'xformers': '0.0.20'
    }
    
    compatible_count = 0
    total_count = len(required_packages)

    print("Ê£ÄÊü•ÂøÖÈúÄÂåÖ:")
    for package_name, min_version in required_packages.items():
        try:
            if package_name == 'PIL':
                import PIL
                current_version = PIL.__version__
                package_display = 'Pillow'
            else:
                module = importlib.import_module(package_name)
                current_version = module.__version__
                package_display = package_name

            if version.parse(current_version) >= version.parse(min_version):
                print(f"‚úÖ {package_display}: {current_version} (>= {min_version})")
                compatible_count += 1
            else:
                print(f"‚ùå {package_display}: {current_version} (< {min_version})")
        except ImportError:
            print(f"‚ùå {package_display}: Êú™ÂÆâË£Ö")
        except Exception as e:
            print(f"‚ö†Ô∏è  {package_display}: Ê£ÄÊü•Â§±Ë¥• ({str(e)})")

    print(f"\nÂøÖÈúÄÂåÖÂÖºÂÆπÊÄß: {compatible_count}/{total_count}")

    # Ê£ÄÊü•ÂèØÈÄâÂåÖ
    print("\nÊ£ÄÊü•ÂèØÈÄâÂåÖ (LightningDiT‰ºòÂåñ):")
    optional_count = 0
    for package_name, min_version in optional_packages.items():
        try:
            module = importlib.import_module(package_name)
            current_version = module.__version__

            if version.parse(current_version) >= version.parse(min_version):
                print(f"‚úÖ {package_name}: {current_version} (>= {min_version})")
                optional_count += 1
            else:
                print(f"‚ö†Ô∏è  {package_name}: {current_version} (< {min_version})")
        except ImportError:
            print(f"‚ö†Ô∏è  {package_name}: Êú™ÂÆâË£Ö (ÂèØÈÄâ)")
        except Exception as e:
            print(f"‚ö†Ô∏è  {package_name}: Ê£ÄÊü•Â§±Ë¥• ({str(e)})")

    print(f"ÂèØÈÄâÂåÖÂèØÁî®: {optional_count}/{len(optional_packages)}")

    return compatible_count == total_count

def test_imports():
    """ÊµãËØïÂÖ≥ÈîÆÊ®°ÂùóÂØºÂÖ•"""
    print_step(7, "ÊµãËØïÂÖ≥ÈîÆÊ®°ÂùóÂØºÂÖ•")
    
    test_modules = [
        ('torch', 'PyTorch'),
        ('pytorch_lightning', 'PyTorch Lightning'),
        ('PIL', 'Pillow'),
        ('numpy', 'NumPy'),
        ('tqdm', 'tqdm'),
        ('tensorboard', 'TensorBoard')
    ]
    
    success_count = 0
    for module_name, display_name in test_modules:
        try:
            importlib.import_module(module_name)
            print(f"‚úÖ {display_name}: ÂØºÂÖ•ÊàêÂäü")
            success_count += 1
        except ImportError as e:
            print(f"‚ùå {display_name}: ÂØºÂÖ•Â§±Ë¥• - {str(e)}")
        except Exception as e:
            print(f"‚ö†Ô∏è  {display_name}: ÂØºÂÖ•ÂºÇÂ∏∏ - {str(e)}")
    
    print(f"\nÂØºÂÖ•ÊµãËØï: {success_count}/{len(test_modules)} ‰∏™Ê®°ÂùóÊàêÂäü")
    return success_count == len(test_modules)

def test_pytorch_functionality():
    """ÊµãËØïPyTorchÂäüËÉΩÂíåÂÆåÊï¥ÊÄß"""
    print_step(10, "ÊµãËØïPyTorchÂäüËÉΩÂíåÂÆåÊï¥ÊÄß")

    try:
        import torch
        import torch.nn as nn
        import torch.distributed as dist

        # ÊµãËØïÂÖ≥ÈîÆC++Êâ©Â±ïÊ®°Âùó
        try:
            import torch._C
            print("‚úÖ torch._CÊ®°Âùó: ÂèØÁî®")
        except ImportError:
            print("‚ùå torch._CÊ®°Âùó: Áº∫Â§± - PyTorchÂÆâË£Ö‰∏çÂÆåÊï¥")
            return False

        # ÊµãËØïÂü∫Êú¨Âº†ÈáèÊìç‰Ωú
        x = torch.randn(2, 3)
        y = torch.randn(3, 4)
        z = torch.mm(x, y)
        print(f"‚úÖ Âº†ÈáèËøêÁÆó: {z.shape}")

        # ÊµãËØïÁ•ûÁªèÁΩëÁªú
        model = nn.Linear(10, 1)
        input_tensor = torch.randn(5, 10)
        output = model(input_tensor)
        print(f"‚úÖ Á•ûÁªèÁΩëÁªú: {output.shape}")

        # ÊµãËØïËá™Âä®Ê±ÇÂØº
        x = torch.randn(2, 2, requires_grad=True)
        y = x.sum()
        y.backward()
        print(f"‚úÖ Ëá™Âä®Ê±ÇÂØº: Ê¢ØÂ∫¶ÂΩ¢Áä∂ {x.grad.shape}")

        # ÊµãËØïCUDAÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
        if torch.cuda.is_available():
            device = torch.device('cuda')
            x_cuda = x.to(device)
            print(f"‚úÖ CUDAËøêÁÆó: ËÆæÂ§á {x_cuda.device}")
            print(f"‚úÖ GPUÊï∞Èáè: {torch.cuda.device_count()}")
        else:
            print("‚ö†Ô∏è  CUDA‰∏çÂèØÁî®Ôºå‰ΩøÁî®CPU")

        # ÊµãËØïÂàÜÂ∏ÉÂºèÂäüËÉΩÔºà‰∏çÂàùÂßãÂåñÔºåÂè™Ê£ÄÊü•Ê®°ÂùóÔºâ
        try:
            from torch.nn.parallel import DistributedDataParallel
            print("‚úÖ ÂàÜÂ∏ÉÂºèÊ®°Âùó: ÂèØÁî®")
        except ImportError:
            print("‚ö†Ô∏è  ÂàÜÂ∏ÉÂºèÊ®°Âùó: ‰∏çÂèØÁî®")

        return True
    except Exception as e:
        print(f"‚ùå PyTorchÂäüËÉΩÊµãËØïÂ§±Ë¥•: {str(e)}")
        return False

def test_lightning_functionality():
    """ÊµãËØïPyTorch LightningÂäüËÉΩ"""
    print_step(9, "ÊµãËØïPyTorch LightningÂäüËÉΩ")
    
    try:
        import pytorch_lightning as pl
        import torch
        import torch.nn as nn
        
        # ÂàõÂª∫ÁÆÄÂçïÁöÑLightningÊ®°Âùó
        class TestModule(pl.LightningModule):
            def __init__(self):
                super().__init__()
                self.layer = nn.Linear(10, 1)
            
            def forward(self, x):
                return self.layer(x)
            
            def training_step(self, batch, batch_idx):
                return torch.tensor(0.0)
            
            def configure_optimizers(self):
                return torch.optim.Adam(self.parameters())
        
        model = TestModule()
        print("‚úÖ LightningÊ®°ÂùóÂàõÂª∫ÊàêÂäü")
        
        # ÊµãËØïTrainerÂàõÂª∫
        trainer = pl.Trainer(max_epochs=1, enable_progress_bar=False, logger=False)
        print("‚úÖ Lightning TrainerÂàõÂª∫ÊàêÂäü")
        
        return True
    except Exception as e:
        print(f"‚ùå PyTorch LightningÂäüËÉΩÊµãËØïÂ§±Ë¥•: {str(e)}")
        return False

def create_environment_summary():
    """ÂàõÂª∫ÁéØÂ¢ÉÊÄªÁªìÊä•Âëä"""
    print_step(10, "ÁîüÊàêÁéØÂ¢ÉÊä•Âëä")
    
    report_path = "/kaggle/working/environment_report.txt"
    
    try:
        with open(report_path, 'w') as f:
            f.write("KaggleÁéØÂ¢ÉÈÖçÁΩÆÊä•Âëä\n")
            f.write("="*50 + "\n\n")
            
            # Python‰ø°ÊÅØ
            f.write(f"PythonÁâàÊú¨: {sys.version}\n")
            f.write(f"PythonË∑ØÂæÑ: {sys.executable}\n\n")
            
            # ÂåÖÁâàÊú¨‰ø°ÊÅØ
            f.write("ÂÖ≥ÈîÆÂåÖÁâàÊú¨:\n")
            packages = ['torch', 'pytorch_lightning', 'PIL', 'numpy', 'tqdm']
            for pkg in packages:
                try:
                    if pkg == 'PIL':
                        import PIL
                        version_str = PIL.__version__
                    else:
                        module = importlib.import_module(pkg)
                        version_str = module.__version__
                    f.write(f"  {pkg}: {version_str}\n")
                except:
                    f.write(f"  {pkg}: Êú™ÂÆâË£Ö\n")
            
            # GPU‰ø°ÊÅØ
            f.write("\nGPU‰ø°ÊÅØ:\n")
            try:
                import torch
                if torch.cuda.is_available():
                    f.write(f"  CUDAÂèØÁî®: True\n")
                    f.write(f"  CUDAÁâàÊú¨: {torch.version.cuda}\n")
                    f.write(f"  GPUÊï∞Èáè: {torch.cuda.device_count()}\n")
                    for i in range(torch.cuda.device_count()):
                        f.write(f"  GPU {i}: {torch.cuda.get_device_name(i)}\n")
                else:
                    f.write("  CUDAÂèØÁî®: False\n")
            except:
                f.write("  GPU‰ø°ÊÅØËé∑ÂèñÂ§±Ë¥•\n")
        
        print(f"‚úÖ ÁéØÂ¢ÉÊä•ÂëäÂ∑≤‰øùÂ≠òÂà∞: {report_path}")
        return True
    except Exception as e:
        print(f"‚ùå ÁéØÂ¢ÉÊä•ÂëäÁîüÊàêÂ§±Ë¥•: {str(e)}")
        return False

def main():
    """‰∏ªÂáΩÊï∞"""
    print_header("KaggleÁéØÂ¢ÉÂÆâË£ÖÂíåÊ£ÄÊµãËÑöÊú¨")
    print("‰∏ì‰∏∫ÂæÆÂ§öÊôÆÂãíVA-VAEÈ°πÁõÆËÆæËÆ°")
    
    # ÊâßË°åÊâÄÊúâÊ£ÄÊü•ÂíåÂÆâË£ÖÊ≠•È™§
    steps = [
        check_python_version,
        check_gpu,
        install_pytorch,
        install_pytorch_lightning,
        install_core_packages,
        install_lightningdit_packages,
        check_package_versions,
        test_imports,
        test_lightningdit_imports,
        test_pytorch_functionality,
        test_lightning_functionality,
        create_environment_summary
    ]
    
    success_count = 0
    for step_func in steps:
        try:
            if step_func():
                success_count += 1
        except Exception as e:
            print(f"‚ùå Ê≠•È™§ÊâßË°åÂ§±Ë¥•: {str(e)}")
    
    # ÊúÄÁªàÊÄªÁªì
    print_header("ÂÆâË£ÖÊÄªÁªì")
    print(f"‚úÖ ÊàêÂäüÂÆåÊàê: {success_count}/{len(steps)} ‰∏™Ê≠•È™§")
    
    if success_count == len(steps):
        print("üéâ ÁéØÂ¢ÉÈÖçÁΩÆÂÆåÊàêÔºÅÂèØ‰ª•ÂºÄÂßãËÆ≠ÁªÉÂæÆÂ§öÊôÆÂãíVA-VAEÊ®°Âûã")
        print("\n‰∏ã‰∏ÄÊ≠•:")
        print("1. ËøêË°åÊï∞ÊçÆÂàíÂàÜ: python data_split.py")
        print("2. ÂºÄÂßãËÆ≠ÁªÉ: python minimal_training_modification.py")
    else:
        print("‚ö†Ô∏è  ÈÉ®ÂàÜÊ≠•È™§Â§±Ë¥•ÔºåËØ∑Ê£ÄÊü•ÈîôËØØ‰ø°ÊÅØ")
        print("Âª∫ËÆÆÊâãÂä®ÂÆâË£ÖÂ§±Ë¥•ÁöÑÂåÖÊàñËÅîÁ≥ªÊäÄÊúØÊîØÊåÅ")
    
    print(f"\nËØ¶ÁªÜÊä•ÂëäÂ∑≤‰øùÂ≠òÂà∞: /kaggle/working/environment_report.txt")

if __name__ == "__main__":
    main()
