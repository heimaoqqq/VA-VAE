#!/usr/bin/env python3
"""
Kaggleç¯å¢ƒå®‰è£…å’Œæ£€æµ‹è„šæœ¬
ä¸“é—¨ä¸ºå¾®å¤šæ™®å‹’VA-VAEé¡¹ç›®è®¾è®¡ï¼Œé€‚é…Kaggleç¯å¢ƒ
"""

import subprocess
import sys
import os
import importlib
import pkg_resources
from packaging import version
import warnings
warnings.filterwarnings('ignore')

def print_header(text):
    """æ‰“å°æ ‡é¢˜"""
    print("\n" + "="*60)
    print(f" {text}")
    print("="*60)

def print_step(step, text):
    """æ‰“å°æ­¥éª¤"""
    print(f"\nğŸ”§ Step {step}: {text}")
    print("-" * 40)

def run_command(cmd, description=""):
    """è¿è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯"""
    print(f"æ‰§è¡Œ: {cmd}")
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=300)
        if result.returncode == 0:
            print(f"âœ… æˆåŠŸ: {description}")
            return True, result.stdout
        else:
            print(f"âŒ å¤±è´¥: {description}")
            print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
            return False, result.stderr
    except subprocess.TimeoutExpired:
        print(f"â° è¶…æ—¶: {description}")
        return False, "Command timeout"
    except Exception as e:
        print(f"âŒ å¼‚å¸¸: {str(e)}")
        return False, str(e)

def check_python_version():
    """æ£€æŸ¥Pythonç‰ˆæœ¬"""
    print_step(1, "æ£€æŸ¥Pythonç‰ˆæœ¬")
    python_version = sys.version_info
    print(f"Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    if python_version.major == 3 and python_version.minor >= 8:
        print("âœ… Pythonç‰ˆæœ¬ç¬¦åˆè¦æ±‚ (>=3.8)")
        return True
    else:
        print("âŒ Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦Python 3.8+")
        return False

def check_gpu():
    """æ£€æŸ¥GPUç¯å¢ƒ"""
    print_step(2, "æ£€æŸ¥GPUç¯å¢ƒ")
    
    # æ£€æŸ¥nvidia-smi
    success, output = run_command("nvidia-smi", "æ£€æŸ¥GPU")
    if success:
        print("âœ… GPUå¯ç”¨")
        print("GPUä¿¡æ¯:")
        lines = output.split('\n')
        for line in lines:
            if 'Tesla' in line or 'RTX' in line or 'GTX' in line or 'P100' in line or 'T4' in line:
                print(f"  {line.strip()}")
        return True
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
        return False

def install_pytorch():
    """å®‰è£…PyTorch"""
    print_step(3, "å®‰è£…/æ£€æŸ¥PyTorch")
    
    # æ£€æŸ¥å½“å‰PyTorchç‰ˆæœ¬
    try:
        import torch
        current_version = torch.__version__
        print(f"å½“å‰PyTorchç‰ˆæœ¬: {current_version}")
        
        # æ£€æŸ¥CUDAæ”¯æŒ
        cuda_available = torch.cuda.is_available()
        print(f"CUDAå¯ç”¨: {cuda_available}")
        if cuda_available:
            print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        
        # æ£€æŸ¥ç‰ˆæœ¬æ˜¯å¦æ»¡è¶³è¦æ±‚
        if version.parse(current_version) >= version.parse("2.0.0"):
            print("âœ… PyTorchç‰ˆæœ¬ç¬¦åˆè¦æ±‚")
            return True
        else:
            print("âš ï¸  PyTorchç‰ˆæœ¬è¿‡ä½ï¼Œå°è¯•å‡çº§...")
    except ImportError:
        print("PyTorchæœªå®‰è£…ï¼Œå¼€å§‹å®‰è£…...")
    
    # å®‰è£…PyTorch
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨ï¼ˆé€šè¿‡nvidia-smiï¼‰
    cuda_available, _ = run_command("nvidia-smi", "æ£€æŸ¥CUDA")
    if cuda_available:
        cmd = "pip install torch>=2.0.0 torchvision>=0.15.0 --index-url https://download.pytorch.org/whl/cu118"
    else:
        cmd = "pip install torch>=2.0.0 torchvision>=0.15.0 --index-url https://download.pytorch.org/whl/cpu"
    
    success, _ = run_command(cmd, "å®‰è£…PyTorch")
    return success

def install_pytorch_lightning():
    """å®‰è£…PyTorch Lightning"""
    print_step(4, "å®‰è£…/æ£€æŸ¥PyTorch Lightning")
    
    try:
        import pytorch_lightning as pl
        current_version = pl.__version__
        print(f"å½“å‰PyTorch Lightningç‰ˆæœ¬: {current_version}")
        
        if version.parse(current_version) >= version.parse("2.0.0"):
            print("âœ… PyTorch Lightningç‰ˆæœ¬ç¬¦åˆè¦æ±‚")
            return True
        else:
            print("âš ï¸  PyTorch Lightningç‰ˆæœ¬è¿‡ä½ï¼Œå°è¯•å‡çº§...")
    except ImportError:
        print("PyTorch Lightningæœªå®‰è£…ï¼Œå¼€å§‹å®‰è£…...")
    
    success, _ = run_command("pip install pytorch-lightning>=2.0.0", "å®‰è£…PyTorch Lightning")
    return success

def install_core_packages():
    """å®‰è£…æ ¸å¿ƒä¾èµ–åŒ…"""
    print_step(5, "å®‰è£…æ ¸å¿ƒä¾èµ–åŒ…")
    
    packages = [
        "pillow>=9.0.0",
        "numpy>=1.21.0", 
        "tqdm>=4.64.0",
        "tensorboard>=2.8.0",
        "matplotlib>=3.5.0",
        "scikit-learn>=1.1.0"
    ]
    
    success_count = 0
    for package in packages:
        success, _ = run_command(f"pip install {package}", f"å®‰è£… {package}")
        if success:
            success_count += 1
    
    print(f"âœ… æˆåŠŸå®‰è£… {success_count}/{len(packages)} ä¸ªåŒ…")
    return success_count == len(packages)

def check_package_versions():
    """æ£€æŸ¥åŒ…ç‰ˆæœ¬å…¼å®¹æ€§"""
    print_step(6, "æ£€æŸ¥åŒ…ç‰ˆæœ¬å…¼å®¹æ€§")
    
    required_packages = {
        'torch': '2.0.0',
        'pytorch_lightning': '2.0.0',
        'PIL': '9.0.0',  # Pillow
        'numpy': '1.21.0',
        'tqdm': '4.64.0',
        'tensorboard': '2.8.0'
    }
    
    compatible_count = 0
    total_count = len(required_packages)
    
    for package_name, min_version in required_packages.items():
        try:
            if package_name == 'PIL':
                import PIL
                current_version = PIL.__version__
                package_display = 'Pillow'
            else:
                module = importlib.import_module(package_name)
                current_version = module.__version__
                package_display = package_name
            
            if version.parse(current_version) >= version.parse(min_version):
                print(f"âœ… {package_display}: {current_version} (>= {min_version})")
                compatible_count += 1
            else:
                print(f"âŒ {package_display}: {current_version} (< {min_version})")
        except ImportError:
            print(f"âŒ {package_display}: æœªå®‰è£…")
        except Exception as e:
            print(f"âš ï¸  {package_display}: æ£€æŸ¥å¤±è´¥ ({str(e)})")
    
    print(f"\nå…¼å®¹æ€§æ£€æŸ¥: {compatible_count}/{total_count} ä¸ªåŒ…ç¬¦åˆè¦æ±‚")
    return compatible_count == total_count

def test_imports():
    """æµ‹è¯•å…³é”®æ¨¡å—å¯¼å…¥"""
    print_step(7, "æµ‹è¯•å…³é”®æ¨¡å—å¯¼å…¥")
    
    test_modules = [
        ('torch', 'PyTorch'),
        ('pytorch_lightning', 'PyTorch Lightning'),
        ('PIL', 'Pillow'),
        ('numpy', 'NumPy'),
        ('tqdm', 'tqdm'),
        ('tensorboard', 'TensorBoard')
    ]
    
    success_count = 0
    for module_name, display_name in test_modules:
        try:
            importlib.import_module(module_name)
            print(f"âœ… {display_name}: å¯¼å…¥æˆåŠŸ")
            success_count += 1
        except ImportError as e:
            print(f"âŒ {display_name}: å¯¼å…¥å¤±è´¥ - {str(e)}")
        except Exception as e:
            print(f"âš ï¸  {display_name}: å¯¼å…¥å¼‚å¸¸ - {str(e)}")
    
    print(f"\nå¯¼å…¥æµ‹è¯•: {success_count}/{len(test_modules)} ä¸ªæ¨¡å—æˆåŠŸ")
    return success_count == len(test_modules)

def test_pytorch_functionality():
    """æµ‹è¯•PyTorchåŠŸèƒ½"""
    print_step(8, "æµ‹è¯•PyTorchåŠŸèƒ½")
    
    try:
        import torch
        import torch.nn as nn
        
        # æµ‹è¯•åŸºæœ¬å¼ é‡æ“ä½œ
        x = torch.randn(2, 3)
        y = torch.randn(3, 4)
        z = torch.mm(x, y)
        print(f"âœ… å¼ é‡è¿ç®—: {z.shape}")
        
        # æµ‹è¯•ç¥ç»ç½‘ç»œ
        model = nn.Linear(10, 1)
        input_tensor = torch.randn(5, 10)
        output = model(input_tensor)
        print(f"âœ… ç¥ç»ç½‘ç»œ: {output.shape}")
        
        # æµ‹è¯•CUDAï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available():
            device = torch.device('cuda')
            x_cuda = x.to(device)
            print(f"âœ… CUDAè¿ç®—: è®¾å¤‡ {x_cuda.device}")
        else:
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        
        return True
    except Exception as e:
        print(f"âŒ PyTorchåŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_lightning_functionality():
    """æµ‹è¯•PyTorch LightningåŠŸèƒ½"""
    print_step(9, "æµ‹è¯•PyTorch LightningåŠŸèƒ½")
    
    try:
        import pytorch_lightning as pl
        import torch
        import torch.nn as nn
        
        # åˆ›å»ºç®€å•çš„Lightningæ¨¡å—
        class TestModule(pl.LightningModule):
            def __init__(self):
                super().__init__()
                self.layer = nn.Linear(10, 1)
            
            def forward(self, x):
                return self.layer(x)
            
            def training_step(self, batch, batch_idx):
                return torch.tensor(0.0)
            
            def configure_optimizers(self):
                return torch.optim.Adam(self.parameters())
        
        model = TestModule()
        print("âœ… Lightningæ¨¡å—åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•Traineråˆ›å»º
        trainer = pl.Trainer(max_epochs=1, enable_progress_bar=False, logger=False)
        print("âœ… Lightning Traineråˆ›å»ºæˆåŠŸ")
        
        return True
    except Exception as e:
        print(f"âŒ PyTorch LightningåŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def create_environment_summary():
    """åˆ›å»ºç¯å¢ƒæ€»ç»“æŠ¥å‘Š"""
    print_step(10, "ç”Ÿæˆç¯å¢ƒæŠ¥å‘Š")
    
    report_path = "/kaggle/working/environment_report.txt"
    
    try:
        with open(report_path, 'w') as f:
            f.write("Kaggleç¯å¢ƒé…ç½®æŠ¥å‘Š\n")
            f.write("="*50 + "\n\n")
            
            # Pythonä¿¡æ¯
            f.write(f"Pythonç‰ˆæœ¬: {sys.version}\n")
            f.write(f"Pythonè·¯å¾„: {sys.executable}\n\n")
            
            # åŒ…ç‰ˆæœ¬ä¿¡æ¯
            f.write("å…³é”®åŒ…ç‰ˆæœ¬:\n")
            packages = ['torch', 'pytorch_lightning', 'PIL', 'numpy', 'tqdm']
            for pkg in packages:
                try:
                    if pkg == 'PIL':
                        import PIL
                        version_str = PIL.__version__
                    else:
                        module = importlib.import_module(pkg)
                        version_str = module.__version__
                    f.write(f"  {pkg}: {version_str}\n")
                except:
                    f.write(f"  {pkg}: æœªå®‰è£…\n")
            
            # GPUä¿¡æ¯
            f.write("\nGPUä¿¡æ¯:\n")
            try:
                import torch
                if torch.cuda.is_available():
                    f.write(f"  CUDAå¯ç”¨: True\n")
                    f.write(f"  CUDAç‰ˆæœ¬: {torch.version.cuda}\n")
                    f.write(f"  GPUæ•°é‡: {torch.cuda.device_count()}\n")
                    for i in range(torch.cuda.device_count()):
                        f.write(f"  GPU {i}: {torch.cuda.get_device_name(i)}\n")
                else:
                    f.write("  CUDAå¯ç”¨: False\n")
            except:
                f.write("  GPUä¿¡æ¯è·å–å¤±è´¥\n")
        
        print(f"âœ… ç¯å¢ƒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        return True
    except Exception as e:
        print(f"âŒ ç¯å¢ƒæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print_header("Kaggleç¯å¢ƒå®‰è£…å’Œæ£€æµ‹è„šæœ¬")
    print("ä¸“ä¸ºå¾®å¤šæ™®å‹’VA-VAEé¡¹ç›®è®¾è®¡")
    
    # æ‰§è¡Œæ‰€æœ‰æ£€æŸ¥å’Œå®‰è£…æ­¥éª¤
    steps = [
        check_python_version,
        check_gpu,
        install_pytorch,
        install_pytorch_lightning,
        install_core_packages,
        check_package_versions,
        test_imports,
        test_pytorch_functionality,
        test_lightning_functionality,
        create_environment_summary
    ]
    
    success_count = 0
    for step_func in steps:
        try:
            if step_func():
                success_count += 1
        except Exception as e:
            print(f"âŒ æ­¥éª¤æ‰§è¡Œå¤±è´¥: {str(e)}")
    
    # æœ€ç»ˆæ€»ç»“
    print_header("å®‰è£…æ€»ç»“")
    print(f"âœ… æˆåŠŸå®Œæˆ: {success_count}/{len(steps)} ä¸ªæ­¥éª¤")
    
    if success_count == len(steps):
        print("ğŸ‰ ç¯å¢ƒé…ç½®å®Œæˆï¼å¯ä»¥å¼€å§‹è®­ç»ƒå¾®å¤šæ™®å‹’VA-VAEæ¨¡å‹")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œæ•°æ®åˆ’åˆ†: python data_split.py")
        print("2. å¼€å§‹è®­ç»ƒ: python minimal_training_modification.py")
    else:
        print("âš ï¸  éƒ¨åˆ†æ­¥éª¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        print("å»ºè®®æ‰‹åŠ¨å®‰è£…å¤±è´¥çš„åŒ…æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ")
    
    print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: /kaggle/working/environment_report.txt")

if __name__ == "__main__":
    main()
