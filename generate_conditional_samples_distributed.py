"""
åˆ†å¸ƒå¼æ¡ä»¶æ‰©æ•£æ ·æœ¬ç”Ÿæˆè„šæœ¬ (torchrunç‰ˆæœ¬)
ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆ200å¼ æ¡ä»¶æ ·æœ¬ï¼Œç”¨äºè¯„ä¼°ç”¨æˆ·åŒºåˆ†åº¦
"""
import torch
import torch.distributed as dist
import sys
import os
import yaml
import numpy as np
from PIL import Image
from tqdm import tqdm
import argparse
from pathlib import Path

# æ·»åŠ LightningDiTè·¯å¾„
sys.path.append('LightningDiT')
from models.lightningdit import LightningDiT_models
from transport import create_transport, Sampler
from simplified_vavae import SimplifiedVAVAE

def setup_distributed():
    """åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ"""
    if 'RANK' in os.environ:
        rank = int(os.environ['RANK'])
        local_rank = int(os.environ['LOCAL_RANK'])
        world_size = int(os.environ['WORLD_SIZE'])
        
        torch.cuda.set_device(local_rank)
        dist.init_process_group(backend='nccl')
        
        return rank, local_rank, world_size
    else:
        return 0, 0, 1

def load_model_and_config(checkpoint_path, config_path, local_rank):
    """åŠ è½½æ¨¡å‹å’Œé…ç½®"""
    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.load(f, Loader=yaml.FullLoader)
    
    # åˆ›å»ºæ¨¡å‹
    device = torch.device(f'cuda:{local_rank}')
    
    # åˆ›å»ºDiTæ¨¡å‹
    latent_size = config['data']['image_size'] // config['vae']['downsample_ratio']
    model = LightningDiT_models[config['model']['model_type']](
        input_size=latent_size,
        num_classes=config['data']['num_classes'],
        class_dropout_prob=config['model']['class_dropout_prob'],
        use_qknorm=config['model']['use_qknorm'],
        use_swiglu=config['model'].get('use_swiglu', False),
        use_rope=config['model'].get('use_rope', False),
        use_rmsnorm=config['model'].get('use_rmsnorm', False),
        wo_shift=config['model'].get('wo_shift', False),
        in_channels=config['model']['in_chans'],
        use_checkpoint=config['model'].get('use_checkpoint', False),
    ).to(device)
    
    # åŠ è½½checkpoint
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # å¤„ç†EMAæƒé‡
    if 'ema' in checkpoint:
        state_dict = checkpoint['ema']
        print("ğŸ“¦ ä½¿ç”¨EMAæƒé‡")
    else:
        state_dict = checkpoint.get('model', checkpoint)
        print("ğŸ“¦ ä½¿ç”¨æ ‡å‡†æƒé‡")
    
    # æ¸…ç†é”®å
    cleaned_state_dict = {}
    for k, v in state_dict.items():
        clean_key = k.replace('module.', '').replace('_orig_mod.', '')
        cleaned_state_dict[clean_key] = v
    
    model.load_state_dict(cleaned_state_dict, strict=False)
    model.eval()
    
    # åˆ›å»ºVAE
    vae = SimplifiedVAVAE(config['vae']['model_name']).to(device)
    vae.eval()
    
    # åˆ›å»ºtransport
    transport = create_transport(
        config['transport']['path_type'],
        config['transport']['prediction'],
        config['transport']['loss_weight'],
        config['transport']['train_eps'],
        config['transport']['sample_eps'],
        use_cosine_loss=config['transport'].get('use_cosine_loss', False),
        use_lognorm=config['transport'].get('use_lognorm', False),
        partitial_train=config['transport'].get('partitial_train', None),
        partial_ratio=config['transport'].get('partial_ratio', 1.0),
        shift_lg=config['transport'].get('shift_lg', False),
    )
    
    return model, vae, transport, config, device

def generate_samples_for_user_distributed(model, vae, transport, sampler, user_id, num_samples, 
                                        output_dir, cfg_scale=10.0, seed=42, batch_size=16, 
                                        rank=0, world_size=1):
    """åˆ†å¸ƒå¼ç”ŸæˆæŒ‡å®šç”¨æˆ·çš„æ¡ä»¶æ ·æœ¬"""
    # åˆ›å»ºé‡‡æ ·å‡½æ•°ï¼ˆä¸å®˜æ–¹train_dit_s_official.pyä¿æŒä¸€è‡´ï¼‰
    sample_fn = sampler.sample_ode(
        sampling_method="dopri5",  # é«˜ç²¾åº¦ODEæ±‚è§£å™¨
        num_steps=300,             # ä½¿ç”¨300æ­¥ä»¥è·å¾—é«˜è´¨é‡
        atol=1e-6,                 # æ›´ä¸¥æ ¼çš„è¯¯å·®å®¹é™
        rtol=1e-3,                 
        reverse=False,
        timestep_shift=0.1,        # ä¸å®˜æ–¹é…ç½®ä¸€è‡´
    )
    
    # è®¡ç®—æ¯ä¸ªè¿›ç¨‹å¤„ç†çš„æ ·æœ¬æ•°
    samples_per_rank = num_samples // world_size
    start_idx = rank * samples_per_rank
    end_idx = start_idx + samples_per_rank
    if rank == world_size - 1:  # æœ€åä¸€ä¸ªè¿›ç¨‹å¤„ç†å‰©ä½™æ ·æœ¬
        end_idx = num_samples
    
    actual_samples = end_idx - start_idx
    
    torch.manual_seed(seed + user_id + rank * 1000)
    np.random.seed(seed + user_id + rank * 1000)
    
    device = next(model.parameters()).device
    user_dir = Path(output_dir) / f"user_{user_id:02d}"
    user_dir.mkdir(parents=True, exist_ok=True)
    
    if rank == 0:
        print(f"ğŸ¨ ç”Ÿæˆç”¨æˆ· {user_id} çš„æ ·æœ¬ (æ€»è®¡{num_samples}å¼ , {world_size}å¡å¹¶è¡Œ)...")
    
    with torch.no_grad():
        num_batches = (actual_samples + batch_size - 1) // batch_size
        sample_idx = start_idx
        
        for batch_idx in tqdm(range(num_batches), desc=f"Rank{rank}-User{user_id}", 
                             disable=(rank != 0)):
            # è®¡ç®—å½“å‰batchå¤§å°
            current_batch_size = min(batch_size, end_idx - sample_idx)
            if current_batch_size <= 0:
                break
            
            # å‡†å¤‡æ¡ä»¶
            y = torch.tensor([user_id] * current_batch_size, device=device)
            
            # åˆ›å»ºéšæœºå™ªå£°
            z = torch.randn(current_batch_size, 32, 16, 16, device=device)
            
            # CFGé‡‡æ ·
            if cfg_scale > 1.0:
                # æ„å»ºCFG batch
                z_cfg = torch.cat([z, z], 0)
                y_null = torch.tensor([31] * current_batch_size, device=device)
                y_cfg = torch.cat([y, y_null], 0)
                
                # æ‰‹åŠ¨å®ç°CFGï¼ˆä¸å®˜æ–¹train_dit_s_official.pyä¸€è‡´ï¼‰
                def model_fn(x, t):
                    # ä½¿ç”¨æ¨¡å‹çš„forward_with_cfgæ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if hasattr(model, 'forward_with_cfg'):
                        return model.forward_with_cfg(x, t, y=y_cfg, cfg_scale=cfg_scale)
                    else:
                        # æ‰‹åŠ¨å®ç°CFG
                        pred = model(x, t, y=y_cfg)
                        pred_cond, pred_uncond = pred.chunk(2, dim=0)
                        return pred_uncond + cfg_scale * (pred_cond - pred_uncond)
                
                samples = sample_fn(z_cfg, model_fn)
                samples = samples[-1]
                samples, _ = samples.chunk(2, dim=0)
            else:
                def model_fn(x, t):
                    return model(x, t, y=y)
                
                samples = sample_fn(z, model_fn)
                samples = samples[-1]
            
            # æ£€æŸ¥latentèŒƒå›´ (ä»…rank 0è¾“å‡º)
            if rank == 0 and batch_idx == 0:
                print(f"ğŸ” ç”Ÿæˆçš„LatentèŒƒå›´: [{samples.min():.3f}, {samples.max():.3f}], æ ‡å‡†å·®: {samples.std():.3f}")
            
            # ğŸ”´ å…³é”®æ­¥éª¤ï¼šåå½’ä¸€åŒ–ï¼
            # å› ä¸ºè®­ç»ƒé…ç½®ä¸­ latent_norm: true
            # è®­ç»ƒæ—¶åšäº†: feature = (feature - mean) / std * 1.0
            # æ‰€ä»¥æ¨ç†æ—¶éœ€è¦: samples = samples * std + mean
            # è°ƒæ•´ä¸ºç”¨æˆ·å®é™…çš„latentç›®å½•è·¯å¾„
            latent_stats_path = './latents_safetensors/train/latent_stats.pt'
            if os.path.exists(latent_stats_path):
                stats = torch.load(latent_stats_path, map_location=device)
                mean = stats['mean'].to(device)  # [32, 1, 1]
                std = stats['std'].to(device)     # [32, 1, 1]
                
                # åå½’ä¸€åŒ–å…¬å¼ï¼ˆå› ä¸ºlatent_multiplier=1.0ï¼‰
                samples_denorm = samples * std + mean
                
                if rank == 0 and batch_idx == 0:
                    print(f"ğŸ” åå½’ä¸€åŒ–åèŒƒå›´: [{samples_denorm.min():.3f}, {samples_denorm.max():.3f}], æ ‡å‡†å·®: {samples_denorm.std():.3f}")
                    print(f"ğŸ“Š ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯: mean shape={mean.shape}, std shape={std.shape}")
            else:
                if rank == 0:
                    print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°latentç»Ÿè®¡æ–‡ä»¶ {latent_stats_path}")
                    print(f"âš ï¸ è·³è¿‡åå½’ä¸€åŒ–æ­¥éª¤ï¼Œå¯èƒ½å¯¼è‡´ç”Ÿæˆå™ªå£°ï¼")
                    print(f"ğŸ’¡ å°è¯•ä»æ•°æ®é›†ç›´æ¥è®¡ç®—ç»Ÿè®¡ä¿¡æ¯...")
                    # å¦‚æœç»Ÿè®¡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»æ•°æ®é›†ç›´æ¥è®¡ç®—
                    try:
                        from LightningDiT.datasets.img_latent_dataset import ImgLatentDataset
                        train_dataset = ImgLatentDataset('./latents_safetensors/train', latent_norm=True)
                        stats = train_dataset.compute_latent_stats()
                        mean = stats['mean'].to(device)  # [1, 32, 1, 1]
                        std = stats['std'].to(device)    # [1, 32, 1, 1]
                        # å»æ‰batchç»´åº¦
                        mean = mean.squeeze(0)  # [32, 1, 1]
                        std = std.squeeze(0)    # [32, 1, 1]
                        
                        # ä¿å­˜ç»Ÿè®¡æ–‡ä»¶ä¾›ä¸‹æ¬¡ä½¿ç”¨
                        os.makedirs('./latents_safetensors/train', exist_ok=True)
                        torch.save({'mean': mean, 'std': std}, './latents_safetensors/train/latent_stats.pt')
                        print(f"âœ… ä»æ•°æ®é›†è®¡ç®—ç»Ÿè®¡å®Œæˆï¼Œå·²ä¿å­˜åˆ° ./latents_safetensors/train/latent_stats.pt")
                        
                        # åå½’ä¸€åŒ–
                        samples_denorm = samples * std + mean
                        
                        if rank == 0 and batch_idx == 0:
                            print(f"ğŸ” åå½’ä¸€åŒ–åèŒƒå›´: [{samples_denorm.min():.3f}, {samples_denorm.max():.3f}], æ ‡å‡†å·®: {samples_denorm.std():.3f}")
                            print(f"ğŸ“Š ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯: mean shape={mean.shape}, std shape={std.shape}")
                    except Exception as e:
                        if rank == 0:
                            print(f"âŒ æ— æ³•è®¡ç®—ç»Ÿè®¡ä¿¡æ¯: {e}")
                            print(f"ğŸ’¡ è¯·å…ˆè¿è¡Œ: python prepare_latent_stats.py --data_dir ./latents_safetensors/train")
                        samples_denorm = samples
                else:
                    samples_denorm = samples
            
            # VAEè§£ç ï¼ˆä½¿ç”¨åå½’ä¸€åŒ–åçš„latentï¼‰
            images = vae.decode(samples_denorm)
            
            # æ£€æŸ¥è§£ç åèŒƒå›´ (ä»…rank 0è¾“å‡º)
            if rank == 0 and batch_idx == 0:
                print(f"ğŸ” è§£ç åå›¾åƒèŒƒå›´: [{images.min():.3f}, {images.max():.3f}], æ ‡å‡†å·®: {images.std():.3f}")
            
            # åå¤„ç†ï¼š[0,1] -> [0,255]
            images = torch.clamp(images, 0, 1)
            images = (images * 255).round().byte()
            
            # ä¿å­˜æ¯ä¸ªå›¾åƒ
            for i in range(current_batch_size):
                image = images[i].permute(1, 2, 0).cpu().numpy()
                if image.shape[2] == 1:  # ç°åº¦å›¾
                    image = image.squeeze(2)
                    pil_image = Image.fromarray(image, mode='L')
                elif image.shape[2] == 3:  # RGBå›¾
                    pil_image = Image.fromarray(image, mode='RGB')
                else:
                    if rank == 0:
                        print(f"âš ï¸ æœªçŸ¥å›¾åƒæ ¼å¼: {image.shape}")
                    continue
                
                filename = user_dir / f"sample_{sample_idx:03d}.png"
                pil_image.save(filename)
                sample_idx += 1
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    if world_size > 1:
        dist.barrier()
    
    if rank == 0:
        print(f"âœ… å®Œæˆç”¨æˆ· {user_id}: {num_samples} ä¸ªæ ·æœ¬å·²ä¿å­˜åˆ° {user_dir}")

def main():
    parser = argparse.ArgumentParser(description='åˆ†å¸ƒå¼ç”Ÿæˆæ¡ä»¶æ‰©æ•£æ ·æœ¬')
    parser.add_argument('--checkpoint', required=True, help='æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--config', required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_dir', default='./generated_samples', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--samples_per_user', type=int, default=200, help='æ¯ç”¨æˆ·ç”Ÿæˆæ ·æœ¬æ•°')
    parser.add_argument('--cfg_scale', type=float, default=10.0, help='CFGå¼•å¯¼å¼ºåº¦')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--num_users', type=int, default=31, help='ç”¨æˆ·æ•°é‡')
    parser.add_argument('--batch_size', type=int, default=16, help='æ‰¹å¤„ç†å¤§å°')
    
    args = parser.parse_args()
    
    # è®¾ç½®åˆ†å¸ƒå¼
    rank, local_rank, world_size = setup_distributed()
    
    if rank == 0:
        print(f"ğŸš€ åˆ†å¸ƒå¼æ¨ç†: {world_size} GPUs")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # åŠ è½½æ¨¡å‹
    model, vae, transport, config, device = load_model_and_config(
        args.checkpoint, args.config, local_rank
    )
    
    # åˆ›å»ºé‡‡æ ·å™¨
    sampler = Sampler(transport)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    if rank == 0:
        output_dir = Path(args.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    if world_size > 1:
        dist.barrier()  # ç­‰å¾…ç›®å½•åˆ›å»ºå®Œæˆ
    
    # ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆæ ·æœ¬
    for user_id in range(args.num_users):
        generate_samples_for_user_distributed(
            model, vae, transport, sampler, 
            user_id, args.samples_per_user, args.output_dir,
            cfg_scale=args.cfg_scale, seed=args.seed, batch_size=args.batch_size,
            rank=rank, world_size=world_size
        )
    
    if rank == 0:
        print(f"\nğŸ‰ åˆ†å¸ƒå¼ç”Ÿæˆå®Œæˆ!")
        print(f"æ€»æ ·æœ¬æ•°: {args.num_users * args.samples_per_user}")
        print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    
    # æ¸…ç†åˆ†å¸ƒå¼
    if world_size > 1:
        dist.destroy_process_group()

if __name__ == "__main__":
    main()
